{"pages":[{"title":"关于我","text":"# 程序员的 35，35 的程序员# 。 微信公众号 站点 独立站点：https://cxy35.com CSDN：https://blog.csdn.net/cxy35 OSCHINA：https://my.oschina.net/cxy35 Gitee：https://gitee.com/cxy35 GitHub：https://github.com/cxy35","link":"/website-hexo-icarus/about/index.html"},{"title":"Elastic 教程合集","text":"Elastic 教程合集持续更新中，敬请期待。 Elasticsearch 常用命令 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/elastic/index.html"},{"title":"Spring Boot 实战项目（人力资源管理系统）教程合集","text":"Spring Boot 实战项目（人力资源管理系统）教程合集持续更新中，敬请期待。 Spring Boot 实战项目（人力资源管理系统）教程合集 Spring Boot 实战项目（人力资源管理系统）源码 Spring Boot 教程合集 Spring Boot 教程合集示例代码 喜大普奔，Spring Boot 实战项目（人力资源管理系统），开源了 如何在人力资源管理系统中提高 RabbitMQ 消息发送的可靠性 如何在人力资源管理系统中提高 RabbitMQ 消息消费的可靠性 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/hr/index.html"},{"title":"Linux 教程合集","text":"Linux 教程合集持续更新中，敬请期待。 Linux 常用命令 - 目录、文件等 Linux 常用命令 - 文件内容编辑 Linux 常用命令 - 打包、压缩、解压缩 Linux 常用命令 - 重启、关机 Linux 常用命令 - 文件传输 Linux 磁盘分区、格式化、挂载 Linux 下查看某个端口被哪个进程或程序占用 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/linux/index.html"},{"title":"MySQL 教程合集","text":"MySQL 教程合集持续更新中，敬请期待。 MySQL 安装 - Linux MySQL 安装 - Windows MySQL 常用函数 MySQL 存储过程 MySQL 事件 MySQL 索引 MySQL 分区表 MySQL 用户与权限 MySQL 主从部署 MySQL 参数配置优化 MySQL 备份与恢复 MySQL 备份与恢复 - mydumper MySQL 备份与恢复 - xtrabackup MySQL 定时备份 MySQL binlog 详解 MySQL 常见问题 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/mysql/index.html"},{"title":"Nginx 教程合集","text":"Nginx 教程合集持续更新中，敬请期待。 Nginx 安装 - Linux Nginx 安装 - Windows Nginx 添加到 Windows 系统服务 Nginx 实现 Tomcat 集群 Nginx 参数配置优化 Nginx 负载均衡 - fair Nginx 配置 SSL 支持 HTTPS（自签证书） Nginx 常见问题 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/nginx/index.html"},{"title":"Redis 教程合集","text":"Redis 教程合集持续更新中，敬请期待。 Redis 安装 Redis 基本数据类型（字符串、列表、集合、散列、有序集合） Redis 常用命令 Redis 中的 Java 客户端（Jedis / Lettuce） Redis 实现分布式锁 Redis 实现消息队列 Redis 实现 UV 统计 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/redis/index.html"},{"title":"其他教程合集","text":"其他教程合集持续更新中，敬请期待。 Tomcat 集群 Apache 实现 Tomcat 集群 - mod_jk（老版本） Apache 实现 Tomcat 集群 - mod_proxy（新版本） Tomcat 访问日志分析工具 - AWStats Tomcat 管理和监控工具 - PSI Probe Mycat 概述 POI 操作手册 MyBatis 主键回填 不要再自己写 Java 工具类了，这些开源的不香吗？ JVM 内存分析工具 - MAT 分布式任务调度与计算中心 PowerJob 通过 canal 将 MySQL 数据实时同步到 Elasticsearch 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/other/index.html"},{"title":"Spring Cloud 教程合集","text":"Spring Cloud 教程合集持续更新中，敬请期待。 Spring Cloud 教程合集 Spring Cloud 教程合集示例代码 相关文章 示例代码 Spring Cloud 概述 spring-cloud-overview Spring Cloud Netflix Eureka 概述 spring-cloud-netflix-eureka Spring Cloud Netflix Eureka Server 搭建服务注册中心 spring-cloud-netflix-eureka Spring Cloud Netflix Eureka Client 服务注册与发现 spring-cloud-netflix-eureka Spring Cloud Consul 服务注册与发现 spring-cloud-consul Spring Cloud Netflix Hystrix 断路器 spring-cloud-netflix-hystrix Spring Cloud Resilience4j 断路器 spring-cloud-resilience4j Spring Cloud Netflix Zuul 服务网关 spring-cloud-netflix-zuul Spring Cloud Gateway 服务网关 spring-cloud-gateway Spring Cloud Config 分布式配置中心 spring-cloud-config Spring Cloud Bus 消息总线 spring-cloud-bus Spring Cloud Stream 构建消息驱动的微服务 spring-cloud-stream Spring Cloud Sleuth 链路追踪 spring-cloud-sleuth Spring Cloud Alibaba Nacos 服务配置中心和注册中心 spring-cloud-alibaba-nacos Spring Cloud Alibaba Sentinel 断路器 spring-cloud-alibaba-sentinel Spring Cloud 中 RestTemplate 的使用说明 spring-cloud-resttemplate Spring Cloud OpenFeign 声明式服务调用 spring-cloud-openfeign 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/springcloud/index.html"},{"title":"常用工具使用教程合集","text":"常用工具使用教程合集持续更新中，敬请期待。 IntelliJ IDEA 常用快捷键 IntelliJ IDEA 常用配置 IntelliJ IDEA 常用插件 IntelliJ IDEA 插件 EasyCode（代码自动生成） Sublime Text 常用快捷键 Sublime Text 常用插件 Maven 常用命令 Maven 实战 Git 安装 Git 常用命令 Git 配置 SSH keys SVN 目录使用规范 Eclipse 常用插件在线安装地址 Eclipse 问题汇总 Markdown 语法 Hexo 搭建个人博客网站 Hexo 主题配置 - NexT Hexo 主题配置 - Icarus 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/tool/index.html"},{"title":"Spring Boot 教程合集","text":"Spring Boot 教程合集持续更新中，链接会逐步加上，敬请期待。 Spring Boot 教程合集 Spring Boot 教程合集示例代码 Spring Boot 实战项目（人力资源管理系统）教程合集 Spring Boot 实战项目（人力资源管理系统）源码 相关文章 示例代码 Spring Boot 项目创建 spring-boot-helloworld Spring Boot 配置 properties spring-boot-properties Spring Boot 配置 yaml spring-boot-yaml Spring Boot 单元测试 spring-boot-test Spring Boot 自定义 Starter spring-boot-starter Spring Boot 配置 Tomcat spring-boot-tomcat Spring Boot 配置 profile spring-boot-profile Spring Boot 整合 DevTools（实现热部署） spring-boot-devtools Spring Boot 整合 Web 开发 spring-boot-web Spring Boot 整合 Thymeleaf spring-boot-web/spring-boot-thymeleaf Spring Boot 整合 Freemarker spring-boot-web/spring-boot-freemarker Spring Boot 整合 JSP spring-boot-web/spring-boot-jsp Spring Boot 整合 JSON（Jackson / Gson / FastJson） spring-boot-web/spring-boot-json Spring Boot 配置静态资源 spring-boot-web/spring-boot-staticresources Spring Boot 文件上传 spring-boot-web/spring-boot-fileupload Spring Boot 使用 @ControllerAdvice spring-boot-web/spring-boot-controlleradvice Spring Boot 自定义异常处理 spring-boot-web/spring-boot-exception Spring Boot 通过 CORS 解决跨域问题 spring-boot-web/spring-boot-cors Spring Boot 使用 XML 配置文件 spring-boot-web/spring-boot-xml Spring Boot 配置拦截器 Interceptor spring-boot-web/spring-boot-interceptor Spring Boot 配置 Servlet/Filter/Listener spring-boot-web/spring-boot-servlet Spring Boot 配置系统启动任务 spring-boot-web/spring-boot-runner Spring Boot 配置 ViewController spring-boot-web/spring-boot-viewcontroller Spring Boot 配置 Converter spring-boot-web/spring-boot-paramconverter Spring Boot 配置 AOP spring-boot-web/spring-boot-aop Spring Boot 配置欢迎页和 Favicon spring-boot-web/spring-boot-welcome Spring Boot 整合持久层框架（JdbcTemplate / MyBatis / TkMybatis / Jpa） spring-boot-dao Spring Boot 整合 JdbcTemplate spring-boot-dao/spring-boot-jdbctemplate Spring Boot 整合 JdbcTemplate 多数据源 spring-boot-dao/spring-boot-jdbctemplatemulti Spring Boot 整合 MyBatis spring-boot-dao/spring-boot-mybatis Spring Boot 整合 MyBatis 多数据源 spring-boot-dao/spring-boot-mybatismulti Spring Boot 整合 MyBatis 通用 Mapper（TkMybatis） spring-boot-dao/spring-boot-mybatis-tkmybatis Spring Boot 整合 Jpa spring-boot-dao/spring-boot-jpa Spring Boot 整合 Jpa 多数据源 spring-boot-dao/spring-boot-jpamulti Spring Boot 整合 NoSQL（Redis / MongoDB / Elasticsearch） spring-boot-nosql Spring Boot 整合 Redis spring-boot-nosql/spring-boot-redis Spring Boot 整合 Redis + Spring Session（实现 Session 共享） spring-boot-nosql/spring-boot-redis-springsession Spring Boot 整合 MongoDB spring-boot-nosql/spring-boot-mongodb Spring Boot 整合 Elasticsearch spring-boot-nosql/spring-boot-elasticsearch Spring Boot 配置定时任务（@Scheduled / Quartz） spring-boot-task Spring Boot 配置定时任务（@Scheduled） spring-boot-task/spring-boot-scheduled Spring Boot 配置定时任务（Quartz） spring-boot-task/spring-boot-quartz Spring Boot 整合 Swagger2 spring-boot-swagger2 Spring Boot 构建 Rest 服务（Jpa / MongoDB） spring-boot-rest Spring Boot 构建 Rest 服务（Jpa） spring-boot-rest/spring-boot-jparest Spring Boot 构建 Rest 服务（MongoDB） spring-boot-rest/spring-boot-mongodbrest Spring Boot 整合缓存框架（Spring Cache + Redis / Ehcache） spring-boot-cache Spring Boot 整合 Spring Cache + Redis（实现数据缓存） spring-boot-cache/spring-boot-springcache-redis Spring Boot 整合 Spring Cache + Ehcache（实现数据缓存） spring-boot-cache/spring-boot-springcache-ehcache Spring Boot 整合安全管理框架（Shiro / Spring Security / OAuth2） spring-boot-security Spring Boot 整合 Shiro（原生） spring-boot-security/spring-boot-shirojava Spring Boot 整合 Shiro（Shiro Starter） spring-boot-security/spring-boot-shirostarter Spring Boot 整合 Spring Security（初次体验） spring-boot-security/spring-boot-springsecurity-helloworld Spring Boot 整合 Spring Security（配置用户 / 角色 - 基于内存） spring-boot-security/spring-boot-springsecurity-user Spring Boot 整合 Spring Security（配置用户 / 角色 - 基于数据库） spring-boot-security/spring-boot-springsecurity-userdb Spring Boot 整合 Spring Security（配置用户 / 角色 / 权限） spring-boot-security/spring-boot-springsecurity-urp Spring Boot 整合 Spring Security（配置方法安全） spring-boot-security/spring-boot-springsecurity-methodsecurity Spring Boot 整合 Spring Security（配置 HttpSecurity） spring-boot-security/spring-boot-springsecurity-httpsecurity Spring Boot 整合 Spring Security（配置多个 HttpSecurity） spring-boot-security/spring-boot-springsecurity-httpsecuritymulti Spring Boot 整合 Spring Security（配置验证码） spring-boot-security/spring-boot-springsecurity-verifycode Spring Boot 整合 Spring Security（配置登录 / 登出） spring-boot-security/spring-boot-springsecurity-login Spring Boot 整合 Spring Security（使用 JSON 格式数据登录） spring-boot-security/spring-boot-springsecurity-loginbyjson Spring Boot 整合 Spring Security + JWT（实现无状态登录） spring-boot-security/spring-boot-springsecurity-jwt Spring Boot 整合 Spring Security + OAuth2 spring-boot-security/spring-boot-springsecurity-oauth2 Spring Boot 整合邮件发送 spring-boot-mail Spring Boot 整合消息服务（WebSocket / ActiveMQ / RabbitMQ） spring-boot-message Spring Boot 整合 WebSocket（实现在线群聊） spring-boot-message/spring-boot-websocket-groupchat Spring Boot 整合 WebSocket（实现在线私聊） spring-boot-message/spring-boot-websocket-privatechat Spring Boot 整合 ActiveMQ spring-boot-message/spring-boot-activemq Spring Boot 整合 RabbitMQ spring-boot-message/spring-boot-rabbitmq Spring Boot 整合监控服务（Admin） spring-boot-monitor Spring Boot Admin Server spring-boot-monitor/spring-boot-admin-server Spring Boot Admin Client spring-boot-monitor/spring-boot-admin-client Spring Boot 打 War 包 spring-boot-war 瞬间几千次的重复提交，我用 Spring Boot + Redis 扛住了 spring-boot-redis-idempotent 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/springboot/index.html"}],"posts":[{"title":"如何在人力资源管理系统中提高 RabbitMQ 消息消费的可靠性","text":"学习如何在人力资源管理系统中提高 RabbitMQ 消息消费的可靠性，避免消息被重复消费。 1 概述 在 如何在人力资源管理系统中提高 RabbitMQ 消息发送的可靠性 一文中，我们确保了消息发送的可靠性。但是，在这样的机制下，又带来了新的问题，就是消息可能会重复投递，进而导致消息重复消费。例如一个员工入职了，结果收到了两封入职欢迎邮件。我们需要通过技术手段去处理这个问题。比如增加 消息消费确认机制，可以有效的提高消息消费的可靠性。 说到这个话题，我们就不得不先来说说消息幂等性。 2 幂等性 幂等性本身是数学上的概念，即使公式：f(x)=f(f(x)) 能够成立的数学性质。在开发领域，则表示对于同一个系统，使用相同的条件，一次请求和多次请求对系统资源的影响是一致的。 在分布式系统中幂等性尤为重要，因为分布式系统中，我们经常会用到接口调用失败进而进行重试这个功能，这样就带来了对一个接口可能会使用相同的条件进行重复调用，在这样的条件下，保证接口的幂等性就尤为重要了。常见的解决方案有： MVCC 机制： MVCC 多版本并发控制，这种方式就是在数据更新的时候需要去比较所持有的数据版本号，版本号不一致的话，操作会失败，这样每个 version 就只有一次执行成功的机会，一旦失败了必须重新获取。 Token 机制： Token 则是目前使用比较广的一种方式，核心思想就是每个操作都有一个唯一凭证 token ，一旦执行成功，对于重复的请求，总是返回同一个结果。 设计去重表 … 人力资源管理系统中的 RabbitMQ 消费端实际上就是采用了 Token 这种方式。 3 Token 机制 大致的思路是这样，首先将 RabbitMQ 的消息自动确认机制改为手动确认，然后每当有一条消息消费成功了，就把该消息的唯一 ID 记录在 Redis 上，然后每次收到消息时，都先去 Redis 上查看是否有该消息的 ID，如果有，表示该消息已经消费过了，不再处理，否则再去处理。 首先，修改 hr-mail 中的 pom 文件，增加 Redis 依赖，如下： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 接着，修改 application.properties 文件，增加 Redis 配置，并修改 RabbitMQ 配置，开启消息消费手动确认，如下： 1234567891011121314# 配置 RabbitMQspring.rabbitmq.host=127.0.0.1spring.rabbitmq.port=5672spring.rabbitmq.username=guestspring.rabbitmq.password=guest## 开启消息消费手动确认，默认自动spring.rabbitmq.listener.simple.acknowledge-mode=manualspring.rabbitmq.listener.simple.prefetch=100# 配置 Redis ，实现 RabbitMQ 消息消费的幂等性，避免消息重复消费，见 RabbitMQReceiverspring.redis.host=127.0.0.1spring.redis.port=6379spring.redis.database=0spring.redis.password= 最后，修改 RabbitMQReceiver 中的消息消费方法，增加 消息消费确认机制，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142// 监听队列@RabbitListener(queues = MailConstants.QUEUE_NAME)public void employeeWelcome(Message message, Channel channel) throws IOException { Employee employee = (Employee) message.getPayload(); MessageHeaders headers = message.getHeaders(); Long tag = (Long) headers.get(AmqpHeaders.DELIVERY_TAG); String msgId = (String) headers.get(\"spring_returned_message_correlation\"); if (stringRedisTemplate.opsForHash().entries(\"mail_log\").containsKey(msgId)) { // redis 中包含该 key，说明该消息已经被消费过 logger.info(\"消息已经被消费：\" + msgId); channel.basicAck(tag, false); // 手动确认消息已消费 return; } logger.info(employee.toString()); // 发送邮件 MimeMessage msg = javaMailSender.createMimeMessage(); MimeMessageHelper helper = new MimeMessageHelper(msg); try { helper.setSubject(\"入职通知\"); helper.setFrom(mailProperties.getUsername()); helper.setTo(employee.getEmail()); helper.setSentDate(new Date()); Context context = new Context(); context.setVariable(\"name\", employee.getName()); context.setVariable(\"positionName\", employee.getPosition().getName()); context.setVariable(\"jobTitlelName\", employee.getJobTitle().getName()); context.setVariable(\"departmentName\", employee.getDepartment().getName()); String process = templateEngine.process(\"employee/welcome\", context); helper.setText(process, true); javaMailSender.send(msg); stringRedisTemplate.opsForHash().put(\"mail_log\", msgId, \"cxy35\"); channel.basicAck(tag, false); // 手动确认消息已消费 logger.info(\"邮件发送成功：\" + msgId); } catch (MessagingException e) { channel.basicNack(tag, false, true); // 消息消费失败，重回队列 e.printStackTrace(); logger.error(\"邮件发送失败：\" + e.getMessage()); }} Spring Boot 实战项目（人力资源管理系统）教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 实战项目（人力资源管理系统）源码：https://github.com/cxy35/hr 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/05/06/hr/hr-rabbitmq-reliability-consumer/"},{"title":"Linux 常用命令 - 重启、关机","text":"通过本文学习 Linux 常用命令 - 重启、关机：reboot shutdown 等。 重启： reboot –&gt; 注：立刻重启 shutdown -r now –&gt; 注：立刻重启（ root 用户使用） shutdown -r 10 –&gt; 注： 10 分钟后重启（ root 用户使用） shutdown -r 20:35 –&gt; 注： 20:35 时重启（ root 用户使用） 注：如果是通过 shutdown 命令设置重启的话，可以用 shutdown -c 命令取消重启。 关机： halt –&gt; 注：立刻关机 shutdown -h now –&gt; 注：立刻关机（ root 用户使用） shutdown -h 10 –&gt; 注： 10 分钟后关机 poweroff –&gt; 注：立刻关机 注：如果是通过 shutdown 命令设置关机的话，可以用 shutdown -c 命令取消关机。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/01/12/linux/linux-command-reboot-shutdown/"},{"title":"Linux 常用命令 - 文件传输","text":"通过本文学习 Linux 常用命令 - 文件传输：scp rz sz 等。 ssh 命令行传输：scp12345678910111213141516# 文件上传，默认 22 端口scp /usr/local/test.txt root@192.168.1.53:/usr/local# 文件上传，指定 8122 端口# test.txt 会被上传到 local 目录下(/usr/local/test.txt)scp -P 8122 /usr/local/test.txt root@192.168.1.53:/usr/local# 目录上传# test 目录会被上传到 local 目录下(/usr/local/test)scp -r /usr/local/test root@192.168.1.53:/usr/local# 文件下载scp root@192.168.1.53:/usr/local/test.txt /usr/local# 目录下载scp -r root@192.168.1.53:/usr/local/test /usr/local xshell 结合 lrzsz 工具传输：rz sz12345678910111213# 检查是否安装过工具 lrzszrpm -qa |grep lrzsz# 安装工具 lrzszyum -y install lrzsz# 文件上传，会打开本地选择文件对话框 rz# 文件下载，会弹出选择本地保存文件对话框sz# xshell 中直接拖拽文件到窗口中也可以上传。 Alt+P 打开属性框，打开[文件传输] 可以调整传输的一些属性 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/01/13/linux/linux-command-scp-rzsz/"},{"title":"Linux 磁盘分区、格式化、挂载","text":"通过本文学习 Linux 磁盘分区、格式化、挂载。 1 查看磁盘分区fdisk -l 可以列出所有的分区，包括没有挂上的分区和 usb 设备。一般可以用这个来查找需要挂载的分区的位置，比如挂上 u 盘。 12345678910111213141516171819202122232425262728293031fdisk -lDisk /dev/xvda: 21.5 GB, 21474836480 bytes255 heads, 63 sectors/track, 2610 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x000b1054 Device Boot Start End Blocks Id System/dev/xvda1 * 1 26 204800 83 LinuxPartition 1 does not end on cylinder boundary./dev/xvda2 26 548 4194304 82 Linux swap / SolarisPartition 2 does not end on cylinder boundary./dev/xvda3 548 2611 16571392 83 LinuxDisk /dev/xvde: 107.4 GB, 107374182400 bytes255 heads, 63 sectors/track, 13054 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0xc0c19043 Device Boot Start End Blocks Id System/dev/xvde1 1 13054 104856223+ 83 LinuxDisk /dev/xvdf: 53.7 GB, 53687091200 bytes255 heads, 63 sectors/track, 6527 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000 通过上面的信息，我们知道此机器中挂载 3 个硬盘（或移动硬盘）：xvda、xvde、xvdf。如果我们想查看单个硬盘情况，可以通过 fdisk -l /dev/xvda1 来操作。 第 1 个 xvda 有三个主分区（包括扩展分区），分别是主分区 xvda1、xvda2、xvda3。如果有逻辑分区，则会从 xvda5 开始，因为主分区（包括扩展分区）的总个数不能超过 4 个，也不能把扩展分区包围在主分区之间。 第 2 个 xvde 有 1 个主分区 xvde1。如果有逻辑分区，则会从 xvde5 开始。 第 3 个 xvdf 还未分区，下面会进行分区。 硬盘总容量 = 主分区（包括扩展分区）总容量。扩展分区容量 = 逻辑分区总容量。通过上面的例子，我们可以得知 xvda=xvda1+xvda2+xvda3。如果 xvda3 为扩展分区，则 xvda3=xvda3+xvda6+xvda7+……。 说明： 硬盘分区的表示：在 Linux 是通过 hd%&amp; 或 sd%&amp; 表示的，上面所列是 xvd%&amp; ，其中 % 表示的是 a、b、c 等，&amp; 表示的数字 1、2、3 等。hd 大多是 IDE 硬盘；sd 大多是 SCSI 或移动存储； 引导（Boot）：表示引导分区，在上面的例子中 hda1 是引导分区； Start （开始）：表示的一个分区从 X cylinder（磁柱）开始； End （结束）：表示一个分区到 Y cylinder（磁柱）结束； id 和 System 表示的是一个意思，id 看起来不太直观，我们要在 fdisk 一个分区时，通过指定 id 来确认分区类型；比如 7 表示的就 NTFS 分区；这个在 fdisk 中要通过 t 功能来指定。下面的部分会提到； Blocks（容量）：这是我翻译的，其实不准确，表示的意思的确是容量的意思，其单位是 K；一个分区容量的值是由下面的公式而来的；Blocks = （相应分区 End 数值 - 相应分区 Start 数值）x 单位 cylinder（磁柱）的容量。 我们估算一个硬盘是否完全被划分，我们只要看 fdisk -l 输出的内容中的 cylinders（柱体） 上一个分区的 End 和下一个分区的 Start 是不是一个连续的数字，另外要看一下每个硬盘设备的 fdisk -l 的开头部份，看一下他的 cylinders（柱体）的值。上一个分区的 End 的值 +1 就是下一个分区的 Start 的值。如果看到 End 的值是跟在 fdisk -l 头部信息中 cylinders 的值一样的话，证明这个硬盘已经完全划分。 2 磁盘分区1234567891011121314151617181920212223242526272829fdisk /dev/xvdfCommand (m for help): m Command action a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d delete a partition 注：d 删除一个分区； l list known partition types 注：l 列出分区类型，以供我们设置相应分区的类型； m print this menu 注：m 列出帮助信息； n add a new partition 注：n 添加一个分区； o create a new empty DOS partition table p print the partition table 注：p 列出分区表； q quit without saving changes 注：q 不保存退出； s create a new empty Sun disklabel t change a partition's system id 注：t 改变分区类型； u change display/entry units v verify the partition table w write table to disk and exit 注：w 把分区表写入硬盘保存并退出； x extra functionality (experts only) 注：扩展应用，专家功能；Command (m for help): nCommand action e extended p primary partition (1-4)p 注：添加主分区Partition number (1-4): 1 注：第一个主分区First cylinder (1-6527, default 1): 1 注：起始位置，可直接回车默认 1Last cylinder, +cylinders or +size{K,M,G} (1-6527, default 6527): 6527 注：结束位置，可直接回车默认 6527，表示磁盘全部空间分到一个分区中。或者输入别的数值，或者也可输 +200M 来指定分区大小为 200M。Command (m for help): w 注：保存退出，q 不保存退出 3 分区格式化、挂载 123456789101112131415161718192021222324# 分区格式化# mkfs - 支持 ext2、ext3（日志）、vfat、msdos、jfs、reiserfs 等mkfs.ext3 /dev/xvdf1# 分区挂载# mount 挂载设备 挂载点mkdir /usr/local/mydatamount /dev/xvdf1 /usr/local/mydatadf -hTFilesystem Type Size Used Avail Use% Mounted on/dev/xvda3 ext4 16G 4.5G 11G 30% /tmpfs tmpfs 32G 80K 32G 1% /dev/shm/dev/xvda1 ext4 194M 46M 139M 25% /boot/dev/xvde1 ext3 99G 40G 55G 43% /usr/local/mysqldata/dev/xvdf1 ext3 53G 976M 50G 2% /usr/local/mydata# 将挂载点写入注册表，系统启动后自动挂载vi /etc/fstab 新增一行：/dev/xvdf1(分区) /usr/local/mydata(挂载点) ext3(类型) defaults 0 0# 分区取消挂载umount /dev/xvdf1# 或umount /usr/local/mydata 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/12/18/linux/linux-command-fdisk-mount/"},{"title":"Linux 常用命令 - 打包、压缩、解压缩","text":"通过本文学习 Linux 常用命令 - 打包、压缩、解压缩：tar 。 名词区分 打包：将一大堆文件或目录变成一个总的文件（ tar 命令） 压缩：将一个大的文件通过一些压缩算法变成一个小文件（ gzip，bzip2 等） Linux 中很多压缩程序只能针对一个文件进行压缩，因此当你想要压缩一大堆文件时，你得将这一大堆文件先打成一个包（ tar 命令），然后再用压缩程序进行压缩（ gzip，bzip2 命令）。 习惯上以 .tar 后缀代表 tar 包，用 xxx.tar.gz 或 .tgz 代表 gzip 压缩过的 tar 文件，用 .tar.bz2 代表 bzip2 压缩过的 tar 文件。 语法 tar [主选项 + 辅选项] 文件或目录 使用该命令时，主选项必须有，且仅有一个，如：tar -xzvf mysql-5.6.42-linux2.6-x86_64.tar.gz 主选项 使用该命令时，主选项必须有，且仅有一个。 -c： 新建一个压缩文档，即打包 -x： 解压文件 -t： 查看压缩文档里的所有内容 -r： 向压缩文档里追加文件 -u： 更新原压缩包中的文件 辅助选项 -z：具有 gzip 属性，一般格式为 xxx.tar.gz 或 xx.tgz -j：具有 bzip2 属性，一般格式为 xx.tar.bz2 -Z：具有 compress 属性, 一般格式为 xx.tar.Z -v：显示操作过程 -f：使用文档名，在 f 之后要立即接文档名，不要再加其他参数 -C：打包 / 压缩时可将当前目录更改为指定的目录，详见下文 打包 / 压缩 tar -cvf img.tar img1 img2 –&gt; 注：将当前目录下 img1 和 img2 两个文件夹打包成 img.tar ，仅打包不压缩 tar -czvf img.tar.gz img1 img2 –&gt; 注：将当前目录下 img1 和 img2 两个文件夹打包成 img.tar.gz ，打包后，以 gzip 压缩 tar -cjvf img.tar.bz2 img1 img2 –&gt; 注：将当前目录下 img1 和 img2 两个文件夹打包成 img.tar.bz2 ，打包后，以 bzip2 来压缩 tar -cvf img.tar -C /usr/local aaa –&gt; 注：将当前目录改为 /usr/local ，并将 /usr/local 下的 aaa 目录打包到 img.tar 不解压的情况下查看 tar -tvf img.tar –&gt; 注：查看当前目录下 img.tar 中的所有内容 解压 tar -xvf img.tar –&gt; 注：将 img.tar 解压到当前目录 tar -xvf img.tar img1 –&gt; 注：将 img.tar 解压到当前目录，但只减压 img.tar 中的 img1 文件夹 tar -xvf img.tar -C /usr/local –&gt; 注：将当前目录改为 /usr/local ，并将 img.tar 解压到 /usr/local 目录 更新 tar -uvf img.tar img1 –&gt; 注：将 img1 文件夹更新到 img.tar 中 追加 tar -rvf img.tar img3 –&gt; 注：将 img3 文件夹追加到 img.tar 中 C 参数-C dir 参数的作用在于改变工作目录，其有效期为该命令中下一次 -C dir 参数之前。 tar -cvf img.tar -C /usr/local aaa –&gt; 注：将当前目录改为 /usr/local ，并将 /usr/local 下的 aaa 目录打包到 img.tar tar -xvf img.tar -C /usr/local –&gt; 注：将当前目录改为 /usr/local ，并将 img.tar 解压到 /usr/local 目录 解压方法总结 *.tar 用 tar –xvf 解压 *.gz 用 gzip -d 或者 gunzip 解压 .tar.gz 和.tgz 用 tar –xzf 解压 *.bz2 用 bzip2 -d 或者用 bunzip2 解压 *.tar.bz2 用 tar –xjf 解压 *.Z 用 uncompress 解压 *.tar.Z 用 tar –xZf 解压 *.rar 用 unrar x 解压，需先安装 *.zip 用 unzip 解压，需先安装 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/01/06/linux/linux-command-tar/"},{"title":"Linux 常用命令 - 文件内容编辑","text":"通过本文学习 Linux 常用命令 - 文件内容编辑：vi 。 vi 有 2 种模式：命令模式、插入模式，用 Esc 或 i 等实现模式切换。 文件的创建 vi 1.txt 文件的保存和退出 :w [newFileName] 保存 :wq! [newFileName] 保存退出 :q! 不保存退出 光标移动 gg 移动至文档开始 GG 移动到文档尾部 ctrl + f 向前翻页（同 PgDn ） ctrl + b 向后翻页（同 PgUp ） j 向下移动一行（同方向键） k 向上移动一行（同方向键） h 向左移动一个字符（同方向键） l 向右移动一个字符（同方向键） 复制 / 粘帖 yy 复制当前行 #yy 复制多行，# 用数字表示，比如 3yy 表示复制 3 行 p 在光标之后粘帖 shift + p 在光标之前粘帖 删除 x 删除 1 个字符 #x 删除多个字符，# 用数字表示，比如 3x 表示删除 3 个字符 dw 删除 1 个单词 #dw 删除多个单词，# 用数字表示，比如 3dw 表示删除 3 个单词 dd 删除 1 行 #dd 删除多行，# 用数字表示，比如 3dd 表示删除光标行及光标的下两行 d$ 删除光标到行尾的内容 撤消 u 撤消修改或删除操作 插入模式 i 在光标之前插入，然后进入插入模式 I 在光标所在行的行首插入，然后进入插入模式 a 在光标之后插入，然后进入插入模式 A 在光标所在行的行末插入，然后进入插入模式 o 在光标所在的行的下面插入一行，然后进入插入模式 O 在光标所在的行的上面插入一行，然后进入插入模式 s 删除光标后的一个字符，然后进入插入模式 S 删除光标所在行的所有字符，然后进入插入模式 查找 / 字符串 注：正向查找，按 n 键往下，按 shift + n 键往上，查找下一个符合条件的地方 ? 字符串 注：反向查找，按 shift + n 键往下，按 n 键往上，查找下一个符合条件的地方。 替换 :s / 字符串 1/ 字符串 2/g 注：替换 当前行 中的所有字符串 1 为字符串 2。如果没有 /g，则只替换 当前行 中的第一个 :%s / 字符串 1/ 字符串 2/g 注：替换 每一行 中的所有字符串 1 为字符串 2。如果没有 /g，则只替换 每一行 中的第一个 :#,# s / 字符串 1/ 字符串 2/g 注：# 表示数字，表示从多少行到多少行，把字符串 1 替换成字符串 2。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/01/03/linux/linux-command-vi/"},{"title":"Linux 下查看某个端口被哪个进程或程序占用","text":"Linux 下查看某个端口被哪个进程或程序占用。 1234567891011[root@dbserver ~]$ netstat -anp|grep 3306tcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN 3005/mysqld tcp 0 0 192.168.71.62:3306 192.168.71.98:57629 ESTABLISHED 3005/mysqld tcp 0 0 192.168.71.62:3306 192.168.11.118:57895 ESTABLISHED 3005/mysqld tcp 0 0 192.168.71.62:3306 192.168.71.98:57639 ESTABLISHED 3005/mysqld tcp 0 0 192.168.71.62:3306 192.168.71.97:57139 ESTABLISHED 3005/mysqld tcp 0 0 192.168.71.62:3306 192.168.71.56:57896 ESTABLISHED 3005/mysqld tcp 0 0 192.168.71.62:3306 192.168.71.35:58646 ESTABLISHED 3005/mysqld tcp 0 0 192.168.71.62:3306 192.168.71.35:58629 ESTABLISHED 3005/mysqld tcp 0 0 192.168.71.62:3306 192.168.71.97:57132 ESTABLISHED 3005/mysqld unix 2 [ACC] STREAM LISTENING 13125 3005/mysqld /usr/local/mysql3306/data/mysqld.sock 由上面可以看到端口 3306 对应的进程 pid=3005 ，进程为 mysqld 。 再执行 kill -9 3005 可结束该进程。 1234[root@dbserver ~]$ ps -ef|grep mysqldroot 2123 1 0 09:39 ? 00:00:00 /bin/sh /usr/local/mysql3306/bin/mysqld_safe --datadir=/usr/local/mysql3306/data --pid-file=/usr/local/mysql3306/data/dbserver.pidmysql 3005 2123 1 09:39 ? 00:03:40 /usr/local/mysql3306/bin/mysqld --basedir=/usr/local/mysql3306 --datadir=/usr/local/mysql3306/data --plugin-dir=/usr/local/mysql3306/lib/plugin --user=mysql --log-error=/usr/local/mysql3306/data/error.log --open-files-limit=8192 --pid-file=/usr/local/mysql3306/data/dbserver.pid --socket=/usr/local/mysql3306/data/mysqld.sock --port=3306root 4186 3632 0 14:23 pts/0 00:00:00 grep mysqld 由上面可以看到进程 pid=3005 对应的 mysqld 进程的具体信息。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/12/16/linux/linux-netstat-ps/"},{"title":"MySQL 备份与恢复 - xtrabackup","text":"【TODO- 未整理、未实测】MySQL 备份与恢复 - xtrabackup 。 数据库备份恢复之 XtraBackup 概述及安装部署 一、xtrabackup 工具介绍及备份过程概述1.xtrabackup 简介：mysqldump 备份方式是采用逻辑备份，其最大的缺陷就是备份和恢复速度都慢，对于一个小于 50G 的数据库而言，这个速度还是能够接受的，如果数据库非常大，那再使用 mysqldump 备份就不太适合了。Xtrabackup 是由 percona 提供的 mysql 数据库备份工具，据官方介绍，这也是世界上唯一一个开源的能够对 innodb 和 xtradb 数据库进行物理热备的工具。2.xtrabakcup 特点：1）备份过程快速，可靠； 2）备份过程不会打断正在执行的事务（不需要锁表） 3）能够给予压缩等功能节约磁盘空间和流量。 4）自动实现备份检验； 5）还原速度快； 6）可以进行流传出备份，备份到另外一台机器上。Xtrabackup 中主要有包含两个工具：1.innobackupex：是将 xtrabackup 进行封装的 perl 脚本，提供了备份 myisam 表的能力，2.xtrabackup：是用于热备 innodb，xtradb 表中数据的工具，不能备份其他类型的表，也不能备份数据表结构； 【xtrabackup 全量备份恢复】 完全备份 创建用于备份恢复的用户 pxb 并赋予权限create user pxb@’localhost’ identified by ‘123456’;grant reload,process,lock tables,replication client on . to pxb@localhost; 创建存放目录mkdir -pv /data/pxb 进行数据库全备（生成全备：/data/pxb/2017-04-24_02-46-11）innobackupex –defaults-file=/etc/my.cnf –user=pxb –password=123456 –socket=/tmp/mysql.sock /data/pxb 全备恢复 关闭数据库并删除数据文件/etc/init.d/mysqld stopcd /home/mysqlmv data data_bakmkdir data 准备 (prepare) 一个完全备份：–apply-log (/data/pxb/2017-04-24_02-46-11/ 为备份目录，执行之后 xtrabackup_checkpoints 文件中的 backup_type = full-prepared)innobackupex –apply-log /data/pxb/2017-04-24_02-46-11/ 执行恢复操作：innobackupex –defaults-file=/etc/my.cnf –copy-back –rsync /data/pxb/2017-04-24_02-46-11/ 更改 data/ 目录权限并启动 mysql：chown -R mysql:mysql data//etc/init.d/mysqld start 验证 【xtrabackup 增量备份恢复】我们以之前做的全备为基准，在其基础上做增量备份：增量备份 1：（以全备为基准：/data/pxb/2017-04-24_02-46-11/）（生成增量 1：/data/pxb/inc/2017-04-28_01-09-40）innobackupex –defaults-file=/etc/my.cnf –user=pxb –password=123456 –socket=/tmp/mysql.sock –incremental /data/pxb/inc –incremental-basedir=/data/pxb/2017-04-24_02-46-11/ –parallel=2 增量备份 2：（以增量 1 为基准：/data/pxb/inc/2017-04-28_01-09-40/）（生成增量 2：/data/pxb/inc/2017-04-28_01-27-46）innobackupex –defaults-file=/etc/my.cnf –user=pxb –password=123456 –socket=/tmp/mysql.sock –incremental /data/pxb/inc –incremental-basedir=/data/pxb/inc/2017-04-28_01-09-40/ –parallel=2 增量备份的恢复 增量备份的恢复需要有 3 个步骤1 恢复完全备份2 恢复增量备份到完全备份(开始恢复的增量备份要添加–redo-only 参数，到最后一次增量备份要去掉–redo-only)3 对整体的完全备份进行恢复，回滚未提交的数据## 准备一个全备 ##innobackupex –apply-log –redo-only /data/pxb/2017-04-24_02-46-11/ ## 将增量 1 应用到完全备份 ##innobackupex –apply-log –redo-only /data/pxb/2017-04-24_02-46-11/ –incremental-dir=/data/pxb/inc/2017-04-28_01-09-40/ ## 将增量 2 应用到完全备份，注意不加 –redo-only 参数了 ##innobackupex –apply-log /data/pxb/2017-04-24_02-46-11/ –incremental-dir=/data/pxb/inc/2017-04-28_01-27-46/ ## 把所有合在一起的完全备份整体进行一次 apply 操作，回滚未提交的数据 ##innobackupex –apply-log /data/pxb/2017-04-24_02-46-11/ 关闭数据库并删除数据文件/etc/init.d/mysqld stopcd /home/mysqlmv data data_bak2mkdir data 执行恢复操作：innobackupex –defaults-file=/etc/my.cnf –copy-back –rsync /data/pxb/2017-04-24_02-46-11/ 更改 data/ 目录权限并启动 mysql：chown -R mysql:mysql data//etc/init.d/mysqld start 验证 MySQL 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/10/14/mysql/mysql-bak-xtrabackup/"},{"title":"MySQL 常见问题","text":"本文记录 MySQL 安装、启动、运行过程中出现的问题汇总，持续更新中。 1 Plugin ‘InnoDB’ registration as a STORAGE ENGINE failed原因：启动时报错，配置文件修改导致出问题。 解决：停服务，删除那些日志文件，再启动服务。 1234rm -f /usr/local/mysql/data/ib_logfile*# 下面的可能也需要删除rm -f /usr/local/mysql/data/mysql-bin* 2 ERROR 1418 (HY000): This function has none of DETERMINISTIC, NO SQL, or READS SQL DATA in its declaration and binary logging is enabled (you might want to use the less safe log_bin_trust_function_creators variable)解决：在 my.cnf 配置文件中添加：log_bin_trust_function_creators=1 3 Waiting for table flush最近遇到一个案例，很多查询被阻塞没有返回结果，使用 show processlist 查看，发现不少 MySQL 线程处于 Waiting for table flush 状态，查询语句一直被阻塞，只能通过 Kill 进程来解决。 原因： 有些时候，是由于 lock table t_test read 引起的阻塞。但生产环境中，很多时候可能是由于 慢查询 导致 flush table 一直无法关闭该表而一直处于等待状态。 另外，网上有个案例，mysqldump 备份时，如果没有使用参数 —single-transaction 或由于同时使用了 flush-logs 与 —single-transaction 两个参数也可能引起这样的等待场景，这个两个参数放在一起，会在开始 dump 数据之前先执行一个 FLUSH TABLES 操作。 解决： 出现 Waiting for table flush 时，我们一般需要找到那些表被 lock 住或那些慢查询导致 flush table 一直在等待而无法关闭该表。然后 Kill 掉对应的线程即可，但是如何精准定位是一个挑战，尤其是生产环境，你使用 show processlist 会看到大量的线程。让你眼花缭乱的，怎么一下子定位问题呢？ 对于慢查询引起的其它线程处于 Waiting for table flush 状态的情形： 可以查看 show processlist 中 Time 值很大的线程，然后甄别确认后 Kill 掉。有种规律就是这个线程的 Time 列值必定比被阻塞的线程要高，这个就能过滤很多记录。 对于 lock table t_test read 引起的其它线程处于 Waiting for table flush 状态的情形： 对于 lock table t_test read 这种情况，这种会话可能处于 Sleep 状态，而且它也不会出现在 show engine innodb status \\G 命令的输出信息中。 即使 show open tables where in_use &gt;=1; 能找到是那张表被 lock 住了，但是无法定位到具体的线程（连接），其实这个是一个头痛的问题，可以使用 MySQL 监控利器 -Innotop 。 另外，在官方文档中 ALTER TABLE, RENAME TABLE, REPAIR TABLE, ANALYZE TABLE, OPTIMIZE TABLE 都能引起这类等待。 4 Host ‘xxx’ is blocked because of many connection errors; unblock with ‘mysqladmin flush-hosts’原因： 同一个 ip 在短时间内产生太多（超过 MySQL 数据库 max_connect_errors 的最大值）中断的数据库连接而导致的阻塞。 说明 MySQL 已经得到了大量 (max_connect_errors) 的主机 ‘hostname’ 的在中途被中断了的连接请求。在 max_connect_errors 次失败请求后， MySQL 认定出错了(像来自一个黑客的攻击)，并且阻止该站点进一步的连接，直到某人执行命令 mysqladmin flush-hosts 。 解决： 提高允许的 max_connect_errors 数量（治标不治本）： 进入 MySQL 数据库查看 max_connect_errors： show variables like ‘%max_connect_errors%’; 修改 max_connect_errors 的数量为 1000： set global max_connect_errors = 1000; 查看是否修改成功：show variables like ‘%max_connect_errors%’; 使用 mysqladmin flush-hosts 命令清理一下 hosts 文件（不知道 mysqladmin 在哪个目录下可以使用命令查找： whereis mysqladmin ） 在查找到的目录下使用命令修改：/usr/local/mysql/bin/mysqladmin flush-hosts -h10.19.11.33 -P3306 -uroot -p123456 备注： 其中端口号，用户名，密码都可以根据需要来添加和修改。 配置有 master/slave 主从数据库的要把主库和从库都修改一遍的，如果连了多个数据库，则都需要处理。 第 2 步也可以在数据库中进行，命令如下： flush hosts; MySQL 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/11/06/mysql/mysql-faq/"},{"title":"MySQL 事件","text":"通过本文学习 MySQL 事件。 1 基本语法 1234567891011121314151617181920212223CREATE EVENT[IF NOT EXISTS]event_nameON SCHEDULE schedle[ON COMPLETION [NOT] PRESERVE][ENABLE|DESABLE][COMMENT 'comment']DO sql_statement-- 说明：-- event_name：事件的名称-- ON SCHEDULE 设定计划任务的方式，有两种： -- 单次计划任务：AT 时戳 -- 重复的计划任务：EVERY 时间(单位) 的数量 时间单位 [STARTS 时戳][ENDS 时戳] -- 在两种计划任务中，时戳可以是任意的 TIMESTAMP 和 DATETIME 数据类型，要求提供的是将来的时间（大于 CURRENT_TIMESTAMP），而且小于 Unix 时间的最后时间（等于或小于 '2037-12-31 23:59:59'） -- 时间单位是关键词：YEAR，MONTH，DAY，HOUR，MINUTE 或者 SECOND-- [ON COMPLETION [NOT] PRESERVE]：COMPLETION 当单次计划任务执行完毕后或当重复性的计划任务执行到了 ENDS 阶段。而声明 PRESERVE 的作用是使事件在执行完毕后不会被 Drop 掉-- [ENABLE|DESABLE]：开启 / 关闭事件-- [COMMENT 'comment']：注释-- DO sql_statement：执行的 sql 语句-- 注意：-- 全局事件调度器启用状态：SHOW VARIABLES LIKE '%event_scheduler%'; -- ON/OFF 2 模板与实例2.1 模板12345678910111213141516171819202122232425262728293031323334DELIMITER $$-- SET GLOBAL event_scheduler = ON$$ -- required for event to execute but not create CREATE /*[DEFINER = { user | CURRENT_USER }]*/ EVENT `E_NAME`ON SCHEDULE /* uncomment the example below you want to use */ -- scheduleexample 1: run once -- AT 'YYYY-MM-DD HH:MM.SS'/CURRENT_TIMESTAMP { + INTERVAL 1 [HOUR|MONTH|WEEK|DAY|MINUTE|...] } -- scheduleexample 2: run at intervals forever after creation -- EVERY 1 [HOUR|MONTH|WEEK|DAY|MINUTE|...] -- scheduleexample 3: specified start time, end time and interval for execution /*EVERY 1 [HOUR|MONTH|WEEK|DAY|MINUTE|...] STARTS CURRENT_TIMESTAMP/'YYYY-MM-DD HH:MM.SS' { + INTERVAL 1[HOUR|MONTH|WEEK|DAY|MINUTE|...] } ENDS CURRENT_TIMESTAMP/'YYYY-MM-DD HH:MM.SS' { + INTERVAL 1 [HOUR|MONTH|WEEK|DAY|MINUTE|...] } *//*[ON COMPLETION [NOT] PRESERVE][ENABLE | DISABLE][COMMENT 'comment']*/DO BEGIN (sql_statements) END$$DELIMITER ; 2.2 实例123456789101112131415161718192021DELIMITER $$ DROP EVENT IF EXISTS `E_TEST`$$CREATE EVENT `E_TEST`ON SCHEDULEEVERY 1 DAY STARTS '2018-01-01 01:00:00'ON COMPLETION NOT PRESERVEENABLEDO BEGIN -- 执行 sql INSERT INTO t_log SET createTime = NOW(); -- 调用存储过程 CALL p_test(); END$$DELIMITER ; MySQL 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/08/10/mysql/mysql-event/"},{"title":"MySQL 索引","text":"索引是快速搜索的关键，索引的建立对于 MySQL 的高效运行很重要。通过本文学习 MySQL 索引。 1 索引类型1.1 普通索引1ALTER TABLE `t_user` ADD INDEX `idx_user_username` (`username`); 1.2 唯一索引 唯一索引的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。 1ALTER TABLE `t_user` ADD UNIQUE `idx_user_username` (`username`); 1.3 主键索引 主键索引是一种特殊的唯一索引，不允许有空值，一般是在建表的时候同时创建主键索引。 12345CREATE TABLE `t_user` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键 id', `username` varchar(16) NOT NULL COMMENT '用户名', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT='用户'; 1.4 组合索引123456CREATE TABLE mytable( ID INT NOT NULL, username VARCHAR(16) NOT NULL, city VARCHAR(50) NOT NULL, age INT NOT NULL ); 为了进一步榨取 MySQL 的效率，就要考虑建立组合索引。就是将 username, city, age 建到一个索引里。 1ALTER TABLE mytable ADD INDEX name_city_age (username(10), city, age); 建表时，usernname 长度为 16，这里用 10。这是因为一般情况下名字的长度不会超过 10，这样会加速索引查询速度，还会减少索引文件的大小，提高 INSERT 的更新速度。建立这样的组合索引，其实是相当于分别建立了下面三组组合索引： usernname, city, age usernname, city usernname 为什么没有 city, age 这样的组合索引呢？这是因为 MySQL 组合索引“最左前缀”的结果。简单的理解就是只从最左面的开始组合。并不是只要包含这三列的查询都会用到该组合索引，下面的几个 SQL 就会用到这个组合索引： 12SELECT * FROM mytable WHREE username=\"admin\" AND city=\"郑州\"SELECT * FROM mytable WHREE username=\"admin\" 而下面几个则不会用到： 12SELECT * FROM mytable WHREE age=20 AND city=\"郑州\"SELECT * FROM mytable WHREE city=\"郑州\" 如果分别在 usernname, city, age 上建立单列索引，让该表有 3 个单列索引，查询时和上述的组合索引效率也会大不一样，远远低于我们的组合索引。虽然此时有了三个索引，但 MySQL 只能用到其中的那个它认为似乎是最有效率的单列索引。 2 建立索引的时机 到这里我们已经学会了建立索引，那么我们需要在什么情况下建立索引呢？ 一般来说，在 WHERE 和 JOIN 中出现的列需要建立索引，但也不完全如此，因为 MySQL 只对 &lt;，&lt;=，=，&gt;，&gt;=，BETWEEN，IN，以及某些时候的 LIKE 才会使用索引。 123SELECT t.usernameFROM mytable t LEFT JOIN mytable2 mON t.username=m.username WHERE m.age=20 AND m.city='郑州'; 1234-- 会使用索引SELECT * FROM mytable WHERE username like 'admin%';-- 不会使用索引（以通配符 % 和 _ 开头）SELECT * FROM mytable WHERE username like '%admin'; 3 索引的不足之处 虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行 INSERT/UPDATE/DELETE。因为更新表时，MySQL 不仅要保存数据，还要保存索引文件。 建立索引会占用磁盘空间的索引文件。一般情况这个问题不太严重，但如果你在一个大表上创建了多种组合索引，索引文件的会膨胀很快。 索引只是提高效率的一个因素，如果你的 MySQL 有大数据量的表，就需要花时间研究建立最优秀的索引，或优化查询语句。 4 使用索引的注意事项 索引不会包含有 NULL 值的列。 只要列中包含有 NULL 值都将不会被包含在索引中，复合索引中只要有一列含有 NULL 值，那么这一列对于此复合索引就是无效的。所以我们在数据库设计时不要让字段的默认值为 NULL。 使用短索引 对串列进行索引，如果可能应该指定一个前缀长度。例如，如果有一个 CHAR(255) 的列，如果在前 10 个或 20 个字符内，多数值是惟一的，那么就不要对整个列进行索引。短索引不仅可以提高查询速度而且可以节省磁盘空间和 I/O 操作。 索引列排序 MySQL 查询只使用一个索引，因此如果 where 子句中已经使用了索引的话，那么 order by 中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作；尽量不要包含多个列的排序，如果需要最好给这些列创建复合索引。 like 语句操作 一般情况下不鼓励使用 like 操作，如果非使用不可，如何使用也是一个问题。like '%aaa%' 不会使用索引而 like 'aaa%' 可以使用索引。 不要在列上进行运算 123select * from users where YEAR(adddate) &lt; 2007;-- 上述语句将在每个行上进行运算，这将导致索引失效而进行全表扫描，因此我们可以改成：select * from users where adddate &lt; '2007-01-01'; 不使用 NOT IN 和 &lt;&gt; 操作 MySQL 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/08/12/mysql/mysql-index/"},{"title":"MySQL 安装 - Windows","text":"手把手带你在 Windows 上安装 MySQL-5.6 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283# 下载免安装版本的 MySQL# https://downloads.mysql.com/archives/community/# mysql-5.6.42-winx64.zip# 解压并准备配置文件 my.ini 放到下列目录中 D:\\mysql-5.6.42-3306# 修改配置文件 my.ini[client]port = 3306#socket = D:\\mysqldata\\tmp\\mysql.sockdefault-character-set = utf8[mysql]default-character-set = utf8prompt = \"\\\\u:\\\\d&gt;\"auto-rehash[mysqld]port = 3306basedir = D:\\mysql-5.6.42-3306datadir = D:\\mysql-5.6.42-3306\\data#socket = D:\\mysql-5.6.42-3306\\tmp\\mysql.sock#tmpdir = D:\\mysql-5.6.42-3306\\tmp#log_bin = D:\\mysql-5.6.42-3306\\log\\mysql-bin.log#relay_log = D:\\mysql-5.6.42-3306\\log\\mysql-relay-bin.log#log_error = D:\\mysql-5.6.42-3306\\log\\alert.log#slow_query_log_file = D:\\mysql-5.6.42-3306\\log\\mysql_slow.logdefault-time-zone = '+8:00'character-set-server = utf8collation-server = utf8_unicode_ciinit_connect = 'SET NAMES utf8'max_connections = 1000max_user_connections = 1000max_connect_errors = 90000000max_allowed_packet = 16Mback_log = 5000wait_timeout = 120interactive_timeout = 120sort_buffer_size = 2Mjoin_buffer_size = 2Mserver-id = 1default-storage-engine = innodbinnodb-file-per-table = 1......# 初始化 d:cd mysql-5.6.42-3306/binmysqld.exe --initialize# 将 mysql 从 windows 服务中移除 mysqld.exe --remove MySQL-3306# 将 mysql 添加到 windows 服务中 mysqld.exe --install MySQL-3306 --defaults-file=\"D:\\mysql-5.6.42-3306\\my.ini\"# 启动服务 net start MySQL-3306# 登录并修改密码（有些时候需要初始密码）cd d:/mysql-5.6.42-3306/binmysql -uroot# mysql -uroot -pupdate mysql.user set password = password('123456') where user='root';# alter user 'root'@'localhost' identified by '123456';flush privileges;# 授权远程访问 GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123456' WITH GRANT OPTION;flush privileges;# 关闭服务 net stop MySQL-3306# 根据端口查询 pidnetstat -ano|findstr \"3306\"# 根据 pid 查询进程名 tasklist|findstr \"9452\"# 杀进程 taskkill /f /pid 9452 MySQL 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/07/28/mysql/mysql-install-windows/"},{"title":"MySQL 核心知识点","text":"本文记录 MySQL 相关的一些核心知识点。 1 存储引擎（MyISAM 和 InnoDB）MyIASM 特点： MyISAM 没有提供对数据库事务的支持。 不支持行级锁和外键。 由于 2，导致当执行 INSERT 插入或 UPDATE 更新语句时，即执行写操作需要锁定整个表，所以会导致效率降低。 MyISAM 保存了表的行数，当执行 SELECT COUNT(*) FROM TABLE 时，可以直接读取相关值，不用全表扫描，速度快。 InnoDB 特点： 支持事务。 支持 4 个级别的事务隔离。 支持多版本读。 支持行级锁。 读写阻塞与事务隔离级别相关。 支持缓存，既能缓存索引，也能缓存数据。 整个表和主键以 Cluster 方式存储，组成一颗平衡树。 MyISAM 和 InnoDB 的区别： MyISAM 是非事务安全的，而 InnoDB 是事务安全的。 MyISAM 锁的粒度是表级的，而 InnoDB 支持行级锁。 MyISAM 支持全文类型索引，而 InnoDB 不支持全文索引，一般我们要借助于 Solr 或者 ES 等来做全文索引。 使用场景： 如果要执行大量 select 操作，应该选择 MyISAM 。 如果要执行大量 insert 和 update 操作，应该选择 InnoDB 。 大尺寸的数据集趋向于选择 InnoDB 引擎，因为它支持事务处理和故障恢复。数据库的大小决定了故障恢复的时间长短，InnoDB 可以利用事务日志进行数据恢复，这会比较快。主键查询在 InnoDB 引擎下也会相当快，不过需要注意的是如果主键太长也会导致性能问题。 相对来说，InnoDB 在互联网公司使用更多一些。 2 事务隔离级别 事务的 ACID 特性： 原子性（Atomicity） 一致性（Consistency） 隔离性（Isolation） 持久性（Durability） 四个特性中最复杂的，莫过于隔离性了。SQL 标准的事务隔离级别： serializable/ 串行执行 repeatable read/ 可重复读 read committed/ 读提交 read uncommitted/ 读未提交 serializable： 如果隔离级别为 serializable，则用户之间通过一个接一个顺序地执行当前的事务，这种隔离级别提供了事务之间最大限度的隔离，当然效率也是最低的。 repeatable read： 事务不会被看成是一个序列。不过，当前正在执行事务的变化仍然不能被外部看到，也就是说，如果用户在另外一个事务中执行同条 SELECT 语句数次，结果总是相同的。（因为正在执行的事务所产生的数据变化不能被外部看到）。 read committed： 安全性比 repeatable read 隔离级别的安全性要差。处于 read committed 级别的事务可以看到其他事务对数据的修改。也就是说，在事务处理期间，如果其他事务修改了相应的表，那么同一个事务的多个 SELECT 语句可能返回不同的结果。 read uncommitted： 提供了事务之间最小限度的隔离。除了容易产生虚幻的读操作和不能重复的读操作外，处于这个隔离级的事务可以读到其他事务还没有提交的数据，如果这个事务使用其他事务不提交的变化作为计算的基础，然后那些未提交的变化被它们的父事务撤销，这就导致了大量的数据变化。不过，这种隔离级别从效率上来说，却是最高的。 MySQL 默认的隔离级别则是 repeatable read，Oracle 默认的隔离级别是 read committed。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/11/12/mysql/mysql-knowledge/"},{"title":"MySQL 存储过程","text":"通过本文学习 MySQL 存储过程的语法和使用。 1 基本语法12345678910111213141516171819CREATE OR REPLACE PROCEDURE 存储过程名 ( -- in/out 参数名 参数类型 in param1 varchar(32)， out param2 varchar(32))BEGIN -- 变量名 变量类型（取值范围） declare var1 varchar(32); declare var2 varchar(32) default ''; -- 定义游标遍历时，作为判断是否遍历完全部记录的标记 declare _done int default 0; -- 定义游标 declare _pqList cursor for select o.`uid`,o.`name` from grid_org_org o where o.type='17'; -- 定义处理程序，声明当游标遍历完全部记录后将标志变量置成某个值 declare continue handler for not found set _done=1; -- 具体实现END; 2 给变量赋值123456789-- 方法 1set var1='100';-- 方法 2select col1,col2 into var1,var2 from test_tb;-- 方法 3set @sqlStr='select count(*) from test_tb'; -- 构造 sql 赋值给一个变量（可以之前没有定义，但要以 @开头）prepare var1 from @sqlStr; -- 预处理需要执行的动态 sql ，其中 var1 是一个变量execute var1; -- 执行 sql 语句deallocate prepare var1; -- 释放掉预处理段 3 游标 3.1 cursor 型游标（ 不能用于参数传递） 赋值 12-- 定义变量时赋值declare var3 cursor for select col1 from temp_tb where id='1'; 遍历 12345678910111213open _pqList;loop_label:loop fetch _pqList into var1,var2; if _done=1 then leave loop_label; end if; -- 具体操作 if var1 is not null and length(var1)&gt;0 then end if;end loop;close _pqList; 4 实例12345678910111213create or replace procedure p_test ( in var1 varchar(32),-- 输入参数 out var2 varchar(32)-- 输出普通参数)begin -- 输出普通参数 select col1 into var2 from test_tb where id=var1; -- set var2='10'; -- 输出结果集，可多个，不用作为参数传进来 select * from test_tb where id='1'; select * from test_tb where id='2';end; MySQL 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/08/08/mysql/mysql-procedure/"},{"title":"MySQL 用户与权限","text":"学习 MySQL 的用户管理与权限管理。 MySQL 用户 123456789101112-- 创建用户 'test'@'%'CREATE USER test IDENTIFIED BY '123456';CREATE USER 'test'@'%' IDENTIFIED BY '123456';-- 创建用户 'test'@'localhost'CREATE USER 'test'@'localhost' IDENTIFIED BY '123456';flush privileges;-- 删除用户 'test'@'%'drop user 'test'@'%';-- 删除用户 'test'@'localhost'drop user 'test'@'localhost';flush privileges; MySQL 权限 1234567891011121314151617181920212223-- 权限汇总 -- SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, RELOAD, SHUTDOWN, PROCESS, FILE, REFERENCES, INDEX, ALTER, SHOW DATABASES, SUPER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, REPLICATION SLAVE, REPLICATION CLIENT, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, CREATE USER -- 授权 / 取消，单个权限 GRANT SELECT ON mydbname.mytbname TO 'test'@'%';REVOKE SELECT ON mydbname.mytbname FROM 'test'@'%';GRANT SELECT ON mydbname.* TO 'test'@'%';REVOKE SELECT ON mydbname.* FROM 'test'@'%';flush privileges;-- 授权 / 取消，多个权限 GRANT SELECT, INSERT ON mydbname.mytbname TO 'test'@'%';REVOKE SELECT, INSERT ON mydbname.mytbname FROM 'test'@'%';flush privileges;-- 授权 / 取消，所有权限 GRANT ALL PRIVILEGES ON mydbname.mytbname TO 'test'@'%';REVOKE ALL PRIVILEGES ON mydbname.mytbname FROM 'test'@'%';flush privileges;-- 查看已授权的权限 show grants for 'test'@'%'; show grants for 'test'@'localhost'; 权限 说明 all alter alter routine 使用 alter procedure 和 drop procedure create create routine 使用 create procedure create temporary tables 使用 create temporary table create user create view delete drop execute 使用 call 和存储过程 file 使用 select into outfile 和 load data infile grant option 使用 grant 和 revoke index 使用 create index 和 drop index insert lock tables 锁表 process 使用 show full processlist reload 使用 flush replication client 服务器位置访问 replication slave 由复制从属使用 select show databases show view shutdown 使用 mysqladmin shutdown 来关闭 mysql super update usage 无访问权限 MySQL 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/09/01/mysql/mysql-user-privileges/"},{"title":"Nginx 负载均衡 - fair","text":"学习在 Nginx 中使用 fair 模块（第三方）来实现负载均衡，fair 采用的不是内建负载均衡使用的轮换的均衡算法，而是 可以根据页面大小、响应时间智能的进行负载均衡。 1 准备工作 nginx-upstream-fair 官方下载地址：https://github.com/gnosek/nginx-upstream-fair 版本问题：如果使用的 Nginx 版本 &gt;= 1.14.0 时，使用上述模块源码编译时会报错误，需要对源码做一些修改，参考：https://github.com/gnosek/nginx-upstream-fair/pull/27/commits/ff979a48a0ccb9217437021b5eb9378448c2bd9e 。也可以直接下载已经修改好的源码包：https://files.cnblogs.com/files/ztlsir/nginx-upstream-fair-master.zip 2 配置 上传 nginx-upstream-fair-master.zip 。 解压到 /usr/local 目录下。 1unzip nginx-upstream-fair-master.zip 未安装过 Nginx 具体安装步骤参考： Nginx 安装 - Linux 12# 只需要在 ./configure 时额外增加 fair 模块--add-module=/usr/local/nginx-upstream-fair-master 已安装过 Nginx 如果已经安装过 Nginx ，又不想重新安装，则可以单独添加 fair 模块。 123456789101112131415161718192021# 关闭 Nginx/usr/local/nginx/sbin/nginx -s stop# 查看 Nginx 安装时的配置参数，复制备用/usr/local/nginx/sbin/nginx -V# configure arguments: --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module --with-http_gzip_static_module ...# 进入 nginx-1.16.1 目录cd /usr/local/nginx-1.16.1# 重新执行 cofigure 命令，增加 fair 模块的配置./configure --prefix=/usr/local/nginx --error-log-path=/usr/local/nginx/logs/error.log --http-log-path=/usr/local/nginx/logs/access.log --pid-path=/usr/local/nginx/logs/nginx.pid --lock-path=/usr/local/nginx/logs/nginx.lock --http-client-body-temp-path=/usr/local/nginx/temp/client-body --http-proxy-temp-path=/usr/local/nginx/temp/proxy --http-fastcgi-temp-path=/usr/local/nginx/temp/fastcgi --http-uwsgi-temp-path=/usr/local/nginx/temp/uwsgi --http-scgi-temp-path=/usr/local/nginx/temp/scgi --with-http_stub_status_module --with-http_ssl_module --with-http_gzip_static_module --with-file-aio --with-http_realip_module --add-module=/usr/local/nginx-upstream-fair-master# 编译（不安装）make# 备份原来的 nginx 命令cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx-bak# 替换原来的 nginx 命令cp /usr/local/nginx-1.16.1/objs/nginx /usr/local/nginx/sbin/nginx 修改配置文件 nginx.conf ，如下： 12345upstream tomcat_test { fair; server 192.168.71.57:8080; server 192.168.71.57:8081;} 最后启动 Nginx 服务，验证。本地采用 tomcat 里面 sleep 的方式测试，结果不对，奇怪！？。 Nginx 教程合集 （微信左下方 阅读全文 可直达）。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/03/05/nginx/nginx-fair/"},{"title":"Nginx 常见问题","text":"本文记录 Nginx 使用过程中出现的问题汇总，持续更新中。 1 maximum number of descriptors supported by select() is 1024原因： 使用 nginx-1.16.0.zip 类似这种官方版本的 Nginx ，在 Windows 下因为文件访问句柄数被限制为 1024 了（参数 worker_connections 配置无效），当访问量大时就会无法响应。 解决： 使用专门的 Windows 版本的 Nginx ，已修改了文件句柄数据的限制。 官网：http://nginx-win.ecsds.eu/ 下载地址：http://nginx-win.ecsds.eu/download/ 下载后 nginx 1.17.8.1 Unicorn.zip 里面有个简要的更新信息和安装指南 Readme nginx-win version.txt 。 复制 conf 文件夹中的 nginx-win.conf 并重命名为 nginx.conf ，然后在此文件中做配置。用 nginx.exe 启动如果无效，改成用 nginx_basic.exe 启动。 如果条件允许的话建议使用 linux 版本。 2 集群中的某个节点正在关闭中或启动中，请求还会被转发过去吗？不会，正在执行的请求会立刻被转发到其他节点上。 3 集群中的某个节点被关闭后，请求还会被转发过去吗？不会。但有些时候请求要等 1 分钟才能收到其他节点的返回结果，偶尔出现，为什么？ 4 集群中的某个节点关闭再启动，请求还会被转发过去吗？居然不会，要重启 Nginx 才会生效，为什么？ Nginx 教程合集 （微信左下方 阅读全文 可直达）。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/03/02/nginx/nginx-faq/"},{"title":"Nginx 安装 - Linux","text":"手把手带你在 Linux 上安装 Nginx-1.16.1 。 1 准备工作1.1 下载安装包 Nginx 下载地址：http://nginx.org/en/download.html 下载当前稳定版本 Stable version ，如：nginx-1.16.1.tar.gz 1.2 安装编译工具及库文件12345678# 根据系统实际情况选择安装# gcc 环境# pcre 库：一个 Perl 库，包括 perl 兼容的正则表达式库。 Nginx 的 http 模块使用 pcre 来解析正则表达式# zlib 库：提供了很多种压缩和解压缩的方式。 Nginx 使用 zlib 对 http 包的内容进行 gzip# openssl 库：一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及 SSL 协议，并提供丰富的应用程序供测试或其它目的使用。 Nginx 不仅支持 http 协议，还支持 https （即在 ssl 协议上传输 http ）# 下面是全部安装yum -y install gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel make libtool 2 安装 Nginx 上传 nginx-1.16.1.tar.gz 或通过 wget http://nginx.org/download/nginx-1.16.1.tar.gz 在线下载。 解压到 /usr/local 目录下。 1tar -xzvf nginx-1.16.1.tar.gz -C /usr/local 编译安装 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# 进入 nginx-1.16.1 目录 cd /usr/local/nginx-1.16.1# 执行 cofigure 命令创建一个 makeFile 文件，如果没有，编译的时候会报错# \\ 表示命令还没有输入完，换行的意思# --prefix=/usr/local/nginx 指定 Nginx 安装目录./configure \\--prefix=/usr/local/nginx \\--error-log-path=/usr/local/nginx/logs/error.log \\--http-log-path=/usr/local/nginx/logs/access.log \\--pid-path=/usr/local/nginx/logs/nginx.pid \\--lock-path=/usr/local/nginx/logs/nginx.lock \\--http-client-body-temp-path=/usr/local/nginx/temp/client-body \\--http-proxy-temp-path=/usr/local/nginx/temp/proxy \\--http-fastcgi-temp-path=/usr/local/nginx/temp/fastcgi \\--http-uwsgi-temp-path=/usr/local/nginx/temp/uwsgi \\--http-scgi-temp-path=/usr/local/nginx/temp/scgi \\--with-http_stub_status_module \\--with-http_ssl_module \\--with-http_gzip_static_module \\--with-file-aio \\--with-http_realip_module# 增加第三方模块（需要提前准备模块源码，供编译时用）# \\# --add-module=/usr/local/nginx-upstream-fair-master \\# --add-module=/usr/local/nginx_upstream_check_module-master# 创建上述相关目录mkdir -p /usr/local/nginx/{logs,temp}# 编译安装make &amp;&amp; make install# 执行完成之后，在 Nginx 安装目录下(/usr/local/nginx) 多个几个目录：conf/html/sbin# 切换到 Nginx 安装目录cd /usr/local/nginx# 查看 Nginx 版本/usr/local/nginx/sbin/nginx -v# nginx version: nginx/1.16.1# 查看 Nginx 安装时的配置参数/usr/local/nginx/sbin/nginx -V# configure arguments: --prefix=/usr/local/nginx --error-log-path=/usr/local/nginx/logs/error.log --http-log-path=/usr/local/nginx/logs/access.log --pid-path=/usr/local/nginx/logs/nginx.pid --lock-path=/usr/local/nginx/logs/nginx.lock --http-client-body-temp-path=/usr/local/nginx/temp/client-body --http-proxy-temp-path=/usr/local/nginx/temp/proxy --http-fastcgi-temp-path=/usr/local/nginx/temp/fastcgi --http-uwsgi-temp-path=/usr/local/nginx/temp/uwsgi --http-scgi-temp-path=/usr/local/nginx/temp/scgi --with-http_stub_status_module --with-http_ssl_module --with-http_gzip_static_module --with-file-aio --with-http_realip_module# 启动/usr/local/nginx/sbin/nginx# 检查是否启动ps -ef|grep nginx# root 26063 1 0 14:14 ? 00:00:00 nginx: master process /usr/local/nginx/sbin/nginx# nobody 26064 26063 0 14:14 ? 00:00:00 nginx: worker process # root 26066 22818 0 14:15 pts/1 00:00:00 grep nginx# 关闭/usr/local/nginx/sbin/nginx -s stop# /usr/local/nginx/sbin/nginx -s quit# 重启/usr/local/nginx/sbin/nginx -s reopen# 重新载入配置文件 nginx.conf ，有失效的风险/usr/local/nginx/sbin/nginx -s reload# 检查配置文件 nginx.conf 的正确性/usr/local/nginx/sbin/nginx -t 启动后，访问 http://127.0.0.1 验证，效果如下： 3 配置 NginxNginx 参数配置优化 123vi /usr/local/nginx/conf/nginx.conf# ...... Nginx 教程合集 （微信左下方 阅读全文 可直达）。 Nginx 参数配置优化 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/03/05/nginx/nginx-install-linux/"},{"title":"Nginx 安装 - Windows","text":"手把手带你在 Windows 上安装 Nginx-1.16.0 。 123456789101112# 下载免安装版本的 Nginx# http://nginx.org/en/download.html# nginx-1.16.1.zip# 解压D:\\nginx-1.16.0# 修改配置文件（如果需要）D:\\nginx-1.16.0\\conf\\nginx.conf# 启动服务（如果需要，可加入系统服务）D:\\nginx-1.16.0\\nginx.exe Nginx 教程合集 （微信左下方 阅读全文 可直达）。 Nginx 参数配置优化 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/03/05/nginx/nginx-install-windows/"},{"title":"Nginx 配置 SSL 支持 HTTPS（自签证书）","text":"Nginx 配置 SSL ，使其支持 HTTPS（自签证书）。 1 检查 Nginx 是否支持 SSL1/usr/local/nginx/sbin/nginx -V 查看是否包含 --with-http_ssl_module 模块，如果没有，则需要在编译时指定或增加该模块。 未安装过 Nginx 具体安装步骤参考： Nginx 安装 - Linux 12# 只需要在 ./configure 时指定 ssl 模块--with-http_ssl_module 已安装过 Nginx 如果已经安装过 Nginx ，又不想重新安装，则可以单独添加 ssl 模块。 123456789101112131415161718192021222324252627282930313233343536# 关闭 Nginx/usr/local/nginx/sbin/nginx -s stop# 查看 Nginx 安装时的配置参数，复制备用/usr/local/nginx/sbin/nginx -V# configure arguments: --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_gzip_static_module ...# 进入 nginx-1.16.1 目录cd /usr/local/nginx-1.16.1# 重新执行 cofigure 命令，增加 ssl 模块的配置./configure \\--prefix=/usr/local/nginx \\--error-log-path=/usr/local/nginx/logs/error.log \\--http-log-path=/usr/local/nginx/logs/access.log \\--pid-path=/usr/local/nginx/logs/nginx.pid \\--lock-path=/usr/local/nginx/logs/nginx.lock \\--http-client-body-temp-path=/usr/local/nginx/temp/client-body \\--http-proxy-temp-path=/usr/local/nginx/temp/proxy \\--http-fastcgi-temp-path=/usr/local/nginx/temp/fastcgi \\--http-uwsgi-temp-path=/usr/local/nginx/temp/uwsgi \\--http-scgi-temp-path=/usr/local/nginx/temp/scgi \\--with-http_stub_status_module \\--with-http_ssl_module \\--with-http_gzip_static_module \\--with-file-aio \\--with-http_realip_module# 编译（不安装）make# 备份原来的 nginx 命令cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx-bak# 替换原来的 nginx 命令cp /usr/local/nginx-1.16.1/objs/nginx /usr/local/nginx/sbin/nginx 2 生成证书1234567891011121314151617# 创建存放证书的目录mkdir /usr/local/sslcd /usr/local/ssl# 创建服务器私钥，命令会让你输入一个口令。openssl genrsa -des3 -out server.key 1024# 再生成一个不带密码的（非必须）# openssl rsa -in server.key -out server-nopassword.key# 创建签名请求的证书（CSR）openssl req -new -key server.key -out server.csr# 标记证书使用上述私钥和 CSRopenssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt# 再生成一个不带密码的（非必须）# openssl x509 -req -days 365 -in server.csr -signkey server-nopassword.key -out server-nopassword.crt 3 配置 Nginx修改配置文件，开启 ssl ，并指定标记的证书和私钥。 1234567891011server { listen 80; server_name localhost; listen 443 ssl; ssl_certificate /usr/local/ssl/server-nopassword.crt; ssl_certificate_key /usr/local/ssl/server-nopassword.key; #rewrite ^(.*)$ https://$host$1 permanent; #...} 重启 Nginx ，此时 http 和 https 都支持。 Nginx 教程合集 （微信左下方 阅读全文 可直达）。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/05/22/nginx/nginx-ssl/"},{"title":"Nginx 实现 Tomcat 集群","text":"使用 Nginx 实现 Tomcat 集群。 1 准备工作 Nginx 版本：nginx-1.16.0 ，推荐使用 linux 版本。 下载地址：http://nginx.org/en/download.html 安装并启动成功。 Tomcat 版本：apache-tomcat-8.0.53-windows-x64 下载地址：http://tomcat.apache.org/download-70.cgi tomcat1（http-8080，webapp/test） tomcat2（http-8081，webapp/test） tomcat3（http-8082，webapp/test。包含静态资源 test/static/…，关于文件的上传和下载的请求会全部转发到这里，可以理解为一个文件服务器） 安装并分别启动成功。 2 配置 Nginx2.1 配置 nginx.conf编辑 Nginx 根目录下的 conf/nginx.conf 文件，配置如下（具体的参数配置说明和优化见下文）： 1234567891011121314151617181920212223242526272829303132333435363738394041worker_processes 1;events { multi_accept on; worker_connections 1024;}http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 120; upstream tomcat_test { server 127.0.0.1:8080 weight=1; server 127.0.0.1:8081 weight=1; } upstream tomcat_test_static { server 127.0.0.1:8082 weight=1; } server { listen 80; server_name localhost; location ~*/test/static/ { proxy_pass http://tomcat_test_static; } location / { proxy_pass http://tomcat_test; proxy_redirect default; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; proxy_next_upstream http_502 http_504 error timeout invalid_header; } }} 2.2 静态资源1234567891011121314# 静态资源服务器 location，正则匹配，~ 为区分大小写，~* 为不区分大小写location ~*/test/static/ { # 方法 1proxy_pass http://tomcat_test_static;# 方法 2：指定相对路径，相对 nginx 安装目录下的 mydata 为根目录 # 如 http://127.0.0.1/test/static/common/images/1.png 会映射到 nginx 安装目录 /mydata/test/static/common/images/1.png # root mydata; # 方法 3：指定绝对路径，注意 windows 系统下分隔符用 / # 如 http://127.0.0.1/test/static/common/images/1.png 会映射到 D:/apache-tomcat-8.0.53-8082/webapps/test/static/common/images/1.png # root D:/apache-tomcat-8.0.53-8082/webapps; # 开启目录浏览权限，默认是 off # autoindex on;} 2.3 参数配置优化 具体配置参考： Nginx 参数配置优化 3 配置 Tomcat编辑 Tomcat 根目录下的 conf/server.xml 文件，修改配置： 12&lt;!-- 添加 jvmRoute ，用于标识该 tomcat --&gt;&lt;Engine defaultHost=\"localhost\" name=\"Catalina\" jvmRoute=\"tomcat1\"&gt; 4 测试 在 Tomcat 根目录下的 webapps 下新建 test 目录，再在里面新建 test.jsp 文件： 1234567891011121314151617181920212223242526272829303132&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%&gt;&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;&lt;%@page import=\"java.util.*\"%&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Tomcat 集群测试&lt;/title&gt; &lt;meta http-equiv=\"pragma\" content=\"no-cache\"&gt; &lt;meta http-equiv=\"cache-control\" content=\"no-cache\"&gt;&lt;/head&gt;&lt;body&gt;&lt;% out.println(new Date() + \"&lt;br/&gt;\");out.println(\"[tomcat1:8080]\" + \"&lt;br/&gt;\");String sessionid = request.getSession().getId();out.println(\"sessionid:\" + sessionid + \"&lt;br/&gt;\");System.out.println(\"sessionid:\" + sessionid);out.println(\"=============================================&lt;br/&gt;\");Enumeration enu = request.getHeaderNames(); while(enu.hasMoreElements()){ String key = (String)enu.nextElement(); out.println(key + \":\" + request.getHeader(key) + \"&lt;br/&gt;\"); }out.println(\"=============================================&lt;br/&gt;\");out.println(\"request.remote:\"+request.getRemoteAddr()+\":\"+request.getRemotePort() + \"&lt;br/&gt;\");out.println(\"request.local:\"+request.getLocalAddr()+\":\"+request.getLocalPort() + \"&lt;br/&gt;\");out.println(\"=============================================&lt;br/&gt;\");%&gt;&lt;/body&gt;&lt;/html&gt; 再在里面新建 WEB-INF/web.xml 文件： 12345&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://java.sun.com/xml/ns/j2ee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_5.xsd\" version=\"2.5\"&gt; &lt;display-name&gt;test&lt;/display-name&gt; &lt;distributable /&gt;&lt;/web-app&gt; test 目录如下： 通过 http://127.0.0.1/test/test.jsp 访问，查看页面与控制台。 通过 http://127.0.0.1/test/static/common/images/1.png 访问（ tomcat1、tomcat2、tomcat3 都有），查看静态资源与浏览器 Network 请求，最终访问 tomcat3 。 通过 http://127.0.0.1/test/static/common/images/2.png 访问（ tomcat3 有， tomcat1 和 tomcat2 没有），查看静态资源与浏览器 Network 请求，最终访问 tomcat3 。 5 其他说明5.1 Nginx 日志Nginx 根目录下的 logs 文件夹下： access.log：用于记录 Nginx 接收到请求以及响应状态的日志。 error.log：用于记录 Nginx 的运行错误。 nginx.pid：用于记录进程 pid 。 5.2 Tomcat 日志Tomcat 根目录下的 logs 文件夹下： localhost_access_log. 日期.txt：用于记录 Tomcat 接收到的请求以及响应的状态等，作用与 Apache 的 access.log 类似。 catalina. 日期.log：用于记录 Tomcat 启动时候控制台的一些信息以及服务端错误信息。 localhost. 日期.log：用于记录站点访问信息， Tomcat 下内部代码丢出的日志。 5.3 其他Nginx 常见问题 Nginx 教程合集 （微信左下方 阅读全文 可直达）。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/05/19/nginx/nginx-tomcat-cluster/"},{"title":"Nginx 添加到 Windows 系统服务","text":"借助第三方工具 WinSW 将 Nginx 添加到 Windows 系统服务，实现自启动。 1 准备工作WinSW 是一个可执行的二进制文件，可用于将自定义进程包装和管理为 Windows 服务。下载安装包后，可以重命名为任何名称，如： myService.exe 。 下载地址：https://github.com/kohsuke/winsw/releases，下载 .NET 对应的 exe 文件，如： WinSW.NET4.exe 。 2 配置 将 WinSW.NET4.exe 拷贝到 nginx 安装目录下，如：D:\\nginx-1.16.0 ，并重命名为 nginx-service.exe 。 在 nginx 安装目录下新建 nginx-service.xml 文件，如下： 1234567891011121314151617181920212223&lt;service&gt; &lt;!-- id 服务唯一标识 --&gt; &lt;id&gt;nginx&lt;/id&gt; &lt;!-- name 在 windowServer 中显示的名字 --&gt; &lt;name&gt;Nginx Service&lt;/name&gt; &lt;!-- description 描述 --&gt; &lt;description&gt;High Performance Nginx Service&lt;/description&gt; &lt;!-- logpath winsw 的日志输出地址 --&gt; &lt;logpath&gt;D:\\nginx-1.16.0\\logs-service&lt;/logpath&gt; &lt;!-- log 日志信息的配置 --&gt; &lt;log mode=\"roll-by-size\"&gt; &lt;sizeThreshold&gt;10240&lt;/sizeThreshold&gt; &lt;keepFiles&gt;8&lt;/keepFiles&gt; &lt;/log&gt; &lt;!-- executable windows 服务启动时要执行的命令 --&gt; &lt;executable&gt;D:\\nginx-1.16.0\\nginx.exe&lt;/executable&gt; &lt;!-- startarguments 启动时要带的参数 --&gt; &lt;startarguments&gt;-p D:\\nginx-1.16.0&lt;/startarguments&gt; &lt;!-- stopexecutable windows 服务停止时要执行的命令 --&gt; &lt;stopexecutable&gt;D:\\nginx-1.16.0\\nginx.exe&lt;/stopexecutable&gt; &lt;!-- stoparguments 停止时要带的参数 --&gt; &lt;stoparguments&gt;-p D:\\nginx-1.16.0 -s stop&lt;/stoparguments&gt;&lt;/service&gt; 在 nginx 安装目录下以管理员身份打开命令行，并执行： 1234# 安装服务nginx-service install# 卸载服务# nginx-service uninstall 之后在 Windows 系统服务中就能看到 Nginx Service 这个服务了，如下： Nginx 教程合集 （微信左下方 阅读全文 可直达）。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/03/02/nginx/nginx-windows-service/"},{"title":"Apache 实现 Tomcat 集群 - mod_jk（老版本）","text":"使用 Apache 实现 Tomcat 集群，采用 mod_jk 组件（老版本）。 1 准备工作 Apache 版本：httpd-2.4.23-x64 下载地址：http://httpd.apache.org/download.cgi Tomcat 版本：apache-tomcat-8.0.53-windows-x64 下载地址：http://tomcat.apache.org/download-70.cgi tomcat1（http-8080，ajp-9009，webapp/test） tomcat2（http-8081，ajp-9010，webapp/test） tomcat3（http-8082，ajp-9011，webapp/test） 安装并分别启动成功。 2 配置 Apache2.1 下载 mod_jk.so下载 mod_jk.so，放到 Apache 根目录下的 modules 文件夹下。 下载地址：http://tomcat.apache.org/download-connectors.cgi 2.2 配置 httpd.conf编辑 Apache 根目录下的 conf/httpd.conf 文件，增加配置如下： 1234567891011##### modify ######Include conf/mod_jk.conf# 加载 mod_jk.so 模块LoadModule jk_module modules/mod_jk.so# 加载 mod_jk.so 配置文件JkWorkersFile conf/workers.properties# 指定那些请求交给 tomcat 处理，\"controller\" 为在 workers.propertise 里指定的负载分配控制器，这里表示所有请求都是 Tomcat 处理JkMount /* controller 2.3 配置 workers.properties在 Apache 根目录下的 conf 下新建 workers.properties 文件，配置如下： 1234567891011121314151617181920212223242526# server# ===== 配置服务器集群列表 =====worker.list = controller,tomcat1,tomcat2# tomcat1# ===== 此名字对应 tomcat 中 server.xml &lt;Engine ...... jvmRoute=\"tomcat1\"&gt; =====worker.tomcat1.port=9009 # tomcat1 中 AJP 协议端口worker.tomcat1.host=localhost # tomcat 的主机地址，如不为本机，请填写 ip 地址worker.tomcat1.type=ajp13 # 指定 tomcat 与 apache 的通讯协议为 AJPworker.tomcat1.lbfactor=1 # 指定负载平衡因数，只有启用了负载平衡才有用。值越高，分得的请求越多# tomcat2# ===== 此名字对应 tomcat 中 server.xml &lt;Engine ...... jvmRoute=\"tomcat2\"&gt; =====worker.tomcat2.port=9010 # tomcat1 中 AJP 协议端口worker.tomcat2.host=localhost # tomcat 的主机地址，如不为本机，请填写 ip 地址worker.tomcat2.type=ajp13 # 指定 tomcat 与 apache 的通讯协议为 AJPworker.tomcat2.lbfactor=1 # 指定负载均衡因数，只有启用了负载均衡才有用。值越高，分得的请求越多# ===== controller，负载均衡控制器 =====worker.controller.type=lb# 指定分担请求的 tomcatworker.controller.balance_workers=tomcat1,tomcat2# 会话是否有粘性，false 表示无粘性，同一个会话的请求会到不同的 tomcat 中处理worker.controller.sticky_session=false# 当 sticky_session 设为 true 时，该参数才有意义。当一个节点蹦了，如果为 true ，那么服务器返回 500 错误给客户端，如果为 false ，则转发给其他的 tomcat ，但是会丢失会话信息# worker.controller.sticky_session_force=true 3 配置 Tomcat编辑 Tomcat 根目录下的 conf/server.xml 文件，修改配置： 123456&lt;!-- 修改 AJP 协议端口，与上面的 worker.properties 中 port 对应 --&gt;&lt;Connector port=\"9009\" protocol=\"AJP/1.3\" redirectPort=\"9443\"/&gt;&lt;!-- 添加 jvmRoute ，与上面的 worker.properties 中对应，集群时候用 --&gt;&lt;Engine defaultHost=\"localhost\" name=\"Catalina\" jvmRoute=\"tomcat1\"&gt;&lt;Cluster className=\"org.apache.catalina.ha.tcp.SimpleTcpCluster\"/&gt; 4 测试 在 Tomcat 根目录下的 webapps 下新建 test 目录，再在里面新建 test.jsp 文件： 1234567891011121314151617181920212223242526272829303132&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%&gt;&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;&lt;%@page import=\"java.util.*\"%&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Tomcat 集群测试&lt;/title&gt; &lt;meta http-equiv=\"pragma\" content=\"no-cache\"&gt; &lt;meta http-equiv=\"cache-control\" content=\"no-cache\"&gt;&lt;/head&gt;&lt;body&gt;&lt;% out.println(new Date() + \"&lt;br/&gt;\");out.println(\"[tomcat1:8080]\" + \"&lt;br/&gt;\");String sessionid = request.getSession().getId();out.println(\"sessionid:\" + sessionid + \"&lt;br/&gt;\");System.out.println(\"sessionid:\" + sessionid);out.println(\"=============================================&lt;br/&gt;\");Enumeration enu = request.getHeaderNames(); while(enu.hasMoreElements()){ String key = (String)enu.nextElement(); out.println(key + \":\" + request.getHeader(key) + \"&lt;br/&gt;\"); }out.println(\"=============================================&lt;br/&gt;\");out.println(\"request.remote:\"+request.getRemoteAddr()+\":\"+request.getRemotePort() + \"&lt;br/&gt;\");out.println(\"request.local:\"+request.getLocalAddr()+\":\"+request.getLocalPort() + \"&lt;br/&gt;\");out.println(\"=============================================&lt;br/&gt;\");%&gt;&lt;/body&gt;&lt;/html&gt; 再在里面新建 WEB-INF/web.xml 文件： 12345&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://java.sun.com/xml/ns/j2ee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_5.xsd\" version=\"2.5\"&gt; &lt;display-name&gt;test&lt;/display-name&gt; &lt;distributable /&gt;&lt;/web-app&gt; 通过 http://127.0.0.1/test/test.jsp 访问，查看页面与控制台。 5 其他说明5.1 mod_jk 与 mod_proxy Apache2.2 之前，主要用 mod_jk 组件，也比较稳定。 Apache2.2 之后，可用 Apache 自带的 mod_proxy 组件。 5.2 Apache 日志Apache 根目录下的 logs 文件夹下： access.log：用于记录 Apache 接收到请求以及响应状态的日志。 error.log：用于记录 Apache 的运行错误。 httpd.pid：用于记录进程 pid 。 mod_jk.log：用于记录请求转发给 Tomcat 的日志。 5.3 Tomcat 日志Tomcat 根目录下的 logs 文件夹下： localhost_access_log. 日期.txt：用于记录 Tomcat 接收到的请求以及响应的状态等，作用与 Apache 的 access.log 类似。 catalina. 日期.log：用于记录 Tomcat 启动时候控制台的一些信息以及服务端错误信息。 localhost. 日期.log：用于记录站点访问信息， Tomcat 下内部代码丢出的日志。 5.4 其他Apache 根目录下的 htdocs 文件夹的作用与 Tomcat 的 webapps 类似。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/05/05/other/apache-tomcat-cluster-mod-jk/"},{"title":"Apache 实现 Tomcat 集群 - mod_proxy（新版本）","text":"使用 Apache 实现 Tomcat 集群，采用 mod_proxy 组件（新版本）。 1 准备工作 Apache 版本：httpd-2.4.23-x64 下载地址：http://httpd.apache.org/download.cgi Tomcat 版本：apache-tomcat-8.0.53-windows-x64 下载地址：http://tomcat.apache.org/download-70.cgi tomcat1（http-8080，ajp-9009，webapp/test） tomcat2（http-8081，ajp-9010，webapp/test） tomcat3（http-8082，ajp-9011，webapp/test） 安装并分别启动成功。 2 配置 Apache2.1 配置 httpd.conf编辑 Apache 根目录下的 conf/httpd.conf 文件，配置如下： 1234567891011121314151617181920212223242526272829# 加载相关模块##### modify #####LoadModule access_compat_module modules/mod_access_compat.so##### modify #####LoadModule info_module modules/mod_info.so##### modify #####LoadModule lbmethod_bybusyness_module modules/mod_lbmethod_bybusyness.soLoadModule lbmethod_byrequests_module modules/mod_lbmethod_byrequests.soLoadModule lbmethod_bytraffic_module modules/mod_lbmethod_bytraffic.soLoadModule lbmethod_heartbeat_module modules/mod_lbmethod_heartbeat.so##### modify #####LoadModule proxy_module modules/mod_proxy.soLoadModule proxy_ajp_module modules/mod_proxy_ajp.soLoadModule proxy_balancer_module modules/mod_proxy_balancer.soLoadModule proxy_connect_module modules/mod_proxy_connect.so# LoadModule proxy_express_module modules/mod_proxy_express.so# LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.soLoadModule proxy_ftp_module modules/mod_proxy_ftp.so# LoadModule proxy_html_module modules/mod_proxy_html.soLoadModule proxy_http_module modules/mod_proxy_http.so##### modify #####LoadModule slotmem_shm_module modules/mod_slotmem_shm.so##### modify #####LoadModule status_module modules/mod_status.so 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# 增加相关配置##### modify #####ProxyRequests Off# Header add Set-Cookie \"ROUTEID=.%{BALANCER_WORKER_ROUTE}e; path=/\" env=BALANCER_ROUTE_CHANGED# ---------- apache 监控 - 开始 -----------# 过滤 server-stauts 监控页面，需要放在 &lt;Proxy balancer://cluster&gt; 前面ProxyPass /server-status ! # 过滤 balancer-manager 监控页面ProxyPass /balancer-manager ! # 设置 server-stauts 监控页面&lt;Location /server-status&gt; SetHandler server-status Order Deny,Allow Deny from all Allow from 127.0.0.1&lt;/Location&gt;# 设置 balancer-manager 监控页面&lt;Location /balancer-manager&gt; SetHandler balancer-manager Order Deny,Allow Deny from all Allow from 127.0.0.1&lt;/Location&gt;# ---------- apache 监控 - 结束 ----------ProxyPassReverse / balancer://cluster/&lt;Proxy balancer://cluster&gt; BalancerMember ajp://127.0.0.1:9009 loadfactor=1 route=tomcat1 retry=30 BalancerMember ajp://127.0.0.1:9010 loadfactor=1 route=tomcat2 retry=30 # 负载均衡方式，默认为 byrequests （进行加权请求计数） ProxySet lbmethod=byrequests&lt;/Proxy&gt;# 请求映射过滤规则配置 # 过滤静态资源， apache 直接返回，不到 tomcat 请求ProxyPassMatch ^/?[\\S]*/test/static !ProxyPass / balancer://cluster/ stickysession=JSESSIONID|jsessionid scolonpathdelim=On&lt;IfModule mpm_winnt_module&gt; ThreadLimit 4000 ThreadsPerChild 3840 MaxRequestsPerChild 0&lt;/IfModule&gt;AddDefaultCharset offTimeout 60KeepAlive OnKeepAliveTimeout 20MaxKeepAliveRequests 500 2.2 静态资源 在 Apache 根目录下的 htdocs 文件夹下增加 test/static/common/images、css、js 等静态文件。 12# 静态资源 apache 直接返回，不到 tomcat 请求ProxyPassMatch ^/\\S+/static ! 3 配置 Tomcat编辑 Tomcat 根目录下的 conf/server.xml 文件，修改配置： 12345&lt;!-- 修改 AJP 协议端口，与上面的 worker.properties 中 port 对应 --&gt;&lt;Connector port=\"9009\" protocol=\"AJP/1.3\" redirectPort=\"9443\"/&gt;&lt;!-- 添加 jvmRoute ，与上面的 httpd.conf 中对应，集群时候用 --&gt;&lt;Engine defaultHost=\"localhost\" name=\"Catalina\" jvmRoute=\"tomcat1\"&gt; 4 测试 在 Tomcat 根目录下的 webapps 下新建 test 目录，再在里面新建 test.jsp 文件： 1234567891011121314151617181920212223242526272829303132&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%&gt;&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;&lt;%@page import=\"java.util.*\"%&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Tomcat 集群测试&lt;/title&gt; &lt;meta http-equiv=\"pragma\" content=\"no-cache\"&gt; &lt;meta http-equiv=\"cache-control\" content=\"no-cache\"&gt;&lt;/head&gt;&lt;body&gt;&lt;% out.println(new Date() + \"&lt;br/&gt;\");out.println(\"[tomcat1:8080]\" + \"&lt;br/&gt;\");String sessionid = request.getSession().getId();out.println(\"sessionid:\" + sessionid + \"&lt;br/&gt;\");System.out.println(\"sessionid:\" + sessionid);out.println(\"=============================================&lt;br/&gt;\");Enumeration enu = request.getHeaderNames(); while(enu.hasMoreElements()){ String key = (String)enu.nextElement(); out.println(key + \":\" + request.getHeader(key) + \"&lt;br/&gt;\"); }out.println(\"=============================================&lt;br/&gt;\");out.println(\"request.remote:\"+request.getRemoteAddr()+\":\"+request.getRemotePort() + \"&lt;br/&gt;\");out.println(\"request.local:\"+request.getLocalAddr()+\":\"+request.getLocalPort() + \"&lt;br/&gt;\");out.println(\"=============================================&lt;br/&gt;\");%&gt;&lt;/body&gt;&lt;/html&gt; 再在里面新建 WEB-INF/web.xml 文件： 12345&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://java.sun.com/xml/ns/j2ee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_5.xsd\" version=\"2.5\"&gt; &lt;display-name&gt;test&lt;/display-name&gt; &lt;distributable /&gt;&lt;/web-app&gt; test 目录如下： 通过 http://127.0.0.1/test/test.jsp 访问，查看页面与控制台。 通过 http://127.0.0.1/test/static/common/images/1.png 访问（ apache 和 tomcat 都有），查看静态资源与浏览器 Network 请求，最终访问 apache 。 通过 http://127.0.0.1/test/static/common/images/2.png 访问（ apache 有， tomcat 没有），查看静态资源与浏览器 Network 请求，最终访问 apache 。 5 其他说明5.1 mod_jk 与 mod_proxy Apache2.2 之前，主要用 mod_jk 组件，也比较稳定。 Apache2.2 之后，可用 Apache 自带的 mod_proxy 组件。 5.2 Apache 日志Apache 根目录下的 logs 文件夹下： access.log：用于记录 Apache 接收到请求以及响应状态的日志。 error.log：用于记录 Apache 的运行错误。 httpd.pid：用于记录进程 pid 。 mod_jk.log：用于记录请求转发给 Tomcat 的日志。 5.3 Tomcat 日志Tomcat 根目录下的 logs 文件夹下： localhost_access_log. 日期.txt：用于记录 Tomcat 接收到的请求以及响应的状态等，作用与 Apache 的 access.log 类似。 catalina. 日期.log：用于记录 Tomcat 启动时候控制台的一些信息以及服务端错误信息。 localhost. 日期.log：用于记录站点访问信息， Tomcat 下内部代码丢出的日志。 5.4 其他Apache 根目录下的 htdocs 文件夹的作用与 Tomcat 的 webapps 类似。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/05/09/other/apache-tomcat-cluster-mod-proxy/"},{"title":"JVM 内存分析工具 - MAT","text":"MAT（Memory Analyzer Tools）是一个快速且功能丰富的 Java 堆分析器，可帮助您查找内存泄漏并减少内存消耗。使用 MAT 分析具有数亿个对象的高效堆转储，快速计算对象的保留大小，查看谁阻止垃圾收集器收集对象，运行报告以自动提取泄漏嫌疑者。 1 简介MAT 是一款非常强大的内存分析工具，在 Eclipse 中有相应的插件，同时也有单独的安装包。在进行内存分析时，只要获得了反映当前设备内存映像的 hprof 文件，通过 MAT 打开就可以直观地看到当前的内存信息。 2 使用 2.1 准备 MAT 下载独立版本的 MAT，下载地址：https://www.eclipse.org/mat/downloads.php，下载后解压。找到 MemoryAnalyzer.ini 文件，该文件里面有个 Xmx 参数，该参数表示最大内存占用量，默认为 1024m，根据堆转储文件大小修改该参数即可。 2.2 准备堆转储文件（Heap Dump）堆转储文件（Heap Dump）是 Java 进程在某个时间内的快照（.hprof 格式）。它在触发快照的时候保存了很多信息，如：Java 对象和类信息（通常在写堆转储文件前会触发一次 Full GC）。 堆转储文件信息： 所有的对象信息，包括对象实例、成员变量、存储于栈中的基本类型值和存储于堆中的其他对象的引用值。 所有的类信息，包括 classloader、类名称、父类、静态变量等。 GC Root 到所有的这些对象的引用路径。 线程信息，包括线程的调用栈及此线程的线程局部变量（TLS）。 多种方式获取堆转储文件： 通过 jmap 命令可以在 cmd 里执行：jmap -dump:format=b,file=&lt; 文件名.hprof&gt; &lt;pid&gt;。 如果想在发生内存溢出的时候自动 dump，需要添加下面 JVM 参数：-XX:+HeapDumpOnOutOfMemoryError。 使用 Ctrl+Break 组合键主动获取获取，需要添加下面 JVM 参数：-XX:+HeapDumpOnCtrlBreak。 使用 HPROF Agent 可以在程序执行结束时或受到 SIGOUT 信号时生成 Dump 文件，配置在虚拟机的参数如下：-agentlib:hprof=heap=dump,format=b。 使用 JConsole 获取。 使用 Memory Analyzer Tools 的 File -&gt; Acquire Heap Dump 功能获取。 2.3 分析堆转储文件 打开 MAT 之后，加载 dump 文件，差不多就下面这样的界面： 常用的两个功能：Histogram、 Leak Suspects。 2.3.1 Histogram Histogram 可以列出内存中的对象，对象的个数及其内存大小，可以用来定位哪些对象在 Full GC 之后还活着，哪些对象占大部分内存。 Class Name：类名称，Java 类名。 Objects：类的对象的数量，这个对象被创建了多少个。 Shallow Heap：对象本身占用内存的大小，不包含其引用的对象内存，实际分析中作用不大。常规对象（非数组）的 Shallow Size 由其成员变量的数量和类型决定。数组的 Shallow Size 由数组元素的类型（对象类型、基本类型）和数组长度决定。对象成员都是些引用，真正的内存都在堆上，看起来是一堆原生的 byte[], char[], int[]，对象本身的内存都很小。 Retained Heap：计算方式是将 Retained Set（当该对象被回收时那些将被 GC 回收的对象集合）中的所有对象大小叠加。或者说，因为 X 被释放，导致其它所有被释放对象（包括被递归释放的）所占的 heap 大小。Retained Heap 可以更精确的反映一个对象实际占用的大小。 Retained Heap 例子：一个 ArrayList 对象持有 100 个对象，每一个占用 16 bytes，如果这个 list 对象被回收，那么其中 100 个对象也可以被回收，可以回收 16*100 + X 的内存，X 代表 ArrayList 的 shallow 大小。 在上述列表中选择一个 Class，右键选择 List objects &gt; with incoming references，在新页面会显示通过这个 class 创建的对象信息。 继续选择一个对象，右键选择 Path to GC Roots &gt; **** ，通常在排查 内存泄漏（一般是因为存在无效的引用）的时候，我们会选择 exclude all phantom/weak/soft etc.references，意思是查看排除虚引用 / 弱引用 / 软引用等的引用链，因为被虚引用 / 弱引用 / 软引用的对象可以直接被 GC 给回收，我们要看的就是某个对象否还存在 Strong 引用链（在导出 Heap Dump 之前要手动触发 GC 来保证），如果有，则说明存在内存泄漏，然后再去排查具体引用。 这时会 拿到 GC Roots 到该对象的路径 ，通过对象之间的引用，可以清楚的看出这个对象没有被回收的原因，然后再去定位问题。如果上面对象此时本来应该是被 GC 掉的，简单的办法就是将其中的某处置为 null 或者 remove 掉，使其到 GC Root 无路径可达，处于不可触及状态，垃圾回收器就可以回收了。 反之，一个存在 GC Root 的对象是不会被垃圾回收器回收掉的。 2.3.2 Leak Suspects Leak Suspects 可以自动分析并提示可能存在的内存泄漏，可以直接定位到 Class 及对应的行数。 比如：这里问题一的描述，列出了一些比较大的实例。点击 Details 可以看到细节信息，另外还可点击 See stacktrace 查看具体的线程栈信息（可直接定位到具体某个类中的方法）。 在 Details 详情页面 Shortest Paths To the Accumulation Point 表示 GC root 到内存消耗聚集点的最短路径，如果某个内存消耗聚集点有路径到达 GC root，则该内存消耗聚集点不会被当做垃圾被回收。 实战：在某项目中，其中几个 Tomcat 响应特别慢，打开 Java VisualVM 观察 Tomcat（pid xxx）-Visual GC 发现 Spaces-Old 升高，Graphs-GC Time 比较频繁且持续时间长、有尖峰（重启后过段时间又出现了），最后通过 Leak Suspects 中的 See stacktrace 定位到某个查询接口，仔细排查代码后发现有个 BUG：在特定查询条件下会一次性查询几万的数据出来（因为脏数据），处理过后恢复正常。 2.3.3 内存快照对比 为了更有效率的找出内存泄露的对象，一般会获取两个堆转储文件（先 dump 一个，隔段时间再 dump 一个），通过对比后的结果可以很方便定位。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/11/01/other/mat/"},{"title":"MyBatis 主键回填","text":"两种方式实现 MyBatis 主键回填。 方式一： useGeneratedKeys123&lt;insert id=\"insert\" parameterType=\"com.xxx.model.User\" useGeneratedKeys=\"true\" keyProperty=\"id\"&gt; insert into t_user (username, phone) values (#{username}, #{phone});&lt;/insert&gt; 通过在 insert 节点上增加 useGeneratedKeys 和 keyProperty 属性来实现，这样通过传入一个对象执行插入操作，插入完成后，这个对象的 id 就会被自动赋值， 推荐使用这种方式 。 方式二： LAST_INSERT_ID123456&lt;insert id=\"insert\" parameterType=\"com.xxx.model.User\"&gt; &lt;selectKey keyProperty=\"id\" resultType=\"java.lang.Integer\"&gt; SELECT LAST_INSERT_ID() &lt;/selectKey&gt; insert into t_user (username, phone) values (#{username}, #{phone});&lt;/insert&gt; 通过在 insert 节点内增加 selectKey 节点来实现，LAST_INSERT_ID() 函数是 MySQL 自带的，可以查询刚刚插入的 id 。其实这种方式更加灵活，因为 selectKey 节点中的 SQL 可以控制在插入之前 / 之后执行（通过设置节点的 Order 属性为 AFTER 或者 BEFORE 可以实现）。 注意：这种方式也要设置 keyProperty 来指定将查询到的数据绑定到哪个属性上。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/02/16/other/mybatis-key/"},{"title":"POI 操作手册","text":"通过本文认识 POI ，并学习 Excel/Word/… 等类型文档的操作。 1 POI 简介POI 是 Apache 下的 Jakata 项目的一个子项目，主要用于提供 java 操作 Microsoft Office 办公套件如 Excel，Word，Powerpoint 等文件的 API 。 微软的 Office 办公软件在企业的日常办公中占据着重要的地位，人们已经非常熟悉 Office 的使用。在我们开发的应用系统中，常常需要将数据导出到 Excel 文件中，或者 Word 文件中进行打印。比如移动的话费查询系统中就提供了将话费清单导入到 excel 表格中的功能。这样在 web 应用中，我们在浏览器中看到的数据可以被导出到 Excel 中了。 Excel 文件： xls 格式文件对应 POI API 为 HSSF。xlsx 格式为 office 2007 的文件格式，POI 中对应的 API 为 XSSF。 Word 文件：doc 格式文件对应的 POI API 为 HWPF 。 docx 格式为 XWPF 。 PowerPoint 文件：ppt 格式对应的 POI API 为 HSLF 。 pptx 格式为 XSLF 。 Outlook 文件：对应的 API 为 HSMF 。 Visio 文件：对应的 API 为 HDGF 。 Publisher 文件：对应的 API 为 HPBF 。 下载地址：http://poi.apache.org/download.html 2 Excel 操作手册 一个 Excel 文档称为工作簿（worksheet），一个工作簿包含多个工作表（sheet），每个工作表看起来像一张二维表格，由很多行（row）组成，每行由多个单元格组成（cell）。 POI HSSF API 中的类 Excel 结构 HSSFWorkbook 工作簿 HSSFSheet 工作表 HSSFRow 行 HSSFCell 单元格 HSSFCellStyle 单元格样式 HSSFFont 字体 HSSFDataFormat 单元格日期格式 HSSFHeader sheet 的页眉 HSSFFooter sheet 的页脚 HSSFDateUtil 日期 HSSFPrintSetup 打印 HSSFErrorConstants 错误信息表 3 Word 操作手册4 PowerPoint 操作手册5 Outlook 操作手册6 Visio 操作手册7 Publisher 操作手册 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/04/23/other/poi/"},{"title":"分布式任务调度与计算中心 PowerJob","text":"PowerJob 是全新一代 分布式任务调度与计算框架，能让您轻松完成作业的调度与繁杂任务的分布式计算。 1 简介1.1 主要特性 使用简单：提供前端 Web 界面，允许开发者可视化地完成调度任务的管理（增、删、改、查）、任务运行状态监控和运行日志查看等功能。 定时策略完善：支持 CRON 表达式、固定频率、固定延迟和 API 四种定时调度策略。 执行模式丰富：支持单机、广播、Map、MapReduce 四种执行模式，其中 Map/MapReduce 处理器能使开发者寥寥数行代码便获得集群分布式计算的能力。 DAG 工作流支持：支持在线配置任务依赖关系，可视化得对任务进行编排，同时还支持上下游任务间的数据传递。 执行器支持广泛：支持 Spring Bean、内置 / 外置 Java 类、Shell、Python 等处理器，应用范围广。 运维便捷：支持 在线日志 功能，执行器产生的日志可以在前端控制台页面实时显示，降低 debug 成本，极大地提高开发效率。 依赖精简：最小仅依赖关系型数据库（MySQL/Oracle/MS SQLServer…），扩展依赖为 MongoDB （用于存储庞大的在线日志）。 高可用 &amp; 高性能：调度服务器经过精心设计，一改其他调度框架基于数据库锁的策略，实现了无锁化调度。部署多个调度服务器可以同时实现高可用和性能的提升（支持无限的水平扩展）。 故障转移与恢复：任务执行失败后，可根据配置的重试策略完成重试，只要执行器集群有足够的计算节点，任务就能顺利完成。 1.2 适用场景 有定时执行需求的业务场景：如每天凌晨全量同步数据、生成业务报表等。 有需要全部机器一同执行的业务场景：如使用广播执行模式清理集群日志。 有需要分布式处理的业务场景：比如需要更新一大批数据，单机执行耗时非常长，可以使用 Map/MapReduce 处理器完成任务的分发，调动整个集群加速计算。 有需要延迟执行某些任务的业务场景：比如订单过期处理等。 1.3 设计目标 PowerJob 的设计目标为 企业级的分布式任务调度平台 ，即成为公司内部的 任务调度中间件。整个公司统一部署调度中心 powerjob-server，旗下所有业务线应用只需要依赖 powerjob-worker 即可接入调度中心获取任务调度与分布式计算能力。 1.4 在线试用 试用地址：http://192.168.71.53:7700/ 应用名称：powerjob-worker-samples 密码：123 1.5 同类产品对比 QuartZ xxl-job SchedulerX 2.0 PowerJob 定时类型 CRON CRON CRON、固定频率、固定延迟、OpenAPI CRON、固定频率、固定延迟、OpenAPI 任务类型 内置 Java 内置 Java、GLUE Java、Shell、Python 等脚本 内置 Java、外置 Java（FatJar）、Shell、Python 等脚本 内置 Java、外置 Java（容器）、Shell、Python 等脚本 分布式任务 无 静态分片 MapReduce 动态分片 MapReduce 动态分片 在线任务治理 不支持 支持 支持 支持 日志白屏化 不支持 支持 不支持 支持 调度方式及性能 基于数据库锁，有性能瓶颈 基于数据库锁，有性能瓶颈 不详 无锁化设计，性能强劲无上限 报警监控 无 邮件 短信 邮件和钉钉（另外开发者可基于接口方便扩展，如：短信） 系统依赖 JDBC 支持的关系型数据库（MySQL、Oracle…） MySQL 人民币 任意 Spring Data Jpa 支持的关系型数据库（MySQL、Oracle…） DAG 工作流 不支持 不支持 支持 支持 2 基本概念2.1 分组概念 appName：应用名称，建议与用户实际接入 PowerJob 的应用名称保持一致，用于业务分组与隔离，一个 appName 等于一个业务集群，也就是实际的一个 Java 项目。 2.2 核心概念 任务（Job）：描述了需要被 PowerJob 调度的任务信息，包括任务名称、调度时间、处理器信息等。 任务实例（JobInstance，简称 Instance）：任务（Job）被调度执行后会生成任务实例（Instance），任务实例记录了任务的运行时信息（任务与任务实例的关系类似于类与对象的关系）。 作业（Task）：任务实例的执行单元，一个 JobInstance 存在至少一个 Task，具体规则如下： 单机任务（STANDALONE）：一个 JobInstance 对应一个 Task。 广播任务（BROADCAST）：一个 JobInstance 对应 N 个 Task，N 为集群机器数量，即每一台机器都会生成一个 Task。 Map/MapReduce 任务：一个 JobInstance 对应若干个 Task，由开发者手动 map 产生。 工作流（Workflow）：由 DAG（有向无环图）描述的一组任务（Job），用于任务编排。 工作流实例（WorkflowInstance）：工作流被调度执行后会生成工作流实例，记录了工作流的运行时信息。 2.3 扩展概念 容器：以 Maven 工程项目的维度组织一堆 Java 文件（开发者开发的众多 Java 处理器），可以通过前端网页动态发布并被执行器加载，具有极强的扩展能力和灵活性。 OpenAPI：允许开发者通过接口来完成手工的操作，让系统整体变得更加灵活。开发者可以基于 API 便捷地扩展 PowerJob 原有的功能。 2.4 定时任务类型 API：该任务只会由 powerjob-client 中提供的 OpenAPI 接口触发，server 不会主动调度。 CRON：该任务的调度时间由 CRON 表达式指定。 固定频率：秒级任务，每隔多少毫秒运行一次，功能与 java.util.concurrent.ScheduledExecutorService#scheduleAtFixedRate 相同。 固定延迟：秒级任务，延迟多少毫秒运行一次，功能与 java.util.concurrent.ScheduledExecutorService#scheduleWithFixedDelay 相同。 工作流：该任务只会由其所属的工作流调度执行，server 不会主动调度该任务。如果该任务不属于任何一个工作流，该任务就不会被调度。 备注：固定延迟和固定频率任务统称秒级任务，这两种任务无法被停止，只有任务被关闭或删除时才能真正停止任务。 3 项目地址 PowerJob 主项目：https://github.com/KFCFans/PowerJob PowerJob 前端项目：https://github.com/PowerJob/PowerJob-Console PowerJob 官网项目：https://github.com/PowerJob/Official-Website 4 项目结构说明 本项目由主体项目（PowerJob）和前端项目（PowerJob-Console）构成，其中 PowerJob 各模块说明如下： 123456789├── LICENSE├── powerjob-client // powerjob-client，普通 Jar 包，提供 OpenAPI├── powerjob-common // 各组件的公共依赖，开发者无需感知├── powerjob-server // powerjob-server，基于 SpringBoot 实现的调度服务器├── powerjob-worker // powerjob-worker, 普通 Jar 包，接入 powerjob-server 的应用需要依赖该 Jar 包├── powerjob-worker-agent // powerjob-agent，可执行 Jar 文件，可直接接入 powerjob-server 的代理应用├── powerjob-worker-samples // 教程项目，包含了各种 Java 处理器的编写样例├── others└── pom.xml 5 交流与讨论 QQ 群： 微信群： 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/06/07/other/powerjob/"},{"title":"Tomcat 集群","text":"多种方式实现 Tomcat 集群。 1 概述 1.1 集群能带来什么 提高服务的性能，例如计算处理能力、并发能力等，以及实现服务的高可用性。 提供项目架构的横向扩展能力，增加集群中的机器就能提高集群的性能。 提升对静态文件的处理性能。 利用 Web 服务器来做负载均衡以及容错。 无缝的升级应用程序。 1.2 集群实现方式 Tomcat 集群的实现方式有多种，最简单的就是通过 Nginx 负载进行请求转发来实现。 session 共享问题。 1.3 集群解决方案 采用 Nginx 中的 ip hash policy 来保持某个 ip 始终连接在某一个机器上 优点：可以不改变现有的技术架构，直接实现横向扩展，省事。但是缺陷也很明显，在实际的生产环境中，极少使用这种方式 缺点：1. 单止服务器请求（负载）不均衡，这是完全依赖 ip hash 的结果。2. 客户机 ip 动态变化频繁的情况下，无法进行服务，因为可能每次的 ip hash 都不一样，就无法始终保持只连接在同一台机器上。 采用 redis 或 memchche 等 nosql 数据库，实现一个缓存 session 的服务器，当请求过来的时候，所有的 Tomcat Server 都统一往这个服务器里读取 session 信息。这是企业中比较常用的一种解决方案，所以大致的 Tomcat 集群的架构图如下： 2 Apache2.1 mod_jk 组件（老版本） 具体配置见：Apache 实现 Tomcat 集群 - mod_jk（老版本） 2.2 mod_proxy 组件（新版本） 具体配置见：Apache 实现 Tomcat 集群 - mod_proxy（新版本） 3 Nginx（推荐） 具体配置见：Nginx 实现 Tomcat 集群（推荐） 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/05/02/other/tomcat-cluster/"},{"title":"Redis 常用命令","text":"通过本文学习 Redis 常用命令。 1 基本数据类型相关命令 参考 Redis 基本数据类型（字符串、列表、集合、散列、有序集合） 。 2 key 相关命令key 相关的命令，对不同的数据类型都通用。 del 以删除一个已经存在的 key 。 123456127.0.0.1:6379&gt; set k1 helloOK127.0.0.1:6379&gt; del k1(integer) 1127.0.0.1:6379&gt; get k1(nil) exists 检测一个给定的 key 是否存在。 123456127.0.0.1:6379&gt; set k1 helloOK127.0.0.1:6379&gt; exists k1(integer) 1127.0.0.1:6379&gt; exists k2(integer) 0 keys 获取满足给定模式的所有 key 。 keys * 表示获取所有的 key ， * 也可以是一个正则表达式。 123456789127.0.0.1:6379&gt; mset k1 hello k2 redis name cxy35OK127.0.0.1:6379&gt; keys *1) \"name\"2) \"k2\"3) \"k1\"127.0.0.1:6379&gt; keys k*1) \"k2\"2) \"k1\" ttl/pttl 查看 key 的有效期（秒 / 毫秒）。 -2 表示 key 不存在或者已过期， -1 表示 key 存在并且没有设置过期时间（永久有效）。默认为 -1 。 123456127.0.0.1:6379&gt; set k1 helloOK127.0.0.1:6379&gt; ttl k1(integer) -1127.0.0.1:6379&gt; ttl k2(integer) -2 expire/pexpire 给 key 设置有效期（秒 / 毫秒），在有效期过后，key 会被销毁。 12345678127.0.0.1:6379&gt; set k1 helloOK127.0.0.1:6379&gt; ttl k1(integer) -1127.0.0.1:6379&gt; expire k1 10(integer) 1127.0.0.1:6379&gt; ttl k1(integer) 6 persist 移除一个 key 的过期时间，这样该 key 就永远不会过期。 123456789101112127.0.0.1:6379&gt; set k1 helloOK127.0.0.1:6379&gt; ttl k1(integer) -1127.0.0.1:6379&gt; expire k1 30(integer) 1127.0.0.1:6379&gt; ttl k1(integer) 27127.0.0.1:6379&gt; persist k1(integer) 1127.0.0.1:6379&gt; ttl k1(integer) -1 dump 序列化给定的 key，并返回序列化之后的值。 1234127.0.0.1:6379&gt; set k1 helloOK127.0.0.1:6379&gt; dump k1\"\\x00\\x05hello\\t\\x00\\xb3\\x80\\x8e\\xba1\\xb2C\\xbb\" Redis 教程合集 （微信左下方 阅读全文 可直达）。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/06/01/redis/redis-command/"},{"title":"Redis 实现分布式锁","text":"本文学习在 Redis 中通过 String 实现分布式锁。 1 概述 业务场景：一个简单的用户操作，一个线程去修改用户的状态，首先从数据库中读出用户的状态，然后在内存中进行修改，修改完成后，再存回去。在单线程中，这个操作没有问题，但是在多线程中，由于读取、修改、存这是三个操作，不是原子操作，这样会出问题。 对于这种类似问题，我们可以使用分布式锁来限制程序的并发执行。分布式锁实现的思路很简单，就是进来一个线程先占位，当别的线程进来操作时，发现已经有人占位了，就会放弃或者稍后再试。 2 基本使用Redis 作为分布式锁，我们可以使用 String 数据结构来实现，通过 setnx 命令来占位，先进来的线程先占位，线程的操作执行完成后，再调用 del 指令释放位置。 12345678910111213141516@Testpublic void testDistributedLock() { Redis redis = new Redis(); redis.execute(jedis -&gt; { Long setnx = jedis.setnx(\"k1\", \"v1\"); if (setnx == 1) { // 没人占位 jedis.set(\"name\", \"cxy35\"); String name = jedis.get(\"name\"); System.out.println(name); jedis.del(\"k1\");// 释放资源 } else { // 有人占位，停止 / 暂缓操作 } });} 上面的代码存在一个问题：如果代码业务执行的过程中抛异常或者挂了，这样会导致 del 指令没有被调用，这样，k1 无法释放，后面来的请求全部堵塞在这里，锁也永远得不到释放。 要解决这个问题，我们可以给锁添加一个过期时间，确保锁在一定的时间之后，能够得到释放。改进后的代码如下： 123456789101112131415161718@Testpublic void testDistributedLock2() { Redis redis = new Redis(); redis.execute(jedis -&gt; { Long setnx = jedis.setnx(\"k1\", \"v1\"); if (setnx == 1) { // 给锁添加一个过期时间，防止应用在运行过程中抛出异常导致锁无法及时得到释放 jedis.expire(\"k1\", 5); // 没人占位 jedis.set(\"name\", \"cxy35\"); String name = jedis.get(\"name\"); System.out.println(name); jedis.del(\"k1\");// 释放资源 } else { // 有人占位，停止 / 暂缓操作 } });} 这样改造之后，还有一个问题，就是在获取锁和设置过期时间之间，如果服务器突然挂掉了，这个时候锁被占用，无法及时得到释放，也会造成死锁，因为获取锁和设置过期时间是两个操作，不具备原子性。 为了解决这个问题，从 Redis 2.8 开始， setnx 和 expire 可以通过一个命令一起来执行了，我们对上述代码再做改进： 12345678910111213141516@Testpublic void testDistributedLock3() { Redis redis = new Redis(); redis.execute(jedis -&gt; { String set = jedis.set(\"k1\", \"v1\", new SetParams().nx().ex(5)); if (\"OK\".equals(set)) { // 没人占位 jedis.set(\"name\", \"cxy35\"); String name = jedis.get(\"name\"); System.out.println(name); jedis.del(\"k1\");// 释放资源 } else { // 有人占位，停止 / 暂缓操作 } });} 3 使用 Lua 脚本解决超时问题 在上述代码中，为了防止业务代码在执行的时候抛出异常，我们给每一个锁添加了一个超时时间，超时之后，锁会被自动释放，但是这也带来了一个新的问题：如果要执行的业务非常耗时，可能会出现紊乱。举个例子：第一个线程首先获取到锁，然后开始执行业务代码，但是业务代码比较耗时，执行了 8 秒，这样，会在第一个线程的任务还未执行成功锁就会被释放了，此时第二个线程会获取到锁开始执行，在第二个线程刚执行了 3 秒，第一个线程也执行完了，此时第一个线程会释放锁，但是注意，它释放的第二个线程的锁，释放之后，第三个线程进来。 对于这个问题，我们可以从两个角度入手： 尽量避免在获取锁之后，执行耗时操作。 可以在锁上面做文章，将锁的 value 设置为一个随机字符串，每次释放锁的时候，都去比较随机字符串是否一致，如果一致，再去释放，否则，不释放。 对于第二种方案，由于释放锁的时候，要去查看锁的 value，第二步比较 value 的值是否正确，第三步释放锁，有三个步骤，很明显三个步骤不具备原子性，为了解决这个问题，我们得引入 Lua 脚本。 Lua 脚本的优势： 使用方便，Redis 中内置了对 Lua 脚本的支持。 Lua 脚本可以在 Redis 服务端原子的执行多个 Redis 命令。 由于网络在很大程度上会影响到 Redis 性能，而使用 Lua 脚本可以让多个命令一次执行，可以有效解决网络给 Redis 带来的性能问题。在 Redis 中，使用 Lua 脚本，大致上有两种思路： 提前在 Redis 服务端写好 Lua 脚本，然后在 Java 客户端去调用脚本（推荐）。 可以直接在 Java 端去写 Lua 脚本，写好之后，需要执行时，每次将脚本发送到 Redis 上去执行。 首先在 Redis 服务端创建 Lua 脚本，内容如下： 123456789cd /usr/local/redis-5.0.8mkdir luavi releasewherevalequal.luaif redis.call(\"get\", KEYS[1]) == ARGV[1] then return redis.call(\"del\", KEYS[1])else return 0end 接下来，可以给 Lua 脚本求一个 SHA1 和，命令如下： 12cat lua/releasewherevalueequal.lua | redis-cli -a 123456 script load --pipe\"b8059ba43af6ffe8bed3db65bac35d452f8115d8\" 上述 script load 会在 Redis 服务器中缓存 Lua 脚本，并返回脚本内容的 SHA1 校验和，然后在 Java 端调用时，传入 SHA1 校验和作为参数，这样 Redis 服务端就知道执行哪个脚本了。 接下来，在 Java 端调用这个脚本。 1234567891011121314151617181920212223@Testpublic void testDistributedLock4ByLua() { Redis redis = new Redis(); for (int i = 0; i &lt; 2; i++) { redis.execute(jedis -&gt; { // 1. 先获取一个随机字符串 String value = UUID.randomUUID().toString(); // 2. 获取锁 String set = jedis.set(\"k1\", value, new SetParams().nx().ex(5)); // 3. 判断是否成功拿到锁 if (\"OK\".equals(set)) { // 4. 具体的业务操作 jedis.set(\"name\", \"cxy35\"); String name = jedis.get(\"name\"); System.out.println(name); // 5. 调用对应的 Lua 脚本释放锁 jedis.evalsha(\"b8059ba43af6ffe8bed3db65bac35d452f8115d8\", Arrays.asList(\"k1\"), Arrays.asList(value)); } else { System.out.println(\"没拿到锁\"); } }); }} 执行结果如下： 12cxy35没拿到锁 Redis 教程合集 （微信左下方 阅读全文 可直达）。 本文示例代码：https://github.com/cxy35/samples/tree/master/redis/redis-jedis 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/06/26/redis/redis-distributedlock/"},{"title":"Redis 实现 UV 统计","text":"本文学习在 Redis 中通过 HyperLogLog 实现 UV 统计。 1 概述 一般我们评估一个网站的访问量，有几个主要的参数：PV（Page View）网页的浏览量、UV（User View）访问的用户量。有很多第三方工具可以统计，如 cnzz，友盟等。如果自己实现的话，PV 比较简单，可以直接通过 Redis 计数器实现。但是 UV 就不一样，UV 涉及到去重的问题。 常规思路：我们首先需要在前端给每一个用户生成一个唯一 id，无论是登录用户还是未登录用户都需要，这个 id 伴随着请求一起到达后端，在后端我们可以通过 Set 数据结构中的 sadd 命令来存储这个 id，最后通过 scard 统计集合大小，进而得出 UV 数据。 按上述思路，如果是千万级别的 UV，需要的存储空间就非常惊人，用 Set 就不是很合适了。一般来说像 UV 统计这种，不需要特别精确，比如 800W 和 803W 的 UV，其实差别不大。因此，我们可以使用 HyperLogLog 来高效的实现。 2 基本使用Redis 中提供的 HyperLogLog 就是专门用来解决上述问题的，HyperLogLog 提供了一套不怎么精确但是够用的去重方案，会有误差，官方给出的误差数据是 0.81%，这对于 UV 的统计够用了。 HyperLogLog 主要提供了以下命令： pfadd：用来添加记录，类似于 sadd ，添加过程中，重复的记录会自动去重。 pfcount：则用来统计数据。 pfmerge：合并多个统计结果，在合并的过程中，会自动去重多个集合中重复的元素。 数据量少的时候看不出来误差，我们在 Java 中多添加几个元素： 1234567891011121314public class HyperLogLogTest { @Test public void testHyperLogLog() { Redis redis = new Redis(); redis.execute(jedis -&gt; { for (int i = 0; i &lt; 1000; i++) { // 重复加入数据，理论值上总数为 1001 jedis.pfadd(\"uv\", \"u\" + i, \"u\" + (i + 1)); } long uv = jedis.pfcount(\"uv\"); System.out.println(uv); }); }} 理论值上总数为 1001，实际打印出来 994，有误差，但是在可以接受的范围内。 Redis 教程合集 （微信左下方 阅读全文 可直达）。 本文示例代码：https://github.com/cxy35/samples/tree/master/redis/redis-jedis 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/07/11/redis/redis-hyperloglog/"},{"title":"Redis 安装","text":"手把手带你使用多种姿势安装 Redis 。 1 简介Redis(Remote Dictionary Service) 是一个使用 ANSI C 编写的开源、支持网络、基于内存、可选持久性的键值对存储数据库。从 2015 年 6 月开始，Redis 的开发由 Redis Labs 赞助，而 2013 年 5 月至 2015 年 6 月期间，其开发由 Pivotal 赞助。在 2013 年 5 月之前，其开发由 VMware 赞助。根据月度排行网站 DB-Engines.com 的数据显示，Redis 是最流行的键值对存储数据库。 很多人想到 Redis ，就想到缓存。但实际上 Redis 除了缓存之外，还有许多更加丰富的使用场景，比如分布式锁、限流等。 主要有如下特点： Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，不会造成数据丢失。 Redis 支持多种不同的数据结构类型之间的映射，包括简单的 key/value 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。 Redis 支持 master-slave 模式的数据备份。 主要有如下功能： 内存存储和持久化：redis 支持异步将内存中的数据写到硬盘上，在持久化的同时不影响继续服务。 取最新 N 个数据的操作，如：可以将最新的 10 条评论的 ID 放在 Redis 的 List 集合里面。 数据可以设置过期时间。 自带发布、订阅消息系统。 定时器、计数器。 2 安装 主要有 4 种方式获取 Redis ： 编译安装（推荐）。 使用 Docker 安装。 直接安装。 在线体验。 2.1 编译安装（推荐）12345678910# 准备 gcc 环境yum install gcc-c++# 下载并安装cd /usr/localwget http://download.redis.io/releases/redis-5.0.8.tar.gztar -zxvf redis-5.0.8.tar.gzcd redis-5.0.8/makemake install 2.2 使用 Docker 安装Docker 安装好之后，启动 Docker ，直接运行安装命令即可： 1docker run --name redis -d -p 6379:6379 redis --requirepass 123456 Docker 上的 Redis 启动成功之后，可以从宿主机上连接（前提是宿主机上存在 redis-cli）： 1redis-cli -a 123456 如果宿主机上没有安装 Redis ，那么也可以进入到 Docker 容器中去操作 Redis: 1docker exec -it redis redis-cli -a 123456 2.3 直接安装 CentOS：yum install redis Ubuntu：apt-get install redis Mac：brew install redis 2.4 在线体验 在线体验地址：http://try.redis.io/ 3 启动 首先，修改 redis.conf 配置文件，将里面的 daemonize no 改成 daemonize yes，让服务在后台启动： 123vi /usr/local/redis-5.0.8/redis.confdaemonize yes 然后，通过 redis-server redis.conf 命令启动 Redis ，如下： 123cd /usr/local/redis-5.0.8redis-server redis.conf 4 连接 通过 redis-cli 命令进入到控制台，然后通过 ping 命令进行连通性测试，如果看到 pong ，表示连接成功了，如下： 123456cd /usr/local/redis-5.0.8redis-cli# 127.0.0.1:6379&gt; ping# PONG 如果在 redis.conf 配置文件配置了密码 requirepass 123456 ，则可通过 redis-cli -a 123456 连接。 也可以使用可视化工具来连接 Redis ，比如：Redis Desktop Manager 。 5 关闭 通过 shutdown 命令关闭 Redis ，如下： 123456cd /usr/local/redis-5.0.8redis-cli# 127.0.0.1:6379&gt; shutdown# not connected&gt; exit Redis 教程合集 （微信左下方 阅读全文 可直达）。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/05/26/redis/redis-install/"},{"title":"Redis 中的 Java 客户端（Jedis / Lettuce）","text":"本文学习使用 Java 客户端（Jedis / Lettuce） 操作 Redis 。 1 开启远程连接Redis 默认是不支持远程连接的，需要手动开启，修改 redis.conf ，主要有 3 个地方改动： 12345vi /usr/local/redis-5.0.8/redis.conf# bind 127.0.0.1protected-mode norequirepass 123456 之后重新启动 Redis 。 2 Jedis2.1 基本使用Jedis 的 GitHub 地址：https://github.com/xetorthio/jedis 。 首先创建一个普通的 Maven 项目 redis-jedis ，项目创建成功后，添加 Jedis 依赖： 123456789101112131415&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 然后创建一个测试类及测试方法： 123456789101112131415161718public class JedisTests { @Test public void testJedis() { // 1. 构造一个 Jedis 对象，因为这里使用的默认端口 6379，所以不用配置端口 Jedis jedis = new Jedis(\"192.168.71.62\"); // 2. 密码认证 jedis.auth(\"123456\"); // 3. 测试是否连接成功 String r = jedis.ping(); // 4. 返回 pong 表示连接成功 System.out.println(r); jedis.set(\"k1\", \"hellojedis\"); String v = jedis.get(\"k1\"); System.out.println(v); }} 在 Jedis 中，方法的 API 和 Redis 的命令高度一致，所以，Jedis 中的方法见名知意，直接使用即可。 2.2 连接池 因为 Jedis 对象不是线程安全的，所以在实际应用中，我们一般都是通过连接池来获取，使用完成之后，再还给连接池。 123456789101112131415161718192021@Testpublic void testJedisPool() { Jedis jedis = null; // 1. 构造一个 Jedis 连接池 JedisPool pool = new JedisPool(\"192.168.71.62\", 6379); // 2. 从连接池中获取一个 Jedis 连接 jedis = pool.getResource(); jedis.auth(\"123456\"); try { // 3.Jedis 操作 String r = jedis.ping(); System.out.println(r); } catch (Exception e) { e.printStackTrace(); } finally { // 4. 归还连接 if (jedis != null) { jedis.close(); } }} 上述代码中，我们使用了 try-catch-finally 来确保 jedis 对象被关闭，也可以使用 JDK1.7 中的 try-with-resources 来实现（代码看着比之前简洁），改造如下： 123456789@Testpublic void testJedisPool2() { JedisPool pool = new JedisPool(\"192.168.71.62\"); try (Jedis jedis = pool.getResource()) { jedis.auth(\"123456\"); String ping = jedis.ping(); System.out.println(ping); }} JedisPool 也可以使用 GenericObjectPoolConfig 来初始化，支持更丰富的配置，如下： 1234567891011121314151617@Testpublic void testJedisPool3() { GenericObjectPoolConfig config = new GenericObjectPoolConfig(); // 连接池最大空闲数 config.setMaxIdle(300); // 最大连接数 config.setMaxTotal(1000); // 连接最大等待时间，如果是 -1 表示没有限制 config.setMaxWaitMillis(30000); // 在空闲时检查有效性 config.setTestOnBorrow(true); JedisPool pool = new JedisPool(config, \"192.168.71.62\", 6379, Protocol.DEFAULT_TIMEOUT, \"123456\"); try (Jedis jedis = pool.getResource()) { String r = jedis.ping(); System.out.println(r); }} 2.3 封装 上面的代码无法实现强约束，下面我们可以做进一步的封装： 123public interface CallWithJedis { void call(Jedis jedis);} 1234567891011121314151617181920212223242526272829303132333435public class Redis { private JedisPool pool; public Redis() { GenericObjectPoolConfig config = new GenericObjectPoolConfig(); // 连接池最大空闲数 config.setMaxIdle(300); // 最大连接数 config.setMaxTotal(1000); // 连接最大等待时间，如果是 -1 表示没有限制 config.setMaxWaitMillis(30000); // 在空闲时检查有效性 config.setTestOnBorrow(true); /** * 1. Redis 地址 * 2. Redis 端口 * 3. 连接超时时间 * 4. 密码 */ pool = new JedisPool(config, \"192.168.71.62\", 6379, 30000, \"123456\"); } public void execute(CallWithJedis callWithJedis) { try (Jedis jedis = pool.getResource()) { callWithJedis.call(jedis); } } public static void main(String[] args) { Redis redis = new Redis(); redis.execute(jedis -&gt; { System.out.println(jedis.ping()); }); }} 3 LettuceLettuce 的 GitHub 地址：https://github.com/lettuce-io/lettuce-core 。 Lettuce 和 Jedis 的比较： Jedis 在实现的过程中是直接连接 Redis 的，在多个线程之间共享一个 Jedis 实例，这是线程不安全的，如果想在多线程场景下使用 Jedis ，就得使用连接池，这样，每个线程都有自己的 Jedis 实例。 Lettuce 基于目前很火的 Netty NIO 框架来构建，所以克服了 Jedis 中线程不安全的问题， Lettuce 支持同步、异步以及响应式调用，多个线程可以共享一个连接实例。 首先创建一个普通的 Maven 项目 redis-lettuce ，项目创建成功后，添加 Lettuce 依赖： 12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.lettuce&lt;/groupId&gt; &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt; &lt;version&gt;5.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 然后创建一个测试类及测试方法： 1234567891011public class LettuceTests { @Test public void testLettuce() { RedisClient redisClient = RedisClient.create(\"redis://123456@192.168.71.62\"); StatefulRedisConnection&lt;String, String&gt; connect = redisClient.connect(); RedisCommands&lt;String, String&gt; sync = connect.sync(); sync.set(\"k1\", \"hellolettuce\"); String v = sync.get(\"k1\"); System.out.println(v); }} Redis 教程合集 （微信左下方 阅读全文 可直达）。 本文示例代码：https://github.com/cxy35/samples/tree/master/redis/redis-jedis 本文示例代码：https://github.com/cxy35/samples/tree/master/redis/redis-lettuce 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/06/07/redis/redis-javaclient/"},{"title":"Redis 实现消息队列","text":"本文学习在 Redis 中通过 List/ZSet 实现消息队列。 1 概述 我们平时使用的消息队列有 RabbitMQ、RocketMQ、ActiveMQ 以及大数据里边的 Kafka，他们都非常专业，提供了很多功能。如果我们的需求或场景非常简单，用他们就有点大材小用了，比如我们只需要 1 个消息队列，且只有 1 个消费者，类似这种简单情况我们可以直接使用 Redis 来做消息队列。 2 基本使用2.1 消息队列Redis 作为消息队列，我们可以使用 List 数据结构来实现，通过 lpush/rpush 命令来实现入列， lpop/rpop 命令来实现出列。 在 Java 客户端，我们一般会维护一个死循环来不停的从队列中读取消息，并处理，如果队列中有消息，则直接获取到，如果没有消息，就会陷入死循环，直到下一次有消息进入，这种死循环会造成大量的资源浪费，这个时候，我们可以使用之前讲的 blpop/brpop 。 2.2 延迟消息队列Redis 作为延迟消息队列，我们可以使用 ZSet 数据结构来实现，因为 ZSet 中有一个 score，我们可以把时间作为 score，将 value 存到 redis 中，然后通过轮询的方式，去不断的读取消息出来。如果消息是一个字符串，直接发送即可，如果是一个对象，则需要对对象进行序列化，这里我们使用 JSON 来实现序列化和反序列化。 首先，在项目中，添加 JSON 依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.10.3&lt;/version&gt;&lt;/dependency&gt; 接着，构造一个消息对象： 12345678910111213141516171819202122232425262728public class MyMessage { private String id; private Object data; @Override public String toString() { return \"MyMessage{\" + \"id='\" + id + '\\'' + \", data=\" + data + '}'; } public String getId() { return id; } public void setId(String id) { this.id = id; } public Object getData() { return data; } public void setData(Object data) { this.data = data; }} 接着，封装一个延迟消息队列： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class MyDelayMq { private Jedis jedis; private String queue; public MyDelayMq(Jedis jedis, String queue) { this.jedis = jedis; this.queue = queue; } /** * 消息入列 * * @param data 要发送的消息 */ public void enqueue(Object data) { // 构造一个 MyMessage MyMessage msg = new MyMessage(); msg.setId(UUID.randomUUID().toString()); msg.setData(data); // 序列化 try { String s = new ObjectMapper().writeValueAsString(msg); System.out.println(\"send msg:\" + new Date()); // 消息发送，score 延迟 5 秒 jedis.zadd(queue, System.currentTimeMillis() + 5000, s); } catch (JsonProcessingException e) { e.printStackTrace(); } } /** * 消息出列 */ public void dequeue() { while (!Thread.interrupted()) { // 读取 score 在 0 到当前时间戳之间的消息 Set&lt;String&gt; zrange = jedis.zrangeByScore(queue, 0, System.currentTimeMillis(), 0, 1); if (zrange.isEmpty()) { // 如果消息是空的，则休息 500 毫秒然后继续 try { Thread.sleep(500); } catch (InterruptedException e) { break; } continue; } // 如果读取到了消息，则直接读取消息出来 String s = zrange.iterator().next(); if (jedis.zrem(queue, s) &gt; 0) { // 抢到了，接下来处理业务 try { MyMessage msg = new ObjectMapper().readValue(s, MyMessage.class); System.out.println(\"receive msg:\" + new Date() + \":\" + msg); } catch (JsonProcessingException e) { e.printStackTrace(); } } } }} 最后，新增测试类： 123456789101112131415161718192021222324252627282930313233343536373839public class DelayMqTest { @Test public void testDelayMq() { Redis redis = new Redis(); redis.execute(jedis -&gt; { // 构造一个消息队列 MyDelayMq queue = new MyDelayMq(jedis, \"mq-delay\"); // 构造消息生产者 Thread producer = new Thread() { @Override public void run() { for (int i = 0; i &lt; 5; i++) { queue.enqueue(\"http://cxy35.com &gt;&gt;&gt;&gt;\" + i); } } }; // 构造一个消息消费者 Thread consumer = new Thread() { @Override public void run() { queue.dequeue(); } }; // 启动 producer.start(); consumer.start(); // 休息 7 秒后，停止程序 try { Thread.sleep(7000); consumer.interrupt(); } catch (InterruptedException e) { e.printStackTrace(); } }); }} Redis 教程合集 （微信左下方 阅读全文 可直达）。 本文示例代码：https://github.com/cxy35/samples/tree/master/redis/redis-jedis 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/06/27/redis/redis-mq/"},{"title":"Spring Boot 通过 CORS 解决跨域问题","text":"学习在 Spring Boot 中通过 CORS 解决跨域问题。 1 介绍 先来了解下同源策略，它是由 Netscape 提出的一个著名的安全策略，是浏览器最核心，也最基本的安全功能，现在所有支持 JavaScript 的浏览器都会使用这个策略，同源是指协议、域名以及端口要相同。传统的跨域解决方案是 JSONP ， JSONP 虽然能解决跨域但是有一个很大的局限性，那就是只支持 GET 请求，不支持其他类型的请求。而 CORS （ Cross-origin resource sharing 跨域源资源共享）是一个 W3C 标准，它是一份浏览器技术的规范，提供了 Web 服务从不同网域传来沙盒脚本的方法，以避开浏览器的同源策略。 2 实战 新建 Spring Boot 工程 spring-boot-corsprovider ，用来提供服务，默认 8080 端口。新增测试类 HelloController ，如下： 123456789101112@RestControllerpublic class HelloController { @GetMapping(\"/get\") public String get() { return \"get\"; } @PutMapping(\"/put\") public String put() { return \"put\"; }} 新建 Spring Boot 工程 spring-boot-corsconsumer ，用来消费服务，配置 8081 端口。在 resources/static 下新建测试页面 index.html ，如下： 123456789101112131415161718192021222324252627282930&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=\"jquery3.3.1.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=\"app\"&gt;&lt;/div&gt;&lt;input type=\"button\" value=\"GET\" onclick=\"getData()\"&gt;&lt;input type=\"button\" value=\"PUT\" onclick=\"putData()\"&gt;&lt;script&gt; function getData() { $.get('http://127.0.0.1:8080/get', function (msg) { $(\"#app\").html(msg); }); } function putData() { $.ajax({ type: 'put', url: 'http://127.0.0.1:8080/put', success: function (msg) { $(\"#app\").html(msg); } }) }&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 启动项目，访问 http://120.0.0.1:8081/index.html ，点击按钮后观察浏览器控制台，报跨域错误，如下： 1Access to XMLHttpRequest at 'http://127.0.0.1:8080/get' from origin 'http://127.0.0.1:8081' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource. 接着修改 HelloController ，在类或方法上增加 CORS 的配置，如下： 123456789101112131415@RestController// @CrossOrigin(origins = \"http://127.0.0.1:8081\")public class HelloController { @GetMapping(\"/get\") @CrossOrigin(origins = \"http://127.0.0.1:8081\") public String get() { return \"get\"; } @PutMapping(\"/put\") @CrossOrigin(origins = \"http://127.0.0.1:8081\") public String put() { return \"put\"; }} 重启 spring-boot-corsprovider 再次测试，可以正常获取到数据。观察对应请求，发现 Response Headers 中多了 Access-Control-Allow-Origin: http://127.0.0.1:8081 表示服务端愿意接收来自 http://127.0.0.1:8081 的请求，这样浏览器就不会再去限制这个请求了。 上述 CORS 的配置实在类或方法上，此外在 Spring Boot 中也支持全局配置，增加 MyWebMvcConfigurer 配置类，重写 addCorsMappings 方法，如下： 1234567891011@Configurationpublic class MyWebMvcConfigurer implements WebMvcConfigurer { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\"/**\") .allowedOrigins(\"http://127.0.0.1:8081\") .allowedHeaders(\"*\") .allowedMethods(\"*\") .maxAge(30 * 1000); }} 3 风险 跨域问题虽然解决了，但带来了潜在的威胁，如：CSRF（Cross-site request forgery）跨站请求伪造。跨站请求伪造也被称为 one-click attack 或者 session riding ，通常缩写为 CSRF 或者 XSRF ，是一种挟制用户在当前已登录的 Web 应用程序上执行非本意操作的攻击方法，如： 假如一家银行用以运行转账操作的 URL 地址如下：http://icbc.com/aa?bb=cc ，那么，一个恶意攻击者可以在另一个网站上放置如下代码：&lt;img src=&quot;http://icbc.com/aa?bb=cc&quot;&gt;，如果用户访问了恶意站点，而她之前刚访问过银行不久，登录信息尚未过期，那么她就会遭受损失。 基于此，浏览器在实际操作中，会对请求进行分类，分为简单请求，预先请求，带凭证的请求等，预先请求会首先发送一个 options 探测请求，和浏览器进行协商是否接受请求。默认情况下跨域请求是不需要凭证的，但是服务端可以配置要求客户端提供凭证，这样就可以有效避免 csrf 攻击。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-web/spring-boot-cors 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/11/25/springboot/spring-boot-cors/"},{"title":"Spring Boot 使用 @ControllerAdvice","text":"学习在 Spring Boot 如何使用 @ControllerAdvice 注解。它其实是 Spring MVC 提供的功能，是一个增强的 Controller ，主要可以实现三个方面的功能：全局异常处理、全局数据绑定、全局数据预处理。 1 全局异常处理123456789101112131415161718@ControllerAdvicepublic class MyControllerAdvice { @ExceptionHandler(ArrayIndexOutOfBoundsException.class) public void globalException(ArrayIndexOutOfBoundsException e, HttpServletResponse resp) throws IOException { resp.setContentType(\"text/html;charset=utf-8\"); PrintWriter out = resp.getWriter(); out.write(\"出错了：globalException\"); out.flush(); out.close(); } /*@ExceptionHandler(ArrayIndexOutOfBoundsException.class) public ModelAndView globalException2(ArrayIndexOutOfBoundsException e) throws IOException { ModelAndView mv = new ModelAndView(\"myerror\"); mv.addObject(\"error\", \"出错了：globalException2\"); return mv; }*/} 在类上添加 @ControllerAdvice 注解。 在方法上添加 @ExceptionHandler 注解，用来指明异常的处理类型，比如这里指定为 ArrayIndexOutOfBoundsException ，则空指针异常就不会进到这个方法中来。 在该类中，可以定义多个方法，不同的方法处理不同的异常，例如专门处理空指针的方法、专门处理数组越界的方法，或者也可以定义一个通用的方法处理所有的异常。 新建测试接口： 12345678910@Controllerpublic class TestController { @ResponseBody @GetMapping(\"/globalException\") public String globalException(Model model){ String[] arr = {\"a\",\"b\"}; System.out.println(arr[2]); return \"success\"; }} 启动项目，访问 http://120.0.0.1:8080/globalException 来验证。 2 全局数据绑定 全局数据绑定功能可以用来做一些初始化的数据操作，我们可以将一些公共的数据定义在添加了 @ControllerAdvice 注解的类中，这样，在每一个 Controller 的接口中，就都能够访问导致这些数据。 12345678910@ControllerAdvicepublic class MyControllerAdvice { @ModelAttribute(value = \"dataKey\") public Map&lt;String,Object&gt; globalData() { Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"name\", \"cxy35\"); map.put(\"address\", \"https://cxy35.com\"); return map; }} 在类上添加 @ControllerAdvice 注解。 在方法上添加 @ModelAttribute 注解，标记该方法的返回数据是一个全局数据，默认情况下，这个全局数据的 key 就是返回的变量名，value 就是方法返回值，当然可以通过 @ModelAttribute 注解的 name 属性去重新指定 key。 新建测试接口： 1234567891011121314@Controllerpublic class TestController { @ResponseBody @GetMapping(\"/globalData\") public String globalData(Model model) { String globalData = \"\"; Map&lt;String, Object&gt; map = model.asMap(); Set&lt;String&gt; keySet = map.keySet(); for (String key : keySet) { globalData += (\"【\"+key + \":\" + map.get(key)+\"】\"); } return globalData; }} 启动项目，访问 http://120.0.0.1:8080/globalData 来验证。 3 全局数据预处理 新建 2 个实体类， Book 和 Author ： 123456public class Book { private String name; private Double price; // getter/setter} 123456public class Author { private String name; private Integer age; // getter/setter} 新建测试接口： 12345678@Controllerpublic class TestController { @PostMapping(\"/initPreParam\") public void initPreParam(Book book, Author author) { System.out.println(book); System.out.println(author); }} 因为 2 个实体类都有一个 name 属性，从前端传递时，无法区分。可以通过 @ControllerAdvice 的全局数据预处理来解决这个问题。 123456789101112@ControllerAdvicepublic class MyControllerAdvice { @InitBinder(\"a\") public void initPreParamA(WebDataBinder binder) { binder.setFieldDefaultPrefix(\"a.\"); } @InitBinder(\"b\") public void initPreParamB(WebDataBinder binder) { binder.setFieldDefaultPrefix(\"b.\"); }} 在类上添加 @ControllerAdvice 注解。 在方法上添加 @InitBinder 注解，比如 @InitBinder(“b”) 注解表示该方法用来处理和 Book 相关的参数，统一给参数添加一个 b 前缀，即请求参数要有 b 前缀。 修改测试接口： 12345678@Controllerpublic class TestController { @PostMapping(\"/initPreParam\") public void initPreParam(@ModelAttribute(\"b\") Book book, @ModelAttribute(\"a\") Author author) { System.out.println(book); System.out.println(author); }} 启动项目，通过 Postman 的 POST 请求 http://120.0.0.1:8080/initPreParam?b.name= 三国演义 &amp;b.price=88.8&amp;a.name= 罗贯中 &amp;a.age=99 来验证。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-web/spring-boot-controlleradvice 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/11/22/springboot/spring-boot-controlleradvice/"},{"title":"Spring Boot 项目创建","text":"3 种方式实现 Spring Boot 项目创建。 1 官方网站在线创建 官方网站：https://start.spring.io/，如下： 配置说明如下： Project：项目构建工具，这里选择 Maven ，Gradle 一般在 Android 中使用较多。 Language：开发语言，这里选择 Java 。 Spring Boot：版本，一般用最新稳定版。 Project Metadata：Maven 工程相关信息，如项目坐标、项目描述等。Packing 表示项目打包方式，这里选择 jar 包，因为 Spring Boot 内嵌了 Servlet 容器，打成 jar 包即可直接运行，当然也可根据实际情况选择 war 包。Java 表示选择构建的 JDK 版本。 Dependencies：选择所需要的依赖，这里先加入 web 依赖，可通过关键字搜索。 最后点击下面的按钮生成并导出后，用 IntelliJ IDEA 或者 Eclipse 打开继续开发。 2 IDE 创建 这里演示使用 IntelliJ IDEA 作为 IDE 来创建。 File -&gt; New Project -&gt; Spring Initializr 。 可以看到这里实际上也是用了官方网站的地址来创建，只是 IntelliJ IDEA 把里面的东西集成进来了。 填写 Maven 工程相关信息： 选择依赖： 填写项目相关信息： 3 Maven 创建File -&gt; New Project -&gt; Maven 。 选择项目骨架（我这里不选择，有兴趣的可以试下里面的 Spring Boot 相关项目骨架）： 填写 Maven 工程相关信息： 填写项目相关信息： 创建完成后，打开 pom.xml 添加依赖： 123456789101112131415161718192021222324&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.4.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接着在 com.cxy35.sample.springboot.helloworld 包中创建启动类 SpringBootHelloworldApplication.java ： 12345678@SpringBootApplicationpublic class SpringBootHelloworldApplication { public static void main(String[] args) { SpringApplication.run(SpringBootHelloworldApplication.class, args); }} 4 启动项目测试 在 com.cxy35.sample.springboot.helloworld.controller 包中创建测试类 HelloController.java ： 1234567@RestControllerpublic class HelloController { @GetMapping(\"/hello\") public String hello() { return \"hello spring boot!\"; }} 运行 SpringBootHelloworldApplication.java 中的 main 方法启动项目，浏览器访问 http://127.0.0.1:8080/hello 测试。 最终的项目结构如下： Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-helloworld 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/11/01/springboot/spring-boot-helloworld/"},{"title":"Spring Boot 整合 JdbcTemplate 多数据源","text":"学习在 Spring Boot 中使用 JdbcTemplate 多数据源来操作不同的数据库。JdbcTemplate 是 Spring 自带的，虽然功能没有 MyBatis 强大，但使用简单。 1 创建工程并配置 创建 Spring Boot 项目 spring-boot-jdbctemplatemulti ，添加 Web/JDBC/MySQL 依赖，如下： 之后手动在 pom 文件中添加 Druid 数据库连接池依赖（Spring Boot 版本），最终的依赖如下： 1234567891011121314151617181920212223242526272829303132&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;version&gt;5.1.27&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接着在 application.properties 配置文件中添加数据库相关信息的配置，有两组配置，用 one 和 two 区分，如下： 123456789spring.datasource.one.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.one.username=rootspring.datasource.one.password=000000spring.datasource.one.url=jdbc:mysql://127.0.0.1:3306/cxy35?useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true&amp;autoReconnectForPools=truespring.datasource.two.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.two.username=rootspring.datasource.two.password=000000spring.datasource.two.url=jdbc:mysql://127.0.0.1:3306/cxy35_2?useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true&amp;autoReconnectForPools=true 数据源配置 因为配置数据库的 key 变化了，导致上述配置无法被 Spring Boot 自动加载，需要我们自己去加载。增加 DataSourceConfig 数据源配置类，使用 Spring Boot 提供的类型安全的属性注入方式来加载上述配置，并创建对应的两个数据源 DataSource 实例，如下： 1234567891011121314@Configurationpublic class DataSourceConfig { @Bean @ConfigurationProperties(prefix = \"spring.datasource.one\") DataSource dsOne() { return DruidDataSourceBuilder.create().build(); } @Bean @ConfigurationProperties(prefix = \"spring.datasource.two\") DataSource dsTwo() { return DruidDataSourceBuilder.create().build(); }} JdbcTemplate 配置 接下来是 JdbcTemplate 的配置，新增 JdbcTemplateConfig 配置类，用上述两个数据源分别创建两个对应 JdbcTemplate 实例，如下： 1234567891011121314@Configurationpublic class JdbcTemplateConfig { @Bean // 此时 Spring 容器中有两个 DataSource 类型的 Bean ，所以这里需要按名称 byName 查找 JdbcTemplate jdbcTemplateOne(@Qualifier(\"dsOne\") DataSource dsOne) { return new JdbcTemplate(dsOne); } @Bean // 此时 Spring 容器中有两个 DataSource 类型的 Bean ，所以这里需要按名称 byName 查找 JdbcTemplate jdbcTemplateTwo(@Qualifier(\"dsTwo\") DataSource dsTwo) { return new JdbcTemplate(dsTwo); }} 2 使用 配置完成之后，在对应的位置分别提供实体类和 service 即可。关于 JdbcTemplate 的使用，可以参考 Spring Boot 整合 JdbcTemplate ，这里不再赘述。但同样需要注意 Spring 容器中的 JdbcTemplate 也有两个，因此不能通过 byType 的方式注入，可通过 @Resource 或 @Autowired/@Qualifier 来解决，如下： 123456789101112@Servicepublic class UserService1 { // 因为同类型的有多个，所以需要指定名称 // 注入方法 1 @Autowired @Qualifier(\"jdbcTemplateOne\") JdbcTemplate jdbcTemplateOne; // 注入方法 2 // @Resource(name = \"jdbcTemplateOne\") // JdbcTemplate jdbcTemplateOne;} Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-dao/spring-boot-jdbctemplatemulti 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/12/05/springboot/spring-boot-jdbctemplatemulti/"},{"title":"Spring Boot 整合 Jpa 多数据源","text":"学习在 Spring Boot 中使用 Jpa 多数据源来操作不同的数据库。 1 创建工程并配置 创建 Spring Boot 项目 spring-boot-jpamulti ，添加 Web/JDBC/MySQL 依赖，如下： 之后手动在 pom 文件中添加 Druid 数据库连接池依赖（Spring Boot 版本），最终的依赖如下： 1234567891011121314151617181920212223242526272829303132&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;version&gt;5.1.27&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接着在 application.properties 配置文件中添加数据库相关信息的配置，有两组配置，用 one 和 two 区分，如下： 123456789101112131415161718192021spring.datasource.one.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.one.username=rootspring.datasource.one.password=000000spring.datasource.one.url=jdbc:mysql://127.0.0.1:3306/cxy35?useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true&amp;autoReconnectForPools=truespring.datasource.two.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.two.username=rootspring.datasource.two.password=000000spring.datasource.two.url=jdbc:mysql://127.0.0.1:3306/cxy35_2?useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true&amp;autoReconnectForPools=true# JPA 配置# 数据库为 MySQLspring.jpa.properties.database=mysql# 在控制台打印 SQLspring.jpa.properties.show-sql=true# 数据库平台spring.jpa.properties.database-platform=mysql# 每次启动项目时，数据库初始化策略spring.jpa.properties.hibernate.ddl-auto=update# 指定默认的存储引擎为 InnoDB ，否则默认情况下，自动创建表的时候会使用 MyISAM 作为表的存储引擎spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL57Dialect 数据源配置 因为配置数据库的 key 变化了，导致上述配置无法被 Spring Boot 自动加载，需要我们自己去加载。增加 DataSourceConfig 数据源配置类，使用 Spring Boot 提供的类型安全的属性注入方式来加载上述配置，并创建对应的两个数据源 DataSource 实例，如下： 123456789101112131415@Configurationpublic class DataSourceConfig { @Bean @Primary @ConfigurationProperties(prefix = \"spring.datasource.one\") DataSource dsOne() { return DruidDataSourceBuilder.create().build(); } @Bean @ConfigurationProperties(prefix = \"spring.datasource.two\") DataSource dsTwo() { return DruidDataSourceBuilder.create().build(); }} 注意这里多了一个 @Primary 注解，表示当某一个类存在多个实例时，优先使用哪个实例，不配置的话在项目启动时会出错。 Jpa 配置 接下来是 Jpa 的配置，新增 JpaConfig1 和 JpaConfig2 两个配置类，用上述两个数据源分别创建对应的 LocalContainerEntityManagerFactoryBean 和 PlatformTransactionManager 实例（注意 Bean 的名称要不一样），分别如下： 1234567891011121314151617181920212223242526@Configuration@EnableJpaRepositories(basePackages = \"com.cxy35.sample.springboot.jpamulti.dao1\", entityManagerFactoryRef = \"localContainerEntityManagerFactoryBean1\", transactionManagerRef = \"platformTransactionManager1\")public class JpaConfig1 { // 此时 Spring 容器中有两个 DataSource 类型的 Bean ，所以这里需要按名称 byName 查找 @Autowired @Qualifier(\"dsOne\") DataSource dsOne; @Autowired JpaProperties jpaProperties; @Bean @Primary LocalContainerEntityManagerFactoryBean localContainerEntityManagerFactoryBean1(EntityManagerFactoryBuilder builder) { return builder.dataSource(dsOne) .properties(jpaProperties.getProperties()) .persistenceUnit(\"pu1\") .packages(\"com.cxy35.sample.springboot.jpamulti.pojo\") .build(); } @Bean PlatformTransactionManager platformTransactionManager1(EntityManagerFactoryBuilder builder) { return new JpaTransactionManager(localContainerEntityManagerFactoryBean1(builder).getObject()); }} 12345678910111213141516171819202122232425@Configuration@EnableJpaRepositories(basePackages = \"com.cxy35.sample.springboot.jpamulti.dao2\", entityManagerFactoryRef = \"localContainerEntityManagerFactoryBean2\", transactionManagerRef = \"platformTransactionManager2\")public class JpaConfig2 { // 此时 Spring 容器中有两个 DataSource 类型的 Bean ，所以这里需要按名称 byName 查找 @Autowired @Qualifier(\"dsTwo\") DataSource dsTwo; @Autowired JpaProperties jpaProperties; @Bean LocalContainerEntityManagerFactoryBean localContainerEntityManagerFactoryBean2(EntityManagerFactoryBuilder builder) { return builder.dataSource(dsTwo) .properties(jpaProperties.getProperties()) .persistenceUnit(\"pu2\") .packages(\"com.cxy35.sample.springboot.jpamulti.pojo\") .build(); } @Bean PlatformTransactionManager platformTransactionManager2(EntityManagerFactoryBuilder builder) { return new JpaTransactionManager(localContainerEntityManagerFactoryBean2(builder).getObject()); }} 关于 Jpa 配置类的说明： 配置 dao 的位置：通过 basePackages 分别配置了扫描 dao1 和 dao2 路径，之后在这两个路径下放 XxxDao.java ，所有操作会自动对应着不同的数据源。 通过 entityManagerFactoryRef 和 transactionManagerRef 分别指定不同 Bean 的引用名字。 配置实体类的位置：在提供 LocalContainerEntityManagerFactoryBean 的时候，需要指定 packages ，即这个数据源对应的实体类所在的位置。 注意 persistenceUnit 的名字要不同。 注意实体类可以共用。 2 使用 配置完成之后，在对应的位置分别提供实体类和 dao 即可。关于 Jpa 的使用，可以参考 Spring Boot 整合 Jpa ，这里不再赘述。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-dao/spring-boot-jpamulti 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/12/11/springboot/spring-boot-jpamulti/"},{"title":"Spring Boot 配置 properties","text":"学习 Spring Boot 项目中的配置文件（ properties 格式），如： application.properties 。 1 文件位置Spring Boot 项目中的配置文件 application.properties 最常见的位置在 src/main/resources 目录下，其实共有 4 个默认位置能放，如下（优先级: 1 &gt; 2 &gt; 3 &gt; 4 ）： 项目根目录下的 config 目录下。 项目的根目录下。 classpath 下的 config 目录下。 classpath 目录下。 Spring Boot 启动时，默认会从这 4 个位置按顺序去查找相关属性并加载，重复的属性以优先级高的为准。 但并非绝对的，我们也可以自定义位置（如：src/main/resources/cxy35/application.properties ），并在项目启动时通过 spring.config.location 属性来手动的指定配置文件的位置，指定方式如下： IntelliJ IDEA 中。 命令行中。 1java -jar spring-boot-properties-0.0.1-SNAPSHOT.jar --spring.config.location=classpath:/cxy35/ 注意：通过 spring.config.location 属性指定时，表示自己重新定义配置文件的位置，项目启动时就按照定义的位置去查找配置文件，这种定义方式会覆盖掉默认的 4 个位置。另外可以通过 spring.config.additional-location 属性来指定，表示在默认的 4 个位置的基础上，再添加几个位置，新添加的位置的优先级大于原本的位置。 2 文件名Spring Boot 项目中的配置文件默认文件名是 application.properties ，与文件位置类似，也可以自定义，比如叫 app.properties ，并在项目启动时通过 spring.config.name 属性来手动的指定配置文件的文件名，如：java -jar spring-boot-properties-0.0.1-SNAPSHOT.jar --spring.config.name=app 。 当然，配置文件的位置和文件名可以同时自定义。 3 普通的属性注入 首先在 application.properties 配置文件中定义属性： 123book.id=99book.name=三国演义 book.author= 罗贯中 再定义一个 Book 类，并通过 @Value 注解将这些属性注入到 Book 对象中（注意： Book 对象必须要交给 Spring 容器去管理）： 1234567891011@Componentpublic class Book { @Value(\"${book.id}\") private Long id; @Value(\"${book.name}\") private String name; @Value(\"${book.author}\") private String author; // getter/setter} 因为 application.properties 配置文件会被自动加载，所以上述属性可以注入成功，可通过在 controller 或者单元测试中注入 Book 对象来测试。 但 application.properties 我们一般用来放系统相关的配置，可以自定义 properties 文件来存在自定义配置，如新建 src/main/resources/book.properties ，内容如下： 123book.id=99book.name=三国演义 book.author= 罗贯中 此时 book.properties 文件并不会被自动加载，需要在 Book 类中通过 @PropertySource 来引入： 123456789101112@Component@PropertySource(\"classpath:book.properties\")public class Book { @Value(\"${book.id}\") private Long id; @Value(\"${book.name}\") private String name; @Value(\"${book.author}\") private String author; // getter/setter} 这样 book.properties 文件中的属性就可以注入成功了。 上述方式在 Spring 中也可以使用，和 Spring Boot 没有关系。 4 类型安全的属性注入（推荐）当配置的属性非常多的时候，上述方式工作量大且容易出错，所以就不合适了。在 Spring Boot 中引入了类型安全的属性注入，通过 @ConfigurationProperties 注解来实现，如下： 12345678910@Component@PropertySource(\"classpath:book.properties\")@ConfigurationProperties(prefix = \"book\")public class Book { private Long id; private String name; private String author; // getter/setter} 5 properties 与 yaml 配置的区别 properties 配置无序，yaml 配置有序。在有些配置中顺序是非常有用的，例如 Spring Cloud Zuul 的配置。 yaml 配置目前不支持 @PropertySource 注解。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-properties 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/11/03/springboot/spring-boot-properties/"},{"title":"Spring Boot 整合 MyBatis 多数据源","text":"学习在 Spring Boot 中使用 MyBatis 多数据源来操作不同的数据库。 1 创建工程并配置 创建 Spring Boot 项目 spring-boot-mybatismulti ，添加 Web/MyBatis/MySQL 依赖，如下： 之后手动在 pom 文件中添加 Druid 数据库连接池依赖（Spring Boot 版本），最终的依赖如下： 123456789101112131415161718192021222324252627282930313233&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;version&gt;5.1.27&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接着在 application.properties 配置文件中添加数据库相关信息的配置，有两组配置，用 one 和 two 区分，如下： 123456789spring.datasource.one.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.one.username=rootspring.datasource.one.password=000000spring.datasource.one.url=jdbc:mysql://127.0.0.1:3306/cxy35?useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true&amp;autoReconnectForPools=truespring.datasource.two.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.two.username=rootspring.datasource.two.password=000000spring.datasource.two.url=jdbc:mysql://127.0.0.1:3306/cxy35_2?useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true&amp;autoReconnectForPools=true 数据源配置 因为配置数据库的 key 变化了，导致上述配置无法被 Spring Boot 自动加载，需要我们自己去加载。增加 DataSourceConfig 数据源配置类，使用 Spring Boot 提供的类型安全的属性注入方式来加载上述配置，并创建对应的两个数据源 DataSource 实例，如下： 1234567891011121314@Configurationpublic class DataSourceConfig { @Bean @ConfigurationProperties(prefix = \"spring.datasource.one\") DataSource dsOne() { return DruidDataSourceBuilder.create().build(); } @Bean @ConfigurationProperties(prefix = \"spring.datasource.two\") DataSource dsTwo() { return DruidDataSourceBuilder.create().build(); }} MyBatis 配置 接下来是 MyBatis 的配置，新增 MyBatisConfigOne 和 MyBatisConfigTwo 两个配置类，用上述两个数据源分别创建对应的 SqlSessionFactory 和 SqlSessionTemplate 实例（注意 Bean 的名称要不一样），分别如下： 12345678910111213141516171819202122232425@Configuration@MapperScan(basePackages = \"com.cxy35.sample.springboot.mybatismulti.mapper1\", sqlSessionFactoryRef = \"sqlSessionFactory1\", sqlSessionTemplateRef = \"sqlSessionTemplate1\")public class MyBatisConfigOne { // 此时 Spring 容器中有两个 DataSource 类型的 Bean ，所以这里需要按名称 byName 查找 @Autowired @Qualifier(\"dsOne\") DataSource dsOne; @Bean SqlSessionFactory sqlSessionFactory1() { SqlSessionFactoryBean factory = new SqlSessionFactoryBean(); try { factory.setDataSource(dsOne); return factory.getObject(); } catch (Exception e) { e.printStackTrace(); } return null; } @Bean SqlSessionTemplate sqlSessionTemplate1() { return new SqlSessionTemplate(sqlSessionFactory1()); }} 12345678910111213141516171819202122232425@Configuration@MapperScan(basePackages = \"com.cxy35.sample.springboot.mybatismulti.mapper2\", sqlSessionFactoryRef = \"sqlSessionFactory2\", sqlSessionTemplateRef = \"sqlSessionTemplate2\")public class MyBatisConfigTwo { // 此时 Spring 容器中有两个 DataSource 类型的 Bean ，所以这里需要按名称 byName 查找 @Autowired @Qualifier(\"dsTwo\") DataSource dsTwo; @Bean SqlSessionFactory sqlSessionFactory2() { SqlSessionFactoryBean factory = new SqlSessionFactoryBean(); try { factory.setDataSource(dsTwo); return factory.getObject(); } catch (Exception e) { e.printStackTrace(); } return null; } @Bean SqlSessionTemplate sqlSessionTemplate2() { return new SqlSessionTemplate(sqlSessionFactory2()); }} 关于 MyBatis 配置类的说明： 配置 mapper 的位置：通过 basePackages 分别配置了扫描 mapper1 和 mapper2 路径，之后在这两个路径下放 XxxMapper.java 和 XxxMapper.xml ，所有操作会自动对应着不同的数据源。 通过 sqlSessionFactoryRef 和 sqlSessionTemplateRef 分别指定不同 Bean 的引用名字。 2 使用 配置完成之后，在对应的位置分别提供实体类和 mapper 即可。关于 MyBatis 的使用，可以参考 Spring Boot 整合 MyBatis ，这里不再赘述。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-dao/spring-boot-mybatismulti 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/12/08/springboot/spring-boot-mybatismulti/"},{"title":"Spring Boot 整合 Redis + Spring Session（实现 Session 共享）","text":"学习在 Spring Boot 中整合 Redis + Spring Session ，实现 Session 共享。先来回顾下在 SSM 中使用 Spring Session 的配置，首先是 web.xml 配置代理过滤器，然后在 Spring 容器中配置 Redis，最后再配置 Spring Session ，步骤有些繁琐。下面来看下在 Spring Boot 中如何使用，比较起来你会发现超级简单。 1 概述 在传统的单服务架构中，一般来说，只有一个服务器，那么不存在 Session 共享问题，但是在分布式 / 集群项目中， Session 共享则是一个必须面对的问题，先看一个简单的架构图： 在这样的架构中，会出现一些单服务中不存在的问题，例如客户端发起一个请求，这个请求到达 Nginx 上之后，被 Nginx 转发到 Tomcat A 上，然后在 Tomcat A 上往 Session 中保存了一份数据，下次又来一个请求，这个请求被转发到 Tomcat B 上，此时再去 Session 中获取数据，发现没有之前的数据。对于这一类问题的解决，思路很简单，就是 将各个服务之间需要共享的数据，保存到一个公共的地方（主流方案就是 Redis ），如下： 当所有 Tomcat 需要往 Session 中写数据时，都往 Redis 中写，当所有 Tomcat 需要读数据时，都从 Redis 中读。这样，不同的服务就可以使用相同的 Session 数据了。 这样的方案，可以由开发者手动实现，即手动往 Redis 中存储数据，手动从 Redis 中读取数据，相当于使用一些 Redis 客户端工具来实现这样的功能，毫无疑问，手动实现工作量还是蛮大的。 一个简化的方案就是使用 Spring Session 来实现这一功能， Spring Session 就是使用 Spring 中的代理过滤器，将所有的 Session 操作拦截下来，自动的将数据同步到 Redis 中，或者自动的从 Redis 中读取数据。 对于开发者来说，所有关于 Session 同步的操作都是透明的，开发者使用 Spring Session ，一旦配置完成后，具体的用法就像使用一个普通的 Session 一样。 2 创建工程并配置 创建 Spring Boot 项目 spring-boot-redis-springsession ，添加 Web/Redis/Spring Session 依赖，如下： 之后手动在 pom 文件中添加 commos-pool2 依赖，最终的依赖如下： 1234567891011121314151617181920212223242526272829&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接着在 application.properties 配置文件中添加 Redis 相关信息的配置和 Redis 连接池的配置，如下： 123456789101112# Redis 配置spring.redis.host=192.168.71.62spring.redis.port=6379spring.redis.database=0spring.redis.password=000000# 连接池配置， Spring Boot 默认用的是 lettuce ，而不是 Jedis ，需增加 commons-pool2 依赖spring.redis.lettuce.pool.min-idle=5spring.redis.lettuce.pool.max-idle=10spring.redis.lettuce.pool.max-active=8spring.redis.lettuce.pool.max-wait=1msspring.redis.lettuce.shutdown-timeout=100ms 3 使用 配置完成后 ，就可以使用 Spring Session 了，其实就是使用普通的 HttpSession ，其他的 Session 同步到 Redis 等操作，框架已经自动帮你完成了。新建 HelloController ，如下： 12345678910111213141516171819@RestControllerpublic class HelloController { // java -jar spring-boot-redis-springsession-0.0.1-SNAPSHOT.jar -- server.port=8080 // java -jar spring-boot-redis-springsession-0.0.1-SNAPSHOT.jar -- server.port=8081 @Value(\"${server.port}\") Integer port; @GetMapping(\"/set\") public String set(HttpSession session) { session.setAttribute(\"name\", \"cxy35\"); return String.valueOf(port); } @GetMapping(\"/get\") public String get(HttpSession session) { return ((String) session.getAttribute(\"name\")) + port; }} 项目打包之后，分别在 8080 和 8081 端口启动服务。先访问 http://127.0.0.1:8080/set 接口向 8080 这个服务的 Session 中保存一个变量，访问完成后，数据就已经自动同步到 Redis 中了。然后再访问 http://127.0.0.1:8081/get 接口，发现可以获取到 8080 服务的 Session 中的数据，大功告成。 另外，上面是手动切换服务来实现测试，略显麻烦，可引入 Nginx 来实现服务实例自动切换。关于 Nginx 的使用可以参考 Nginx 教程合集 。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-nosql/spring-boot-redis-springsession 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/12/17/springboot/spring-boot-redis-springsession/"},{"title":"Spring Boot 配置系统启动任务","text":"学习如何在 Spring Boot 中配置系统启动任务。 先来回顾下在普通的 web 项目中如何在项目启动的时做一些初始化操作，一般会自己定义一个 Listener 实现 ServletContextListener 接口，这样就能监听到项目的启动和销毁，并做相应的数据初始化和销毁操作，如下： 12345678910public class MyServletContextListener implements ServletContextListener { @Override public void contextInitialized(ServletContextEvent sce) { // 在这里做数据初始化操作 } @Override public void contextDestroyed(ServletContextEvent sce) { // 在这里做数据备份操作 }} 在 Spring Boot 中，对系统启动任务有 2 种解决方案，分别是 CommandLineRunner 和 ApplicationRunner 。 1 CommandLineRunner新建 MyCommandLineRunner1 和 MyCommandLineRunner2 配置类，分别如下： 123456789@Component// 数字越小，优先级越大，默认情况下，优先级的值为 Integer.MAX_VALUE，表示优先级最低@Order(99)public class MyCommandLineRunner1 implements CommandLineRunner { @Override public void run(String... args) throws Exception { System.out.println(\"MyCommandLineRunner1&gt;&gt;&gt;\"+Arrays.toString(args)); }} 123456789@Component// 数字越小，优先级越大，默认情况下，优先级的值为 Integer.MAX_VALUE，表示优先级最低@Order(100)public class MyCommandLineRunner2 implements CommandLineRunner { @Override public void run(String... args) throws Exception { System.out.println(\"MyCommandLineRunner2&gt;&gt;&gt;\"+Arrays.toString(args)); }} 此时启动项目， run 方法就会被自动执行。参数传递有 2 种方式，无需指定 key ，直接写 value ： 通过 IDEA 配置参数，如下： 项目打包后通过命令行启动时传入参数，如下：java -jar spring-boot-commandlinerunner-0.0.1-SNAPSHOT.jar 三国演义 西游记 2 ApplicationRunnerApplicationRunner 与 CommandLineRunner 类似，区别是它支持更多形式的参数，如 key/value 。 新建 MyApplicationRunner1 和 MyApplicationRunner2 配置类，分别如下： 12345678910111213141516171819202122232425@Component// 数字越小，优先级越大，默认情况下，优先级的值为 Integer.MAX_VALUE，表示优先级最低@Order(99)public class MyApplicationRunner1 implements ApplicationRunner { @Override public void run(ApplicationArguments args) throws Exception { // 获取命令行中的所有参数 String[] sourceArgs = args.getSourceArgs(); System.out.println(\"sourceArgs:\" + Arrays.toString(sourceArgs)); // 获取命令行中的无 key 参数（和 CommandLineRunner 一样） List&lt;String&gt; nonOptionArgs = args.getNonOptionArgs(); System.out.println(\"nonOptionArgs:\" + nonOptionArgs); // 获取所有 key/value 形式的参数的 key Set&lt;String&gt; optionNames = args.getOptionNames(); System.out.println(\"optionNames/optionValues&gt;&gt;&gt;:\"); for (String optionName : optionNames) { // 根据 key 获取 key/value 形式的参数的 value System.out.println(optionName + \":\" + args.getOptionValues(optionName)); } System.out.println(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; MyApplicationRunner1 结束 &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\"); }} 12345678910111213141516171819202122232425@Component// 数字越小，优先级越大，默认情况下，优先级的值为 Integer.MAX_VALUE，表示优先级最低@Order(100)public class MyApplicationRunner2 implements ApplicationRunner { @Override public void run(ApplicationArguments args) throws Exception { // 获取命令行中的所有参数 String[] sourceArgs = args.getSourceArgs(); System.out.println(\"sourceArgs:\" + Arrays.toString(sourceArgs)); // 获取命令行中的无 key 参数（和 CommandLineRunne r 一样） List&lt;String&gt; nonOptionArgs = args.getNonOptionArgs(); System.out.println(\"nonOptionArgs:\" + nonOptionArgs); // 获取所有 key/value 形式的参数的 key Set&lt;String&gt; optionNames = args.getOptionNames(); System.out.println(\"optionNames/optionValues&gt;&gt;&gt;:\"); for (String optionName : optionNames) { // 根据 key 获取 key/value 形式的参数的 value System.out.println(optionName + \":\" + args.getOptionValues(optionName)); } System.out.println(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; MyApplicationRunner2 结束 &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\"); }} ApplicationArguments 类型的参数说明： args.getSourceArgs()：用来获取命令行中的所有参数。 args.getNonOptionArgs()：用来获取命令行中的无 key 参数（和 CommandLineRunner 一样）。 args.getOptionNames()：用来获取所有 key/value 形式的参数的 key 。 args.getOptionValues(key))：根据 key 获取 key/value 形式的参数的 value 。 此时启动项目， run 方法就会被自动执行。参数传递有 2 种方式： 通过 IDEA 配置参数，如下： 项目打包后通过命令行启动时传入参数，如下：java -jar spring-boot-applicationrunner-0.0.1-SNAPSHOT.jar 三国演义 西游记 --age=99 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-web/spring-boot-runner 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/11/27/springboot/spring-boot-runner/"},{"title":"Spring Boot 整合 Redis","text":"学习在 Spring Boot 中使用 Redis 来实现数据存储。在 Spring Boot 中，默认集成的 Redis 就是 Spring Data Redis ，默认底层的连接池使用了 lettuce ，可以自行修改为自己的熟悉的，例如 Jedis 。 1 创建工程并配置 创建 Spring Boot 项目 spring-boot-redis ，添加 Web/Redis 依赖，如下： 之后手动在 pom 文件中添加 commos-pool2 依赖，最终的依赖如下： 12345678910111213141516171819202122232425&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接着在 application.properties 配置文件中添加 Redis 相关信息的配置和 Redis 连接池的配置，如下： 123456789101112# Redis 配置spring.redis.host=192.168.71.62spring.redis.port=6379spring.redis.database=0spring.redis.password=000000# 连接池配置， Spring Boot 默认用的是 lettuce ，而不是 Jedis ，需增加 commons-pool2 依赖spring.redis.lettuce.pool.min-idle=5spring.redis.lettuce.pool.max-idle=10spring.redis.lettuce.pool.max-active=8spring.redis.lettuce.pool.max-wait=1msspring.redis.lettuce.shutdown-timeout=100ms 2 使用 配置完成之后，就可以直接在 Service 或 Controller 中注入 StringRedisTemplate 或者 RedisTemplate 来使用。新建 HelloController ，如下： 12345678910111213141516171819202122232425262728293031323334353637@RestControllerpublic class HelloController { // 模板 1：&lt;Object, Object&gt; @Autowired RedisTemplate redisTemplate; // 模板 2：&lt;String, String&gt; @Autowired StringRedisTemplate stringRedisTemplate; @GetMapping(\"/set\") public void set() { // RedisTemplate 中，key 默认的序列化方案是 JdkSerializationRedisSerializer， key 不易读 // 下面这句可修改为 StringRedisSerializer redisTemplate.setKeySerializer(new StringRedisSerializer()); ValueOperations ops = redisTemplate.opsForValue(); ops.set(\"k1\", \"v1\"); } @GetMapping(\"/get\") public void get(){ ValueOperations ops = redisTemplate.opsForValue(); System.out.println(ops.get(\"k1\")); } @GetMapping(\"/set2\") public void set2() { // StringRedisTemplate 中，key 默认的序列化方案是 StringRedisSerializer ValueOperations&lt;String, String&gt; ops = stringRedisTemplate.opsForValue(); ops.set(\"k2\", \"v2\"); } @GetMapping(\"/get2\") public void get2() { ValueOperations&lt;String, String&gt; ops = stringRedisTemplate.opsForValue(); System.out.println(ops.get(\"k2\")); }} 3 源码解读Redis 对应的自动化配置类是 org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration ，源码如下： 12345678910111213141516171819202122232425262728@Configuration( proxyBeanMethods = false)@ConditionalOnClass({RedisOperations.class})@EnableConfigurationProperties({RedisProperties.class})@Import({LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class})public class RedisAutoConfiguration { public RedisAutoConfiguration() { } @Bean @ConditionalOnMissingBean( name = {\"redisTemplate\"} ) public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; }} 自动化配置类说明： 该配置类在 RedisOperations 存在的情况下才会生效（即项目中引入了 Spring Data Redis ）。 通过 @EnableConfigurationProperties 导入 application.properties 中配置的属性。 然后导入连接池信息（如果存在的话）。 最后提供了两个默认 Bean : RedisTemplate 和 StringRedisTemplate ，其中 StringRedisTemplate 是 RedisTemplate 的子类，两个的方法基本一致，不同之处主要体现在操作的数据类型不同。 RedisTemplate 中的两个泛型都是 Object ，意味者存储的 key 和 value 都可以是一个对象，而 StringRedisTemplate 的两个泛型都是 String ，意味者 StringRedisTemplate 的 key 和 value 都只能是字符串。如果开发者没有提供相关的 Bean ，这两个配置就会生效，否则不会生效。 注意：自动化配置，只能配置单机的 Redis ，但如果是 Redis 集群，则所有的东西都需要我们自己来配置。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-nosql/spring-boot-redis 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/12/15/springboot/spring-boot-redis/"},{"title":"Spring Boot 整合 Spring Security（初次体验）","text":"通过本文体验 Spring Boot 整合 Spring Security 。 Spring Security 是 Spring 家族中的一个安全管理框架，但在 Spring Boot 出现之前，使用的没有 Shiro 多，因为在 SSM/SSH 项目中整合 Spring Security 比较麻烦，直到 Spring Boot 的出现。目前关于安全管理框架的整合模式一般有两种，一种是 SSM/SSH + Shiro ，另一种是 Spring Boot/Spring Cloud + Spring Security ，但并非绝对。 1 创建工程 创建 Spring Boot 项目 spring-boot-springsecurity-helloworld ，添加 Web/Spring Security 依赖，如下： 最终的依赖如下： 123456789101112131415161718192021222324252627&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2 测试 新增测试类 HelloController ，如下： 12345678@RestControllerpublic class HelloController { // 默认用户名为 user ，密码在项目启动时打印在控制台 @GetMapping(\"/hello\") public String hello() { return \"hello\"; }} 启动项目之后，浏览器访问 http://127.0.0.1:8080/hello ，会跳转到登录页面（默认用户名为 user ，密码在项目启动时打印在控制台），这是因为加入 Spring Security 依赖之后，接口就被自动保护起来了。 控制台信息：Using generated security password: 3629761f-b103-4392-8318-c7a8d43ed80d 当用户从浏览器发送请求访问 /hello 接口时，服务端会返回 302 响应码，让客户端重定向到 /login 页面，用户在 /login 页面登录，登陆成功之后，就会自动跳转到 /hello 接口。 当然也可以用 HTTP 请求工具来测试（如 Postman ），将用户信息放在请求头中，这样可以避免重定向到登录页面。 通过以上两种不同的登录方式可以看出 Spring Security 支持两种不同的认证方式： 通过 form 表单来认证。 通过 HttpBasic 来认证。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-security/spring-boot-springsecurity-helloworld 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/01/07/springboot/spring-boot-springsecurity-helloworld/"},{"title":"Spring Boot 整合 Spring Security（配置用户 / 角色 - 基于内存）","text":"Spring Boot 整合 Spring Security 之后，默认用户名为 user ，密码在项目启动时打印在控制台。这个随机生成的密码，每次项目启动时都会变，不是很方便。我们可以自己配置 Spring Security 的用户和角色，有三种方式可以实现： 通过 application.properties 配置文件配置 在内存中。 通过 Java 代码配置 在内存中。 配置 在数据库中，然后通过 Java 代码从数据库中加载。 本文学习前面两种 在内存中 的配置方式，在数据库中 的配置方式可以参考 Spring Boot 整合 Spring Security（配置用户 / 角色 - 基于数据库） 。 1 创建工程 创建 Spring Boot 项目 spring-boot-springsecurity-user ，添加 Web/Spring Security 依赖，如下： 最终的依赖如下： 123456789101112131415161718192021222324252627&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2 配置用户和角色 通过 application.properties 配置文件。 1234# 方法 1：通过配置文件配置用户 / 角色# spring.security.user.name=admin# spring.security.user.password=123456# spring.security.user.roles=admin 通过 Java 代码。 新增 SecurityConfig 配置类，如下： 1234567891011121314151617181920212223// 方法 2：通过 SecurityConfig 配置用户和角色@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter { @Bean PasswordEncoder passwordEncoder() { // return NoOpPasswordEncoder.getInstance();// 密码不加密 return new BCryptPasswordEncoder();// 密码加密 } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 在内存中配置 2 个用户 /*auth.inMemoryAuthentication() .withUser(\"admin\").password(\"123456\").roles(\"admin\") .and() .withUser(\"user\").password(\"123456\").roles(\"user\");// 密码不加密 */ auth.inMemoryAuthentication() .withUser(\"admin\").password(\"$2a$10$fB2UU8iJmXsjpdk6T6hGMup8uNcJnOGwo2.QGR.e3qjIsdPYaS4LO\").roles(\"admin\") .and() .withUser(\"user\").password(\"$2a$10$3TQ2HO/Xz1bVHw5nlfYTBON2TDJsQ0FMDwAS81uh7D.i9ax5DR46q\").roles(\"user\");// 密码加密 }} 配置类说明： 在 configure 方法中配置了两个用户，密码是加密之后的字符串（明文为 123456）。 从 Spring 5 开始，强制要求密码要加密。如果坚持不想加密，可以使用一个过期的 PasswordEncoder 的实例 NoOpPasswordEncoder ，但不建议。 Spring Security 中提供了 BCryptPasswordEncoder 密码编码工具，可以非常方便的实现密码的加密加盐，相同明文加密出来的结果总是不同，这样就不需要用户去额外保存 盐 的字段了，这一点比 Shiro 要方便很多。 1234567891011@SpringBootTestclass SpringBootSpringsecurityUserApplicationTests { @Test void contextLoads() { // 同样的明文加密后不重复 for (int i = 0; i &lt; 10; i++) { BCryptPasswordEncoder encoder = new BCryptPasswordEncoder(); System.out.println(encoder.encode(\"123456\")); } }} 3 测试 新增测试类 HelloController ，如下： 1234567@RestControllerpublic class HelloController { @GetMapping(\"/hello\") public String hello() { return \"hello\"; }} 项目启动之后，浏览器访问 http://127.0.0.1:8080/hello ，跳转到登录页面，用上述配置的用户名和密码就能登录了。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-security/spring-boot-springsecurity-user 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/01/09/springboot/spring-boot-springsecurity-user/"},{"title":"Spring Boot 自定义 Starter","text":"认识 Spring Boot 中的自动化配置，并手把手带你写一个自己的 Starter 。 1 认识 StarterSpring Boot 中的 Starter 为我们完成了很多自动化配置，使得我们可以很轻松的搭建一个生产级的开发环境。其实 Starter 并不难，都是 Spring + Spring MVC 中的基础知识点实现的，他的核心就是条件注解 @Conditional ，当 classpath 下存在某个 Class 时，某个配置才会生效。 除了 Spring Boot 官方提供的 Starter 之外，第三方公司的功能针对 Spring Boot 一般都会有 1 个 Starter 提供自动化配置类，命名都有一定的规范，有兴趣的可以看下源码，比如： Thymeleaf ： spring-boot-autoconfigure jar 包中的org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration 类，对应的源码解读可查看文章 Spring Boot 整合 Thymeleaf 。 Redis ： spring-boot-autoconfigure jar 包中的 org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration 类。 Mybatis ： mybatis-spring-boot-starter jar 包中的 org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration 类。 2 自定义 Starter首先创建一个普通的 Maven 项目 spring-boot-mystarter ，创建完成后，添加官方的 Starter 依赖 spring-boot-autoconfigure ，如下： 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;version&gt;2.2.0.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在 src/main/java 下相应的包中新建 HelloService 类，如下： 123456789101112131415161718192021222324public class HelloService { private String name; private String msg; public String sayHello() { return name + \"say\" + msg + \"!\"; } public String getName() { return name; } public void setName(String name) { this.name = name; } public String getMsg() { return msg; } public void setMsg(String msg) { this.msg = msg; }} 在 src/main/java 下相应的包中新建 HelloProperties 类，用来接收 application.properties 中注入的值，如下： 123456789101112131415161718192021222324// 类型安全的属性注入，指定配置的前缀@ConfigurationProperties(prefix = \"cxy35\")public class HelloProperties { private static final String DEFAULT_NAME = \"默认名称\"; private static final String DEFAULT_MSG = \"默认消息\"; private String name = DEFAULT_NAME; private String msg = DEFAULT_MSG; public String getName() { return name; } public void setName(String name) { this.name = name; } public String getMsg() { return msg; } public void setMsg(String msg) { this.msg = msg; }} 在 src/main/java 下相应的包中新建 HelloServiceAutoConfiguration 类，就是我们的自动化配置类，如下： 123456789101112131415@Configuration@EnableConfigurationProperties(HelloProperties.class)@ConditionalOnClass(HelloService.class)public class HelloServiceAutoConfiguration { @Autowired HelloProperties helloProperties; @Bean HelloService helloService() { HelloService helloService = new HelloService(); helloService.setName(helloProperties.getName()); helloService.setMsg(helloProperties.getMsg()); return helloService; }} 自动化配置类说明： @Configuration 注解表示这是一个配置类。 @EnableConfigurationProperties 注解表示开启 ConfigurationProperties ，即使得我们上面 HelloProperties 类上配置的 @ConfigurationProperties 生效。 @ConditionalOnClass 表示当项目 classpath 下存在 HelloService 时，当前的自动化配置类才会生效。 首先注入 HelloProperties ，这个实例中含有我们在 application.properties 中配置的相关数据。 最后提供一个 HelloService 的实例，将 HelloProperties 中的值注入进去。 接下来在 src/main/resources/META-INF 下中新建 spring.factories 文件，指我们的自动化配置类，如下： 1org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.cxy35.sample.springboot.mystarter.HelloServiceAutoConfiguration 这个文件干嘛用的呢？我们的 Spring Boot 项目的启动类都有一个 @SpringBootApplication 注解，这个注解的定义如下： 12345678@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })public @interface SpringBootApplication {} 其中 @EnableAutoConfiguration 表示启用 Spring 应用程序上下文的自动化配置，该注解会自动导入一个名为 AutoConfigurationImportSelector 的类，而这个类会去读取一个名为 spring.factories 的文件, spring.factories 中则定义需要加载的自动化配置类，我们打开任意一个框架的 Starter ，都能看到它有一个 spring.factories 文件，例如 MyBatis 的 Starter 如下： 最后需要将这个自动化配置类安装到本地仓库，然后在其他项目中使用即可。安装方式很简单，在 IntelliJ IDEA 中，点击右边的 Maven ，然后选择 Lifecycle 中的 install ，双击即可，如下： 或者使用 Maven 命令安装也行。 3 使用自定义 Starter首先创建一个普通的 Spring Boot 项目 spring-boot-usemystarter ，增加 Web 依赖，创建完成后，再手动添加我们自定义的 Starter 依赖 spring-boot-mystarter ，如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.cxy35.sample&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-mystarter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 加入上述依赖后，我们的项目中就有了一个默认的 HelloService 实例，可以通过在单元测试中注入该实例使用，如下： 1234567891011@SpringBootTestpublic class SpringBootUsemystarterApplicationTests { @Autowired HelloService helloService; @Test void contextLoads() { System.out.println(helloService.sayHello()); }} 也可以在 application.properties 配置文件中添加我们自定义的配置，如下： 12cxy35.name=自定义名称 cxy35.msg= 自定义消息 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-starter 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/11/11/springboot/spring-boot-starter/"},{"title":"Spring Boot 配置静态资源","text":"学习 Spring Boot 配置静态资源。 1 Spring MVC 配置静态资源 先来回顾下在 Spring MVC 中如何配置静态资源。使用 Spring MVC 时，静态资源会被拦截，需要添加额外的配置，一般在 spring-mvc.xml 中配置，如下： 12&lt;mvc:resources mapping=\"/favicon.ico\" location=\"favicon.ico\" /&gt;&lt;mvc:resources mapping=\"/static/**\" location=\"/static/\" /&gt; 2 Spring Boot 配置静态资源2.1 默认位置Spring Boot 项目中的静态资源最常见的位置在 src/main/resources/static 目录下，其实共有 5 个默认位置能放，重复的资源以优先级高的为准。如下（优先级: 1 &gt; 2 &gt; 3 &gt; 4 &gt; 5 ）： classpath:/META-INF/resources/ classpath:/resources/ classpath:/static/ classpath:/public/ / 其中，/ 表示 类似 webapp 目录，即 webapp 中的静态文件也可以直接访问。 如果在 src/main/resources/static 目录下有一个 1.png 的文件，那么访问路径是 http://127.0.0.1:8080/1.png ，不需要加 static 。类似 Spring MVC 中的配置 &lt;mvc:resources mapping=&quot;/**&quot; location=&quot;/static/&quot;/&gt; ，实际上系统会去 /static/1.png 目录下查找相关的文件。 2.2 源码解读 打开 org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration ，找到了静态资源拦截的配置，如下： 12345678910String staticPathPattern = this.mvcProperties.getStaticPathPattern();if (!registry.hasMappingForPattern(staticPathPattern)) { this.customizeResourceHandlerRegistration( registry.addResourceHandler(new String[]{staticPathPattern}) .addResourceLocations( WebMvcAutoConfiguration.getResourceLocations(this.resourceProperties.getStaticLocations()) ) .setCachePeriod(this.getSeconds(cachePeriod)) .setCacheControl(cacheControl));} this.mvcProperties.getStaticPathPattern() 返回 “/**” 。 this.resourceProperties.getStaticLocations() 返回 4 个位置 “classpath:/META-INF/resources/“, “classpath:/resources/“, “classpath:/static/“, “classpath:/public/“ ，然后 WebMvcAutoConfiguration.getResourceLocations 又添加了 “/“ ，这样总共就是上述 5 个位置。 2.3 自定义位置 上述 5 个是系统默认的位置，有 2 种办法可以实现自定义位置。 通过 application.properties 配置文件。 12345# 自定义配置静态资源的匹配规则和路径# 定义请求 URL 规则# spring.mvc.static-path-pattern=/**# 定义资源位置# spring.resources.static-locations=classpath:/cxy35/ 通过 Java 代码。 新增配置类 WebMvcConfig， 如下： 12345678@Configurationpublic class WebMvcConfig implements WebMvcConfigurer { // 自定义配置静态资源的匹配规则和路径 @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(\"/**\").addResourceLocations(\"classpath:/cxy35/\"); }} Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-web/spring-boot-staticresources 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/11/20/springboot/spring-boot-staticresources/"},{"title":"Spring Boot 单元测试","text":"学习 Spring Boot 项目中的单元测试，实现 Service/Controller/JSON 测试。 1 准备工作 在 src/main/java 下相应的包中新建 Book 类，如下： 1234567public class Book { private Integer id; private String name; private String author; // getter/setter} 在 src/main/java 下相应的包中新建 HelloService 类，如下： 123456@Servicepublic class HelloService { public String sayHello(String name) { return \"hello\" + name; }} 在 src/main/java 下相应的包中新建 HelloController 类，如下： 123456789101112@RestControllerpublic class HelloController { @GetMapping(\"/hello\") public String hello(String name) { return \"hello\" + name; } @PostMapping(\"/book\") public Book addBook(@RequestBody Book book) { return book; }} 2 Service 测试 在 src/test/java 下相应的包中新建 TestService 测试类，如下： 12345678910111213// @RunWith(SpringRunner.class)@SpringBootTestpublic class TestService { @Autowired HelloService helloService; @Test public void contextLoads() { String hello = helloService.sayHello(\"cxy35\"); Assert.assertThat(hello, Matchers.is(\"hello cxy35\")); }} 3 Controller 测试 通过模拟 web 环境和请求来实现，支持 get/post/… 等请求方式。 在 src/test/java 下相应的包中新建 TestController 测试类，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243@RunWith(SpringRunner.class)@SpringBootTestpublic class TestController { @Autowired WebApplicationContext wac; MockMvc mockMvc; @Test public void contextLoads() { } @Before public void before() { mockMvc = MockMvcBuilders.webAppContextSetup(wac).build(); } @Test public void testGet() throws Exception { MvcResult mvcResult = mockMvc.perform( MockMvcRequestBuilders.get(\"/hello\") .contentType(MediaType.APPLICATION_FORM_URLENCODED) .param(\"name\", \"cxy35\")) .andExpect(MockMvcResultMatchers.status().isOk()) .andDo(MockMvcResultHandlers.print()) .andReturn(); System.out.println(mvcResult.getResponse().getContentAsString()); } @Test public void testPost() throws Exception { Book book = new Book(); book.setId(99); book.setName(\"三国演义\"); book.setAuthor(\"罗贯中\"); String s = new ObjectMapper().writeValueAsString(book); MvcResult mvcResult = mockMvc.perform(MockMvcRequestBuilders.post(\"/book\").contentType(MediaType.APPLICATION_JSON).content(s)) .andExpect(MockMvcResultMatchers.status().isOk()) .andReturn(); System.out.println(mvcResult.getResponse().getContentAsString()); }} 在 src/test/java 下相应的包中新建 TestController2 测试类，通过模板实现，如下： 123456789101112@RunWith(SpringRunner.class)@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.DEFINED_PORT)public class TestController2 { @Autowired TestRestTemplate testRestTemplate; @Test public void contextLoads() { String cxy35 = testRestTemplate.getForObject(\"/hello?name={1}\", String.class, \"cxy35\"); System.out.println(cxy35); }} 4 JSON 测试 在 src/test/java 下相应的包中新建 book.json 测试数据，如下： 1{\"id\":99,\"name\":\"红楼梦\",\"author\":\"曹雪芹\"} 在 src/test/java 下相应的包中新建 TestJson 测试类，如下： 123456789101112131415161718192021222324252627282930@RunWith(SpringRunner.class)// @SpringBootTest@org.springframework.boot.test.autoconfigure.json.JsonTestpublic class TestJson { @Autowired JacksonTester&lt;Book&gt; jacksonTester; @Test public void test() throws IOException { // 序列化 Book book = new Book(); book.setId(99); book.setName(\"红楼梦\"); book.setAuthor(\"曹雪芹\"); Assertions.assertThat(jacksonTester.write(book)) .isEqualToJson(\"book.json\"); Assertions.assertThat(jacksonTester.write(book)) .hasJsonPathStringValue(\"@.name\"); Assertions.assertThat(jacksonTester.write(book)) .extractingJsonPathStringValue(\"@.name\") .isEqualTo(\"红楼梦\"); } @Test public void test2() throws IOException { // 反序列化 String content = \"{\\\"id\\\":99,\\\"name\\\":\\\" 红楼梦 \\\",\\\"author\\\":\\\" 曹雪芹 \\\"}\"; Assertions.assertThat(jacksonTester.parseObject(content).getName()).isEqualTo(\"红楼梦\"); }} Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-test 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/11/07/springboot/spring-boot-test/"},{"title":"Spring Boot 配置 yaml","text":"学习 Spring Boot 项目中的配置文件（ yaml 格式），如： application.yaml 。 1 文件位置Spring Boot 项目中的配置文件 application.yaml 最常见的位置在 src/main/resources 目录下，其实共有 4 个默认位置能放，如下（优先级: 1 &gt; 2 &gt; 3 &gt; 4 ）： 项目根目录下的 config 目录下。 项目的根目录下。 classpath 目录下的 config 目录下。 classpath 目录下。 Spring Boot 启动时，默认会从这 4 个位置按顺序去查找相关属性并加载，重复的属性以优先级高的为准。 但并非绝对的，我们也可以自定义位置（如：src/main/resources/cxy35/application.yaml ），并在项目启动时通过 spring.config.location 属性来手动的指定配置文件的位置，指定方式如下： IntelliJ IDEA 中。 命令行中。 1java -jar spring-boot-yaml-0.0.1-SNAPSHOT.jar --spring.config.location=classpath:/cxy35/ 注意：通过 spring.config.location 属性指定时，表示自己重新定义配置文件的位置，项目启动时就按照定义的位置去查找配置文件，这种定义方式会覆盖掉默认的 4 个位置。另外可以通过 spring.config.additional-location 属性来指定，表示在默认的 4 个位置的基础上，再添加几个位置，新添加的位置的优先级大于原本的位置。 2 文件名Spring Boot 项目中的配置文件默认文件名是 application.yaml ，与文件位置类似，也可以自定义，比如叫 app.yaml ，并在项目启动时通过 spring.config.name 属性来手动的指定配置文件的文件名，如：java -jar spring-boot-yaml-0.0.1-SNAPSHOT.jar --spring.config.name=app 。 当然，配置文件的位置和文件名可以同时自定义。 3 普通的属性注入 首先在 application.yaml 配置文件中定义属性： 123456789101112book: id: 1 name: 三国演义 author: 罗贯中 editors: - 张三 - 李四 chapters: - id: 1 name: 第一章 桃园结义 - id: 2 name: 第二章 除董卓 再定义一个 Book 和 Chapter 类，并通过 @Value 注解将这些属性注入到 Book 对象中（注意： Book 对象必须要交给 Spring 容器去管理）： 123456789101112131415@Componentpublic class Book { @Value(\"${book.id}\") private Long id; @Value(\"${book.name}\") private String name; @Value(\"${book.author}\") private String author; @Value(\"${book.editors}\") private List&lt;String&gt; editors; // 普通数组 / 列表注入 @Value(\"${book.chapters}\") private List&lt;Chapter&gt; chapters; // 对象数组 / 列表注入 // getter/setter} 123456public class Chapter { private Long id; private String name; // getter/setter} 因为 application.yaml 配置文件会被自动加载，所以上述属性可以注入成功，可通过在 controller 或者单元测试中注入 Book 对象来测试。 yaml 配置目前不支持 @PropertySource 注解。 上述方式在 Spring 中也可以使用，和 Spring Boot 没有关系。 4 类型安全的属性注入（推荐）当配置的属性非常多的时候，上述方式工作量大且容易出错，所以就不合适了。在 Spring Boot 中引入了类型安全的属性注入，通过 @ConfigurationProperties 注解来实现，如下： 1234567891011@Component@ConfigurationProperties(prefix = \"book\")public class Book { private Long id; private String name; private String author; private List&lt;String&gt; editors; // 普通数组 / 列表注入 private List&lt;Chapter&gt; chapters; // 对象数组 / 列表注入 // getter/setter} 5 properties 与 yaml 配置的区别 properties 配置无序，yaml 配置有序。在有些配置中顺序是非常有用的，例如 Spring Cloud Zuul 的配置。 yaml 配置目前不支持 @PropertySource 注解。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-yaml 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/11/04/springboot/spring-boot-yaml/"},{"title":"Spring Boot 整合 Thymeleaf","text":"学习 Spring Boot 整合页面模板 Thymeleaf 。 1 Thymeleaf 简介Thymeleaf 是新一代 Java 模板引擎，它类似于 Velocity 、 FreeMarker 等传统 Java 模板引擎，但是与传统 Java 模板引擎不同的是，Thymeleaf 支持 HTML 原型。 它既可以让前端工程师在浏览器中直接打开查看样式，也可以让后端工程师结合真实数据查看显示效果，同时，Spring Boot 提供了 Thymeleaf 自动化配置解决方案，因此在 SpringBoot 中使用 Thymeleaf 非常方便。 事实上， Thymeleaf 除了展示基本的 HTML ，进行页面渲染之外，也可以作为一个 HTML 片段进行渲染，例如我们在做邮件发送时，可以使用 Thymeleaf 作为邮件发送模板。 另外，由于 Thymeleaf 模板后缀为 .html，可以直接被浏览器打开，因此，预览时非常方便。 2 整合 Thymeleaf创建 Spring Boot 项目 spring-boot-thymeleaf ，增加 Web 和 Thymeleaf 依赖。 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; Thymeleaf 提供了一整套的自动化配置方案，对应的源码如下： org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration 123456@Configuration@EnableConfigurationProperties(ThymeleafProperties.class)@ConditionalOnClass({ TemplateMode.class, SpringTemplateEngine.class })@AutoConfigureAfter({ WebMvcAutoConfiguration.class, WebFluxAutoConfiguration.class })public class ThymeleafAutoConfiguration {} @Configuration 注解表示这是一个配置类。 @EnableConfigurationProperties 注解表示开启 ConfigurationProperties ，即使得 ThymeleafProperties 类上配置的 @ConfigurationProperties 生效。 @ConditionalOnClass 表示当项目 classpath 下存在 TemplateMode 和 SpringTemplateEngine 时，当前的自动化配置类才会生效。只要项目中引入了 Thymeleaf 相关的依赖，这个配置就会生效。 @AutoConfigureAfter 表示当前自动化配置在 WebMvcAutoConfiguration 和 WebFluxAutoConfiguration 之后完成。 org.springframework.boot.autoconfigure.thymeleaf.ThymeleafProperties 123456789101112131415@ConfigurationProperties(prefix = \"spring.thymeleaf\")public class ThymeleafProperties { private static final Charset DEFAULT_ENCODING = StandardCharsets.UTF_8; public static final String DEFAULT_PREFIX = \"classpath:/templates/\"; public static final String DEFAULT_SUFFIX = \".html\"; private boolean checkTemplate = true; private boolean checkTemplateLocation = true; private String prefix = DEFAULT_PREFIX; private String suffix = DEFAULT_SUFFIX; private String mode = \"HTML\"; private Charset encoding = DEFAULT_ENCODING; private boolean cache = true; // ...} 通过 @ConfigurationProperties 注解，将 application.properties 中前缀为 spring.thymeleaf 的配置和这个类中的属性绑定。 前三个 static 变量定义了默认的编码格式、视图解析器的前缀、后缀等。 从前三行配置中，可以看出来，Thymeleaf 模板的默认位置在 classpath:/templates/ 目录下，默认的后缀是 html 。 这些配置，如果开发者不自己提供，则使用默认的，如果自己提供，则在 application.properties 中以 spring.thymeleaf 开头进行相关的配置。 在 src/main/java 下相应的包中新建 Book 类，如下： 12345678public class Book { private Integer id; private String name; private String author; private Double price; // getter/setter} 在 src/main/java 下相应的包中新建 BookController 类，如下： 1234567891011121314151617181920@Controllerpublic class BookController { @GetMapping(\"/book\") public String book(Model model) { List&lt;Book&gt; bookList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) { Book book = new Book(); book.setId(i); book.setName(\"三国演义:\" + i); book.setAuthor(\"罗贯中:\" + i); book.setPrice(30.0); bookList.add(book); } model.addAttribute(\"books\", bookList); model.addAttribute(\"username\",\"张三\"); // 返回视图，默认为 src/main/resources/templates/book.html return \"book\"; }} 在 src/main/resources/templates 下新建 book.html ，如下： 12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;table border=\"1\"&gt; &lt;tr&gt; &lt;td&gt;图书编号 &lt;/td&gt; &lt;td&gt; 图书名称 &lt;/td&gt; &lt;td&gt; 图书作者 &lt;/td&gt; &lt;td&gt; 图书价格&lt;/td&gt; &lt;/tr&gt; &lt;tr th:each=\"book :${books}\"&gt; &lt;td th:text=\"${book.id}\"&gt;&lt;/td&gt; &lt;td th:text=\"${book.name}\"&gt;&lt;/td&gt; &lt;td th:text=\"${book.author}\"&gt;&lt;/td&gt; &lt;td th:text=\"${book.price}\"&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;script th:inline=\"javascript\"&gt; var username = [[${username}]]; console.log(\"Thymeleaf 支持在 js 中直接获取 Model 中的变量。username =\" + username);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 通过 &lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt; 引入 thymeleaf 名称空间。 通过 th:each 指令遍历集合，通过 th:text 指令展示数据。 通过 [[${username}]] 在 js 中直接获取 Model 中的变量。 Thymeleaf 的其他用法可以参考官方文档：https://www.thymeleaf.org 。 启动项目，访问 http://120.0.0.1:8080/book 来验证。 3 手动渲染 Thymeleaf另外我们可以使用 TemplateEngine 实例手动渲染 Thymeleaf 模板，一般在发邮件时用到，可查看文章 Spring Boot 整合邮件发送 。 4 配置说明 在 application.properties 中配置，以 spring.thymeleaf 开头： 123456# 这里可以覆盖 thymeleaf 的默认配置# 模板文件位置，默认为 classpath:/templates/# spring.thymeleaf.prefix=classpath:/templates/thymeleaf/# 是否开启缓存# spring.thymeleaf.cache=false# ...... Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-web//spring-boot-thymeleaf 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/11/13/springboot/spring-boot-thymeleaf/"},{"title":"Spring Cloud Alibaba Sentinel 断路器","text":"学习在 Spring Cloud 中使用 Sentinel 实现断路器，类似 Spring Cloud Netflix Hystrix ，包括实时监控、簇点链路、流控、降级等功能。 Sentinel 提供的功能更强大，使用更方便，可以替代 Hystrix ，还能结合 Nacos 中的配置中心一起使用。 1 概述Sentinel 的使用场景丰富，有完备的实时监控，广泛的开源生态。 Sentinel 整体上可以分为两个核心部分：核心库和控制台。 2 安装 首先下载控制台 jar 包，这是一个 Spring Boot 工程，下载好之后，直接启动。 下载地址：https://github.com/alibaba/Sentinel/releases/download/1.7.2/sentinel-dashboard-1.7.2.jar Sentinel 启动成功后，访问 http://127.0.0.1:8080 就能看到后台页面了，默认用户名 / 密码都是 sentinel 。 3 基本使用 创建 Spring Boot 项目 spring-cloud-alibaba-sentinel ，添加 Web/Sentinel 依赖，如下： 最终的依赖如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，修改 application.properties 配置文件，配置 Sentinel 控制台地址，如下： 12345spring.application.name=spring-cloud-alibaba-sentinelserver.port=8081# Sentinel 控制台地址spring.cloud.sentinel.transport.dashboard=127.0.0.1:8080 接着，提供一个 hello 接口，如下： 1234567@RestControllerpublic class HelloController { @GetMapping(\"/hello\") public String hello() { return \"hello sentinel\"; }} 然后，在测试类中增加测试代码，如下： 12345678@Testvoid contextLoads() { RestTemplate restTemplate = new RestTemplate(); for (int i = 0; i &lt; 15; i++) { String s = restTemplate.getForObject(\"http://127.0.0.1:8081/hello\", String.class); System.out.println(s + \":\" + new Date()); }} 启动项目之后，访问 http://127.0.0.1:8081/hello ，之后，在 Sentinel 控制台页面上就能看到这个应用及 /hello 接口了，下面新增流控配置，限制每 1 秒中响应 5 个请求： 最后，执行测试类中的方法，结果如下： 4 结合 Nacos 中的配置中心使用Sentinel 还能结合 Nacos 中的配置中心一起使用。 首先，在 pom.xml 中增加 Nacos Configuration 和 sentinel-datasource-nacos 依赖，如下： 123456789&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;version&gt;1.7.1&lt;/version&gt;&lt;/dependency&gt; 修改 application.properties 配置文件，增加 Nacos 相关配置信息，如下： 1234567891011spring.application.name=spring-cloud-alibaba-sentinelserver.port=8081# Sentinel 控制台地址spring.cloud.sentinel.transport.dashboard=127.0.0.1:8080# 结合 Nacos 中的配置中心使用spring.cloud.sentinel.datasource.ds.nacos.server-addr=127.0.0.1:8848spring.cloud.sentinel.datasource.ds.nacos.data-id=spring-cloud-alibaba-sentinelspring.cloud.sentinel.datasource.ds.nacos.group-id=DEFAULT_GROUPspring.cloud.sentinel.datasource.ds.nacos.rule-type=flow 接着，新建 bootstrap.properties 配置文件，配置 Nacos 相关信息： 1spring.cloud.nacos.config.server-addr=127.0.0.1:8848 然后，在 Nacos 后台增加配置（注意 Data Id/GROUP 要与上述配置文件中的配置对应上）， JSON 格式，内容其实就是对应前面章节 Sentinel 控制台页面上配置的流控规则。 1234567891011[ { &quot;resource&quot;:&quot;/hello&quot;, // 资源名 &quot;limitApp&quot;:&quot;default&quot;, // 针对来源 &quot;grade&quot;:1, // 阈值类型 =QPS &quot;count&quot;:5, // 单机阈值 &quot;clusterMode&quot;:false, // 是否集群 &quot;strategy&quot;:0, // 流控模式 = 直接 &quot;controlBehavior&quot;:2 // 流控效果 = 排队等待 }] 最后，重启项目，访问 http://127.0.0.1:8081/hello ，之后， Sentinel 会根据 Nacos 后台的 spring-cloud-alibaba-sentinel 这项配置，自动在 Sentinel 控制台生成一条对应的流控规则。 测试结果如下： Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 本文示例代码：https://github.com/cxy35/spring-cloud-samples/tree/master/spring-cloud-alibaba-sentinel 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/05/24/springcloud/spring-cloud-alibaba-sentinel/"},{"title":"Spring Cloud Bus 消息总线","text":"学习在 Spring Cloud 中使用 Bus 实现消息总线，包括配置文件自动批量刷新、逐个刷新等功能。 1 概述 Spring Cloud Bus 通过轻量级的消息代理连接各个微服务，可以用来广播配置文件的更改，或者管理服务监控。在 Spring Cloud Config 分布式配置中心 一文中，我们提到， 当配置文件发生变化之后， conﬁg-server 可以及时感知到变化，但是 conﬁg-client 不会及时感知到变化，默认情况下， conﬁg-client 只有重启才能加载到最新的配置文件。当时我们在 conﬁg-client 中结合 actuator 中的 refresh 来解决了这个问题，但是，如果 conﬁg-client 数量很多的时候，这种方案就显得很繁琐了，不合适。本文我们结合 Spring Cloud Bus 来解决这一问题。 2 基本使用 将 spring-cloud-config 中的代码（包括 conﬁg-server/conﬁg-client ）拷贝一份到 spring-cloud-bus 中（重命名为 bus-conﬁg-server/bus-conﬁg-client ），在此基础上进行修改。 首先，安装并启动 RabbitMQ 。 接着，在 bus-conﬁg-server 和 bus-conﬁg-client 中分别添加 Spring Cloud Bus 依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 然后，在 bus-conﬁg-server 和 bus-conﬁg-client 中分别添加 RabbitMQ 配置： 12345# 配置 RabbitMQspring.rabbitmq.host=127.0.0.1spring.rabbitmq.port=5672spring.rabbitmq.username=guestspring.rabbitmq.password=guest 同时，给 bus-conﬁg-server 添加 actuator 依赖，将提供刷新接口： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 然后，修改 bus-conﬁg-server 中的 bootstrap.properties 配置文件，使 bus-refresh 端点暴露出来： 12# 暴露 bus-refresh 端点management.endpoints.web.exposure.include=bus-refresh 由于给 bus-conﬁg-server 中的所有接口都添加了保护，所以刷新接口将无法直接访问，此时，可以通过修改 Security 配置，对端点的权限做出修改： 123456789101112@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .anyRequest().authenticated() .and() .httpBasic() .and() .csrf().disable(); }} 在这段配置中，开启了 HttpBasic 登录，这样，在发送刷新请求时，就可以直接通过 HttpBasic 配置认证信息了。 最后分别启动 Eureka Server/bus-config-server/bus-config-client ，然后修改配置信息提交到 GitHub，访问 http://127.0.0.1:8082/hello 不会有变化。然后，调用 http://127.0.0.1:8080/actuator/bus-refresh [POST]。再次访问 http://127.0.0.1:8082/hello 发现有变化。 这个 POST 是针对 bus-conﬁg-server 的， bus-conﬁg-server 会把这个刷新的指令传到 RabbitMQ ，然后 RabbitMQ 再把指令传给各个 bus-conﬁg-client ，实现了配置文件自动批量刷新。 如果更新配置文件之后，不希望每一个微服务 bus-conﬁg-client 都去刷新配置文件，那么可以通过如下配置解决问题。 首先，修改 bus-conﬁg-client 中的 bootstrap.properties 配置文件，给每一个 bus-conﬁg-client 添加一个 instance-id： 1eureka.instance.instance-id=${spring.application.name}:${server.port} 然后，对 bus-conﬁg-client 进行打包，打包完成后，通过如下命令启动两个 bus-conﬁg-client 实例： 12java -jar bus-config-client-0.0.1-SNAPSHOT.jar --server.port=8082java -jar bus-config-client-0.0.1-SNAPSHOT.jar --server.port=8083 修改配置文件，并且提交到 GitHub 之后，可以通过如下方式只刷新某一个微服务，例如只刷新 8082 的服务。 http://127.0.0.1:8080/actuator/bus-refresh/bus-conﬁg-client:8082 [POST] 其中 bus-conﬁg-client:8082 表示服务的 instance-id 。 Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 本文示例代码：https://github.com/cxy35/spring-cloud-samples/tree/master/spring-cloud-bus 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/05/14/springcloud/spring-cloud-bus/"},{"title":"Spring Cloud Netflix Eureka 概述","text":"Eureka 是 Spring Cloud 中的服务注册中心，类似于 Dubbo 中的 Zookeeper 。本文学习 Eureka 概述、工作细节、集群等。它是 Netflix 家族成员之一。 1 服务注册中心 什么是注册中心，我们为什么需要注册中心？我们首先来看一个传统的单体应用： 在单体应用中，所有的业务都集中在一个项目中，当用户从浏览器发起请求时，直接由前端发起请求给后端，后端调用业务逻辑，给前端请求做出响应，完成一次调用。整个调用过程是一条直线，不需要服务之间的中转，所以没有必要引入注册中心。 随着公司项目越来越大，我们会将系统进行拆分，例如一个电商项目，可以拆分为订单模块、物流模块、支付模块、 CMS 模块等。这样，当用户发起请求时，就需要各个模块之间进行协作，这样不可避免的要进行模块之间的调用。此时，我们的系统架构就会发生变化： 在这里，大家可以看到，模块之间的调用，变得越来越复杂，而且模块之间还存在强耦合。例如 A 调用 B ，那么就要在 A 中写上 B 的地址，也意味着 B 的部署位置要固定，同时，如果以后 B 要进行集群化部署， A 也需要修改，非常麻烦，此时就需要注册中心了。 2 Eureka2.1 Eureka 概述Eureka 是 Netﬂix 公司提供的一款服务注册中心， Eureka 基于 REST 来实现服务的注册与发现，曾经的 Eureka 是 Spring Cloud 中最重要的核心组件之一。 Spring Cloud 中封装了 Eureka，在 Eureka 的基础上，优化了一些配置，然后提供了可视化的页面，可以方便的查看服务的注册情况以及服务注册中心集群的运行情况。 Eureka 由两部分：服务端和客户端，服务端就是注册中心，用来接收其他服务的注册，客户端则是一个 Java 客户端，需要向服务端注册，并可以实现负载均衡等功能。 从图中我们可以看出 Eureka 中有三个角色： Eureka Server ：注册中心 Eureka Provider ：服务提供者 Eureka Consumer ：服务消费者 2.2 Eureka 工作细节Eureka 本身可以分为两大部分： Eureka Server 和 Eureka Client 。 2.2.1 Eureka ServerEureka Server 主要对外提供了三个功能： 服务注册：所有的服务都注册到 Eureka Server 上面来。 提供注册表：注册表就是所有注册上来服务的一个列表， Eureka Client 在调用服务时，需要获取这个注册表，一般来说，这个注册表会缓存下来，如果缓存失效，则直接获取最新的注册表。 同步状态： Eureka Client 通过注册、心跳等机制，和 Eureka Server 同步当前客户端的状态。 2.2.2 Eureka ClientEureka Client 主要是用来简化每一个服务和 Eureka Server 之间的交互。 Eureka Client 会自动拉取、更新以及缓存 Eureka Server 中的信息，这样，即使 Eureka Server 所有节点都宕机， Eureka Client 依然能够获取到想要调用服务的地址（但是地址可能不准确）。 服务注册 服务提供者将自己注册到服务注册中心（ Eureka Server ），需要注意，所谓的服务提供者，只是一个业务上的划分，本质上就是一个 Eureka Client 。当 Eureka Client 向 Eureka Server 注册时，他需要提供自身的一些元数据信息，例如 IP 地址、端口、名称、运行状态等。 服务续约 Eureka Client 注册到 Eureka Server 上之后，事情没有结束，刚刚开始而已。注册成功后，默认情况下， Eureka CLient 每隔 30 秒就要向 Eureka Server 发送一条心跳消息，来告诉 Eureka Server 我还在运行。如果 Eureka Server 连续 90 秒都有没有收到 Eureka Client 的续约消息（连续三次没发送），它会认为 Eureka Client 已经掉线了，会将掉线的 Eureka Client 从当前的服务注册列表中剔除。 服务续约有两个相关的属性（一般不建议修改）： 1234# 服务续约时间，默认是 30 秒eureka.instance.lease-renewal-interval-in-seconds=30# 服务失效时间，默认是 90 秒eureka.instance.lease-expiration-duration-in-seconds=90 服务下线 当 Eureka Client 下线时，它会主动发送一条消息，告诉 Eureka Server ，我下线了。 获取注册表信息 Eureka Client 从 Eureka Server 上获取服务的注册信息，并将其缓存在本地。本地客户端，在需要调用远程服务时，会从该信息中查找远程服务所对应的 IP 地址、端口等信息。 Eureka Client 上缓存的服务注册信息会定期更新 (30 秒)，如果 Eureka Server 返回的注册表信息与本地缓存的注册表信息不同的 话， Eureka Client 会自动处理。 这里也涉及到两个属性： 1234# 是否允许获取注册表信息eureka.client.fetch-registry=true# Eureka Client 上缓存的服务注册信息，定期更新的时间间隔，默认 30 秒eureka.client.registry-fetch-interval-seconds=30 2.3 Eureka 集群 在这个集群架构中， Eureka Server 之间通过 Replicate 进行数据同步，不同的 Eureka Server 之间不区分主从节点，所有节点都是平等的。节点之间，通过置顶 serviceUrl 来互相注册，形成一个集群，进而提高节点的可用性。 在 Eureka Server 集群中，如果有某一个节点宕机， Eureka Client 会自动切换到新的 Eureka Server 上。每一个 Eureka Server 节点，都会互相同步数据。Eureka Server 的连接方式，可以是单线的，如： A–&gt;B–&gt;C ，此时， A 的数据也会和 C 之间互相同步。但是一般不建议这种写法，在我们配置 serviceUrl 时，可以指定多个注册地址，即 A 可以即注册到 B 上，也可以同时注册到 C 上。 Eureka 分区： region ：地理上的不同区域。 zone ：具体的机房。 Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/04/07/springcloud/spring-cloud-netflix-eureka-overview/"},{"title":"Spring Cloud 概述","text":"通过本文学习 微服务介绍、 Spring Cloud 介绍，让大家对 Spring Cloud 有个初步的认识。 1 微服务介绍2009 年， Netflix 公司重新定义了它的应用程序员的开发模型，这个算是微服务的首次探索。 2014 年， 《Microservices》 这篇文章以一个更加通俗易懂的方式，为大家定义了微服务。 互联网应用 产品的两大特点： 需求变化快。 用户群体庞大。 在这样的情况下，我们需要构建一个能够 灵活扩展 ，同时能够 快速应对外部环境变化 的一个应用，使用传统的开发方式，显然无法满足需求。这个时候，微服务就登场了。 1.1 什么是微服务 简单来说，微服务就是一种 将一个单一应用程序拆分为一组小型服务 的方法，拆分完成后，每一个服务都运行在独立的进程中，服务与服务之间采用轻量级的通信机制来进行沟通（其中 Spring Cloud 中采用基于 HTTP 的 RESTful API ）。 每一个服务，都是围绕具体的业务进行构建，例如一个电商系统，包括：订单服务、支付服务、物流服务、会员服务等，这些拆分后的应用都是独立的应用，都可以独立的部署到生产环境中。同时在采用微服务之后，我们的项目不再拘泥于一种语言，可以是 Java/Go/Python/PHP 等混合使用，这在传统的应用开发中，是无法想象的。而使用了微服务之后，我们可以根据业务上下文来选择合适的语言和构建工具进行构建。 微服务可以理解为是 SOA 的一个传承，一个本质的区别是微服务是一个真正分布式、去中心化的，微服务的拆分比 SOA 更加彻底。 1.2 微服务的优势 复杂度可控。 独立部署。 技术选型灵活。 较好的容错性。 较强的可扩展性。 1.3 微服务的特性 不主动 不拒绝 不负责 2 Spring Cloud 介绍Spring Cloud 可以理解为微服务这种思想在 Java 领域的一个具体落地。 Spring Cloud 在发展之初，就借鉴了微服务的思想，同时结合 Spring Boot 让 Spring Cloud 具备了组件的一键式启动和部署的能力，极大的简化了微服务架构的落地。 Spring Cloud 这种框架，从设计之初，就充分考虑了分布式架构演化所需要的功能，例如服务注册、配置中心、消息总线、负载均衡等。这些功能都是以可插拔的形式提供出来的，这样，在分布式系统不断演化的过程中，我们的 Spring Cloud 也可以非常方便的进化。 2.1 什么是 Spring CloudSpring Cloud 是一系列框架的集合， 内部包含了许多框架，这些框架互相协作，共同来构建 分布式系统。利用这些组件，可以非常方便的构建一个分布式系统。 2.2 核心特性 分布式配置中心。 服务注册与发现。 链路器。 服务调用。 负载均衡。 断路器 / 熔断机制。 全局锁。 选举与集群状态管理。 分布式消息 / 消息总线。 2.3 版本名称 不同于其他的框架， Spring Cloud 的版本名称是通过 A(Angel)、 B(Brixton)、 C(Camden)、D(Dalston)、 E(Edgware)、 F(Finchley) 这样来命名的，这些名字使用了伦敦地铁站的名 字，目前最新版是 Hoxton SR3 。 Spring Cloud 中，除了大的版本之外，还有一些小版本，小版本命名方式如下： M: 是 Milestone 的缩写，如: M1/M2。 RC: 是 Release Candidate 的缩写，表示该项目处于候选状态，这是正式发版之前的一个状态，如: RC1/RC2 。 SR: 是 Service Release 的缩写，表示项目正式发布的稳定版，相当于 GA(Generally Available) 版。如: SR1/SR2 。 SNAPSHOT: 表示快照版。 2.4 组件 Spring Cloud Netflix: 这个组件，在 Spring Cloud 成立之初，立下了汗马功劳。但 2018 年的断更事件，使得 Netflix 走下神坛。 Spring Cloud Config: 分布式配置中心，利用 Git/SVN 来集中管理项目的配置文件。 Spring Cloud Bus: 消息总线，可以构建消息驱动的微服务，也可以用来做一些状态管理等。 Spring Cloud Consul: 服务注册与发现。 Spring Cloud Stream: 基于 Redis/RabbitMQ/Kafka 实现的消息微服务。 Spring Cloud OpenFeign: 提供 OpenFeign 集成到 Spring Boot 应用中的方式，主要解决微服务之间的调用问题。 Spring Cloud Gateway: Spring Cloud 官方推出的网关服务。 Spring Cloud Cloudfoundry: 利用 Cloudfoundry 集成我们的应用程序。 Spring Cloud Security: 在 Zuul 代理中，为 OAuth2 客户端认证提供支持。 Spring Cloud AWS: 快速集成亚马逊云服务。 Spring Cloud Contract: 一个消费者驱动的、面向 Java 的契约框架。 Spring Cloud Zookeeper: 基于 Apache Zookeeper 的服务注册和发现。 Spring Cloud Data Flow: 在一个结构化的平台上，组成数据微服务。 Spring Cloud Kubernetes: Spring Cloud 提供的针对 Kubernetes 的支持。 Spring Cloud Function: Spring Cloud Task: 短生命周期的微服务。 Spring Cloud 第一代 Spring Cloud 第二代 网关 spring-cloud-zuul（来源于 Netflix Zuul ，性能一般） Spring Cloud Gateway 注册中心 spring-cloud-netflix-eureka（集成于 Netflix Eureka ，不再维护，Consul，ZK） 阿里 Nacos ，拍拍贷 radar 等可选 配置中心 spring-cloud-config（自研，功能不足，国内使用其它配置中心替代） 阿里 Nacos ，携程 Apollo ，随行付 Config Keeper 客户端软负载均衡 spring-cloud-ribbon（来源于 Netflix 集成，不支持 webFlux 的负载均衡） spring-cloud-loadbalancer 熔断器 spring-cloud-hystrix（来源于 Netflix 集成，不再开发新功能，进入维护状态） spring-cloud-r4j(Resilience4J)，阿里 Sentinel 2.5 与 Spring Boot 的版本对应关系 Spring Cloud 版本 Spring Boot 版本 Hoxton 2.2.x Greenwich 2.1.x Finchley 2.0.x Edgware 1.5.x Dalston 1.5.x Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/03/20/springcloud/spring-cloud-overview/"},{"title":"Eclipse 问题汇总","text":"本文记录 Eclipse 使用过程中的相关问题汇总，持续更新中。 1 打包时没有生成目录信息，导致 Spring 扫描时找不到 jar 包中的 Bean 原因： 打包错误，没有选中这个选项：Add directory entries 。 区别如下： 1234567891011# 选中 cn/cn/com/cn/com/log/cn/com/log/dao/cn/com/log/dao/ReadLogInfoDao.classcn/com/log/dao/LogInfoDao.class# 不选中（错误）cn/com/log/dao/ReadLogInfoDao.classcn/com/log/dao/LogInfoDao.class 解决：打包时需要选中上述选项。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/04/06/tool/eclipse-error/"},{"title":"Eclipse 常用插件在线安装地址","text":"Eclipse 常用插件在线安装地址。 Maven2: http://m2eclipse.sonatype.org/sites/m2e Maven-wtp: http://m2eclipse.sonatype.org/sites/m2e-extras Subclipse： http://subclipse.tigris.org/update_1.8.x（支持 Subversion 1.7.x ） Android(Eclipse ADT)：https://dl-ssl.google.com/android/eclipse/ FreeMarker：http://download.jboss.org/jbosstools/updates/development/helios（最后一个为 Eclipse 的版本） 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/04/04/tool/eclipse-plugins/"},{"title":"Git 安装","text":"手把手带你安装 Git 。 Windowswindows 安装 Git 整体上来说有两种解决方案： 安装 Cygwin 用来模拟 Linux 运行环境，但是 Cygwin 配置非常麻烦，容易出错，所以一般不推荐这种方式。 安装独立的 Git，也就是 msysGit，下载 Git-2.23.0-64-bit.exe ，安装成功后，在你的开始菜单中找到 Git Bash，或者鼠标右键 Git Bash Here 可打开命令行。 12$ git --versiongit version 2.23.0.windows.1 Ubuntu1sudo apt-get install git Git 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/02/05/tool/git-install/"},{"title":"Git 配置 SSH keys","text":"GitHub 支持 HTTPS 和 SSH 两种协议。使用 HTTPS 协议时，每次提交都要求输入用户名和密码，显得有点麻烦。本文介绍如何通过配置 SSH keys 实现愉快的提交。 配置 SSH keys 的原理很简单，采用非对称加密方式生成公钥和私钥，公钥告诉 GitHub ，私钥留在自己电脑上 (私钥不可泄露)，当我们向 GitHub 上提交数据时，GitHub 会用我们留给它的公钥加密一段消息返回给我们的电脑，如果我们能够用私钥解密成功，说明是合法的用户，这样就避免我们输入用户名密码了。大致的原理就是这样，现在很多免登录的系统都采用了这种方式，比如 Hadoop 免登录配置也是这样。 1 查看本地是否已有 SSH keys 查看当前用户目录下是否有 .ssh 文件夹，如果有就跳过第 2 和 3 步。 1234567$ ls -la ~/.sshtotal 32drwxr-xr-x 1 Administrator 197121 0 八月 27 15:29 ./drwxr-xr-x 1 Administrator 197121 0 二月 10 16:44 ../-rw-r--r-- 1 Administrator 197121 3381 八月 27 15:21 id_rsa-rw-r--r-- 1 Administrator 197121 742 八月 27 15:21 id_rsa.pub-rw-r--r-- 1 Administrator 197121 1593 九月 5 17:05 known_hosts 2 生成 SSH 指纹 1ssh-keygen -t rsa -b 4096 -C \"你的邮箱地址\" 3 添加 SSH 到 ssh-agent 中 1eval \"$(ssh-agent -s)\" 执行完上述语句之后，我们当前用户目录下已经有了一个名为 .ssh 的隐藏文件夹了，打开这个目录，会发现有一个名为 id_rsa.pub 的文件，这就是我们一会要使用的公钥文件。 4 将公钥告诉 GitHub 登录 GitHub ，点击右上角的向下的箭头，选择 Settings ，在新打开的页面中左边侧栏选择 SSH and GPG keys ，再右边选择 New SSH key，输入 Title 和 Key 。 Title 的值建议能标识出哪台设备，如你的电脑型号、操作系统名称等信息。Key 的值为上述 id_rsa.pub 文件中的内容。 Git 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/02/10/tool/git-ssh/"},{"title":"IntelliJ IDEA 常用快捷键","text":"工欲善其事，必先利其器。本文收集 IntelliJ IDEA 常用快捷键，持续更新中…… 搜索所有文件：双击 Shift 搜索类文件：Ctrl+N 搜索文件：Ctrl+Shift+N 搜索函数：Ctrl+Alt+Shift+N 全局内容搜索：Ctrl+Shift+F 全局内容替换：Ctrl+Shift+R 快速打开或隐藏工程面板：Alt+1 切换代码视图：Alt+ 左箭头 / 右箭头 关闭当前代码文件：Ctrl+F4 查看近期文件：Ctrl+E 查看近期位置：Ctrl+Shift+E 查看变量、方法 - 参数 / 返回值、接口：Ctrl+F12 查看类结构图 / 继承层次：Ctrl+H 查看注释文档（光标处的类或方法）：Ctrl+Q 查看 Maven 依赖图、类图：Ctrl+Shift+Alt+U 查看某一个方法或者变量在哪里被使用了：ALT+F7 高亮错误或警告快速定位：F2 或 Shift+F2 跳转到上一次修改的地方：Ctrl+Shift+Backspace 跳转到上一个浏览的地方：Ctrl+Alt+ 左箭头 跳转到下一个浏览的地方：Ctrl+Alt+ 右箭头 跳转到类或方法的实现处：Ctrl+Alt+B 或 Ctrl+Alt+ 鼠标左键 跳转到类或方法的定义处：Ctrl+B/Ctrl+ 鼠标左键 代码提示：Ctrl+ALT+ 空格键 代码注释（单行）：Ctrl+/ 代码注释（多行）：Ctrl+Shift+/ 变量或者类重命名：Shift+F6 重构函数：Ctrl+F6 生成 Constructor/Getter/Setter/equals/hashCode/toString 等方法：Alt+Insert 选择可以覆盖或实现的方法：Ctrl+O 列编辑：按住 Alt，多行时再按住 Shift 代码包裹（for/if/trycache 等）：Ctrl+ALT+T 代码格式化：Ctrl+Alt+L 移除无用的 import：Ctrl+Alt+O 编译：Ctrl+F9 代码复制到新的一行：Ctrl+D 代码向上或者向下移动一行：Ctrl+Shift+↑/↓ 删除当前行：Ctrl+Y 在当前行的上面创建新的一行：Ctrl+Alt+Enter 在当前行的下面创建新的一行：Ctrl+Shift+Enter 打开复制内容列表供选择粘贴：Ctrl+Shift+V 抽取变量：Ctrl+Alt+V 抽取静态变量：Ctrl+Alt+C 抽取成员变量：Ctrl+Alt+F 抽取方法：Ctrl+Alt+M 抽取方法参数：Ctrl+Alt+P 在当前目录下新建类 / 包 / 文件等：Ctrl+Alt+Insert Alt+Enter： 提供代码提示。 自动创建函数。 list replace。 实现接口。 单词拼写。 导包。 配置 Settings： 模板 Live Templates：如输入 psvm 会自动生成 public static void main 方法。Ctrl+J 可查看并选择。 后缀补全 Postfix Completion：如输入 o.null 会自动生成 if(o == null){} 代码块；输入 b.sout 会自动生成 System.out.println(b); 代码块。 插件 Plugins：如编码规范插件（Alibaba Java Coding Guidelines）。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/10/08/tool/idea-keymap/"},{"title":"IntelliJ IDEA 常用插件","text":"工欲善其事，必先利其器。本文收集 IntelliJ IDEA 常用插件，持续更新中…… Alibaba Java Coding Guidelines 阿里巴巴《Java 开发手册》配套插件，可以实时检测代码中不符合手册规约的地方，助你码出高效，码出质量。 使用： 当我们违反手册规约时，该插件会自动检测并进行提示。 同时提供了一键检测所有代码规约情况和切换语言的功能。 如果你想修改某条规约的检测规则的话，可以通过设置的 Editor -&gt; Inspections 进行修改。 Easy Code EasyCode 用于 代码自动生成，支持模板自定义、导入、导出，方便团队之间共享。 介绍： 基于 IntelliJ IDEA 开发的代码生成插件，支持自定义任意模板（Java，html，js，xml）。 只要是与数据库相关的代码都可以通过自定义模板来生成。支持数据库类型与 java 类型映射关系配置。 支持同时生成生成多张表的代码。每张表有独立的配置信息。完全的个性化定义，规则由你设置。 具体使用见：IntelliJ IDEA 插件 EasyCode（代码自动生成） Lombok Lombok 为 Java 项目提供了非常有趣的附加功能，使用它的注解可以有效的地解决那些繁琐又重复的代码，如: Setter、Getter、toString、equals、hashCode 以及非空判断等。 使用： 比如给一个类添加 @Getter 和 @Setter 注解， Lombok 就会为我们自动生成所有属性的 Getter 和 Setter 方法。 Free MyBatis plugin MyBatis 扩展插件，可以在 Mapper 接口的方法和 xml 实现之间自由跳转，也可以用来一键生成某些 xml 实现。 介绍： 生成 mapper xml 文件。 快速从代码跳转到 mapper 及从 mapper 返回代码。 mybatis 自动补全及语法错误提示。 集成 mybatis generator gui 界面。 使用： 通过 Alt+Enter 生成新方法的 xml 实现。 通过 Mapper 接口中方法左侧的箭头直接跳转到对应的 xml 实现中去。 通过 xml 中 Statement 左侧的箭头直接跳转到对应的 Mapper 接口方法中去。 MyBatis Log Plugin 可以把 Mybatis 输出的 SQL 日志还原成完整的 SQL 语句，无需手动转换。 使用： 打开这款插件的窗口，当控制台输出 Mybatis 的 SQL 日志时，该插件会自动帮我们转换成对应的 SQL 语句。 有的时候我们需要转换的日志并不在自己的控制台上，这时可以使用插件的 SQL Text 功能：直接复制我们需要转换的日志，然后点击 Restore Sql 按钮即可。 RestfulToolkit 一套 Restful 服务开发辅助工具集，提供了项目中的接口概览信息，可以根据 URL 跳转到对应的接口方法中去，内置了 HTTP 请求工具，对请求方法做了一些增强功能，总之功能很强大！ 介绍： 根据 URL 直接跳转到对应的方法定义 (Ctrl \\ or Ctrl Alt N); 提供了一个 Services tree 的显示窗口; 一个简单的 http 请求工具; 在请求方法上添加了有用功能: 复制生成 URL；复制方法参数… 其他功能: java 类上添加 Convert to JSON 功能，格式化 json 数据 (Windows: Ctrl + Enter; Mac: Command + Enter)。 使用： 右上角的 RestServices 按钮可以显示项目中接口的概览信息。 可以通过搜索按钮根据 URL 搜索对应接口。 可以通过底部的 HTTP 请求工具来发起接口测试请求。 通过在接口方法上右键可以生成查询参数、请求参数、请求 URL 。 通过在实体类上右键可以直接生成实体类对应的 JSON 。 Translation 翻译插件，支持 Google、有道、百度翻译，看源码时看注释很有帮助。 使用： 选中需要翻译的内容，右键翻译。 翻译整个文档。 右上角的翻译按钮翻译指定内容。 GsonFormat 可以把 JSON 格式的字符串转化为实体类。 使用： 先创建一个实体类，然后在类名上右键 Generate -&gt; GsonFormat 。 再输入我们需要转换的 JSON 字符串，选择性的更改属性名称和类型，点击确定后直接生成实体类。 Grep Console 分析控制台日志，对不同级别的日志进行不同颜色的高亮显示，还可以用来按关键字搜索日志内容。 使用： 打印日志时不同日志级别的日志会以不同颜色来显示。 可以通过 Tools 打开该插件的配置菜单，然后通过配置菜单修改配色方案。 可以通过在控制台右键并使用 Grep 按钮来调出日志分析的窗口，然后直接通过关键字来搜索即可。 Maven Helper 解决 Maven 依赖冲突，可以快速查找项目中的依赖冲突，并予以解决。 使用： 可以通过 pom.xml 文件底部的依赖分析标签页查看当前项目中的所有依赖。 通过冲突按钮我们可以筛选出所有冲突的依赖，选中有冲突的依赖，点击 Exclude 按钮可以直接排除该依赖。 同时 pom.xml 中也会对该依赖添加 &lt;exclusion&gt; 标签。 Statistic 代码统计工具，可以用来统计当前项目中代码的行数和大小。 使用： 可以通过顶部菜单中的 View -&gt; Tool Windows -&gt; Statistic 按钮开启该功能。 此时就可以看到我们项目代码的统计情况了。 Vue.js Vue.js 支持插件，可以根据模板创建 .vue 文件，也可以对 Vue 相关代码进行智能提示。 使用： 启用该插件后，可以根据模板新建 .vue 文件。 当我们在标签中写入以 v- 开头的代码时，会提示 Vue 中的相关指令。 element Element-UI 支持插件，可以对 Element-UI 中的标签进行智能提示。 使用： 当我们写入以 el- 开头的标签时，会提示 Element-UI 相关组件。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/05/14/tool/idea-plugins/"},{"title":"IntelliJ IDEA 插件 EasyCode（代码自动生成）","text":"IntelliJ IDEA 中的插件 EasyCode，用于 代码自动生成，支持模板自定义、导入、导出，方便团队之间共享。 1 介绍 基于 IntelliJ IDEA 开发的代码生成插件，支持自定义任意模板（Java，html，js，xml）。 只要是与数据库相关的代码都可以通过自定义模板来生成。支持数据库类型与 java 类型映射关系配置。 支持同时生成多张表的代码。每张表有独立的配置信息。完全的个性化定义，规则由你设置。 2 安装File -&gt; Settings -&gt; Plugins，在插件市场中搜索 EasyCode 安装，重启 IDEA。 3 使用3.1 创建项目File -&gt; New Project -&gt; Spring Initializr 。 3.2 添加数据源EasyCode 是基于 IDEA 上的 Database Tools 开发的，因此要通过 IDEA 上的 Database 连接数据源。 配置数据库连接信息。 3.3 生成代码 选择对应的数据库和表（支持多张表同时生成），右键单击，选择 EasyCode -&gt; Generate Code 。 可能需要添加部分数据库类型与 Java 类型的映射关系。 支持单张表单独配置，右键单击，选择 EasyCode -&gt; Config Table 。 配置生成代码。 如果 controller/entity/service/dao 等包不存在会提示自动创建。最终生成的代码如下： 3.4 自定义模板 支持 自定义模板 ，并且可以 实时调试。 File -&gt; Settings -&gt; Easy Code -&gt; Template Setting 。 建议自己新建一套模板（包括 Type Mapper/Template Setting/Global Config 等），默认的 Default 模板供参考。 3.5 模板共享 支持模板导入、导出，方便团队之间共享。 File -&gt; Settings -&gt; Easy Code 。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/02/18/tool/idea-plugins-easycode/"},{"title":"IntelliJ IDEA 常用配置","text":"工欲善其事，必先利其器。本文收集 IntelliJ IDEA 常用配置，持续更新中…… Settings Settings 是对软件本身的一些属性进行配置，例如字体 主题 背景图 插件等。 Appearance &amp; Behavior 外观和行为 Appearance System Settings Keymap 快捷键 Editor 编辑器设置 General Font Color Scheme Code Style File and Code Templates File Encodings Plugins 插件 IntelliJ IDEA 常用插件 Version Control 版本控制 Git GitHub Build，Execution，Deployment 构建，执行，部署 Maven Build project automatically 开启自动编译： Registry 配置（快捷键： Ctrl + Shift + Alt + / ）： Application Servers Project Structure 当前项目结构设置 项目结构配置就是关于当前模块的配置，只对当前模块生效，例如 Jar 包，包结构，源码文件夹，输出路径，依赖和项目构建信息。 Project Modules Artifacts Facets 当前项目配置文件的相关信息。 Other Settings 其他 Run/Debug Configurations Split Vertically/Horizontally Set Background Image Power Save Mode 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/10/22/tool/idea-settings/"},{"title":"Maven 常用命令","text":"Maven 常用命令。 创建 Maven 的普通 java 项目：mvn archetype:generate -DgroupId=com.demo -DartifactId=demo_maven -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false 创建 Maven 的 Web 项目：mvn archetype:generate -DgroupId=com.demo -DartifactId=demo_maven2 -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false 编译源代码： mvn compile 编译测试代码：mvn test-compile 运行测试：mvn test 产生 site：mvn site 打包：mvn package 在本地 Repository 中安装 jar：mvn install 清除产生的项目：mvn clean 跳过测试运行：mvn package -DskipTests 跳过测试编译和运行：mvn package -Dmaven.test.skip=true 只打 jar 包: mvn jar:jar 生成 idea 项目：mvn idea:idea 生成 eclipse 项目：mvn eclipse:eclipse 清除 eclipse 的一些系统设置:mvn eclipse:clean 运行项目于 jetty 上：mvn jetty:run 显示版本信息：mvn -version/-v 显示详细错误信息：mvn -e 验证工程是否正确，所有需要的资源是否可用：mvn validate 在集成测试可以运行的环境中处理和发布包：mvn integration-test 运行任何检查，验证包是否有效且达到质量标准：mvn verify 产生应用需要的任何额外的源代码，如 xdoclet：mvn generate-sources 删除再编译：mvn clean install 打印出已解决依赖的列表：mvn dependency:resolve 打印整个依赖树：mvn dependency:tree 想要查看完整的依赖踪迹，包含那些因为冲突或者其它原因而被拒绝引入的构件，打开 Maven 的调试标记运行：mvn install -X 构建装配 Maven Assembly 插件是一个用来创建你应用程序特有分发包的插件：mvn install assembly:assembly 使用 Hibernate3 插件构造数据库：mvn hibernate3:hbm2ddl 使用 help 插件的 describe 目标来输出 Maven Help 插件的信息：mvn help:describe -Dplugin=help 使用 Help 插件输出完整的带有参数的目标列：mvn help:describe -Dplugin=help -Dfull 获取单个目标的信息, 设置 mojo 参数和 plugin 参数。此命令列出了 Compiler 插件的 compile 目标的所有信息：mvn help:describe -Dplugin=compiler -Dmojo=compile -Dfull 列出所有 Maven Exec 插件可用的目标：mvn help:describe -Dplugin=exec -Dfull 看这个“有效的 (effective)”POM ，它暴露了 Maven 的默认设置：mvn help:effective-pom Main Exec 插件让我们能够在不往 classpath 载入适当的依赖的情况下，运行这个程序：mvn exec:java -Dexec.mainClass=org.sonatype.mavenbook.weather 打包同时生成源码包：mvn clean source:jar install 参数 1：-DdownloadSources=true（构建项目时下载源码 jar ） 参数 2：-DdownloadJavadocs=true（构建项目时下载 javadoc 包） 参数 3：-Dwtpversion=2.0（构建项目时表示是 web 项目, 而不是简单的 java 项目） 参数 4：-Dmaven.test.skip=true（ install 时跳过测试） 示例 1：【eclipse.bat】 SET MAVEN_OPTS= -Xms512M -Xmx512M -XX:PermSize=128M -XX:MaxPermSize=128M -XX:ReservedCodeCacheSize=64Mmvn eclipse:clean eclipse:eclipse -DdownloadSources=true -Dwtpversion=2.0 示例 2：【install.bat】 SET MAVEN_OPTS= -Xms512M -Xmx512M -XX:PermSize=128M -XX:MaxPermSize=128M -XX:ReservedCodeCacheSize=64Mmvn clean source:jar install -Dmaven.test.skip=true 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/06/05/tool/maven-command/"},{"title":"Sublime Text 常用快捷键","text":"工欲善其事，必先利其器。本文收集 Sublime Text 常用快捷键，持续更新中…… 通用（General） ↑↓←→：上下左右移动光标 Alt：调出菜单 Ctrl + Shift + P：调出命令板（Command Palette） Ctrl + `：调出控制台 编辑（Editing） Ctrl + Enter：在当前行下面新增一行然后跳至该行 Ctrl + Shift + Enter：在当前行上面增加一行并跳至该行 Ctrl + ←/→：进行逐词移动 Ctrl + Shift + ←/→：进行逐词选择 Ctrl + ↑/↓：移动当前显示区域 Ctrl + Shift + ↑/↓：移动当前行 选择（Selecting） Ctrl + D：选择当前光标所在的词并高亮该词所有出现的位置，再次 Ctrl + D 选择该词出现的下一个位置，在多重选词的过程中，使用 Ctrl + K 进行跳过，使用 Ctrl + U 进行回退，使用 Esc 退出多重编辑 Ctrl + Shift + L：将当前选中区域打散 Ctrl + J：把当前选中区域合并为一行 Ctrl + M：在起始括号和结尾括号间切换 Ctrl + Shift + M：快速选择括号间的内容 Ctrl + Shift + J：快速选择同缩进的内容 Ctrl + Shift + Space：快速选择当前作用域（Scope）的内容 查找 &amp; 替换（Finding&amp;Replacing） F3：跳至当前关键字下一个位置 Shift + F3：跳到当前关键字上一个位置 Alt + F3：选中当前关键字出现的所有位置 Ctrl + F/H：进行标准查找 / 替换，之后： Alt + C：切换大小写敏感（Case-sensitive）模式 Alt + W：切换整字匹配（Whole matching）模式 Alt + R：切换正则匹配（Regex matching）模式 Ctrl + Shift + H：替换当前关键字 Ctrl + Alt + Enter：替换所有关键字匹配 Ctrl + Shift + F：多文件搜索 &amp; 替换 跳转（Jumping） Ctrl + P：跳转到指定文件，输入文件名后可以： @ 符号跳转：输入 @symbol 跳转到 symbol 符号所在的位置 # 关键字跳转：输入 #keyword 跳转到 keyword 所在的位置 : 行号跳转：输入 :12 跳转到文件的第 12 行。 Ctrl + R：跳转到指定符号 Ctrl + G：跳转到指定行号 窗口（Window） Ctrl + Shift + N：创建一个新窗口 Ctrl + N：在当前窗口创建一个新标签 Ctrl + W：关闭当前标签，当窗口内没有标签时会关闭该窗口 Ctrl + Shift + T：恢复刚刚关闭的标签 屏幕（Screen） F11：切换普通全屏 Shift + F11：切换无干扰全屏 Alt + Shift + 2：进行左右分屏 Alt + Shift + 8：进行上下分屏 Alt + Shift + 5：进行上下左右分屏 分屏之后，使用 Ctrl + 数字键 跳转到指定屏，使用 Ctrl + Shift + 数字键 将当前屏移动到指定屏 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/11/02/tool/sublime-keymap/"},{"title":"SVN 目录使用规范","text":"SVN 目录使用规范。 规范 1（推荐） 目录名称 说明 trunk trunk 是树干，主分支，日常开发进行的地方。 branches branches 是分支。是用来做并行开发的，这里的并行是指和 trunk 进行比较，完成后一般会被合并到 trunk 中。一般有 3 类：【1.】一些阶段性的 release 版本，这些版本是可以继续进行开发和维护的，如 2.1 或 2.x （ 2 系列版本的最新代码）。【2.】为不同用户客制化的版本，也可以放在分支中进行开发，如 2.2_dev 。【3.】某个版本的 bug 修复，如： 2.1_bugfix 。 tags tags 是标记，一般是只读的，这里存储阶段性的发布版本，只是作为一个里程碑的版本进行存档，如： 2.1 ，2.1.1 。 规范 2 目录名称 稳定程度 权限 说明 branches 开发分支，不稳定 开发 team 有权限 有开发任务时，从 trunk 打分支到 branches ，分支命名以日期为前缀，如： 20170101 ，可再加上_本次分支主要内容，如： _monitor 。（如果 trunk 分支在测试且证明极度不稳定，想取稳定分支，从 tags 取）。开发且自测完成时，由研发 Leader 合并到主干 trunk ，测试从 trunk 发包进行测试。一般有 3 类：1.】准备发布的分支（进行生产环境的测试、准备） Release Branch ，如 BUG-1.0_235 (copy from tag/tag_release_1.0 , bug 版本号为 235)。【2.】Bug 修复的分支（进行某编号的 bug 修复） Bug fix branch ，如 RB-1.1 (1.1 版本的 Release Branch)。【3.】新技术实验性分支（将某个新技术引进项目） Experimental branch ，如 TRY-1.0_PHP7 (copy from tag/tag_release_1.0 ，PHP7 实验技术)。这些都要根据需要最终 merge 到 trunk 里面。 trunk 主干分支，趋于稳定 开发 Leader 有权限 最新趋于稳定版本代码存放地。开发 Leader 有权限从开发分支 merge 代码到主干，然后质量部进行测试，测试通过由运维部打上线分支到 tags 。研发 leader 要控制 trunk 的时序性。（也就是说尽量避免一个 brances 合并到 trunk 进行测试之后，在没有完成测试前又合并一个分支，导致测试返工。） tags 上线分支，稳定 运维有权限 方便回滚和记录。以版本号命名，如 1.1、1.2 。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/04/02/tool/svn-dir/"},{"title":"MySQL 定时备份","text":"在 Linux 上实现 MySQL 定时备份。 1 准备备份的脚本文件 1.1 创建脚本文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546vi /usr/local/mysqldata/bak/bak.sh# !/bin/bash# db-export variablesEXPORT_DB_HOST=\"127.0.0.1\"EXPORT_DB_PORT=\"3306\"EXPORT_DB_USER=\"root\"EXPORT_DB_PASSWORD=\"123456\"EXPORT_DB_NAME=\"db1\"EXPORT_DB_CMD=\"/usr/local/mysql/bin/mysqldump\"EXPORT_CMD_PREFIX=\"$EXPORT_DB_CMD -h$EXPORT_DB_HOST -P$EXPORT_DB_PORT -u$EXPORT_DB_USER -p$EXPORT_DB_PASSWORD $EXPORT_DB_NAME\"# db-import variablesIMPORT_DB_HOST=\"127.0.0.1\"IMPORT_DB_PORT=\"3306\"IMPORT_DB_USER=\"root\"IMPORT_DB_PASSWORD=\"123456\"IMPORT_DB_NAME=\"db2\"IMPORT_DB_CMD=\"/usr/local/mysql/bin/mysql\"IMPORT_CMD_PREFIX=\"$IMPORT_DB_CMD -h$IMPORT_DB_HOST -P$IMPORT_DB_PORT -u$IMPORT_DB_USER -p$IMPORT_DB_PASSWORD $IMPORT_DB_NAME\"# bak variables# BAK_FILE_DATE=`date +%Y%m%d%H%M%S`BAK_FILE_DATE=`date +%Y%m%d`BAK_FILE_DIR=\"/usr/local/mysqldata/bak/$BAK_FILE_DATE\"# BAK_FILE_DIR=\"/usr/local/mysqldata/bak/$(date +%Y%m%d)\"# shell scriptecho start $(date +%Y-%m-%d_%H:%M:%S).mkdir -p $BAK_FILE_DIRecho export start.tabs=\"tb1 tb2\"echo export tbs...$EXPORT_CMD_PREFIX $tbs &gt; $BAK_FILE_DIR/tbs.sqlecho export tbs...done.echo export end.echo import start.echo import tbs...IMPORT_CMD_PREFIX &lt; $BAK_FILE_DIR/tbs.sqlecho import tbs...done.echo import end.echo end $(date +%Y-%m-%d_%H:%M:%S). 1.2 脚本文件添加可执行权限 1chmod u+x /usr/local/mysqldata/bak/bak.sh 1.3 测试脚本文件 1234sh /usr/local/mysqldata/bak/bak.sh# 或者 cd /usr/local/mysqldata/bak./bak.sh 2 添加计划任务 - crontab123456789101112131415161718192021# 编辑任务。会打开 vi，增加上述脚本文件的配置，下面是每 1 分钟执行一次。实际会对应到 /var/spool/cron 目录下的 root （当前用户）文件中。crontab -e*/1 * * * * /usr/local/mysqldata/bak/bak.sh# 查看任务 crontab -l*/1 * * * * /usr/local/mysqldata/bak/bak.sh。# 如果任务执行失败了，可以通过以下命令查看任务日志 tail -f /var/log/cron# 输出类似如下：Oct 31 15:19:18 gridserver crontab[8951]: (root) REPLACE (root)Oct 31 15:19:18 gridserver crontab[8951]: (root) END EDIT (root)Oct 31 15:20:01 gridserver crond[4487]: (root) RELOAD (/var/spool/cron/root)Oct 31 15:20:01 gridserver CROND[8965]: (root) CMD (/usr/lib64/sa/sa1 1 1)Oct 31 15:20:01 gridserver CROND[8966]: (root) CMD (/usr/local/mysqldata/bak/bak.sh)Oct 31 15:21:01 gridserver CROND[8980]: (root) CMD (/usr/local/mysqldata/bak/bak.sh)Oct 31 15:22:01 gridserver CROND[8991]: (root) CMD (/usr/local/mysqldata/bak/bak.sh)Oct 31 15:23:01 gridserver CROND[9001]: (root) CMD (/usr/local/mysqldata/bak/bak.sh)Oct 31 15:24:01 gridserver CROND[9015]: (root) CMD (/usr/local/mysqldata/bak/bak.sh) MySQL 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/10/20/mysql/mysql-bak-timer/"},{"title":"如何在人力资源管理系统中提高 RabbitMQ 消息发送的可靠性","text":"学习如何在人力资源管理系统中提高 RabbitMQ 消息发送的可靠性，避免因为网络抖动等原因导致消息发送失败。 1 概述 我们在 人力资源管理系统 中引入了消息中间件 RabbitMQ ，并结合 RabbitMQ 搭建了独立的邮件服务器 hr-mail 。当在系统中录入一个员工后，系统会自动向消息中间件 RabbitMQ 发送一条消息，这条消息包含了新入职员工的基本信息。然后邮件服务器从 RabbitMQ 上消费消息，根据收到的消息，自动的发送一封入职欢迎邮件。 RabbitMQ 虽然用着方便，有很多优势，但是也带来了很多问题，例如网络抖动怎么办？如何确保消息的可靠性？在理想的环境下这些问题都不存在，但是在复杂的生产环境中，什么都是有可能的。所以，我们需要通过技术手段去处理这些问题。比如增加 消息发送确认机制 和消息发送失败自动重试机制，可以有效的提高消息发送的可靠性。 2 准备工作 新增 邮件发送日志 模块，用于记录消息发送相关信息，如消息投递状态、重试时间、重试次数等。 1234567891011121314public class MailSendLog { private Integer id; private String msgId; private Integer empId; private Integer status; // 0 投递中 1 投递成功 2 投递失败 private String routeKey; private String exchange; private Integer count; // 重试次数 private Date tryTime; // 第一次重试时间 private Date createTime; private Date updateTime; // getter/setter} 123456789public interface MailSendLogMapper { Integer updateMailSendLogStatus(@Param(\"msgId\") String msgId, @Param(\"status\") Integer status); Integer insert(MailSendLog mailSendLog); List&lt;MailSendLog&gt; getMailSendLogsByStatus(); Integer updateCount(@Param(\"msgId\") String msgId, @Param(\"date\") Date date);} 1234567891011121314151617&lt;mapper namespace=\"com.zhengjian.hr.mapper.MailSendLogMapper\"&gt; &lt;insert id=\"insert\" parameterType=\"com.zhengjian.hr.model.MailSendLog\"&gt; insert into t_mail_send_log (msgId,empId,routeKey,exchange,tryTime,createTime,updateTime) values (#{msgId},#{empId},#{routeKey},#{exchange},#{tryTime},#{createTime},#{updateTime}); &lt;/insert&gt; &lt;update id=\"updateMailSendLogStatus\"&gt; update t_mail_send_log set status = #{status} where msgId=#{msgId}; &lt;/update&gt; &lt;select id=\"getMailSendLogsByStatus\" resultType=\"com.zhengjian.hr.model.MailSendLog\"&gt; select * from t_mail_send_log where status=0 and tryTime &amp;lt; sysdate() &lt;/select&gt; &lt;update id=\"updateCount\"&gt; update t_mail_send_log set count=count+1,updateTime=#{date} where msgId=#{msgId}; &lt;/update&gt;&lt;/mapper&gt; 123456789101112131415161718192021@Servicepublic class MailSendLogService { @Autowired MailSendLogMapper mailSendLogMapper; public Integer insert(MailSendLog mailSendLog) { return mailSendLogMapper.insert(mailSendLog); } public Integer updateMailSendLogStatus(String msgId, Integer status) { return mailSendLogMapper.updateMailSendLogStatus(msgId, status); } public List&lt;MailSendLog&gt; getMailSendLogsByStatus() { return mailSendLogMapper.getMailSendLogsByStatus(); } public Integer updateCount(String msgId, Date date) { return mailSendLogMapper.updateCount(msgId, date); }} 12345678910public class MailConstants { public static final Integer STATUS_DELIVERING = 0; // 消息投递中 public static final Integer STATUS_SUCCESS = 1; // 消息投递成功 public static final Integer STATUS_FAILURE = 2; // 消息投递失败 public static final Integer MAX_TRY_COUNT = 3; // 最大重试次数 public static final Integer MSG_TIMEOUT = 1; // 消息超时时间（分钟），超过这个时间才会开始重试 public static final String QUEUE_NAME = \"hr.mail.employee.welcome.queue\"; public static final String EXCHANGE_NAME = \"hr.mail.employee.welcome.exchange\"; public static final String ROUTING_KEY_NAME = \"hr.mail.employee.welcome.routingKey\";} 3 消息发送确认 开启消息发送失败回调，路由失败回调。 新增 RabbitMQConfig 配置类，自定义 RabbitTemplate ，增加了消息发送回调，提高消息发送的可靠性。 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Configurationpublic class RabbitMQConfig { public final static Logger logger = LoggerFactory.getLogger(RabbitMQConfig.class); @Autowired CachingConnectionFactory cachingConnectionFactory; @Autowired MailSendLogService mailSendLogService; @Bean RabbitTemplate rabbitTemplate() { RabbitTemplate rabbitTemplate = new RabbitTemplate(cachingConnectionFactory); // 消息发送到交换机的回调 rabbitTemplate.setConfirmCallback((data, ack, cause) -&gt; { String msgId = data.getId(); if (ack) { // 修改数据库中的记录，消息投递成功 mailSendLogService.updateMailSendLogStatus(msgId, MailConstants.STATUS_SUCCESS); logger.info(\"消息发送成功：\" + msgId); } else { logger.info(\"消息发送失败：\" + msgId); } }); // 消息从交换机发送到队列的回调 rabbitTemplate.setReturnCallback((msg, repCode, repText, exchange, routingkey) -&gt; { logger.info(\"消息发送失败\"); }); return rabbitTemplate; } @Bean Queue mailQueue() { return new Queue(MailConstants.QUEUE_NAME, true); } @Bean DirectExchange mailExchange() { return new DirectExchange(MailConstants.EXCHANGE_NAME, true, false); } @Bean Binding mailBinding() { return BindingBuilder.bind(mailQueue()).to(mailExchange()).with(MailConstants.ROUTING_KEY_NAME); }} 注意，需要在配置文件中开启 RabbitMQ 的相关回调，如下： 1234## 开启 confirm 回调spring.rabbitmq.publisher-confirms=true## 开启 return 回调spring.rabbitmq.publisher-returns=true 修改 EmployeeService 中新增员工的方法，保存邮件发送日志，并向 RabbitMQ 投递消息，如下： 12345678910111213141516171819202122232425public int add(Employee employee) { handleContractTerm(employee); int r = employeeMapper.insertSelective(employee); if (r == 1) { // 获取关联信息 Employee employeeWithAll = employeeMapper.selectWithAllByPrimaryKey(employee.getId()); // jmsMessagingTemplate.convertAndSend(MailConstants.QUEUE_NAME, employeeWithAll); // 生成消息的唯一 id String msgId = UUID.randomUUID().toString(); MailSendLog mailSendLog = new MailSendLog(); mailSendLog.setMsgId(msgId); Date date = new Date(); mailSendLog.setCreateTime(date); mailSendLog.setUpdateTime(date); mailSendLog.setExchange(MailConstants.EXCHANGE_NAME); mailSendLog.setRouteKey(MailConstants.ROUTING_KEY_NAME); mailSendLog.setEmpId(employeeWithAll.getId()); mailSendLog.setTryTime(new Date(System.currentTimeMillis() + 1000 * 60 * MailConstants.MSG_TIMEOUT)); mailSendLogService.insert(mailSendLog); rabbitTemplate.convertAndSend(MailConstants.EXCHANGE_NAME, MailConstants.ROUTING_KEY_NAME, employeeWithAll, new CorrelationData(msgId)); } return r;} 4 消息发送失败自动重试 开启定时任务巡查，发现有发送失败的消息自动重新投递。 新增 消息发送定时任务，针对发送失败的消息会自动重试一定的次数，提高消息发送的可靠性。 123456789101112131415161718192021222324252627@Componentpublic class MailSendTask { @Autowired MailSendLogService mailSendLogService; @Autowired RabbitTemplate rabbitTemplate; @Autowired EmployeeMapper employeeMapper; @Scheduled(cron = \"0/10 * * * * ?\") public void mailResendTask() { List&lt;MailSendLog&gt; logs = mailSendLogService.getMailSendLogsByStatus(); if (logs == null || logs.size() == 0) { return; } logs.forEach(mailSendLog -&gt; { if (mailSendLog.getCount() &gt;= MailConstants.MAX_TRY_COUNT) { // 设置该条消息发送失败 mailSendLogService.updateMailSendLogStatus(mailSendLog.getMsgId(), MailConstants.STATUS_FAILURE); } else { mailSendLogService.updateCount(mailSendLog.getMsgId(), new Date()); Employee emp = employeeMapper.selectWithAllByPrimaryKey(mailSendLog.getEmpId()); rabbitTemplate.convertAndSend(MailConstants.EXCHANGE_NAME, MailConstants.ROUTING_KEY_NAME, emp, new CorrelationData(mailSendLog.getMsgId())); } }); }} 注意，需要在启动类上增加 @EnableScheduling 注解，开启定时任务，如下： 1234567891011@SpringBootApplication@MapperScan(basePackages = \"com.zhengjian.hr.mapper\")@EnableCaching // 开启缓存@EnableScheduling // 开启定时任务public class HrApplication { public static void main(String[] args) { SpringApplication.run(HrApplication.class, args); }} Spring Boot 实战项目（人力资源管理系统）教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 实战项目（人力资源管理系统）源码：https://github.com/cxy35/hr 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/05/05/hr/hr-rabbitmq-reliability-producer/"},{"title":"Linux 常用命令 - 目录、文件等","text":"通过本文学习 Linux 常用命令 - 目录、文件：cd mkdir touch cp mv rm more du 等。 创建目录：mkdir 命令格式：mkdir [选项] 目录 命令功能：在指定位置创建指定文件名命名的文件夹或目录，要创建文件夹或目录的用户必须对所创建的文件夹的父文件夹具有写权限，且同一个目录下不能有重名的 命令参数： -m：&lt;mode 模式 &gt; 设定权限 &lt; 模式 &gt;(类似 chmod)，而不是 rwxrwxrwx -p： 可以是一个路径的名称，此时若路径中的某些目录不存在，加上此选项后系统将自动建立好 + 那些尚不存在的目录 -v： 显示操作进程 命令实例： mkdir test –&gt; 在当前目录下创建 test 目录 mkdir –p ./test/1/11 –&gt; 在当前目录下创建 test/1/11 目录，每级都会建起来 mkdir -p /usr/local/mydata/{data,tmp,run,log,etc} –&gt; 同时建多个目录 mkdir –m 777 test777 –&gt; 在当前目录下创建权限为 777 的目录 mkdir –v test –&gt; 创建目录时会显示操作进程 查看目录：ls 命令格式：ls [选项] [目录名] 命令功能：列出目标目录中所有的子目录和文件 命令参数： -a：列出目录下的所有文件，包括以. 开头的隐藏文件 -l：除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来 -t：以文件的修改时间顺序排序 -c：以文件状态最后更改的时间 ctime 顺序排序，配合 -lt 根据 ctime 排序及根据 ctime , 配合 -l 显示 ctime 但根据名称排序 -u：以文件的访问时间顺序排序，配合 -lt 显示访问时间，而且依据访问时间排序，配合 -l 显示访问时间，但根据名称排序 -v：依据版本进行排序 -x：逐行列出项目，而不是逐栏列出 -X：根据扩展名进行排序 -1：每行只列出一个文件 -F：可以在显示子目录的时候在它的文件名之后加一个 “/” ，而文件后面的 “*” 表示这是一个可执行程序 -R：递归显示所有文件和目录 命令实例： ls –l t* –&gt; 列出当前目录中所有以 “t” 开头的目录和文件的信息 统计目录大小：du du -sh / –&gt; 统计根目录大小 du -sh /* –&gt; 统计根目录下每个子目录大小 du / –max-depth=1 -h –&gt; 统计根目录（/）下，所有一级目录（–max-depth）的总大小，如 /var、/dev 等 切换目录：cd 命令格式：cd [目录名] 命令功能：切换当前目录至 dirName 命令实例： cd / –&gt; 进入系统根目录 cd .. 或者 cd ..// –&gt; 进入当前目录的上一级目录 cd 或者 cd ~ –&gt; 进入当前用户的主目录 cd – –&gt; 返回进入此目录之前所在的目录 cd !$ –&gt; 把上个命令的参数作为 cd 参数使用 删除空目录：rmdir 命令格式：rmdir [选项] 目录 命令功能：该命令从一个目录中删除一个或多个子目录项（前提是空目录），删除某目录时也必须对父目录有写权限 命令参数： -p：递归删除父目录，当子目录被删除后如果使其父目录成为空目录的话，则父目录一同被删除 -v： 显示操作进程 命令实例： rmdir –p test/t1 –&gt; 当 t1 被删除后如果使 test 成为空目录的话，则 test 一同被删除 创建文件或修改文件时间：touch 命令格式：touch [选项] 文件 命令功能：touch- 命令参数可更改文档或目录的日期时间，包括存取时间和更改时间 命令参数： -a：只更新访问时间，不改变修改时间 -c：不创建不存在的文件 -m：只更新修改时间，不改变访问时间 -t：将时间修改为参数指定的日期，如：07081556 代表 7 月 8 号 15 点 56 分 -r：将指定文档或目录的日期时间，设成和参考文档或目录的日期时间一样 命令实例： touch test –&gt; 在当前目录下创建文件名为 test 的文件或者更新已有文件 test 的修改时间和访问时间 touch –r 1.txt 2.txtt –&gt; 更新 2.txt 的时间和 1.txt 时间戳相同 复制目录 / 文件：cp 命令格式：cp [选项] sourceFileName targetFileName 命令功能：将源文件复制至目标文件，或将多个源文件复制至目标文件 命令参数： -i：&lt;interactive 互动 &gt; 如果文件将覆盖目标中的文件，会提示确认 -r：&lt;recursive 递归 &gt; 这个选项会复制整个目录树、子目录以及其他 -v：显示文件的复制进度 命令实例： cp test.log test2.log –&gt; 复制文件 cp test.log aaa/test2.log –&gt; 将当前目录下的 test.log 文件复制到 aaa 目录下，并重命名为 test2.log cp –r test3 test5 –&gt; 复制整个目录 移动、重命名目录 / 文件：mv 命令格式：mv [选项] 源文件或目录 目标文件或目录 命令功能：视 mv 命令中第二个参数类型的不同（是目标文件还是目标目录）， mv 命令将文件重命名或将其移至一个新的目录中。当第二个参数类型是文件时， mv 命令完成文件重命名，此时，源文件只能有一个（也可以是源目录名），它将所给的源文件或目录重命名为给定的目标文件名。当第二个参数是已存在的目录名时，源文件或目录参数可以有多个，mv 命令将各参数指定的源文件均移至目标目录中。在跨文件系统移动文件时， mv 先拷贝，再将原有文件删除，而链接该文件的链接也将丢失 命令参数： -i：&lt;interactive 互动 &gt; 若目标文件已经存在时，就会询问是否覆盖 -f：&lt; 强制 &gt; 如果目标文件已存在，不会询问而直接覆盖，属于很危险的选项 -v：显示文件的移动进度 -b：若需要覆盖文件，则覆盖前先行备份。 -t：指定 mv 的目标目录，该选项适用于移动多个源文件到一个目录的情况，此时目标目录在前，源文件在后 命令实例： mv test.log test –&gt; 移动文件或文件重命名。如果 test 是已存在的目录，则移动文件，否则重命名文件 mv test.log test2.log test3.log test –&gt; 移动多个文件到目录中 mv test.log test2.log –&gt; 文件重命名 mv test.log test/test2.log –&gt; 移动文件到其他目录并重命名 mv dir1 dir2 –&gt; 目录的移动或重命名。如果目录 dir2 不存在，将目录 dir1 改名为 dir2 ，否则将 dir1 移动到 dir2 中 mv * ../ –&gt; 移动当前文件夹下的所有文件到上一级目录 mv test3/*.txt test5 –&gt; 把当前目录的一个子目录里的文件移动到另一个子目录里 mv -b test.log test2.log –&gt; 文件被覆盖前做简单备份 删除目录 / 文件：rm 命令格式：rm [选项] 文件 命令功能：删除指定目录中的一个或多个文件或目录，如果没有使用 -r 选项，则 rm 不会删除目录，如果使用 rm 来删除文件，通常仍可以将文件恢复原状 命令参数： -i：&lt;interactive 互动 &gt; 提示确认删除 -f：&lt;force 强制 &gt; 代替互动模式，不提示确认删除 -r：&lt;recursive 递归 &gt; 将删除某个目录以及其中所有的子目录和文件 -v：&lt;recursive 强制 &gt; 显示文件的删除进度 命令实例： rm 11.log –&gt; 删除文件 rm -f 11.log –&gt; 强行删除文件 rm –r test –&gt; 递归删除目录和文件 rm –rf test –&gt; 递归强行删除目录和文件 rm – -f –&gt; 删除以 -f 开头的文件 查看 / 合并文件：cat、tac（反向） 命令格式：cat [选项] [文件] 命令功能：cat 主要有三大功能： 一次显示整个文件：cat filename 创建一个新文件：cat&gt;filename 将几个文件合并为一个文件：cat file1 file2&gt;file 命令参数： -A： -b： 对非空输出行编号 -n： 对输出的所有行编号，由 1 开始对所有输出的行数编号 -s： 有连续两行以上的空白行，就代换为一行的空白行 -E： 在每行结束处显示 $ -T： 将跳格字符显示为 ^I 命令实例： cat 1.log –&gt; 显示 1.log 文件内容 cat –n 1.log –&gt; 显示 1.log 文件内容（加上行号） cat –b 1.log 2.log –&gt; 合并显示 1.log 和 2.log 文件内容（加上行号，空白行不加） cat&gt;1.log –&gt; 创建新文件 1.log cat –n 1.log&gt;2.log –&gt; 将 1.log 的文件内容加上行号后写入 2.log 这个文件里，如果 2.log 不存在，则会自动新建 查看文件：more（分页） 命令格式：more [-dlfpcsu][-num][+/pattern][+linenum][file…] 命令功能：more 命令和 cat 的功能一样都是查看文件里的内容，但有所不同的是 more 可以按页来查看文件的内容，还支持直接跳转行等功能 命令参数： +3：从第 3 行开始显示 -3：定义屏幕大小为 3 行 +/pattern：在每个档案显示前搜寻该字串（ pattern ），然后从该字串前两行之后开始显示 -c：从顶部清屏，然后显示 -p：通过清除窗口而不是滚屏来对文件进行换页，与 -c 选项相似 常用操作命令： Enter：向下 n 行，需要定义，默认为 1 行 Ctrl+F 或空格键：向下滚动一屏 Ctrl+B： 返回上一屏 =： 输出当前行的行号 :f：输出文件名和当前行的行号 V：调用 vi 编辑器 q：退出 more 命令实例： more +3 1.log –&gt; 显示文件中从第 3 行起的内容 more -3 1.log –&gt; 设定每屏显示行数 more +/day3 1.log –&gt; 从文件中查找第一个出现 “day3” 字符串的行，并从该处前两行开始显示输出 ls –l | more -5 –&gt; 每页显示 5 个文件信息 查看文件：less（分页） 命令格式：less [参数] 文件 命令功能：less 与 more 类似，但使用 less 可以随意浏览文件，而且 less 在查看之前不会加载整个文件 命令参数： -b：&lt; 缓冲区大小 &gt; 设置缓冲区的大小 -e：当文件显示结束后，自动离开 -f：强迫打开特殊文件，例如外围设备代号、目录和二进制文件 -g：只标志最后搜索的关键词 -i：忽略搜索时的大小写 -m：显示类似 more 命令的百分比 -N：显示每行的行号 -o：&lt; 文件名 &gt; 将 less 输出的内容在指定文件中保存起来 -Q：不使用警告音 -s：显示连续空行为一行 -S：行过长时间将超出部分舍弃 -x：&lt; 数字 &gt; 将 “tab” 键显示为规定的数字空格 常用操作命令： / 字符串：向下搜索“字符串”的功能 ? 字符串：向上搜索“字符串”的功能 n：重复前一个搜索（与 / 或 ? 有关） N：反向重复前一个搜索（与 / 或 ? 有关） b：向后翻一页 d：向后翻半页 h：显示帮助界面 Q：退出 less 命令 u：向前滚动半页 y：向前滚动一行 空格键：滚动一行 回车键：滚动一页 [pagedown]：向下翻动一页 [pageup]：向上翻动一页 命令实例： less 1.log –&gt; 查看文件 less 1.log 2.log –&gt; 查看多个文件 ps -ef | less –&gt; ps 查看进程信息并通过 less 分页显示 history | less –&gt; 查看命令历史使用记录并通过 less 分页显示 查看文件：head（开头内容） 命令格式：head [参数] [文件] 命令功能：用来显示文件的开头至标准输出中，默认 head 命令打印其相应文件的开头 10 行 命令参数： -n：&lt; 行数 &gt; 显示的行数 -c：&lt; 字节 &gt; 显示的字节数 -q：隐藏文件名 -v：显示文件名 命令实例： head -n 5 1.log –&gt; 显示文件内容（开头的 5 行） head -n 5 1.log &gt; 2.log –&gt; 将文件内容（开头的 5 行）输出到 2.log 文件中 head -n -5 1.log –&gt; 显示文件内容（除了最后的 5 行） head -c 20 1.log –&gt; 显示文件内容（开头的 20 个字节） head -c -20 1.log –&gt; 显示文件内容（除了最后的 20 个字节） 查看文件：tail（结尾内容，支持动态刷新） 命令格式：tail [参数] [文件] 命令功能：用于显示指定文件末尾内容，并且不断刷新（常用于查看日志文件）。不指定文件时，作为输入信息进行处理 命令参数： -f：循环读取 -n：&lt; 行数 &gt; 显示的行数 -c：&lt; 字节 &gt; 显示的字节数 -q：不显示处理信息 -v：显示详细的处理信息 命令实例： tail -f 1.log –&gt; 循环查看文件末尾内容 tail -n 5 1.log –&gt; 显示文件内容（最后的 5 行） tail -n 5 1.log &gt; 2.log –&gt; 将文件内容（最后的 5 行）输出到 2.log 文件中 tail -n +5 1.log –&gt; 显示文件内容（除了开头的 5 行） 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/01/08/linux/linux-command/"},{"title":"MySQL 备份与恢复 - mydumper","text":"mydumper 是第三方支持 mysql 的备份恢复工具，支持多线程，备份与恢复速度快。 1 准备工作 mydumper 特性 支持多线程导出数据，速度比 mysqldump 快。 支持一致性备份，使用 FTWRL(FLUSH TABLES WITH READ LOCK) 会阻塞 DML 语句, 保证备份数据的一致性。 支持将导出文件压缩，节约空间。 支持多线程恢复。 支持以守护进程模式工作，定时快照和连续二进制日志。 支持按照指定大小将备份文件切割。 数据与建表语句分离。 mydumper 主要工作步骤 主线程 FLUSH TABLES WITH READ LOCK, 施加全局只读锁，以阻止 DML 语句写入，保证数据的一致性。 读取当前时间点的二进制日志文件名和日志写入的位置并记录在 metadata 文件中，以供即时点恢复使用。 START TRANSACTION WITH CONSISTENT SNAPSHOT; 开启读一致事务。 启用 N 个（线程数可以指定，默认是 4） dump 线程导出表和表结构 。 备份非事务类型的表。 主线程 UNLOCK TABLES，备份完成非事务类型的表之后，释放全局只读锁。 dump InnoDB tables, 基于事物导出 InnoDB 表。 事物结束。 下载安装包 mydumper 版本：mydumper-0.9.1 手动下载地址：https://github.com/maxbube/mydumper/releases linux 自动获取：wget https://github.com/maxbube/mydumper/archive/v0.9.1.tar.gz 2 安装 1234567891011121314151617# 解压，重命名 tar -xvzf mydumper-0.9.1.tar.gz -C /usr/local/mv /usr/local/mydumper-0.9.1 /usr/local/mydumper# 查看注意事项 #cat /usr/local/mydumper/README# 安装依赖 yum -y install glib2-devel mysql-devel zlib-devel pcre-devel zlib gcc-c++ gcc cmake# 编译安装，完成之后在会 /usr/local/mydumper 目录下生成 mydumper 和 myloader 二进制文件 cd /usr/local/mydumpercmake .make &amp;&amp; make install# 编译报错的话查看报错信息，一般是因为依赖包的问题 # cat /usr/local/mydumper/CMakeFiles/CMakeOutput.log 具体的编译安装过程如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758[root@localhost local]$ cd /usr/local/mydumper[root@localhost mydumper]$ cmake .-- The C compiler identification is GNU 4.4.7-- The CXX compiler identification is GNU 4.4.7-- Check for working C compiler: /usr/bin/cc-- Check for working C compiler: /usr/bin/cc -- works-- Detecting C compiler ABI info-- Detecting C compiler ABI info - done-- Check for working CXX compiler: /usr/bin/c++-- Check for working CXX compiler: /usr/bin/c++ -- works-- Detecting CXX compiler ABI info-- Detecting CXX compiler ABI info - done-- Using mysql-config: /usr/bin/mysql_config-- Found MySQL: /usr/include/mysql, /usr/lib64/mysql/libmysqlclient_r.so;/usr/lib64/libz.so;/usr/lib64/libpthread.so;/usr/lib64/libcrypt.so;/usr/lib64/libnsl.so;/usr/lib64/libm.so;/usr/lib64/libpthread.so;/usr/lib64/libssl.so;/usr/lib64/libcrypto.so-- Found ZLIB: /usr/lib64/libz.so (found version \"1.2.3\") -- Found PkgConfig: /usr/bin/pkg-config (found version \"0.23\") -- checking for one of the modules 'glib-2.0'-- checking for one of the modules 'gthread-2.0'-- checking for module 'libpcre'-- found libpcre, version 7.8-- Found PCRE: /usr/include CMake Warning at docs/CMakeLists.txt:9 (message): Unable to find Sphinx documentation generator-- -------------------------------------------------- MYSQL_CONFIG = /usr/bin/mysql_config-- CMAKE_INSTALL_PREFIX = /usr/local-- BUILD_DOCS = ON-- WITH_BINLOG = OFF-- RUN_CPPCHECK = OFF-- Change a values with: cmake -D&lt;Variable&gt;=&lt;Value&gt;-- -------------------------------------------------- -- Configuring done-- Generating done-- Build files have been written to: /usr/local/mydumper[root@localhost mydumper]$ make &amp;&amp; make installScanning dependencies of target mydumper[25%] Building C object CMakeFiles/mydumper.dir/mydumper.c.o[50%] Building C object CMakeFiles/mydumper.dir/server_detect.c.o[75%] Building C object CMakeFiles/mydumper.dir/g_unix_signal.c.oLinking C executable mydumper[75%] Built target mydumperScanning dependencies of target myloader[100%] Building C object CMakeFiles/myloader.dir/myloader.c.oLinking C executable myloader[100%] Built target myloader[75%] Built target mydumper[100%] Built target myloaderInstall the project...-- Install configuration: \"\"-- Installing: /usr/local/bin/mydumper-- Removed runtime path from \"/usr/local/bin/mydumper\"-- Installing: /usr/local/bin/myloader-- Removed runtime path from \"/usr/local/bin/myloader\"[root@localhost mydumper]$ 3 使用 12345678910111213141516# 导出整个库 /usr/local/bin/mydumper -u root -S /srv/my3308/run/mysql.sock -B trade_platform -o /data/trade_platform# 只导出表结构，不导数据 /usr/local/bin/mydumper -u root -S /srv/my3308/run/mysql.sock -B trade_platform -d -o /data/trade_platform# 以压缩的方式导出的文件 /usr/local/bin/mydumper -u root -S /srv/my3308/run/mysql.sock -B trade_platform -c -o /data/trade_platform# 备份文件以 .gz 的格式压缩 # lsmetadata trade_platform.config.sql.gz trade_platform.trade_order-schema.sql.gztrade_platform.config-schema.sql.gz trade_platform-schema-create.sql.gz trade_platform.trade_order.sql.gz# 使用正则表达式。其中正则表达式可以是 --regex=order.* 导出所有 order 开头的表 /usr/local/bin/mydumper -u root -S /srv/my3308/run/mysql.sock --regex='^(?!(mysql|test))' -o /data/bk20170120 mydumper 导出的文件包括 metadata trade\\_platform.config.sql trade\\_platform.order.sql ： metadata：记录导出时 binlog 的位点信息，如果启用 gtid ，则记录 gtid 信息。 123456Started dump at: 2017-01-20 17:26:53 SHOW MASTER STATUS: Log: mysql-bin.000025 Pos: 505819083 GTID: Finished dump at: 2017-01-20 17:27:02 db.table.sql : 数据文件，insert 语句 db.table-schema.sql : 包含建表语句 db-schema.sql : 包含建库语句 相比 mysqldump ， mydumper 导出的文件形式是每个表一个文件，对于开发 / 测试环境的误操作恢复十分有效。 实际使用： 123456789101112131415161718192021222324252627282930313233# 导出数据库 mydb/usr/local/bin/mydumper -u root -h 127.0.0.1 -P 3306 -S /usr/local/griddata/tmp/mysql.sock --skip-tz-utc --less-locking -B mydb -o /usr/local/mydata/mydb_0708 -v 3 | tee -a /tmp/mydb_0708.log# ** Message: Thread 2 dumping table for `mydb`.`t_user`# ** Message: Thread 2 dumping schema for `mydb`.`t_user`# ** Message: Thread 2 dumping view for `mydb`.`view_user`# ** Message: Thread 2 shutting down# ** Message: Thread 4 shutting down# ** Message: Thread 1 shutting down# ** Message: Thread 3 shutting down# ** Message: Finished dump at: 2019-07-08 22:32:30[root@localhost mydata]$ cat mydb_0708/metadata Started dump at: 2019-07-08 16:41:24SHOW MASTER STATUS: Log: mysql-bin.000739 Pos: 71397008 GTID:SHOW SLAVE STATUS: Host: 10.68.128.149 Log: mysql-bin.000763 Pos: 77168544 GTID:Finished dump at: 2019-07-08 22:32:30# 导入数据库 mydb/usr/local/bin/myloader -u root -h 127.0.0.1 -P 3308 -o -e -B mydb -d /usr/local/mydata/mydb_0708 -t 8 -v 3 | tee -a /tmp/mydb_0710.log# ** Message: Dropping table or view (if exists) `mydb`.`t_user`# ** Message: Creating table `mydb`.`t_user`# ** Message: Thread 3 restoring `mydb`.`t_user` part 0 4 参数说明 4.1 mydumper 常用参数 1234567891011121314151617181920212223242526-B, --database 要导出的 dbname-T, --tables-list 需要导出的表名, 导出多个表需要逗号分隔，t1[,t2,t3 ....] -o, --outputdir 导出数据文件存放的目录，mydumper 会自动创建 -s, --statement-size 生成插入语句的字节数, 默认 1000000 字节 -r, --rows Try to split tables into chunks of this many rows. This option turns off --chunk-filesize-F, --chunk-filesize 切割表文件的大小，默认单位是 MB ，如果表大于 -c, --compress 压缩导出的文件 -e, --build-empty-files 即使是空表也为表创建文件 -x, --regex 使用正则表达式匹配 db.table -i, --ignore-engines 忽略的存储引擎，多个值使用逗号分隔 -m, --no-schemas 只导出数据，不导出建库建表语句 -d, --no-data 仅仅导出建表结构，创建 db 的语句 -G, --triggers 导出触发器 -E, --events 导出 events-R, --routines 导出存储过程和函数 -k, --no-locks 不执行临时的只读锁，会导致备份不一致 。WARNING: This will cause inconsistent backups--less-locking 最小化在 innodb 表上的锁表时间 --butai-l, --long-query-guard 设置长时间执行的 sql 的时间标准 -K, --kill-long-queries 将长时间执行的 sql kill-D, --daemon 以守护进程的方式执行 -I, --snapshot-interval 创建导出快照的时间间隔，默认是 60s ，该参数只有在守护进程执行的时候有用。-L, --logfile 指定 mydumper 输出的日志文件，默认使用控制台输出。--tz-utc SET TIME_ZONE='+00:00' at top of dump to allow dumping of TIMESTAMP data when a server has data in different time zones or data is being moved between servers with different time zones, defaults to on use --skip-tz-utc to disable.--skip-tz-utc--use-savepoints 使用 savepoints 减少 MDL 锁事件 需要 SUPER 权限 --success-on-1146 Not increment error count and Warning instead of Critical in case of table doesn 4.2 myloader 常用参数 1234567891011121314-d, --directory 备份文件的文件夹 -q, --queries-per-transaction 每次事物执行的查询数量，默认是 1000-o, --overwrite-tables 如果要恢复的表存在，则先 drop 掉该表，使用该参数，需要备份时候要备份表结构 -B, --database 需要还原的数据库 -e, --enable-binlog 启用还原数据的二进制日志 -h, --host The host to connect to-u, --user Username with privileges to run the dump-p, --password User password-P, --port TCP/IP port to connect to-S, --socket UNIX domain socket file to use for connection-t, --threads 还原所使用的线程数，默认是 4-C, --compress-protocol 压缩协议 -V, --version 显示版本 -v, --verbose 输出模式, 0 = silent, 1 = errors, 2 = warnings, 3 = info, 默认为 2 MySQL 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/10/13/mysql/mysql-bak-mydumper/"},{"title":"MySQL binlog 详解","text":"通过本文学习 MySQL 中 binlog 相关的内容，包括概述、配置及常用操作、数据恢复实战等。 1 概述MySQL 的二进制日志 binlog 可以说是 MySQL 最重要的日志，它记录了所有的 DDL 和 DML 语句（除了数据查询语句 select ），以事件形式记录，还包含语句所执行的消耗的时间，MySQL 的二进制日志是事务安全型的。 DDL：Data Definition Language 数据库定义语言。主要的命令有 create、alter、drop 等，ddl 主要是用在定义或改变表（table）结构、数据类型、表之间的连接和约束等初始工作上，他们大多在建表时候使用。 DML：Data Manipulation Language 数据操纵语言。主要命令是 select/update/insert/delete ，就像它的名字一样，这 4 条命令是用来对数据库里的数据进行操作的语言。 二进制日志包括两类文件：二进制日志索引文件（文件名后缀为 .index ，如 mysql-bin.index），用于记录所有的二进制文件；二进制日志文件（文件名后缀为 .00000* ，如 mysql-bin.000001），用于记录数据库所有的 DDL 和 DML （除了数据查询）语句事件。 binlog 日志两个最重要的使用场景：主从同步、数据恢复。 一般来说开启 binlog 日志大概会有 1% 的性能损耗。 2 配置及常用操作2.1 配置 binlog 日志1234567891011121314vi /usr/local/mydata/etc/my.cnf[mysqld]# 必须log_bin=/usr/local/mydata/log/mysql-bin.logbinlog_format=MIXEDserver_id=1# 非必须sync_binlog = 100binlog_cache_size = 1Gmax_binlog_cache_size = 1Gmax_binlog_size = 1Gexpire_logs_days = 7 2.2 验证 binlog 日志是否开启12345678910111213141516171819mysql&gt; show variables like 'log_%';+----------------------------------------+---------------------------------------+| Variable_name | Value |+----------------------------------------+---------------------------------------+| log_bin | ON || log_bin_basename | /usr/local/mydata/log/mysql-bin || log_bin_index | /usr/local/mydata/log/mysql-bin.index || log_bin_trust_function_creators | OFF || log_bin_use_v1_row_events | OFF || log_error | /usr/local/mydata/log/alert.log || log_output | FILE || log_queries_not_using_indexes | OFF || log_slave_updates | ON || log_slow_admin_statements | OFF || log_slow_slave_statements | OFF || log_throttle_queries_not_using_indexes | 0 || log_warnings | 1 |+----------------------------------------+---------------------------------------+13 rows in set (0.00 sec) 看到 log_bin=ON，表示开启成功。 2.3 查看所有 binlog 日志列表12345678mysql&gt; show binary logs;+------------------+------------+| Log_name | File_size |+------------------+------------+| mysql-bin.000001 | 1678110651 || mysql-bin.000002 | 62841042 |+------------------+------------+2 rows in set (0.00 sec) 如果搭建了主从，还可以使用下列命令。 12345678mysql&gt; show master logs;+------------------+------------+| Log_name | File_size |+------------------+------------+| mysql-bin.000001 | 1678110651 || mysql-bin.000002 | 63933358 |+------------------+------------+2 rows in set (0.00 sec) 查看 master 状态，即最后（最新）一个 binlog 日志的编号名称，及其最后一个操作事件 pos 结束点（Position）值 1234567mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000002 | 80981731 | | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 2.4 刷新 log 日志1mysql&gt; flush logs; 自此刻开始产生一个新编号的 binlog 日志文件。每当 MySQL 服务重启时，会自动执行此命令，刷新 binlog 日志。另外在 mysqlddump 备份数据时加 -F 选项也会刷新 binlog 日志。 2.5 清除日志文件到指定文件1mysql&gt; purge master logs to 'mysql-bin.000008'; 会删除编号之前的日志文件。 注意：该命令在生产环境下不要轻易执行，特别是要清除的文件较多时，会影响 MySQL 性能。 2.6 重置（清空）所有 binlog 日志1mysql&gt; reset master; 2.7 查看 binlog 日志（使用 mysqlbinlog）123456789# 按时间范围查询，分页查看/usr/local/mysql/bin/mysqlbinlog --no-defaults --database=mydb --start-datetime=\"2020-07-09 10:00:00\" --stop-datetime=\"2020-07-09 12:00:00\" /usr/local/mydata/log/mysql-bin.004735 | more# 按位置范围查询，分页查看/usr/local/mysql/bin/mysqlbinlog --no-defaults --database=mydb --start-position=188002427 --stop-position=258376950 /usr/local/mydata/log/mysql-bin.004735 | more# 按时间范围查询，并将结果导出到新的文件中，方便查看/usr/local/mysql/bin/mysqlbinlog --no-defaults --database=mydb --start-datetime=\"2020-07-09 10:00:00\" --stop-datetime=\"2020-07-09 12:00:00\" /usr/local/mydata/log/mysql-bin.004735 &gt; /usr/local/mydata/binlog4375# 按位置范围查询，并将结果导出到新的文件中，方便查看/usr/local/mysql/bin/mysqlbinlog --no-defaults --database=mydb --start-position=188002427 --stop-position=258376950 /usr/local/mydata/log/mysql-bin.004735 &gt; /usr/local/mydata/binlog4375 上述查询的结果无法直接阅读，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/usr/local/mysql/bin/mysqlbinlog --no-defaults --database=mydb --start-datetime=\"2020-07-09 10:00:00\" --stop-datetime=\"2020-07-09 12:00:00\" /usr/local/mydata/log/mysql-bin.004735 | more/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#200709 8:53:46 server id 20001 end_log_pos 120 CRC32 0xaf81b3f4 Start: binlog v 4, server v 5.6.42-log created 200709 8:53:46BINLOG 'mmoGXw8hTgAAdAAAAHgAAAAAAAQANS42LjQyLWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXAAEGggAAAAICAgCAAAACgoKGRkAAfSzga8='/*!*/;# at 188002427#200709 10:00:00 server id 20001 end_log_pos 188002501 CRC32 0xf0727217 Query thread_id=313330 exec_time=0 error_code=0SET TIMESTAMP=1594260000/*!*/;SET @@session.pseudo_thread_id=313330/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=2097152/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=192/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;BEGIN/*!*/;# at 188002501#200709 10:00:00 server id 20001 end_log_pos 188002674 CRC32 0x50c4e1d3 Table_map: `mydb`.`mytable` mapped to number 301# at 188002674#200709 10:00:00 server id 20001 end_log_pos 188002965 CRC32 0x4ad4cbb4 Write_rows: table id 301 flags: STMT_END_FBINLOG 'IHoGXxMhTgAArQAAAHKxNAsAAC0BAAAAAAEABm5iZ3JpZAASZ3JpZF9ldmVudF94dF90YXNrACgPDw8P/AMICA8PCA8PDw8PDw8PDw8PDw8PDw8PDw8PDw8IDw8PDw8DQ2AAYABgAB4AAmAA3AUeANwFHgAsAR4AEgCWAJYAWgASAB4AEgBgAJYAYADcBRIABgCWAJYABgBgAGAAYAAeAGAAYAD+/////9PhxFA=IHoGXx4hTgAAIwEAAJWyNAsAAC0BAAAAAAEAAgAo//////8Q+//wfCA4YTkzMzVjNzcyZmEzOGQzMDE3MzMxNGQzYmJlNTRkNiA4YTkzMzVjNzcyZmEzOGQzMDE3MzMxNGQzYjUwNTRjYyA4YTkzMzVjNzcyZmEzOGQzMDE3MzMxNGQzYjUwNTRjZQZ1bmRvbmUAAAAArjtNMXMBAACuO00xcwEAAAAAAAAAAAAAC2V2ZW50SGFuZGxlIGJiNGE5ZGEzNWU5ZGFhYWEwMTVlOWRiZjdmZTgwMDRmEgDnjq/kv53mo4Dmn6XmraPluLgCMzAgZmY4MDgwODE1ZDU1MTMyMDAxNWQ1ODljNzIzNTAwMTMAAAAAAAAAAAAAAAC0y9RK'/*!*/;# at 188002965#200709 10:00:00 server id 20001 end_log_pos 188002996 CRC32 0x8c0912cc Xid = 15280903421COMMIT/*!*/;# at 188002996#200709 10:00:00 server id 20001 end_log_pos 188003070 CRC32 0xd595d036 Query thread_id=313330 exec_time=0 error_code=0SET TIMESTAMP=1594260000/*!*/;--More-- 可在上面的基础上增加 --base64-output=decode-rows -v 参数将基于行的事件解码成一个 SQL 语句，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/usr/local/mysql/bin/mysqlbinlog --no-defaults --database=mydb --base64-output=decode-rows -v --start-datetime=\"2020-07-09 10:00:00\" --stop-datetime=\"2020-07-09 12:00:00\" /usr/local/mydata/log/mysql-bin.004735 | more/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#200709 8:53:46 server id 20001 end_log_pos 120 CRC32 0xaf81b3f4 Start: binlog v 4, server v 5.6.42-log created 200709 8:53:46# at 188002427#200709 10:00:00 server id 20001 end_log_pos 188002501 CRC32 0xf0727217 Query thread_id=313330 exec_time=0 error_code=0SET TIMESTAMP=1594260000/*!*/;SET @@session.pseudo_thread_id=313330/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=2097152/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=192/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;BEGIN/*!*/;# at 188002501#200709 10:00:00 server id 20001 end_log_pos 188002674 CRC32 0x50c4e1d3 Table_map: `mydb`.`mytable` mapped to number 301# at 188002674#200709 10:00:00 server id 20001 end_log_pos 188002965 CRC32 0x4ad4cbb4 Write_rows: table id 301 flags: STMT_END_F### INSERT INTO `mydb`.`mytable`### SET### @1='8a9335c772fa38d30173314d3bbe54d6'### @2='8a9335c772fa38d30173314d3b5054cc'### @3='8a9335c772fa38d30173314d3b5054ce'### @4='undone'### @5=NULL### @6=0### @7=1594260011950### @8=1594260011950### @9=NULL### @10=NULL### @11=0### @12=NULL### @13=NULL### @14=NULL### @15=NULL### @16=NULL### @17=NULL### @18=NULL### @19=NULL### @20=NULL### @21=NULL### @22=NULL### @23=NULL### @24=NULL### @25='eventHandle'### @26='bb4a9da35e9daaaa015e9dbf7fe8004f'### @27='环保检查正常'### @28='30'### @29=NULL### @30=NULL### @31=NULL### @32=NULL### @33='ff8080815d551320015d589c72350013'### @34=0### @35=NULL### @36=NULL### @37=NULL### @38=NULL### @39=NULL### @40=0# at 188002965#200709 10:00:00 server id 20001 end_log_pos 188002996 CRC32 0x8c0912cc Xid = 15280903421COMMIT/*!*/;# at 188002996#200709 10:00:00 server id 20001 end_log_pos 188003070 CRC32 0xd595d036 Query thread_id=313330 exec_time=0 error_code=0SET TIMESTAMP=1594260000/*!*/;BEGIN/*!*/;# at 188003070 2.8 根据 binlog 日志恢复数据（使用 mysqlbinlog）12# 注意数据备份的时间节点、需要恢复数据的精确位置（起止），千万不要重复执行了相同的数据/usr/local/mysql/bin/mysqlbinlog --no-defaults --database=mydb --start-position=188002427 --stop-position=258376950 /usr/local/mydata/log/mysql-bin.004735 | /usr/local/mysql/bin/mysql -uroot -p123456 -v mydb 3 数据恢复实战3.1 准备测试数据123456789101112131415161718192021CREATE DATABASE mydb DEFAULT CHARACTER SET utf8mb4;USE mydb;CREATE TABLE `t_user` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键 id', `username` varchar(255) DEFAULT NULL COMMENT '用户名', `password` varchar(255) DEFAULT NULL COMMENT '密码', `enabled` tinyint(1) DEFAULT '1' COMMENT '是否启用：1 启用；0 未启用', `locked` tinyint(1) DEFAULT '0' COMMENT '是否锁定：1 锁定；0 未锁定', `address` varchar(255) DEFAULT NULL COMMENT '地址', `nick_name` varchar(255) DEFAULT NULL COMMENT '昵称', `create_time` datetime DEFAULT NULL COMMENT '创建时间', `update_time` datetime DEFAULT NULL COMMENT '更新时间', PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;INSERT INTO t_user(username,password,address,create_time,update_time) VALUES ('user01','123456','HZ',NOW(),NOW());INSERT INTO t_user(username,password,address,create_time,update_time) VALUES ('user02','123456','HZ',NOW(),NOW());INSERT INTO t_user(username,password,address,create_time,update_time) VALUES ('user03','123456','HZ',NOW(),NOW());INSERT INTO t_user(username,password,address,create_time,update_time) VALUES ('user04','123456','HZ',NOW(),NOW()); 3.2 模拟误操作 假如在 11:00 做了如下误操作，导致部分数据错误： 12345678910INSERT INTO t_user(username,password,address,create_time,update_time) VALUES ('user05','123456','HZ',NOW(),NOW());INSERT INTO t_user(username,password,address,create_time,update_time) VALUES ('user06','123456','HZ',NOW(),NOW());INSERT INTO t_user(username,password,address,create_time,update_time) VALUES ('user07','123456','HZ',NOW(),NOW());INSERT INTO t_user(username,password,address,create_time,update_time) VALUES ('user08','123456','HZ',NOW(),NOW());DELETE FROM t_user WHERE id=1;DELETE FROM t_user WHERE id=5;UPDATE t_user SET address='SH' where id=2;UPDATE t_user SET address='SH' where id=6; 3.3 模拟误操作之后数据的正常变更123456789INSERT INTO t_user(username,password,address,create_time,update_time) VALUES ('user09','123456','HZ',NOW(),NOW());INSERT INTO t_user(username,password,address,create_time,update_time) VALUES ('user10','123456','HZ',NOW(),NOW());DELETE FROM t_user WHERE id=3;DELETE FROM t_user WHERE id=7;UPDATE t_user SET address='BJ' where id=2;UPDATE t_user SET address='BJ' where id=4;UPDATE t_user SET address='BJ' where id=8; 3.4 根据 binlog 日志恢复数据 前提：假设在 10:00 做了数据备份（云服务器自动备份或手动备份，如果一直没备份，那没的玩）。 通过备份将数据库的数据还原到 10:00 的状态，之后在这基础上通过 binlog 日志将 3.2 中做的误操作跳过。 通过备份的时间节点（10:00）查询 binlog 日志（比如：mysql-bin.000002），找到对应的位置 position（比如分别为：63926791）。 通过 3.2 中大致的时间节点（比如：11:00-11:05）查询 binlog 日志（比如：mysql-bin.000002），找到对应的开始位置和结束位置 position（比如分别为：63933358 和 63938729）。 开始还原 10:00-11:00 的数据： /usr/local/mysql/bin/mysqlbinlog --no-defaults --database=mydb --start-position=63926791 --stop-position=63933358 /usr/local/mydata/log/mysql-bin.000002 | /usr/local/mysql/bin/mysql -uroot -p123456 -v mydb。 开始还原 11:05 之后的数据： /usr/local/mysql/bin/mysqlbinlog --no-defaults --database=mydb --start-position=63938729 /usr/local/mydata/log/mysql-bin.000002 | /usr/local/mysql/bin/mysql -uroot -p123456 -v mydb。 另外注意特殊情况：涉及到多个 binlog 日志文件。 MySQL 教程合集 （微信左下方 阅读全文 可直达）。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/07/11/mysql/mysql-binlog/"},{"title":"MySQL 参数配置优化","text":"MySQL 参数配置优化，提升 MySQL 效率与稳定性。 character_set_server可设置成 utf8。 default_character_set可设置成 utf8。 collation_server可设置成 utf8_unicode_ci。 init_connect可设置成 ‘SET NAMES utf8’ 。每个连接都会先执行 init_connect，进行连接的初始化。当一个连接进来时做一些操作，比如 ‘SET NAMES utf8’ ，比如设置 autocommit 为 0 ，比如记录当前连接的 ip 来源和用户等信息到一个新表里，当做登陆日志信息。只有超级账户才可以设置(super_priv 权限)，超级账户无视 init_connect 设置(即 init_connect 的设置对来自超级账户的连接不生效)。 log_error可设置成 /usr/local/mydata/log/alert.log 。 log_bin可设置成 /usr/local/mydata/log/mysql_bin.log 。 relay_log可设置成 /usr/local/mydata/log/mysql_relay_bin.log 。 slow_query_log_file可设置成 /usr/local/mydata/log/mysql_slow.log 。 read_only可设置成 1 。 max_connectionsMySQL 服务端允许的最大连接会话数量。根据机器的配置来设置，如 CPU32 核，内存 64G ，可设置成 4000。 max_user_connections单个用户允许连接的最大会话数量，可设置成 4000。 max_connect_errors可设置成 90000000 。对于同一主机， 如果有超出该参数值个数的中断错误连接， 则该主机将被禁止连接。 如需对该主机进行解禁， 执行： FLUSH HOST 。 wait_timeout、interactive_timeout默认 28800 秒（即 8 小时），建议设置成 120 秒。注意数据库连接池的配置，避免取出的连接是已经被数据库清理掉的。 控制连接的最大空闲时间（可通过 show processlist 输出中 Sleep 状态的时间）的是 wait_timeout 参数（对于非交互式连接，类似于 jdbc 连接， wait_timeout=wait_timeout 。对于交互式连接，类似于 mysql 客户端连接， wait_timeout=interactive_timeout ）。 lower_case_table_namesWindows 中默认 1 ， Linux 中默认 0 。表名忽略大小写。1= 忽略，0= 不忽略。可设置成 1。设置 1，大小写不敏感。创建的表，数据库都是以小写形式存放在磁盘上，对于 sql 语句都是转换为小写对表和 DB 进行查找。当想设置 lower_case_table_names = 1 时，在重启数据库实例之前就需要将原来的数据库和表转换为小写，否则将找不到。 binlog_format可设置成 MIXED 。 expire_logs_days可设置成 7 。 master_info_repository可设置成 TABLE 。 max_binlog_size可设置成 1G 。 slow_query_log可设置成 1 。 long_query_time可设置成 10 。 innodb_file_per_table建议设置成 ON ，一个表对应一个数据文件，否则所有表的数据都在 ibdata1 一个文件中。 innodb_buffer_pool_size默认 134217728 字节（即 128M ），建议设置成机器内存的 50%-80% ，如机器 64G 内存，则可设置成 45G 。这个参数控制 Innodb 本身的缓存大小，影响多少数据能在缓存中。 innodb_lock_wait_timeout可设置成 120 。事务锁等待超时时间。如果批量处理数据，有大事务时可临时调大。 sort_buffer_size建议设置成 1M 或 2M ，设置的值过大会造成系统内存不足。 我们一般可以通过增大 sort buffer 的大小来提高 order by 或者 group by 的处理性能。 Sort_Buffer_Size 是一个 connection 级参数，在每个 connection 第一次需要使用这个 buffer 的时候，一次性分配设置的内存。 Sort_Buffer_Size 并不是越大越好，由于是 connection 级的参数，过大的设置 + 高并发可能会耗尽系统内存资源。 文档说 “On Linux, there are thresholds of 256KB and 2MB where larger values may significantly slow down memory allocation” 。 join_buffer_size建议设置成 1M 或 2M ，设置的值过大会造成系统内存不足。 max_allowed_packet可设置成 16M 。 back_log可设置成 5000 。 MySQL 在瞬时能够接收的连接数，高并发时需要配置。 back_log 值指出在 MySQL 暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。也就是说，如果 MySQL 的连接数达到 max_connections 时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即 back_log ，如果等待连接的数量超过 back_log ，将不被授予连接资源。 sync_binlog可设置成 100 。 innodb_flush_log_at_trx_commit可设置成 2 。设为 1 当然是最安全的，但性能也是最差的（相对其他两个参数而言， 但不是不能接受） 。如果对数据一致性和完整性要求不高，完全可以设为 2 ，如果只追求性能，例如高并发写的日志服务器，设为 0 来获得更高性能。 innodb_write_io_threadsinnodb_read_io_threadsinnodb_thread_concurrencyMySQL Innodb 并发涉及参数：https://www.cnblogs.com/xinysu/p/6439715.html 这个是 innodb 内核的并发线程处理参数，即同一时刻能够进入 innodb 层次并发执行的线程数（注意是并发不是并行）。比如前端有 100 个连接，发来 1000 个 sql ，如果这个参数被设置成 2 。那么这 1000 个 sql 中，最多只有 2 个 sql 在 innodb 内核运行。其它都得等。(事实上，处理过程很复杂，可以先这么理解，不是所有 sql 都需要放在 Innodb 内核处理的)。 默认 0 ，则表示没有并发线程数限制，所有请求都会直接请求线程执行。注意：当 innodb_thread_concurrency 设置为 0 时，则 innodb_thread_sleep_delay 的设置将会被忽略，不起作用。如果数据库没出现性能问题时，使用默认值即可。 当 &gt;0 ，则表示有并发数限制，当一个新的请求发起时，会检查当前并发线程数是否达到了 innodb_thread_concurrency 的限制值，如果有，则需要 sleep 一段时间（ sleep 的设置详见下一部分），然后再再次请求，如果再次请求时，当前并发数还是达到限制值，那么就会进入 FIFO 队列等待执行。当进入到内核执行时，会得到一个消费凭证 ticket ，则这个线程，在后面的多次进入 innodb 执行操作是都不需要重复上面的检查步骤，当把次数消费完，那么这个线程就会被驱逐，等待下次再次进入 Innodb ，再重新分配 ticket 。那些等待获取锁的线程则不会被计入到并发执行线程 innodb_thread_concurrency 的数量中。 建议配置（来自官网）： 当并发用户线程数量小于 64 ，建议设置 innodb_thread_concurrency=0 ； 如果负载不稳定，时而低，时而高到峰值，建议先设置 innodb_thread_concurrency=128 ，并通过不断的降低这个参数， 96, 80, 64 等等，直到发现能够提供最佳性能的线程数，例如，假设系统通常有 40 到 50 个用户，但定期的数量增加至 60，70 ，甚至 200 。你会发现，性能在 80 个并发用户设置时表现稳定，如果高于这个数，性能反而下降。在这种情况下，建议设置 innodb_thread_concurrency 参数为 80 ，以避免影响性能； 如果 DB 服务器上还允许其他应用，需要限制 MySQL 的线程使用情况，则可以设置可分配给 DB 的线程数，但是不建议 DB 上跑其他应用，也不建议这么设置，因为这样可能导致数据库没有对硬件最优使用； 设置过高值，可能会因为系统资源内部争夺导致性能下降； 在大多数情况下，最佳的值是小于并接近虚拟 CPU 的个数； 定期监控和分析 DB ，因为随着数据库负载的变化，业务的增加， innodb_thread_concurrency 也需要动态的调整。 innodb_thread_sleep_delay5.6.3 版本前，需要反复测试才能确定 innodb_thread_sleep_delay 值，并且固定为一个值，在 5.6.3 版本后，因为 Innodb 自动调整 innodb_thread_sleep_delay 参数： Innodb_adaptive_max_sleep_delay ：最大 sleep 的时间，微秒为单位。可以通过设置参数 innodb_adaptive_max_sleep_delay 来限制 innodb_thread_sleep_delay 的最大值，不设置 innodb_thread_sleep_delay 的取值情况，让 Innodb 自动跟进负载来调整，当系统负荷较高时， Innodb 动态调整 sleep 时间可使得数据库稳定运行。 innodb_commit_concurrency该值只能为默认值 0 ， mysql 不限制并发提交。大于 0 表示允许 N 个事务在同一时间点提交， N 的范围是 0-1000 。注意事项： mysqld 运行时，不许把 innodb_commit_concurrency 的值从 0 改为非 0 ，或非 0 的值改为 0 ；但允许从 N 改为 M （ N 及 M 均大于 0 ）。 innodb_concurrency_tickets当请求被 innodb 接受的时候，会获得一个消费凭证 innodb_concurrency_tickets（ mysql 版本 v5.5 默认 500 ， v5.6 和 v5.7 默认 5000 ），当这个请求中有多个 SQL 被执行的时候，每执行一次，消费一次 tickets ，在次数用完之前，该线程重新请求时无须再进行前面 thread 是否达到并发限制值的检查。如果 innodb_concurrency_tickets 设 置小些，适用于小事物操作较多的系统，可以快速使用完线程后退出来，提供给其他请求使用；而对于大事务来说，可能会循环进入等待队列中等待执行完成，这会耗费更多时间及资源；如果 innodb_concurrency_tickets 设置大些，适用于大事务频繁操作的系统，这样大事务则不需要频繁进入 queue 等待队列，可以通过较少的请求来处理；但是对于小事务来说，则意味着他们要等待更长的时候，才能排队进入到内核执行。所以，当 innodb_thread_concurrency&gt;0 时，需要上下调整 innodb_concurrency_tickets ，使其达到最佳性能。可以通过 show engine innodb status 的 queue 查看，也可以通过 information_schema.INNODB_TRX 表中的 trx_concurrency_tickets 字段值 查看消费次数情况。 transaction_isolationtable_open_cache可设置成 2048 。表的缓存： 2max_connections-5max_connections ，但是不能大于操作系统文件描述符限制。当某一连接访问一个表时， MySQL 会检查当前已缓存表的数量。如果该表已经在缓存中打开，则会直接访问缓存中的表已加快查询速度；如果该表未被缓存，则会将当前的表添加进缓存并进行查询。 query_cache_size、query_cache_type默认 0 ，建议设置成？。 Query Cache（查询缓存，以下简称 QC ）存储 SELECT 语句及其产生的数据结果，特别适用于：频繁提交同一个语句，并且该表数据变化不是很频繁的场景，例如一些静态页面，或者页面中的某块不经常发生变化的信息。 QC 有可能会从 InnoDB Buffer Pool 或者 MyISAM key buffer 里读取结果。 由于 QC 需要缓存最新数据结果，因此表数据发生任何变化（ INSERT、UPDATE、DELETE 或其他可能产生数据变化的操作），都会导致 QC 被刷新。 QC 严格要求 2 次 SQL 请求要完全一样，包括 SQL 语句，连接的数据库、协议版本、字符集等因素都会影响。 如果线上环境中 99% 以上都是只读，很少有更新，才考虑开启 QC ，否则建议关闭（设置选项 query_cache_type=0 和 query_cache_size=0 ）。 查询缓存能够加速已经存在缓存的查询语句的速度，可以不用重新解析和执行而获得正确的记录集； 查询缓存中涉及的表，每一个表对象都有一个属于自己的全局性质的锁； 表若是做 DDL、FLUSH TABLES 等类似操作，触发相关表的查询缓存信息清空； 表对象的 DML 操作，必须优先判断是否需要清理相关查询缓存的记录信息，将不可避免地出现锁等待事件； 查询缓存的内存分配问题，不可避免地产生一些内存碎片； 查询缓存对是否是一样的查询语句，要求非常苛刻，而且还不智能； MySQL 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/09/26/mysql/mysql-cnf/"},{"title":"MySQL 常用函数","text":"通过本文学习 MySQL 常用函数。 1 运算符1.1 算术运算符12-- +, -, *, /-- 可以在 select 语句中使用 1.2 比较运算符1-- &gt;, &gt;=, =, !=, &lt;, &lt;=, like, between, is null, in 1.3 逻辑运算符1-- not, and, or 1.4 集合运算符12345678910111213141516-- intersect, union, union all, minus -- 要求：-- 1. 对应集合的列数和数据类型相同。-- 2. 查询中不能包含 long 列。-- 3. 列的标签是第一个集合的标签。select * from emp intersect select * from emp where deptno=10;select * from emp minus select * from emp where deptno=10;-- 不包括重复行select * from emp where deptno=10 union select * from emp where deptno in (10,20); -- 包括重复行select * from emp where deptno=10 union all select * from emp where deptno in (10,20); 2 字符串函数2.1 字符串截取12345678-- left/right/substr/substring-- 截取长度为负数的话从后面开始计算select left('abcdef',2); -- abselect right('abcdef',2); -- efselect substr('abcdef',1,3); -- abcselect substring('abcdef',1,3); -- abcselect substring_index('aa.bb.cc', '.', 2); -- aa.bb 2.2 查找子串位置1234-- instr-- 首次出现，从 1 开始select instr('abcfdgfdhd','fd'); -- 4 2.3 字符串连接123-- concatselect concat('hello','world'); -- hello world 2.4 去掉字符串中的空格12345678910-- ltrim、rtrim、trimselect ltrim('abc') s1, rtrim('zhang') s2, trim('zhang') s3;-- 去掉前导和后缀select trim(leading 9 from 9998767999) s1, trim(trailing 9 from 9998767999) s2, trim(9 from 9998767999) s3; -- 8767999 9998767 8767 2.5 返回字符串首字母的 Ascii 值1select ascii('abc'); -- 97 2.6 返回 Ascii 值对应的字母1select char(97); -- a 2.7 计算字符串长度123-- lengthselect length('abcdef'); -- 6 2.8 大小写转换1234-- lower/upperselect lower('ABC') s1, upper('def') s2; -- abc DEF 2.9 替换123-- replaceselect replace('abcbc','b','xy'); -- axycxyc 2.10 左右填充（用于控制输出格式）123456-- lpad/rpadselect lpad('func',6,'='), lpad('func',3,'='), rpad('func',6,'='), rpad('func',3,'='); -- ==func fun func== fun 2.11 逐字符比较两字串大小12345-- strcmpselect strcmp('a1','a1'); -- 0select strcmp('a1','a0'); -- 1select strcmp('a1','a2'); -- -1 2.12 生成空格123-- spaceselect concat('a',space(2),'b'); -- a b 2.13 条件判断 if1select if(1+2=3,'A','B'); -- A 2.14 条件判断 case1234567-- 实现类似 switch case 逻辑select case 1+2 when 3 then 'A' when 4 then 'B' else 'C' end; -- A 3 日期时间函数3.1 日期转字符串12345-- date_format -- 同 oracle 中的 to_char()select date_format(now(),'%Y'); -- 2018select date_format(now(),'%Y-%m-%d'); -- 2018-08-06select date_format(now(),'%Y-%m-%d %H:%i:%s'); -- 2018-08-06 10:54:46 3.2 字符串转日期1234-- str_to_date -- 同 oracle 中的 to_date()select str_to_date('2018-08-06','%Y-%m-%d'); -- 2018-08-06select str_to_date('2018-08-06 08:30:14','%Y-%m-%d'); -- 2018-08-06 3.3 秒（毫秒）值与日期转换12345678910-- from_unixtime()/unix_timestamp()-- 将秒（毫秒）值转换为日期select from_unixtime(1454313212000 div 1000,'%Y-%m-%d %H:%i:%s'); select from_unixtime(1454313212000/1000,'%Y-%m-%d %H:%i:%s'); -- 2016-02-01 15:53:32-- 将日期转换为日期（毫秒）值select unix_timestamp('2016-02-01 15:53:32'); -- 1454313212(秒)，毫秒需要乘 1000 3.4 日期相关的函数1234567891011121314151617181920212223242526272829303132-- ADDTIME(date2 ,time_interval) -- 将 time_interval 加到 date2 -- CONVERT_TZ(datetime2 ,fromTZ ,toTZ) -- 转换时区 -- CURRENT_DATE() -- 当前日期 -- CURRENT_TIME() -- 当前时间 -- CURRENT_TIMESTAMP() -- 当前时间戳 -- DATE(datetime) -- 返回 datetime 的日期部分 -- DATE_ADD(date2 , INTERVAL d_value d_type) -- 在 date2 中加上日期或时间 -- DATE_FORMAT(datetime ,FormatCodes) -- 使用 formatcodes 格式显示 datetime -- DATE_SUB(date2 , INTERVAL d_value d_type) -- 在 date2 上 减去一个时间 -- DATEDIFF(date1 ,date2) -- 两个日期差 -- DAY(date) -- 返回日期的天 -- DAYNAME(date) -- 英文星期 -- DAYOFWEEK(date) -- 星期(1-7) ,1 为星期天 -- DAYOFYEAR(date) -- 一年中的第几天 -- EXTRACT(interval_name FROM date) -- 从 date 中提取日期的指定部分 -- MAKEDATE(year ,day) -- 给出年及年中的第几天, 生成日期串 -- MAKETIME(hour ,minute ,second) -- 生成时间串 -- MONTHNAME(date) -- 英文月份名 -- NOW() -- 当前时间 -- SEC_TO_TIME(seconds) -- 秒数转成时间 -- STR_TO_DATE(string ,format) -- 字串转成时间, 以 format 格式显示 -- TIMEDIFF(datetime1 ,datetime2) -- 两个时间差 -- TIME_TO_SEC(time) -- 时间转秒数] -- WEEK(date_time [,start_of_week]) -- 第几周 -- YEAR(datetime) -- 年份 -- DAYOFMONTH(datetime) -- 月的第几天 -- HOUR(datetime) -- 小时 -- LAST_DAY(date) -- date 的月的最后日期 -- MICROSECOND(datetime) -- 微秒 -- MONTH(datetime) -- 月 -- MINUTE(datetime) -- 分返回符号, 正负或 0 -- SQRT(number2) -- 开平方 3.5 日期相关的参数说明12345678910111213141516171819202122232425262728-- 根据 format 字符串格式化 date 值，下列修饰符可以被用在 format 字符串中：-- %M 月名字(January……December) -- %W 星期名字(Sunday……Saturday) -- %D 有英语前缀的月份的日期(1st, 2nd, 3rd, 等等。） -- %Y 年, 数字, 4 位 -- %y 年, 数字, 2 位 -- %a 缩写的星期名字(Sun……Sat) -- %d 月份中的天数, 数字(00……31) -- %e 月份中的天数, 数字(0……31) -- %m 月, 数字(01……12) -- %c 月, 数字(1……12) -- %b 缩写的月份名字(Jan……Dec) -- %j 一年中的天数(001……366) -- %H 小时(00……23) -- %k 小时(0……23) -- %h 小时(01……12) -- %I 小时(01……12) -- %l 小时(1……12) -- %i 分钟, 数字(00……59) -- %r 时间,12 小时(hh:mm:ss [AP]M) -- %T 时间,24 小时(hh:mm:ss) -- %S 秒(00……59) -- %s 秒(00……59) -- %p AM 或 PM -- %w 一个星期中的天数(0=Sunday ……6=Saturday ） -- %U 星期(0……52), 这里星期天是星期的第一天 -- %u 星期(0……52), 这里星期一是星期的第一天 -- %% 一个文字“%” 4 数字函数4.1 向上 / 向下取整123-- ceil/floorselect ceil(66.6) N1,floor(66.6) N2; -- 67 66 4.2 取幂 / 求平方根123-- power/sqrtselect power(3,2) N1,sqrt(9) N2; -- 9 3 4.3 求余123-- modselect mod(9,5); -- 4 4.4 返回固定小数位数（四舍五入）123-- roundselect round(66.667,2); -- 66.67 4.5 返回值的符号（正数为 1, 负数为 -1）123-- signselect sign(-32),sign(293); -- -1 1 4.6 求最小值123-- leastselect least(1,2,2,4,3); -- 1 4.7 随机数123-- randselect rand(); -- 0.12119520839415045 5 转换函数 5.1 日期转字符串 见上文。 5.2 字符串转日期 见上文。 5.3 秒（毫秒）值与日期转换 见上文。 5.4 类型转换123456789101112-- cast(xxx AS 类型) -- convert(xxx, 类型)-- 可用的类型： -- 二进制, 同带 binary 前缀的效果 : BINARY -- 字符型, 可带参数 : CHAR() -- 日期 : DATE -- 时间: TIME -- 日期时间型 : DATETIME -- 浮点数 : DECIMAL -- 整数 : SIGNED -- 无符号整数 : UNSIGNED 6 分组函数6.1 整个结果集是一个组1234567891011-- max min avg count sum-- 例：求部门 30 的最高工资，最低工资, 平均工资，总人数，有工作的人数，工种数量及工资总和select max(ename),max(sal), min(ename),min(sal), avg(sal), count(*), count(job), count(distinct(job)), sum(sal)from emp where deptno=30; 6.2 带 group by 和 having 的分组123456789101112131415161718192021-- 例：按部门分组求最高工资，最低工资，总人数，有工作的人数，工种数量及工资总和select deptno, max(ename),max(sal), min(ename),min(sal), avg(sal), count(*), count(job), count(distinct(job)), sum(sal)from emp group by deptno;-- 例：部门 30 的最高工资，最低工资，总人数，有工作的人数，工种数量及工资总和select deptno, max(ename),max(sal), min(ename),min(sal), avg(sal), count(*), count(job), count(distinct(job)), sum(sal)from emp group by deptno having deptno=30; 6.3 标准偏差 / 方差1234-- stddev/varianceselect deptno,stddev(sal) from emp group by deptno;select deptno,variance(sal) from emp group by deptno; 6.4 带有 rollup 和 cube 操作符的 group By123456-- rollup 按分组的第一个列进行统计和最后的小计-- cube 按分组的所有列的进行统计和最后的小计select deptno,job,sum(sal) from emp group by deptno,job;select deptno,job,sum(sal) from emp group by rollup(deptno,job); select deptno,job,sum(sal) from emp group by cube(deptno,job); 7 其他函数7.1 值是否相等1234-- nullif(ex1,ex2) -- 值相等返回 null ，否则返回第一个值select nullif(1,1); -- select nullif(1,2); -- 1 MySQL 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/08/06/mysql/mysql-function/"},{"title":"MySQL 安装 - Linux","text":"手把手带你在 Linux 上安装 MySQL-5.6/5.7 ，图文并茂。 1 准备工作1.1 确认系统环境12345678# 查看 Linux 版本cat /etc/issue# CentOS release 6.5 (Final)# Kernel \\r on an \\m# 查看内核版本cat /proc/version# Linux version 2.6.32-431.el6.x86_64 (mockbuild@c6b8.bsys.dev.centos.org) (gcc version 4.4.7 20120313 (Red Hat 4.4.7-4) (GCC) ) #1 SMP Fri Nov 22 03:15:09 UTC 2013 1.2 删除 MySQL 历史版本123456789101112131415161718192021# 检查是否有历史版本rpm -qa|grep -i mysql ##-i 选项表示匹配时忽略大小写# mysql-5.1.73-8.el6_8.x86_64# mysql-devel-5.1.73-8.el6_8.x86_64# mysql-libs-5.1.73-8.el6_8.x86_64# 删除，--nodeps 选项表示忽略依赖关系rpm -e mysql-5.1.73-8.el6_8.x86_64 --nodepsrpm -e mysql-devel-5.1.73-8.el6_8.x86_64 --nodepsrpm -e mysql-libs-5.1.73-8.el6_8.x86_64 --nodeps# 查找 mysql 相关目录find / -name mysql# /usr/local/mysql# /usr/share/mysql# /usr/lib64/mysql# /var/lib/mysql# 删除rm -rf /usr/local/mysql /usr/share/mysql /usr/lib64/mysql /var/lib/mysql 1.3 下载安装包MySQL 下载地址：https://downloads.mysql.com/archives/community/ 通用安装：Operating System: 下拉项选择 Linux - Generic ，然后下载后缀为 .tar.gz 的二进制文件，如 mysql-5.6.42-linux-glibc2.12-x86_64.tar.gz 或 mysql-5.7.29-linux-glibc2.12-x86_64.tar.gz 。 rpm 安装：如 MySQL-5.6.42-1.el6.x86_64.rpm-bundle.tar 。 yun 安装。 2 安装 MySQL 安装 MySQL 主要有两种方法： 通过源码自行编译安装，这种适合高级用户定制 MySQL 的特性，这里不做说明。 通过编译过的二进制文件进行安装。二进制文件安装的方法又分为两种： 2.1. 不针对特定平台的通用安装方法，使用后缀为 .tar.gz 的二进制文件。 2.2. 使用 rpm 或其他包进行安装，这种安装进程会自动完成系统的相关配置，所以比较方便。 2.1 通用安装 上传 mysql-5.6.42-linux-glibc2.12-x86_64.tar.gz 或 mysql-5.7.29-linux-glibc2.12-x86_64.tar.gz 。 添加 mysql 组和 mysql 用户，用于设置 mysql 安装目录文件所有者和所属组。 1234groupadd mysql# -r 参数表示 mysql 用户是系统用户，不可用于登录系统useradd -r -g mysql mysql 将二进制文件解压到 /usr/local ，并重命名为 mysql（这里也可以不重命名，编译安装时可指定目录为 mysql ） 。 123tar -xzvf mysql-5.6.42-linux2.6-x86_64.tar.gz -C /usr/localmv mysql-5.6.42-linux2.6-x86_64 mysql 准备数据库实例需要的目录。 12345# 创建数据库实例的相关目录mkdir -p /usr/local/mydata/{data,etc,log,tmp}# 修改目录权限chown -R mysql:mysql /usr/local/mydata 复制并修改配置文件。 具体参考：MySQL 配置文件 - 5.6 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119# 下面复制的是最简单最低要求的一个配置文件（可根据实际需要拷贝不同的配置文件），具体的参数配置优化见下文# cp /usr/local/mysql/support-files/my-small.cnf /usr/local/mydata/etc/my.cnfvi /usr/local/mydata/etc/my.cnf# MySQL-5.6 主从，主库 1（CPU 32 核，内存 64G）[client]port = 3306socket = /usr/local/mydata/tmp/mysql.sockdefault_character_set = utf8[mysql]default_character_set = utf8prompt = \"\\\\u:\\\\d&gt;\"auto_rehash[mysqld]port = 3306basedir = /usr/local/mysqlsocket = /usr/local/mydata/tmp/mysql.socktmpdir = /usr/local/mydata/tmpdatadir = /usr/local/mydata/datalog_bin = /usr/local/mydata/log/mysql_bin.logrelay_log = /usr/local/mydata/log/mysql_relay_bin.loglog_error = /usr/local/mydata/log/alert.logslow_query_log_file = /usr/local/mydata/log/mysql_slow.logdefault_time_zone = '+8:00'character_set_server = utf8collation_server = utf8_unicode_ciinit_connect = 'SET NAMES utf8'read_only = 1relay_log_purge = 0skip_name_resolveskip_external_lockingmax_connections = 4000max_user_connections = 4000max_connect_errors = 90000000max_allowed_packet = 16Mback_log = 5000wait_timeout = 120interactive_timeout = 120sort_buffer_size = 2Mjoin_buffer_size = 2Mthread_cache_size = 32tmp_table_size = 256Mmax_heap_table_size = 256Mquery_cache_type = 0key_buffer_size = 128Mread_buffer_size = 2Mread_rnd_buffer_size = 8Mlower_case_table_names = 1bulk_insert_buffer_size = 16M#sql_mode = NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLESsql_mode = \"\"explicit_defaults_for_timestamp = trueserver_id = 20001sync_binlog = 100log_slave_updates = 1relay_log_info_repository = TABLEmaster_info_repository = TABLErelay_log_recovery = 1relay_log_purge = ONbinlog_format =MIXED binlog_cache_size = 1Gmax_binlog_cache_size = 1Gmax_binlog_size = 1Gexpire_logs_days = 7long_query_time = 10slow_query_log = 1default_storage_engine = innodbinnodb_fast_shutdown = 1innodb_force_recovery = 0innodb_buffer_pool_size = 40Ginnodb_buffer_pool_instances = 2innodb_buffer_pool_dump_at_shutdown = 1innodb_file_per_table = 1innodb_write_io_threads = 16innodb_read_io_threads = 16innodb_thread_concurrency = 32innodb_flush_log_at_trx_commit = 2innodb_log_buffer_size = 8Minnodb_log_files_in_group = 4innodb_max_dirty_pages_pct = 80innodb_lock_wait_timeout = 120innodb_flush_method = O_DIRECTinnodb_log_file_size = 10Minnodb_data_file_path = ibdata1:10M:autoextendtransaction_isolation = READ-COMMITTEDinnodb_io_capacity_max = 10000innodb_io_capacity = 6000innodb_lru_scan_depth = 8000innodb_file_format = Barracudainnodb_file_format_max = Barracuda#replicate_ignore_db = mysql#replicate_ignore_db = test#replicate_ignore_db = performance_schema#replicate_ignore_db = information_schema[mysqldump]quickmax_allowed_packet = 16M[isamchk]key_buffer = 128Msort_buffer_size = 16Mread_buffer = 8Mwrite_buffer = 8M[myisamchk]key_buffer = 128Msort_buffer_size = 16Mread_buffer = 8Mwrite_buffer = 8M[mysqlhotcopy]interactive_timeout[mysqld_safe]open_files_limit = 8192 初始化 mysql 数据库实例。 1234567891011121314151617181920212223242526# 进入 mysql 目录cd /usr/local/mysql# 修改 mysql 目录与文件的所有者为 mysql，必须要 mysql 用户的才能进行后续安装（目录权限，重要！！！）chown -R mysql:mysql /usr/local/mysql# 初始化数据库实例，会对 mysql 中的 data 目录进行初始化并创建一些系统表格# --user 指定运行 mysqld 进程的用户，如：mysql。# --basedir 指定 mysql 的安装目录，如：/usr/local/mysql，也可在配置文件中指定。# --datadir 指定 mysql 的数据存放目录，如：/usr/local/mydata/data，也可在配置文件中指定。# --defaults-file 指定配置文件，如：/etc/my.cnf。###### V5.6 初始化命令 ######/usr/local/mysql/scripts/mysql_install_db --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mydata/data --defaults-file=/usr/local/mydata/etc/my.cnf###### V5.6 初始化命令 ############ V5.7 初始化命令 ######/usr/local/mysql/bin/mysqld --user=mysql --basedir=/usr/local/mysql/ --datadir=/usr/local/mydata/data --initialize# 会生成一个临时密码# A temporary password is generated for root@localhost: Uk*ui4)!,sM+###### V5.7 初始化命令 ####### 修改 mysql 目录与文件的所有者为 root，非必须# chown -R root:root /usr/local/mysql# 修改 mydata 目录与文件的所有者为 mysql（目录权限，重要！！！）chown -R mysql:mysql /usr/local/mydata 启动 mysql（如果需要可通过将 mysql 配置成服务注册开机启动）。 1234567891011121314151617181920212223242526272829303132333435# 服务名为 mysql，这样就可以使用 service mysql 命令启动 / 停止服务，非必须#cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysql# 把 mysql 服务注册为开机启动，非必须# chkconfig --add mysql# 查看是否添加成功，非必须# chkconfig --list mysql# 启动 start / 停止 stop / 重启 restart / 查看状态 status，不推荐# service mysql start# 也可以用下面的方法启动，不推荐# /usr/local/mysql/support-files/mysql.server start# 推荐用下面的方法启动，推荐！！！# --read_only=1 # 打开只读，从库设置# --skip-slave-start # 不启动主从# set global read_only=0; # 关闭只读，主库需要/bin/bash /usr/local/mysql/bin/mysqld_safe --defaults-file=/usr/local/mydata/etc/my.cnf &amp;# /bin/bash /usr/local/mysql/bin/mysqld_safe --defaults-file=/usr/local/mydata/etc/my.cnf --read_only=1 &amp;# 推荐用下面的方法停止，推荐！！！/usr/local/mysql/bin/mysqladmin -uroot -p123456 -S /usr/local/mydata/tmp/mysql.sock shutdown# 推荐用下面的方法登录，推荐！！！###### V5.6 默认无密码 ############ V5.7 初始化的时候会生成一个临时密码 ######/usr/local/mysql/bin/mysql -uroot -p123456 -S /usr/local/mydata/tmp/mysql.sock# 检查是否启动ps -ef|grep mysql 或 netstat -anp|grep mysqlroot 2248 1 0 Jun15 ? 00:00:00 /bin/bash /usr/local/mysql/bin/mysqld_safe --defaults-file=/usr/local/mydata/etc/my.cnf --read_only=1mysql 3344 2248 19 Jun15 ? 3-22:41:14 /usr/local/mysql/bin/mysqld --defaults-file=/usr/local/mydata/etc/my.cnf --basedir=/usr/local/mysql --datadir=/usr/local/mydata/data --plugin-dir=/usr/local/mysql/lib/plugin --user=mysql --read-only=1 --log-error=/usr/local/mydata/log/alert.log --open-files-limit=8192 --pid-file=localhost.localdomain.pid --socket=/usr/local/mydata/tmp/mysql.sock --port=3306root 30497 1836 0 16:57 pts/0 00:00:00 grep mysql 2.2 rpm 安装 上传 MySQL-5.6.42-1.el6.x86_64.rpm-bundle.tar 。 将 rpm 安装包解压到 /usr/local/mysqlrpm。 123456789tar -xvf MySQL-5.6.42-1.el6.x86_64.rpm-bundle.tar -C /usr/local/mysqlrpm# MySQL-client-5.6.42-1.el6.x86_64.rpm# MySQL-devel-5.6.42-1.el6.x86_64.rpm# MySQL-embedded-5.6.42-1.el6.x86_64.rpm# MySQL-server-5.6.42-1.el6.x86_64.rpm# MySQL-shared-5.6.42-1.el6.x86_64.rpm# MySQL-shared-compat-5.6.42-1.el6.x86_64.rpm# MySQL-test-5.6.42-1.el6.x86_64.rpm 安装。 1234# 可能需要给文件增加执行权限# chmod a+x *.rpmrpm -ivh *.rpm# rpm -ivh MySQL-5.6.42-1.el6.x86_64.rpm 如果报错，则对应解决。 12345678910111213# 报错：file /usr/share/mysql/charsets/cp1251.xml from install of MySQL-5.6.42-1.el6.x86_64 conflicts with file from package mysql-libs-5.1.52-1.el6_0.1.i686# 安装包冲突，卸载安装包# -y 的意思就是不用询问是否 removeyum -y remove remove mysql-libs-5.1.52*# 报错：error: Failed dependencies:libc.so.6 is needed by MySQL-server-community-5.1.63-1.rhel4.i386libc.so.6(GLIBC_2.0) is needed by MySQL-server-community-5.1.63-1.rhel4.i386libc.so.6(GLIBC_2.1) is needed by MySQL-server-community-5.1.63-1.rhel4.i386# 缺少相关包，安装相关包yum install libc.so.6 再次安装。 12rpm -ivh *.rpm# rpm -ivh MySQL-5.6.42-1.el6.x86_64.rpm 启动服务。 123456789101112# 不是原生的 systemctl 服务，建议使用 serviceservice start mysqlchkconfig --list mysqlchkconfig mysql on# systemctl start mysql# systemctl stop mysql# 检查是否启动ps -ef|grep mysql 或 netstat -anp|grep mysqltcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN 6602/mysqld unix 2 [ACC] STREAM LISTENING 23737 6602/mysqld /usr/local/mydata/data/mysql.sock 2.3 yum 安装 安装。 1yum install -y mysql-server mysql mysql-devel 如果报错，则对应解决。 12345# 报错：file /usr/share/mysql/ukrainian/errmsg.sys from install of MySQL-server-5.5.18-1.rhel5.i386 conflicts with file from package mysql-libs-5.0.46-1.rhel5.i386# 卸载安装包# -y 的意思就是不用询问是否 removeyum -y remove mysql-libs-5.0.46-1.rhel5.i386 再次安装。 1yum install -y mysql-server mysql mysql-devel 启动服务。 123456service mysql start# 检查是否启动ps -ef|grep mysql 或 netstat -anp|grep mysqltcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTEN 6602/mysqld unix 2 [ACC] STREAM LISTENING 23737 6602/mysqld /usr/local/mydata/data/mysql.sock 3 配置 MySQL3.1 设置 root 密码12345# 设置 root 的密码/usr/local/mysql/bin/mysqladmin -u root password '123456' -S /usr/local/mydata/tmp/mysql.sock# 或# alter user 'root'@'localhost' identified by '123456'; 3.2 登录123456789# 登录 mysql# /usr/local/mysql/bin/mysql -uroot -p123456/usr/local/mysql/bin/mysql -uroot -p123456 -S /usr/local/mydata/tmp/mysql.sock# 或者增加 my 快捷登录方式，非必须# vim /usr/local/bin/my# 加入以下内容：/usr/local/mysql/bin/mysql -uroot -p123456 -S /usr/local/mydata/tmp/mysql.sock# chmod +x /usr/local/bin/my# my 3.3 授权远程访问123# 配置授权mysql&gt;GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123456' WITH GRANT OPTION;mysql&gt;flush privileges; 3.4 新建用户并授权1234# 新建 grid 用户并授权（无 DROP 权限），用于业务操作。因为 root 用户对从库的只读设置无效，操作有风险。mysql&gt;CREATE USER 'grid'@'%' IDENTIFIED BY 'grid@123456';mysql&gt;GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, INDEX, ALTER ON `mydbname`.* TO 'grid'@'%';mysql&gt;flush privileges; 3.5 参数配置优化 具体配置参考：MySQL 参数配置优化 123456789101112131415161718192021222324252627282930313233vi /usr/local/mydata/etc/my.cnf[client]port = 3306socket = /usr/local/mydata/data/mysql.sock[mysqld]port = 3306socket = /usr/local/mydata/data/mysql.sockbasedir = /usr/local/mysqldatadir = /usr/local/mydata/datatmpdir = /usr/local/mydata/tmp# 字符集character_set_server = utf8init_connect = 'SET NAMES utf8'# Windows 中默认 1，Linux 中默认 0。表名忽略大小写。1= 忽略，0= 不忽略。lower_case_table_names = 1# 最大连接数max_connections = 2000# 防止数据导入时内容太大导致无法导入的问题max_allowed_packet = 16Minnodb_buffer_pool_size = 50Gjoin_buffer_size = 32Msort_buffer_size = 1Mread_rnd_buffer_size = 64Mwait_timeout = 120interactive_timeout = 120sync_binlog = 1000# ...... MySQL 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/07/27/mysql/mysql-install-linux/"},{"title":"MySQL 主从部署","text":"认识 MySQL 主从，并手把手带你实现 MySQL 主从部署，图文并茂。 1 概述 1.1 什么是数据库主从 主库把所有的操作都记入二进制日志，从库通过网络把主库日志拷贝入自己的日志，从库读取日志进行数据更改。 示意图： 原理图： 注意事项： 主数据库和从数据库版本应一致，如果不一致，从数据库版本应高于主数据库版本。 主从同步实质是同步数据库操作，不是保证两者数据一致。所以启动主从前，应先保证两者数据一致。 从库的数据相对主库有滞后性。 主从配置会影响主库的性能，从库越多对主库的影响越大。 当一次配置成功后，主从随着数据库启动而启动。 master 随主库 mysql 启动而启动， slave 随从库 mysql 启动而启动。 必须先启动主库，再启动从库。 只要主库正常，从库停机后启动，主从自动可以把主库数据同步过来。 1.2 主从的同步方式 同步复制：所谓的同步复制，意思是 master 的变化，必须等待 slave-1, slave-2,…, slave-n 完成后才能返回。这样，显然不可取，也不是 MySQL 复制的默认设置。比如，在 WEB 前端页面上，用户增加了条记录，需要等待很长时间。 异步复制：如同 AJAX 请求一样。master 只需要完成自己的数据库操作即可。至于 slaves 是否收到二进制日志，是否完成操作，不用关心。MySQL 的默认设置。 半同步复制：master 只保证 slaves 中的一个操作成功，就返回，其他 slave 不管。 1.3 主从有什么用 读写分离：把统计等费时、占资源高的操作移到从库。 异地备份：类似于高可用的功能，一旦 master 挂了，可以让 slave 顶上去，同时 slave 提升为 master 。 1.4 主从架构选择 数据库主从架构有多种选择，每种架构都有其适应性，我认为最有用的有如下两种： 1.4.1 一主多从架构 当写入操作较少，读操作较多可以采取此架构。可以有效的均衡压力，但是，当 slave 增加到一定数量时， slave 对 master 的负载以及网络带宽都会成为一个严重的问题。这种结构虽然简单，但是，它却非常灵活，足够满足大多数应用需求。一些建议： 不同的 slave 扮演不同的作用（例如使用不同的索引，或者不同的存储引擎）。 用一个 slave 作为备用 master ，只进行复制。 用一个远程的 slave ，用于灾难恢复。 1.4.2 级联复制架构 在有些应用场景中，可能读写压力差别比较大，读压力特别的大，一个 Master 可能需要上 10 台甚至更多的 Slave 才能够支撑注读的压力。这时候， Master 就会比较吃力了，因为仅仅连上来的 Slave IO 线程就比较多了，这样写的压力稍微大一点的时候， Master 端因为复制就会消耗较多的资源，很容易造成复制的延时。 2 主库 master 配置2.1 创建用户并授权123456# 登录 mysql/usr/local/mysql/bin/mysql -uroot -p123456 -S /usr/local/mydata/tmp/mysql.sockmysql&gt; CREATE USER 'repl'@'%' IDENTIFIED BY '123456';mysql&gt; GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%';mysql&gt; flush privileges; 2.2 修改配置文件123456789101112131415161718192021vi /etc/my.cnf# 在 [mysqld] 中增加server-id=1log-bin=/usr/local/mydata/log/mysql-bin.logbinlog_format=mixedexpire_logs_days=7# 也可不指定，代表默认所有binlog-do-db=db1binlog-ignore-db=mysqlbinlog-ignore-db=information_schemabinlog-ignore-db=performance_schemabinlog-ignore-db=test# 参数说明：# server-id：唯一 ID，主库建议为 1，必须。# log-bin：是否开启二进制日志，必须。# binlog_format：日志记录格式，推荐。# expire_logs_days：日志过期删除的时间。# binlog-do-db：需要同步的数据库，多个时用多行。# binlog-ignore-db：不需要同步的数据库，多个时用多行。 2.3 启动 mysql ，会自动启动 master12# 启动 mysql/bin/bash /usr/local/mysql/bin/mysqld_safe --defaults-file=/usr/local/mydata/etc/my.cnf &amp; 2.4 查看主库状态12345678910# 登录 mysql/usr/local/mysql/bin/mysql -uroot -p123456 -S /usr/local/mydata/tmp/mysql.sockmysql&gt; show master status \\G;*************************** 1. row *************************** File: mysql-bin.001167 Position: 439884600 Binlog_Do_DB: db1Binlog_Ignore_DB: mysql,information_schema,performance_schema,test1 row in set (0.00 sec) 3 从库 slave 配置3.1 修改配置文件12345678910111213141516171819202122232425vi /etc/my.cnf# 在 [mysqld] 中增加server-id=2# log-bin=/usr/local/mydata/log/mysql-bin.log# log_slave_updates=1relay-log=/usr/local/mydata/log/mysql-relay-bin.logread_only=1expire_logs_days=7# 也可不指定，代表默认所有replicate-do-db=db1replicate-ignore-db=mysqlreplicate-ignore-db=information_schemareplicate-ignore-db=performance_schemareplicate-ignore-db=test# 参数说明：# server-id：唯一 ID，必须。# log-bin：是否开启二进制日志，单纯作为从库不需要配置，如果该从库同时作为其他从库的主库时则必须设置。# log_slave_updates：将复制事件写进自己的二进制日志，单纯作为从库不需要配置，如果该从库同时作为其他从库的主库时则必须设置。# relay-log：中继日志。# read_only 只读，但对 root 用户无效。# expire_logs_days：日志过期删除的时间。# replicate-do-db：需要同步的数据库，多个时用多行。# replicate-ignore-db：不需要同步的数据库，多个时用多行。 3.2 启动 mysql ，会自动启动 slave12345678910111213141516171819202122# 启动 mysql# --read_only=1 # 打开只读，从库设置/bin/bash /usr/local/mysql/bin/mysqld_safe --defaults-file=/usr/local/mydata/etc/my.cnf --read_only=1 &amp;# 登录 mysql/usr/local/mysql/bin/mysql -uroot -p123456 -S /usr/local/mydata/tmp/mysql.sock# 第 1 次需要配置主从mysql&gt; stop slave;mysql&gt; change master to master_host='192.168.71.57', master_user='repl', master_password='123456', master_log_file='mysql-bin.001167', master_log_pos=439884600, master_port=3306;mysql&gt; start slave;# 停止主从复制# mysql&gt; stop slave;# 清除从库的同步复制信息，包括连接信息和二进制文件名、位置（使用 show slave status 将不会有输出）# mysql&gt; reset slave all; 3.3 查看从库状态12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 登录 mysql/usr/local/mysql/bin/mysql -uroot -p123456 -S /usr/local/mydata/tmp/mysql.sockmysql&gt; show slave status \\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.71.57 # 主服务器地址。 Master_User: repl # 授权用户名，尽量避免使用 root。 Master_Port: 3306 # 数据库端口，部分版本没有此行。 Connect_Retry: 60 Master_Log_File: mysql-bin.001167 # 主库最大的二进制日志文件。 Read_Master_Log_Pos: 647719681 # 从库读取主库二进制日志文件，已经读取到的位置，&gt;=Exec_Master_Log_Pos。 Relay_Log_File: mysql-relay-bin.002932 Relay_Log_Pos: 647719828 Relay_Master_Log_File: mysql-bin.001167 # 从库已经收到的主库最大的二进制日志文件。 Slave_IO_Running: Yes # 此状态必须 YES。 Slave_SQL_Running: Yes # 此状态必须 YES。 Replicate_Do_DB: db1 Replicate_Ignore_DB: mysql,information_schema,performance_schema,test Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 # 错误编号 Last_Error: # 错误描述 Skip_Counter: 0 Exec_Master_Log_Pos: 647719681 # 从库执行主库二进制日志文件，已经执行到的位置。 Relay_Log_Space: 647720028 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0 # 从库落后主库的秒数，大部分情况是准的。Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 11 row in set (0.01 sec) 4 问题汇总 4.1 跨库更新问题 举例：某两个数据库已经实现了主从同步，现在主库中有两个数据库 test01 和 test02 ，然后 test01 中有一张表 table01 ，如果在 my.cnf 的参数里面设置了 replicate_do_db=test01 , test02 ，即只同步这两个库的数据，然后执行以下的更新语句： 12use test01; update test01.table1 set...... 执行的结果是主从库都能看到更新的数据。但如果是另外一种执行的情况进行更新语句： 12use test02; update test01.table1 set...... 执行的结果是主库能够看到数据，但是从库却无法看到更新的数据。 原因：设置 replicate_do_db 后， MySQL 执行 sql 前检查的是当前默认数据库，所以跨库更新语句在 Slave 上会被忽略。而对于跨库更新 SQL 语句的问题， replicate_wild_do_table 可以解决，即在 my.cnf 的参数里面设置 12345# （正确写法） replicate_wild_do_table=test01.% replicate_wild_do_table=test02.% # （错误写法） replicate_wild_do_table=test01.%,test02.% 注意需要同步的库必须分行写而不能在同一行用逗号隔开，否则在同步的时候该参数不生效。 建议：同步所有数据，如果确实不需要同步某几个库，一定要确认没有跨库问题。 4.2 从库同步错误问题 跳过 1 个错误 123456789# 登入从库查看错误类型show slave status \\G;# 停止从库slave stop;# 跳过一个错误SET GLOBAL SQL_SLAVE_SKIP_COUNTER=1;# 启动从库slave start;# 稍后再次查看从库是否正常（ Slave_IQ_Running 和 Slave_SQL_Running 均为 YES 状态表示正常）。 跳过 1 类错误 12345678vi /etc/my.cnf # 在 [mysqld] 中增加# 跳过指定类型的错误，Last_SQL_Errno 可查看错误编号 # slave-skip-errors=1062,1053,1146# 跳过所有错误# slave-skip-errors=all MySQL 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/09/12/mysql/mysql-master-slave/"},{"title":"MySQL 分区表","text":"通过本文学习 MySQL 分区表。 1 定义 表的分区指根据可以设置为任意大小的规则，跨文件系统分配单个表的多个部分。实际上，表的不同部分在不同的位置被存储为单独的表。用户所选择的、实现数据分割的规则被称为分区函数，这在 MySQL 中它可以是模数，或者是简单的匹配一个连续的数值区间或数值列表，或者是一个内部 HASH 函数，或一个线性 HASH 函数。当然，表的分区并不是分的越多越好，当表的分区太多时找分区又是一个性能的瓶颈了，建议在 200 个分区以内。 MySQL 支持 4 种类型的分区表，即 RANGE、LIST、HASH、KEY ，其中 RANGE 和 LIST 类似，按一种区间进行分区， HASH 与 KEY 类似，是按照某种算法对字段进行分区。 2 使用场景 某张表的数据量非常大，通过索引已经不能很好的解决查询性能的问题。 表的数据可以按照某种条件进行分类，以致于在查询的时候性能得到很大的提升。 3 特性3.1 优点 对于那些已经失去保存意义的数据，通常可以通过删除与那些数据有关的分区，很容易地删除那些数据。相反地，在某些情况下，添加新数据的过程又可以通过为那些新数据专门增加一个新的分区，来很方便地实现。 分区表的数据更容易维护，如：想批量删除大量数据可以使用清除整个分区的方式。另外，还可以对一个独立分区进行优化、检查、修复等操作。如果需要，还可以备份和恢复独立的分区，这在非常大的数据集的场景下效果非常好。 一些查询可以得到极大的优化，这主要是借助于满足一个给定 WHERE 语句的数据可以只保存在一个或多个分区内，这样在查找时就不用查找其他剩余的分区。因为分区可以在创建了分区表后进行修改，所以在第一次配置分区方案时还不曾这么做时，可以重新组织数据，来提高那些常用查询的效率。 涉及到例如 SUM() 和 COUNT() 这样聚合函数的查询，可以很容易地进行并行处理。这意味着查询可以在每个分区上同时进行，最终结果只需通过总计所有分区得到的结果。 通过跨多个磁盘来分散数据查询，来获得更大的查询吞吐量。 分区表的数据可以分布在不同的物理设备上，从而高效地利用多个硬件设备。(PARTITION p0 VALUES LESS THAN (3000000) DATA DIRECTORY = ‘/data0/data’ INDEX DIRECTORY = ‘/data1/idx’)。 可以使用分区表来避免某些特殊的瓶颈，如：innodb 的单个索引的互斥访问，ext3 文件系统的 inode 锁竞争等。 3.2 限制 一个表最多只能有 1024 个分区（mysql5.6 之后支持 8192 个分区）。 在 mysql5.1 中分区表达式必须是整数，或者是返回整数的表达式，在 5.5 之后，某些场景可以直接使用字符串列和日期类型列来进行分区（使用 varchar 字符串类型列时，一般还是字符串的日期作为分区）。 分区表要求分区字段必须是主键或者是主键的一部分（即联合主键）。唯一索引列？? mysql 数据库支持的分区类型为水平（横向）分区，并不支持垂直（纵向）分区。因此，mysql 数据库的分区中索引是局部分区索引，一个分区中既存放了数据又存放了索引，而全局分区是指的数据库放在各个分区中，但是所有的数据的索引放在另外一个对象中。 目前 mysql 不支持空间类型和临时表类型进行分区。不支持全文索引。 对表执行分区操作的进程会占用表的写锁，不影响读，例如在这些分区上的 INSERT 和 UPDATE 操作只有在分区操作完成后才能执行。 使用 InnoDB 引擎的分区表不支持外键。 分区表不支持 query cache ，在分区表的查询中自动避开了 query cache 。 分区表不支持全文索引或者搜索，即使分区表的存储引擎是 InnoDB 或者 MyISAM 也不行。 4 使用4.1 验证是否支持分区12-- YES/NOSHOW VARIABLES LIKE '%have_partitioning%'; 4.2 分区类型4.2.1 RANGERANGE 分区：基于属于一个给定连续区间的列值，把多行分配给分区。 123456789101112131415161718192021222324252627282930313233343536373839-- 订单表分区字段是 atime ，根据 RANGE 分区，这样当你向该表中插入数据的时候， MySQL 会根据 YEAR(atime) 的值进行分区存储DROP TABLE IF EXISTS `my_orders`;CREATE TABLE `my_orders` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '表主键', `pid` int(10) unsigned NOT NULL COMMENT '产品 ID', `price` decimal(15,2) NOT NULL COMMENT '单价', `num` int(11) NOT NULL COMMENT '购买数量', `uid` int(10) unsigned NOT NULL COMMENT '客户 ID', `atime` datetime NOT NULL COMMENT '下单时间', `utime` int(10) unsigned NOT NULL DEFAULT 0 COMMENT '修改时间', `isdel` tinyint(4) NOT NULL DEFAULT '0' COMMENT '软删除标识', PRIMARY KEY (`id`,`atime`)) ENGINE=InnoDB DEFAULT CHARSET=utf8-- 分区信息PARTITION BY RANGE (YEAR(atime))( PARTITION p0 VALUES LESS THAN (2016), PARTITION p1 VALUES LESS THAN (2017), PARTITION p_other VALUES LESS THAN MAXVALUE);-- 检查分区是否创建成功EXPLAIN PARTITIONS SELECT * FROM `my_orders`-- 向分区表插入数据INSERT INTO my_orders(`pid`,`price`,`num`,`uid`,`atime`) VALUES(1,12.23,1,89757,CURRENT_TIMESTAMP());INSERT INTO my_orders(`pid`,`price`,`num`,`uid`,`atime`) VALUES(1,12.23,1,89757,'2016-05-01 00:00:00');INSERT INTO my_orders(`pid`,`price`,`num`,`uid`,`atime`) VALUES(1,12.23,1,89757,'2017-05-01 00:00:00');INSERT INTO my_orders(`pid`,`price`,`num`,`uid`,`atime`) VALUES(1,12.23,1,89757,'2018-05-01 00:00:00');INSERT INTO my_orders(`pid`,`price`,`num`,`uid`,`atime`) VALUES(1,12.23,1,89756,'2015-05-01 00:00:00');INSERT INTO my_orders(`pid`,`price`,`num`,`uid`,`atime`) VALUES(1,12.23,1,89756,'2016-05-01 00:00:00');INSERT INTO my_orders(`pid`,`price`,`num`,`uid`,`atime`) VALUES(1,12.23,1,89756,'2017-05-01 00:00:00');INSERT INTO my_orders(`pid`,`price`,`num`,`uid`,`atime`) VALUES(1,12.23,1,89756,'2018-05-01 00:00:00');-- 复制大量数据INSERT INTO `my_orders`(`pid`,`price`,`num`,`uid`,`atime`) SELECT `pid`,`price`,`num`,`uid`,`atime` FROM `my_orders`;-- 检查性能：扫描的行数比没用分区表时少，查询效率提高EXPLAIN PARTITIONS SELECT * FROM `my_orders` WHERE `uid`=89757 AND `atime`&lt; CURRENT_TIMESTAMP(); 4.2.2 LISTLIST 分区：类似于按 RANGE 分区，区别在于 LIST 分区是基于列值匹配一个离散值集合中的某个值来进行选择。 12345678910111213141516171819202122-- LIST 分区和 RANGE 分区很类似CREATE TABLE `products` (`id` bigint UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '表主键' ,`name` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '产品名称' ,`metrial` tinyint UNSIGNED NOT NULL COMMENT '材质' ,`weight` double UNSIGNED NOT NULL DEFAULT 0 COMMENT '重量' ,`vol` double UNSIGNED NOT NULL DEFAULT 0 COMMENT '容积' ,`c_id` tinyint UNSIGNED NOT NULL COMMENT '供货公司 ID' ,PRIMARY KEY (`id`,`c_id`))ENGINE=InnoDB DEFAULT CHARSET=utf8-- 分区信息PARTITION BY LIST(c_id)( PARTITION pA VALUES IN (1,3,11,13), PARTITION pB VALUES IN (2,4,12,14), PARTITION pC VALUES IN (5,7,15,17), PARTITION pD VALUES IN (6,8,16,18), PARTITION pE VALUES IN (9,10,19,20));-- 检查分区是否创建成功EXPLAIN PARTITIONS SELECT * FROM `products` 4.2.3 HASHHASH 分区：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含 MySQL 中有效的、产生非负整数值的任何表达式。 1234567891011121314151617-- msgs 表按照 sub_id 进行 HASH 分区，一共分了十个区CREATE TABLE `msgs` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '表主键', `sender` int(10) unsigned NOT NULL COMMENT '发送者 ID', `reciver` int(10) unsigned NOT NULL COMMENT '接收者 ID', `msg_type` tinyint(3) unsigned NOT NULL COMMENT '消息类型', `msg` varchar(225) NOT NULL COMMENT '消息内容', `atime` int(10) unsigned NOT NULL COMMENT '发送时间', `sub_id` tinyint(3) unsigned NOT NULL COMMENT '部门 ID', PRIMARY KEY (`id`,`sub_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8-- 分区信息PARTITION BY HASH(sub_id)PARTITIONS 10;-- 检查分区是否创建成功EXPLAIN PARTITIONS SELECT * FROM `msgs` 4.2.4 KEYKEY 分区：类似于按 HASH 分区，区别在于 KEY 分区只支持计算一列或多列，且 MySQL 服务器提供其自身的哈希函数。必须有一列或多列包含整数值。 4.2.5 子分区123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566CREATE TABLE `msgss` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '表主键', `sender` int(10) unsigned NOT NULL COMMENT '发送者 ID', `reciver` int(10) unsigned NOT NULL COMMENT '接收者 ID', `msg_type` tinyint(3) unsigned NOT NULL COMMENT '消息类型', `msg` varchar(225) NOT NULL COMMENT '消息内容', `atime` int(10) unsigned NOT NULL COMMENT '发送时间', `sub_id` tinyint(3) unsigned NOT NULL COMMENT '部门 ID', PRIMARY KEY (`id`,`atime`,`sub_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8-- 分区信息PARTITION BY RANGE (atime) SUBPARTITION BY HASH (sub_id) ( PARTITION t0 VALUES LESS THAN(1451577600) ( SUBPARTITION s0, SUBPARTITION s1, SUBPARTITION s2, SUBPARTITION s3, SUBPARTITION s4, SUBPARTITION s5 ), PARTITION t1 VALUES LESS THAN(1483200000) ( SUBPARTITION s6, SUBPARTITION s7, SUBPARTITION s8, SUBPARTITION s9, SUBPARTITION s10, SUBPARTITION s11 ), PARTITION t_other VALUES LESS THAN MAXVALUE ( SUBPARTITION s_other1, SUBPARTITION s_other2, SUBPARTITION s_other3, SUBPARTITION s_other4, SUBPARTITION s_other5, SUBPARTITION s_other6 ));-- 向分区表插入数据INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH',UNIX_TIMESTAMP(NOW()),1);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH 2',UNIX_TIMESTAMP(NOW()),2);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH 3',UNIX_TIMESTAMP(NOW()),3);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH 10',UNIX_TIMESTAMP(NOW()),10);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH 7',UNIX_TIMESTAMP(NOW()),7);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH 5',UNIX_TIMESTAMP(NOW()),5);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH',1451577607,1);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH 2',1451577609,2);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH 3',1451577623,3);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH 10',1451577654,10);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH 7',1451577687,7);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH 5',1451577699,5);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH',1514736056,1);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH 2',1514736066,2);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH 3',1514736076,3);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH 10',1514736086,10);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH 7',1514736089,7);INSERT INTO `msgss`(`sender`,`reciver`,`msg_type`,`msg`,`atime`,`sub_id`) VALUES(1,2,0,'Hello HASH 5',1514736098,5);-- 检查分区是否创建成功EXPLAIN PARTITIONS SELECT * FROM `msgss` 子分区注意事项： 每个子分区的数量必须相同。 只要在一个分区表的任何分区上使用 subpartition 来明确定义任何子分区，就必须在所有分区上定义子分区，不能漏掉一些分区不进行子分区。 每个 subpartition 子句必须包括子分区的一个名字。 子分区的名字必须是唯一的，不能在一张表中出现重名的子分区。 子分区必须使用 HASH 或者 KEY 分区。只有 RANG E 和 LIST 分区支持被子分区； HASH 和 KEY 不支持被子分区。 4.3 新增分区12345678-- RANGE 类型ALTER TABLE `my_orders` ADD PARTITION( PARTITION p2 VALUES LESS THAN (2018));-- HASH/KEY 类型。将分区总数扩展到 12 个ALTER TABLE `msgs` ADD PARTITION PARTITIONS 12; 4.4 合并分区1234567891011121314-- RANGE 类型ALTER TABLE `my_orders` REORGANIZE PARTITION p0,p1 INTO( PARTITION p0_p1 VALUES LESS THAN (2017));-- LIST 类型ALTER TABLE `products` REORGANIZE PARTITION pA,pB INTO( PARTITION pA_pB VALUES IN (1,3,11,13,2,4,12,14));-- HASH/KEY 类型。在这里数量只能比原来少不能多，想要增加可以用 ADD PARTITION 方法ALTER TABLE `msgs` REORGANIZE PARTITION COALESCE PARTITION 8; 4.5 删除分区12345-- 先删除。当删除了一个分区，也同时删除了该分区中所有的数据ALTER TABLE `my_orders` DROP PARTITION p0;-- 再重建，数据重新组合ALTER TABLE `my_orders` PARTITION BY RANGE (YEAR(atime)) (......); 5 扩展阅读 姜海强 - MySQL：http://blog.csdn.net/jhq0113/article/category/2897729 MySQL 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/08/14/mysql/mysql-partiton/"},{"title":"Nginx 参数配置优化","text":"Nginx 参数配置优化，提升 Nginx 效率与稳定性，官方文档：http://nginx.org/en/docs/ 。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196# 使用的用户和组# user nobody;# user root root;# 指定工作衍生进程数（一般等于 CPU 的总核数或总核数的两倍，例如两个四核 CPU ，则综合数为 8 。通过命令 ps -ef|grep nginx 可以看出来设置的是几个）worker_processes 1;#worker_processes 8;# 指定错误日志存放的路径，错误日志记录级别可选项为：[debug|info|notice|warn|error|crit]，默认是 crit ，记录的日志数量从 crit 到 debug ，由少到多# error_log logs/error.log;# error_log logs/error.log notice;# error_log logs/error.log info;# 指定 pid 存放的路径# pid logs/nginx.pid;# events settingsevents { # 设置网路连接序列化，防止惊群现象发生，默认为 on 惊群现象：一个网路连接到来，多个睡眠的进程被同时叫醒，但只有一个进程能获得链接，这样会影响系统性能。 # accept_mutex on; # 设置一个进程是否同时接受多个网络连接，默认为 off multi_accept on; # 使用的网络 I/O 模型， Linux 系统推荐采用 epoll 模型， FreeeBSD 系统推荐采用 kqueue 模型， Windows 系统不指定。 # use epoll; # 允许的连接数 worker_connections 1024;}# 遵循 http 协议的服务器全局设置http { include mime.types; default_type application/octet-stream; # 设置使用的字符集，如果一个网站有多种字符集，请不要随便设置，应让程序员在 HTML 代码中通过 Meta 标签设置 # charset utf-8; # 设置客户端能够上传的文件大小，注意要与应用程序中的文件大小限制兼容。 # client_max_body_size 30m; # 关闭日志记录 # access_log off; # 自定义日志记录格式设置， main 为名字，在 access_log 命令中引用 # log_format main '$remote_addr - $remote_user [$time_local]\"$request\"' #'$status $body_bytes_sent \"$http_referer\" ' #'\"$http_user_agent\"\"$http_x_forwarded_for\"'; # 指定日志存放路径，如果想使用默认的 combined 格式记录日志，可以使用 access_log logs/access.log combined; 以下是使用 log_format 自定义的格式记录日志的。 # access_log logs/access.log main; sendfile on; # tcp_nopush on; # keepalive_timeout 0; keepalive_timeout 120; # 开启 gzi p 压缩设置（只能在 http 模块中设置） # 该指令用于开启或关闭 gzip 模块(on/off) # gzip on; # 设置允许压缩的页面最小字节数，页面字节数从 header 头的 content‐length 中进行获取。默认值是 0，不管页面多大都压缩。建议设置成大于 1k 的字节数，小于 1k 可能会越压越大。 # gzip_min_length 1k; # 设置系统获取几个单位的缓存用于存储 gzip 的压缩结果数据流。4 16k 代表以 16k 为单位，安装原始数据大小以 16k 为单位的 4 倍申请内存。 # gzip_buffers 4 16k; # 识别 http 的协议版本(1. 0/1. 1) # gzip_http_version 1.1; # gzip 压缩比，1 压缩比最小处理速度最快，9 压缩比最大但处理速度最慢(传输快但比较消耗 cpu) # gzip_comp_level 2; # 匹配 mime 类型进行压缩，无论是否指定, “text/html” 类型总是会被压缩的。 # gzip_types application/x-javascript text/css application/xml; # 和 http 头有关系，加个 vary 头，给代理服务器用的，有的浏览器支持压缩，有的不支持，所以避免浪费不支持的也压缩，所以根据客户端的 HTTP 头来判断，是否需要压缩。 跟 Squid 等缓存服务有关， on 的话会在 Header 里增加 \"Vary: Accept‐Encoding\" # gzip_vary on; # IE6 对 Gzip 不怎么友好， 不给它 Gzip 了 # gzip_disable \"MSIE [1‐6] \\.\"; # 用于设置如果出现指定的 HTTP 错误状态码，则返回指定的 url 页面 # error_page 404 /404.html; # error_page 500 502 503 504 /50x.html; # upstream 负载均衡器 1 设置，用来处理普通请求。 upstream tomcat_test { server 127.0.0.1:8080 weight=1; server 127.0.0.1:8081 weight=1; # 轮询（默认）：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。 # server 127.0.0.1:8080; # server 127.0.0.1:8081; # 权重（weight）：指定轮询几率， weight 和访问比率成正比，用于后端服务器性能不均的情况。权重越高，在被访问的概率越大，如下分别是 30%，70%。 # server 127.0.0.1:8080 weight=3; # server 127.0.0.1:8081 weight=7; # IP 分配（ip_hash）：每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 的问题。 # ip_hash; # server 127.0.0.1:8080; # server 127.0.0.1:8081; # URL 分配（url_hash）：（需要事先安装插件）每个请求按访问地址 url 的 hash 结果分配，能实现同一个 url 访问同一个服务器，也就是根据 url 进行负载，后端服务器为缓存时比较有效。 # hash $request_uri; # hash_method crc32; # server 127.0.0.1:8080; # server 127.0.0.1:8081; # 响应时间（fair）：（需要事先安装插件）按后端服务器的响应时间来分配请求，响应时间短的优先分配。 # fair; # server 127.0.0.1:8080; # server 127.0.0.1:8081; # server 指令的参数为: # 1. down：表示当前的服务暂不参于负载。如：server 127.0.0.1:9080 down; # 2. backup：备用服务器，当其它所有非 backup 机器 down 或者忙时，才会请求 backup 机器。如：server 127.0.0.1:9081 backup; # 3. weight：设置服务器的权重，默认值是 1，权重值越大那么该服务器被访问到的几率就越大。 # 4. max_fails：允许请求失败的次数，默认为 1（这意味着一发生错误就认为服务器挂掉），如果把 max_fails 设为 0 则表示把这个检查取消。当超过最大次数时，返回 proxy_next_upstream 模块定义的错误。 # 5. fail_timeout：max_fails 次失败后，暂停的时间，默认是 10 秒。 # 4 和 5 一般关联使用，举个例子：server 127.0.0.1:8080 max_fails=3 fail_timeout=30s; 表示如果服务器 127.0.0.1:8080 在 30 秒内出现了 3 次错误，那么就认为这个服务器工作不正常，从而在接下来的 30 秒内 nginx 不再去访问这个服务器。 } # upstream 负载均衡器 2 设置，主要用来处理文件的上传和下载，可以理解为一个文件服务器，所有文件相关的上传和下载都通过这组服务器。 upstream tomcat_test_static { server 127.0.0.1:8082 weight=1; } # server 虚拟主机设置，可以设置多个：基于 IP 的虚拟主机，基于域名的虚拟主机 # 虚拟主机 - 基于域名，反向代理 tomcat_test 和 tomcat_test_static 这两组服务器 server { # 监听的端口 listen 80; # 主机名称 server_name localhost; # 设置 Nginx 的默认首页文件 # index index.html index.htm index.jsp index.do; # root D:/nginx-1.16.0; # 配置该虚拟机的字符设置，如果不配置继承自 http 中的 charset 设置 # charset koi8-r; # 访问日志文件设置，如果 server 虚拟机中不设置，则继承 http 模块中的 access_log 的设置 # if ($time_iso8601 ~ '(\\d{4}-\\d{2}-\\d{2})') { # set $date_yyyy_MM_dd $1; # } # access_log logs/access-$date_yyyy_MM_dd.log combined; # access_log logs/access.log main; # location settings，可以用在 server 节点中。 # 静态资源服务器 location，正则匹配，~ 为区分大小写，~* 为不区分大小写 location ~*/test/static/ { # 方法 1 proxy_pass http://tomcat_test_static; # 方法 2：指定相对路径，相对 nginx 安装目录下的 mydata 为根目录 # 如 http://127.0.0.1/test/static/common/images/1.png 会映射到 nginx 安装目录 /mydata/test/static/common/images/1.png # root mydata; # 方法 3：指定绝对路径，注意 windows 系统下分隔符用 / # 如 http://127.0.0.1/test/static/common/images/1.png 会映射到 D:/apache-tomcat-8.0.53-8082/webapps/test/static/common/images/1.png # root D:/apache-tomcat-8.0.53-8082/webapps; # 开启目录浏览权限，默认是 off # autoindex on; } # 普通服务器 location location / { # 请求转发的地址，/ 表示拦截到所有的请求 proxy_pass http://tomcat_test; # 设置当发生重定向请求时，nginx 自动修正响应头数据（默认是 Tomcat 返回重定向，此时重定向的地址是 Tomcat 的地址，我们需要将之修改 使之成为 Nginx 的地址） proxy_redirect default; # 变量 $host 等于客户端请求头中的 Host 值。 proxy_set_header Host $host; # 后端的 web 服务器可以通过 X-Forwarded-For 获取真实的 IP 地址， $remote_addr 客户端的 ip 地址 proxy_set_header X-Forwarded-For $remote_addr; # HTTP 代理模块 proxy，主要是用来转发请求到其他服务器 # 如果后端服务器返回 502，504，执行超时等错误，自动将请求转发到 upstream 负载均衡池中的另一台服务器，实现 failover 。 proxy_next_upstream http_502 http_504 error timeout invalid_header; } # image expires settings # expires 属于 http Header 模块，主要用来 Nginx 返回给用户网页添加附件的 header 信息，可以在 http,server,location 中使用 location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ { expires 30d; } # js/css/html expires settings # expires 属于 http Header 模块，主要用来 Nginx 返回给用户网页添加附件的 header 信息，可以在 http,server,location 中使用 location ~ .*\\.(js|css|html)?$ { expires 2h; } # 如果 http 模块设置了，则继承。此处设置了则覆盖。 # error_page 404 /404.html; # error_page 500 502 503 504 /50x.html; #location = /50x.html { # root html; #} }} Nginx 教程合集 （微信左下方 阅读全文 可直达）。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/03/05/nginx/nginx-conf/"},{"title":"通过 canal 将 MySQL 数据实时同步到 Elasticsearch","text":"通过本文学习如何通过 canal 将 MySQL 数据实时同步到 Elasticsearch。 1 简介 canal [kə'næl]，译意为水道 / 管道 / 沟渠，主要用途是基于 MySQL 数据库增量日志解析，提供增量数据订阅和消费。 基于日志增量订阅和消费的业务包括： 数据库镜像 数据库实时备份 索引构建和实时维护（拆分异构索引、倒排索引等） 业务 cache 刷新 带业务逻辑的增量数据处理 当前的 canal 支持源端 MySQL 版本包括 5.1.x , 5.5.x , 5.6.x , 5.7.x , 8.0.x 2 工作原理2.1 MySQL 主备复制原理 MySQL master 将数据变更写入二进制日志（binary log, 其中记录叫做二进制日志事件 binary log events，可以通过 show binlog events 进行查看）。 MySQL slave 将 master 的 binary log events 拷贝到它的中继日志（relay log）。 MySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据。 2.2 canal 工作原理 canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送 dump 协议。 MySQL master 收到 dump 请求，开始推送 binary log 给 slave（即 canal）。 canal 解析 binary log 对象（原始为 byte 流）。 3 基本使用 3.1 版本约定 本文使用的各组件版本约定如下： 组件 版本 端口 MySQL 5.7.29 3306 Elasticsearch 7.8.0 9200 Kibanba 7.8.0 5601 canal.deployer 1.1.15 11111 canal.adapter 1.1.15 8081 canal.admin 1.1.15 8089 3.2 组件下载与介绍 下载地址：https://github.com/alibaba/canal/releases canal.deployer（canal.server）：可以直接监听 MySQL 的 binlog，把自己伪装成 MySQL 的从库，只负责接收数据，并不做处理。 canal.adapter：相当于 canal 的客户端，会从 canal.deployer 中获取数据，然后对数据进行同步，可以同步到 MySQL、Elasticsearch 和 HBase 等存储中去。 canal.admin：为 canal 提供整体配置管理、节点运维等面向运维的功能，提供相对友好的 WebUI 操作界面，方便更多用户快速和安全的操作（非必须）。 3.3 MySQL 配置 首先，修改配置文件，关键配置如下（主要是开启 binlog 写入功能，模式为 ROW，其他参数的配置以实际为准）： 1234567891011[client]port = 3306[mysqld]port = 3306default-time-zone = '+8:00'server-id=1log-bin=mysql-binbinlog_format=ROWexpire_logs_days=7 接着，需要创建一个拥有从库权限的账号，用于订阅 binlog，这里创建的账号为 canal:canal： 1234CREATE USER canal IDENTIFIED BY 'canal'; GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';-- GRANT ALL PRIVILEGES ON *.* TO 'canal'@'%' ;FLUSH PRIVILEGES; 最后，在数据库 cxy35 中创建和表 t_user，如下： 123456789101112CREATE TABLE `t_user` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '主键 id', `username` varchar(255) DEFAULT NULL COMMENT '用户名', `password` varchar(255) DEFAULT NULL COMMENT '密码', `enabled` tinyint(1) DEFAULT '1' COMMENT '是否启用：1 启用；0 未启用', `locked` tinyint(1) DEFAULT '0' COMMENT '是否锁定：1 锁定；0 未锁定', `address` varchar(255) DEFAULT NULL COMMENT '地址', `nick_name` varchar(255) DEFAULT NULL COMMENT '昵称', `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '创建时间', `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间', PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 3.4 canal.deployer 配置 将 canal.deployer-1.1.5-SNAPSHOT.tar.gz 解压到 canal.deployer-1.1.5-SNAPSHOT，解压完成后目录结构如下： 123456789101112131415161718├── bin│ ├── restart.sh│ ├── startup.bat│ ├── startup.sh│ └── stop.sh├── conf│ ├── canal_local.properties│ ├── canal.properties│ └── example│ └── instance.properties├── lib├── logs│ ├── canal│ │ └── canal.log│ └── example│ ├── example.log│ └── example.log└── plugin 修改配置文件 conf/example/instance.properties，主要是修改数据库相关配置： 12345678910111213141516# position infocanal.instance.master.address=127.0.0.1:3306canal.instance.master.journal.name=canal.instance.master.position=canal.instance.master.timestamp=canal.instance.master.gtid=# username/passwordcanal.instance.dbUsername=canalcanal.instance.dbPassword=canalcanal.instance.connectionCharset = UTF-8# table regexcanal.instance.filter.regex=.*\\\\..*# table black regexcanal.instance.filter.black.regex=mysql\\\\.slave_.* 使用 startup.sh 或 startup.bat 启动 canal.deployer 服务，日志信息如下： logs/canal/canal.log：查看服务日志信息。 logs/example/example.log：查看 instance 日志信息 3.5 canal.adapter 配置 将 canal.adapter-1.1.5-SNAPSHOT.tar.gz 解压到 canal.adapter-1.1.5-SNAPSHOT，解压完成后目录结构如下： 123456789101112131415161718192021222324├── bin│ ├── adapter.pid│ ├── restart.sh│ ├── startup.bat│ ├── startup.sh│ └── stop.sh├── conf│ ├── application.yml│ ├── es6│ ├── es7│ │ ├── biz_order.yml│ │ ├── customer.yml│ │ └── product.yml│ ├── hbase│ ├── kudu│ ├── logback.xml│ ├── META-INF│ │ └── spring.factories│ └── rdb├── lib├── logs│ └── adapter│ └── adapter.log└── plugin 修改配置文件 conf/application.properties，主要是修改 canal.deployer(consumer) 配置、数据源配置和客户端适配器配置（同步到 ES）： 12345678910111213141516171819202122232425262728293031323334canal.conf: mode: tcp #tcp #kafka rocketMQ rabbitMQ flatMessage: true zookeeperHosts: syncBatchSize: 1000 retries: 0 timeout: accessKey: secretKey: consumerProperties: # canal tcp consumer canal.tcp.server.host: 127.0.0.1:11111 canal.tcp.zookeeper.hosts: canal.tcp.batch.size: 500 canal.tcp.username: canal.tcp.password: srcDataSources: defaultDS: url: jdbc:mysql://127.0.0.1:3306/cxy35?useUnicode=true username: canal password: canal canalAdapters: - instance: example # canal instance Name or mq topic name groups: - groupId: g1 outerAdapters: - name: logger - name: es7 hosts: 127.0.0.1:9200 properties: mode: rest security.auth: elastic:000000 cluster.name: elasticsearch 添加配置文件 canal-adapter/conf/es7/t_user.yml（adapter 将会自动加载 conf/es7 下的所有 .yml 结尾的配置文件），用于配置 MySQL 中的表与 Elasticsearch 中索引的映射关系： 123456789101112131415dataSourceKey: defaultDSdestination: examplegroupId: g1esMapping: _index: canal_user _id: _id# upsert: true# pk: id sql: \"select u.id as _id, u.id, u.username, u.password, u.enabled, u.locked, u.address, u.nick_name, u.create_time, u.update_time from t_user u\"# objFields:# _labels: array:; etlCondition: \"where u.create_time&gt;={}\" commitBatch: 3000 使用 startup.sh 或 startup.bat 启动 canal.deployer 服务，可通过 logs/adapter/adapter.log 查看服务日志信息。 更多同步到 ES 的配置参考：https://github.com/alibaba/canal/wiki/Sync-ES 3.6 测试 首先，在 Elasticsearch 中创建上述配置文件 t_user.yml 中对应的索引 canal_user，和 MySQL 中的 t_user 表相对应，直接在 Kibana 的 Dev Tools 中使用如下命令创建即可： 12345678910111213141516171819202122232425262728293031323334353637383940PUT /canal_user{ &quot;mappings&quot;: { &quot;properties&quot;: { &quot;address&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; }, &quot;create_time&quot;: { &quot;type&quot;: &quot;date&quot; }, &quot;enabled&quot;: { &quot;type&quot;: &quot;boolean&quot; }, &quot;id&quot;: { &quot;type&quot;: &quot;long&quot; }, &quot;locked&quot;: { &quot;type&quot;: &quot;boolean&quot; }, &quot;nick_name&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; }, &quot;password&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;update_time&quot;: { &quot;type&quot;: &quot;date&quot; }, &quot;username&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; } } }} 创建完成后可以通过 GET /canal_user/_mapping 命令查看索引的结构。 接着，在 MySQL 中针对 t_user 表做增删改操作，脚本如下： 123456789INSERT INTO t_user(username, password, enabled, locked, address, nick_name, create_time, update_time) VALUES ('zhangsan', '123456', '1', '0', '杭州', '张三', '2020-11-13 11:05:04', '2020-11-13 11:05:04');INSERT INTO t_user(username, password, enabled, locked, address, nick_name, create_time, update_time) VALUES ('lisi', '123456', '1', '0', '杭州', '李四', '2020-11-13 11:05:04', '2020-11-13 11:05:04');INSERT INTO t_user(username, password, enabled, locked, address, nick_name, create_time, update_time) VALUES ('wangwu', '123456', '1', '0', '宁波', '王五', '2020-11-13 11:05:04', '2020-11-13 11:05:04');INSERT INTO t_user(username, password, enabled, locked, address, nick_name, create_time, update_time) VALUES ('test', '123456', '1', '0', '宁波', '测试', '2020-11-13 11:05:04', '2020-11-13 11:05:04');UPDATE t_user set nick_name='测试 222' WHERE id=4;DELETE FROM t_user WHERE id=4; 最后，通过 GET /canal_user/_search 命令，查看 Elasticsearch 中的数据，发现会实时同步。 3.7 adapter 管理 REST 接口 查询所有订阅同步的 canal instance 或 MQ topic：curl http://127.0.0.1:8081/destinations 数据同步开关状态：curl http://127.0.0.1:8081/syncSwitch/example 数据同步开关：curl http://127.0.0.1:8081/syncSwitch/example/off -X PUT 手动 ETL，可用于数据全量 / 增量同步（如果 params 参数为空则全表导入, 参数对应的查询条件在配置中的 etlCondition 指定）：curl http://127.0.0.1:8081/etl/es7/t_user.yml -X POST -d &quot;params=2020-10-20 00:00:00&quot; 查看相关库总数据：curl http://127.0.0.1:8081/count/es7/t_user.yml 4 使用 canal.admin4.1 简介canal 1.1.4 版本之后，提供了 canal.admin。它为 canal 提供整体配置管理、节点运维等面向运维的功能，提供相对友好的 WebUI 操作界面，方便更多用户快速和安全的操作。 canal.admin 的核心模型主要有： instance：对应 canal.deployer（canal.server） 里的 instance，一个最小的订阅 MySQL 的队列。 server：对应 canal.deployer（canal.server），一个 server 里可以包含多个 instance。 集群：对应一组 canal.deployer（canal.server），组合在一起面向高可用 HA 的运维。 简单解释： instance 因为是最原始的业务订阅诉求，它会和 server/ 集群 这两个面向资源服务属性的进行关联，比如 instance A 绑定到 server A 上或者集群 A 上。 有了任务和资源的绑定关系后，对应的资源服务就会接收到这个任务配置，在对应的资源上动态加载 instance，并提供服务。动态加载的过程，有点类似于之前的 autoScan 机制，只不过基于 canal.admin 之后可就以变为远程的 web 操作，而不需要在机器上运维配置文件。 将 server 抽象成资源之后，原本 canal.deployer 运行所需要的 canal.properties/instance.properties 配置文件就需要在 WebUI 上进行统一运维，每个 server 只需要以最基本的启动配置（比如知道一下 canal.admin 的 manager 地址，以及访问配置的账号、密码即可）。 4.2 canal.admin 配置 将 canal.admin-1.1.5-SNAPSHOT.tar.gz 解压到 canal.admin-1.1.5-SNAPSHOT，解压完成后目录结构如下： 123456789101112131415161718├── bin│ ├── restart.sh│ ├── startup.bat│ ├── startup.sh│ └── stop.sh├── conf│ ├── application.yml│ ├── canal_manager.sql│ ├── canal-template.properties│ ├── instance-template.properties│ ├── logback.xml│ └── public│ ├── avatar.gif│ ├── index.html│ ├── logo.png│ └── static├── lib└── logs 创建 canal.admin 需要使用的数据库 canal_manager，创建 SQL 脚本为 conf/canal_manager.sql，会创建如下表： 修改 canal.admin 中的配置文件 conf/application.yml，主要是修改数据源配置和 canal.admin 的管理账号配置，注意需要用一个有读写权限的数据库账号（比如 root）： 123456789101112131415161718192021server: port: 8089spring: jackson: date-format: yyyy-MM-dd HH:mm:ss time-zone: GMT+8spring.datasource: address: 127.0.0.1:3306 database: canal_manager username: root password: '000000' driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://${spring.datasource.address}/${spring.datasource.database}?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false hikari: maximum-pool-size: 30 minimum-idle: 1canal: adminUser: admin adminPasswd: admin 使用 startup.sh 或 startup.bat 启动 canal.admin 服务，可通过 logs/admin.log 查看服务日志信息。 4.3 canal.deployer 配置 修改 canal.deployer 中的配置文件 conf/canal.properties，将 conf/canal_local.properties 中的内容替换到 conf/canal.properties 中，主要是修改 canal.admin 的配置： 1234567891011121314# register ipcanal.register.ip =# canal admin configcanal.admin.manager = 127.0.0.1:8089canal.admin.port = 11110canal.admin.user = admin# 账号密码要与 canal.admin 配置文件中的对应canal.admin.user = admin# 使用 MySQL 中 password 方法加密（明文：admin）canal.admin.passwd = 4ACFE3202A5FF5CF467898FC58AAB1D615029441# admin auto registercanal.admin.register.auto = truecanal.admin.register.cluster = 使用 startup.sh 或 startup.bat 重新启动 canal.deployer 服务。 关于配置文件，也可以不修改 conf/canal.properties ，而直接使用 conf/canal_local.properties，此时启动时需要指定配置文件，如下：sh bin/startup.sh local。 4.4 测试 访问 http://127.0.0.1:8089 就可以看到 canal.admin 的 Web 界面了，默认的账号密码为：admin/123456（对应 canal_manager.canal_user 表）。 更多 canal.admin 的配置和操作参考：https://github.com/alibaba/canal/wiki/Canal-Admin-Guide 5 扩展阅读 canal 官方项目：https://github.com/alibaba/canal canal 官方文档：https://github.com/alibaba/canal/wiki 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/11/15/other/canal-mysql-es/"},{"title":"不要再自己写 Java 工具类了，这些开源的不香吗？","text":"本文收集各种 Java 常用工具类，包括字符串、日期、集合 / 数组、IO、计时等。 1 字符串 1.1 StringUtilsMaven 依赖信息： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.10&lt;/version&gt;&lt;/dependency&gt; 判断字符串是否为空 1234567if (StringUtils.isEmpty(str)) {}// 如果字符串都是空格的话 StringUtils.isBlank(\"\") = true;StringUtils.isEmpty(\" \") = false； 判断字符串是否为空，使用频率非常高，这里大家可以使用 IDEA Prefix 的功能，输入直接生成判空语句。 字符串固定长度 1234// 字符串固定长度 8 位，若不足，往左补 0StringUtils.leftPad(\"test\", 8, \"0\");// 字符串固定长度 8 位，若不足，往右补 0StringUtils.rightPad(\"test\", 8, \"0\"); 字符串关键字替换 12345678// 默认替换所有关键字 StringUtils.replace(\"aba\", \"a\", \"z\") = \"zbz\";// 替换关键字，仅替换一次 StringUtils.replaceOnce(\"aba\", \"a\", \"z\") = \"zba\";// 使用正则表达式替换 StringUtils.replacePattern(\"ABCabc123\", \"[^A-Z0-9]+\", \"\") = \"ABC123\";// ...... 字符串拼接 1StringUtils.join([\"a\", \"b\", \"c\"], \",\") = \"a,b,c\" StringUtils 只能传入数组拼接字符串，不支持集合拼接，推荐使用 Guava 中的 Joiner ，具体使用见下文。 字符串拆分 123// 返回数组 StringUtils.split(\"a..b.c\", '.') = [\"a\", \"b\", \"c\"]StringUtils.splitByWholeSeparatorPreserveAllTokens(\"a..b.c\", \".\") = [\"a\",\"\", \"b\", \"c\"] 1.2 Joiner/SplitterMaven 依赖信息： 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;29.0-jre&lt;/version&gt;&lt;/dependency&gt; 字符串拼接 1234567891011String[] array = new String[]{\"test\", \"1234\", \"5678\"};List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add(\"test\");list.add(\"1234\");list.add(\"5678\");StringUtils.join(array, \",\");// 逗号分隔符，跳过 nullJoiner joiner = Joiner.on(\",\").skipNulls();joiner.join(array);joiner.join(list); 字符串拆分 123456// 返回 List 集合 Splitter splitter = Splitter.on(\",\");// 结果：[ab, , b, c]splitter.splitToList(\"ab,,b,c\");// 忽略空字符串，输出结果 [ab, b, c]splitter.omitEmptyStrings().splitToList(\"ab,,b,c\") 2 日期 2.1 DateUtils/DateFormatUtilsMaven 依赖信息： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.10&lt;/version&gt;&lt;/dependency&gt; JDK8 之前，Java 只提供一个 Date 类，平常我们需要将 Date 按照一定格式转化成字符串，我们需要使用 SimpleDateFormat 。 12345SimpleDateFormat simpleDateFormat=new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");// Date 转 字符串 simpleDateFormat.format(new Date());// 字符串 转 DatesimpleDateFormat.parse(\"2020-05-07 22:00:00\"); 代码虽然简单，但是这里需要注意 SimpleDateFormat ，不是线程安全的，多线程环境一定要注意使用安全。推荐使用 commons-lang3 下的时间工具类 DateUtils/DateFormatUtils 来解决 Date 与字符串转化问题。。 1234// Date 转化为字符串 DateFormatUtils.format(new Date(),\"yyyy-MM-dd HH:mm:ss\");// 字符串 转 DateDateUtils.parseDate(\"2020-05-07 22:00:00\",\"yyyy-MM-dd HH:mm:ss\"); 除了格式转化之外，DateUtils 还提供时间计算的相关功能。 123456789101112Date now = new Date();// Date 加 1 天 Date addDays = DateUtils.addDays(now, 1);// Date 加 33 分钟 Date addMinutes = DateUtils.addMinutes(now, 33);// Date 减去 233 秒 Date addSeconds = DateUtils.addSeconds(now, -233);// 判断是否 Wie 同一天 boolean sameDay = DateUtils.isSameDay(addDays, addMinutes);// 过滤时分秒, 若 now 为 2020-05-07 22:13:00 调用 truncate 方法以后 // 返回时间为 2020-05-07 00:00:00Date truncate = DateUtils.truncate(now, Calendar.DATE); 2.2 JDK8 时间类 JDK8 之后，Java 将日期与时间分为 LocalDate 和 LocalTime ，功能定义更加清晰，当然其也提供一个 LocalDateTime ，包含日期与时间。这些类相对于 Date 类优点在于，这些类与 String 类一样都是不变类型，不但线程安全，而且不能修改。 ps：仔细对比 mysql 时间日期类型 DATE/TIME/DATETIME ，有没有感觉差不多 现在 mybatis 等 ORM 框架已经支持 LocalDate 与 JDBC 时间类型转化，所以大家可以直接将时间字段实际类型定义为 JDK8 时间类型，然后再进行相关转化。 如果依然使用的是 Date 类型，如果需要使用新的时间类型，我们需要进行相关转化。两者之间进行转化， 稍微复杂一点，我们需要显示指定当前时区。 12345Date now = new Date();// Date-----&gt; LocalDateTime 这里指定使用当前系统默认时区 LocalDateTime localDateTime = now.toInstant().atZone(ZoneId.systemDefault()).toLocalDateTime();// LocalDateTime------&gt; Date 这里指定使用当前系统默认时区 Date date = Date.from(localDateTime.atZone(ZoneId.systemDefault()).toInstant()); 接下来我们使用 LocalDateTime 进行字符串格式化。 1234// 按照 yyyy-MM-dd HH:mm:ss 转化时间 LocalDateTime dateTime = LocalDateTime.parse(\"2020-05-07 22:34:00\", DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"));// 将 LocalDateTime 格式化字符串 String format = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\").format(dateTime); 另外我们使用 LocalDateTime 获取当前时间年份，月份特别简单： 1234567LocalDateTime now = LocalDateTime.now();// 年 int year = now.getYear();// 月 int month = now.getMonthValue();// 日 int day = now.getDayOfMonth(); 最后我们还可以使用 LocalDateTime 进行日期加减，获取下一天的时间： 1234567LocalDateTime now = LocalDateTime.now();// 当前时间加一天 LocalDateTime plusDays = now.plusDays(1l);// 当前时间减一个小时 LocalDateTime minusHours = now.minusHours(1l);// ...... 3 集合 / 数组 3.1 CollectionUtils/MapUtilsMaven 依赖信息： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-collections4&lt;/artifactId&gt; &lt;version&gt;4.4&lt;/vesion&gt;&lt;/dependency&gt; 我们可以使用 CollectionUtils/MapUtils 进行判空判断。 12345678// List/Set 集合判空 if(CollectionUtils.isEmpty(list)){}// Map 等集合进行判空 if (MapUtils.isEmpty(map)) { } 至于数组判空判断需要使用 commons-lang 下的 ArrayUtils 进行判断: 1234// 数组判空 if (ArrayUtils.isEmpty(array)) { } 除此之外还有一些别的对于集合增强方法，比如快速将数组加入到现有集合中： 123456List&lt;String&gt; listA = new ArrayList&lt;&gt;();listA.add(\"1\");listA.add(\"2\");listA.add(\"3\");String[] arrays = new String[]{\"a\", \"b\", \"c\"};CollectionUtils.addAll(listA, arrays); 3.2 Lists/Maps/SetsMaven 依赖信息： 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;29.0-jre&lt;/version&gt;&lt;/dependency&gt; 使用工具类，我们可以快速创建集合，如： 123List&lt;String&gt; list = Lists.newArrayList();Map&lt;String,String&gt; map = Maps.newHashMap();Set&lt;String&gt; set = Sets.newHashSet(); 另外还可以指定集合类的初始化大小。 123List&lt;String&gt; list = Lists.newArrayList(\"a\", \"b\");List&lt;String&gt; list2 = Lists.newArrayListWithExpectedSize(100);List&lt;String&gt; list3 = Lists.newArrayListWithCapacity(100); 4 IOMaven 依赖信息： 12345&lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt;&lt;/dependency&gt; 4.1 FileUtils（文件操作工具类） 快速实现文件 / 文件夹拷贝操作，如：FileUtils.copyDirectory/FileUtils.copyFile 1234// 拷贝文件 File fileA = new File(\"E:\\\\test\\\\test.txt\");File fileB = new File(\"E:\\\\test1\\\\test.txt\");FileUtils.copyFile(fileA,fileB); 使用 FileUtils.listFiles 获取指定文件夹上所有文件 123// 按照指定文件后缀如 java,txt 等去查找指定文件夹的文件 File directory = new File(\"E:\\\\test\");FileUtils.listFiles(directory, new String[]{\"txt\"}, false); 使用 FileUtils.readLines 读取该文件所有行。 12// 读取指定文件所有行 不需要使用 while 循环读取流了 List&lt;String&gt; lines = FileUtils.readLines(fileA) 有读就存在写，可以使用 FileUtils.writeLines，直接将集合中数据，一行行写入文本。 1234// 可以一行行写入文本 List&lt;String&gt; lines = new ArrayList&lt;&gt;();.....FileUtils.writeLines(lines) 4.2 IOUtils（I/O 操作相关工具类）FileUtils 主要针对相关文件操作，IOUtils 更加针对底层 I/O，可以快速读取 InputStream。实际上 FileUtils 底层操作依赖就是 IOUtils 。 IOUtils 可以适用于一个比较实用的场景，比如支付场景下，HTTP 异步通知场景（从 Servlet 获取异步通知内容）。如果我们使用 JDK 原生方法写: 1234567891011121314151617181920212223242526byte[] b = null;ByteArrayOutputStream baos = null;String respMsg = null;try { byte[] buffer = new byte[1024]; baos = new ByteArrayOutputStream(); // 获取输入流 InputStream in = request.getInputStream(); for (int len = 0; (len = in.read(buffer)) &gt; 0; ) { baos.write(buffer, 0, len); } b = baos.toByteArray(); baos.close(); // 字节数组转化成字符串 String reqMessage = new String(b, \"utf-8\");} catch (IOException e) { } finally { if (baos != null) { try { baos.close(); } catch (IOException e) { } }} 上面代码说起来还是挺复杂的。不过我们使用 IOUtils ，一个方法就可以简单搞定： 1234// 将输入流信息全部输出到字节数组中 byte[] b = IOUtils.toByteArray(request.getInputStream());// 或将输入流信息转化为字符串 // String resMsg = IOUtils.toString(request.getInputStream()); 5 计时 5.1 StopwatchMaven 依赖信息： 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;29.0-jre&lt;/version&gt;&lt;/dependency&gt; 编程中有时需要统计代码的的执行耗时，当然执行代码非常简单，结束时间与开始时间相减即可。 1234567long start = System.currentTimeMillis(); // 获取开始时间 // 其他代码 //...long end = System.currentTimeMillis(); // 获取结束时间 System.out.println(\"程序运行时间：\" + (end - start) + \"ms\"); 虽然代码很简单，但是非常不灵活，默认情况我们只能获取 ms 单位，如果需要转换为秒，分钟，就需要另外再计算。 这里我们介绍 Guava 中的 Stopwatch 计时工具类，借助他统计程序执行时间，使用方式非常灵活。 commons-lang3 与 spring-core 也有这个工具类，使用方式大同小异，大家根据情况选择。 123456789101112131415161718192021// 创建之后立刻计时，若想主动开始计时 Stopwatch stopwatch = Stopwatch.createStarted();// 创建计时器，但是需要主动调用 start 方法开始计时 // Stopwatch stopwatch = Stopwatch.createUnstarted();// stopWatch.start();// 模拟其他代码耗时 TimeUnit.SECONDS.sleep(2L);// 当前已经消耗的时间 System.out.println(stopwatch.elapsed(TimeUnit.SECONDS));TimeUnit.SECONDS.sleep(2L);// 停止计时 未开始的计时器调用 stop 将会抛错 IllegalStateExceptionstopwatch.stop();// 再次统计总耗时 System.out.println(stopwatch.elapsed(TimeUnit.SECONDS));// 重新开始，将会在原来时间基础计算，若想重新从 0 开始计算，需要调用 stopwatch.reset()stopwatch.start();TimeUnit.SECONDS.sleep(2L);System.out.println(stopwatch.elapsed(TimeUnit.SECONDS)); 输出结果为： 123246 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/05/31/other/java-utils/"},{"title":"Mycat 概述","text":"通过本文学习 Mycat 的介绍、架构、原理、应用场景等。 1 Mycat 介绍 Mycat 是什么？从定义和分类来看，它是一个开源的分布式数据库系统，是一个实现了 MySQL 协议的的 Server ，前端用户可以把它看作是一个数据库代理，用 MySQL 客户端工具和命令行访问，而其后端可以用 MySQL 原生（ Native ）协议与多个 MySQL 服务器通信，也可以用 JDBC 协议与大多数主流数据库服务器通信。 Mycat 的前身是阿里巴巴的 Cobar ， 其核心功能是分表分库，即将一个大表水平分割为 N 个小表，存储在后端 MySQL 服务器里或者其他数据库里。可以这样理解：数据库是对底层存储文件的抽象，而 Mycat 是对数据库的抽象。 Mycat 发展到目前的版本，已经不是一个单纯的 MySQL 代理了，它的后端可以支持 MySQL、SQL Server、Oracle、DB2、PostgreSQL 等主流数据库，也支持 MongoDB 这种新型 NoSQL 方式的存储，未来还会支持更多类型的存储。而在最终用户看来，无论是那种存储方式，在 Mycat 里，都是一个传统的数据库表，支持标准的 SQL 语句进行数据的操作，这样一来，对前端业务系统来说，可以大幅降低开发难度，提升开发速度。 在测试阶段，可以将一个表定义为任何一种 Mycat 支持的存储方式，比如 MySQL 的 MyASIM 表、内存表、或者 MongoDB、LevelDB 以及号称是世界上最快的内存数据库 MemSQL 上。试想一下，用户表存放在 MemSQL 上，大量读频率远超过写频率的数据如订单的快照数据存放于 InnoDB 中，一些日志数据存放于 MongoDB 中，而且还能把 Oracle 的表跟 MySQL 的表做关联查询，你是否有一种不能呼吸的感觉？而未来，还能通过 Mycat 自动将一些计算分析后的数据灌入到 Hadoop 中，并能用 Mycat+Storm/Spark Stream 引擎做大规模数据分析，看到这里，你大概明白了， Mycat 是什么？ Mycat 就是 BigSQL，Big Data On SQL Database。 对于 DBA 来说，可以这么理解 Mycat：Mycat 就是 MySQL Server ，而 Mycat 后面连接的 MySQL Server ，就好象是 MySQL 的存储引擎，如 InnoDB，MyISAM 等，因此，Mycat 本身并不存储数据，数据是在后端的 MySQL 上存储的，因此数据可靠性以及事务等都是 MySQL 保证的，简单的说， Mycat 就是 MySQL 最佳伴侣，它在一定程度上让 MySQL 拥有了能跟 Oracle PK 的能力。 对于软件工程师来说，可以这么理解 Mycat：Mycat 就是一个近似等于 MySQL 的数据库服务器，你可以用连接 MySQL 的方式去连接 Mycat （除了端口不同，默认的 Mycat 端口是 8066 而非 MySQL 的 3306 ，因此需要在连接字符串上增加端口信息），大多数情况下，可以用你熟悉的对象映射框架使用 Mycat ，但建议对于分片表，尽量使用基础的 SQL 语句，因为这样能达到最佳性能，特别是几千万甚至几百亿条记录的情况下。 对于架构师来说，可以这么理解 Mycat：Mycat 是一个强大的数据库中间件，不仅仅可以用作读写分离、以及分表分库、容灾备份，而且可以用于多租户应用开发、云平台基础设施、让你的架构具备很强的适应性和灵活性，借助于即将发布的 Mycat 智能优化模块，系统的数据访问瓶颈和热点一目了然，根据这些统计分析数据，你可以自动或手工调整后端存储，将不同的表映射到不同存储引擎上，而整个应用的代码一行也不用改变。 当前是个大数据的时代，但究竟怎样规模的数据适合数据库系统呢？对此，国外有一个数据库领域的权威人士说了一个结论：千亿以下的数据规模仍然是数据库领域的专长，而 Hadoop 等这种系统，更适合的是千亿以上的规模。所以， Mycat 适合 1000 亿条以下的单表规模，如果你的数据超过了这个规模，请投靠 Mycat Plus 吧！ 2 Mycat 架构 3 Mycat 原理Mycat 的原理并不复杂，复杂的是代码，如果代码也不复杂，那么早就成为一个传说了。 Mycat 的原理中最重要的一个动词是“拦截”，它拦截了用户发送过来的 SQL 语句，首先对 SQL 语句做了一些特定的分析：如分片分析、路由分析、读写分离分析、缓存分析等，然后将此 SQL 发往后端的真实数据库，并将返回的结果做适当的处理，最终再返回给用户。 上述图片里， Orders 表被分为三个分片 datanode （简称 dn )，这三个分片是分布在两台 MySQL Server 上 (DataHost)，即 datanode=database@datahost 方式，因此你可以用一台到 N 台服务器来分片，分片规则为（ sharding rule ) 典型的字符串枚举分片规则，一个规则的定义是分片字段（ sharding column )+ 分片函数(rule function)，这里的分片字段为 prov 而分片函数为字符串枚举方式。 当 Mycat 收到一个 SQL 时，会先解析这个 SQL ，查找涉及到的表，然后看此表的定义，如果有分片规则，则获取到 SQL 里分片字段的值，并匹配分片函数，得到该 SQL 对应的分片列表，然后将 SQL 发往这些分片去执行，最后收集和处理所有分片返回的结果数据，并输出到客户端。以 select * from Orders where prov=? 语句为例，查到 prov=wuhan ，按照分片函数， wuhan 返回 dn1 ，于是 SQL 就发给了 MySQL1 ，去取 DB1 上的查询结果，并返回给用户。 如果上述 SQL 改为 select * from Orders where prov in (‘wuhan’,‘beijing’) ，那么， SQL 就会发给 MySQL1 与 MySQL2 去执行，然后结果集合并后输出给用户。但通常业务中我们的 SQL 会有 Order By 以及 Limit 翻页语法，此时就涉及到结果集在 Mycat 端的二次处理，这部分的代码也比较复杂，而最复杂的则属两个表的 Jion 问题，为此， Mycat 提出了创新性的 ER 分片、全局表、HBT（Human Brain Tech) 人工智能的 Catlet 、以及结合 Storm/Spark 引擎等十八般武艺的解决办法，从而成为目前业界最强大的方案，这就是开源的力量！ 4 Mycat 应用场景Mycat 发展到现在，适用的场景已经很丰富，而且不断有新用户给出新的创新性的方案，以下是几个典型的应用场景： 单纯的 读写分离，此时配置最为简单，支持读写分离，主从切换。 分表分库，对于超过 1000 万的表进行分片，最大支持 1000 亿的单表分片。 多租户应用，每个应用一个库，但应用程序只连接 Mycat ，从而不改造程序本身，实现多租户化。 报表系统，借助于 Mycat 的分表能力，处理大规模报表的统计。 替代 Hbase ，分析大数据。 作为 海量数据实时查询 的一种简单有效方案，比如 100 亿条频繁查询的记录需要在 3 秒内查询出来结果，除了基于主键的查询，还可能存在范围查询或其他属性查询，此时 Mycat 可能是最简单有效的选择。 5 Mycat 长期路线图 强化分布式数据库中间件的方面的功能，使之具备丰富的插件、强大的数据库智能优化功能、全面的系统监控能力、以及方便的数据运维工具，实现在线数据扩容、迁移等高级功能。 进一步挺进大数据计算领域，深度结合 Spark Stream 和 Storm 等分布式实时流引擎，能够完成快速的巨表关联、排序、分组聚合等 OLAP 方向的能力，并集成一些热门常用的实时分析算法，让工程师以及 DBA 们更容易用 Mycat 实现一些高级数据分析处理功能。 不断强化 Mycat 开源社区的技术水平，吸引更多的 IT 技术专家，使得 Mycat 社区成为中国的 Apache ，并将 Mycat 推到 Apache 基金会，成为国内顶尖开源项目，最终能够让一部分志愿者成为专职的 Mycat 开发者，荣耀跟实力一起提升。 依托 Mycat 社区，聚集 100 个 CXO 级别的精英，众筹建设亲亲山庄， Mycat 社区 + 亲亲山庄 = 中国最大 IT O2O 社区。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/03/19/other/mycat-overview/"},{"title":"Tomcat 访问日志分析工具 - AWStats","text":"使用服务器日志分析工具 AWStats 分析 Tomcat 的访问日志。 1 准备工作Advanced Web Statistics(AWStats) 是一个免费的功能强大的服务器日志分析工具，它可以告诉你所有的 Web 统计数据，包括访问量、访问者数量、页面、 点击、高峰时段、操作系统、浏览器版本、搜索引擎、关键字、机械访问、无效连接等等。可以工作在大多数服务器上(IIS 5.0+,Apache,Tomcat)，可以从命令行或者 CGI 运行。 Linux 或 windows Tomcat：7.0.70 Java：jdk1.7.0_80(64 bit) ActivePerl：5.24.3(linux 系统自带， Win 环境需要额外安装) AWStats：7.7 下载 ActivePerl：http://www.activestate.com/activeperl/downloads/ 下载 AWStats：http://sourceforge.net/projects/awstats/ 2 安装及配置 AWStat将 AWStats 解压或安装，目录如下： 在 $TOMCAT_HOME$/webapps 下创建 awstats 文件夹，将 AWStats 解压后目录中的文件拷贝过来，目录如下： 并在 WEB-INF 目录下创建 web.xml 文件，内容如下： 1234567891011121314151617181920212223242526272829303132&lt;?xml version=\"1.0\" encoding=\"ISO-8859-1\"?&gt; &lt;web-app xmlns=\"http://java.sun.com/xml/ns/j2ee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd\" version=\"2.4\"&gt; &lt;servlet&gt; &lt;servlet-name&gt;cgi&lt;/servlet-name&gt; &lt;servlet-class&gt;org.apache.catalina.servlets.CGIServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;debug&lt;/param-name&gt; &lt;param-value&gt;0&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;cgiPathPrefix&lt;/param-name&gt; &lt;param-value&gt;WEB-INF/cgi-bin&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;5&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;cgi&lt;/servlet-name&gt; &lt;url-pattern&gt;/cgi-bin/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;/web-app&gt; 在 cgi-bin 目录下，重命名 awstats.model.conf 为 common.conf ，并创建 awstats.localhost.conf 输入： 123456789101112131415161718192021222324252627282930# awstats.xxx.conf：xxxx 为需要监控的站点域名，如果需要监控多个站点，可配置多个文件即可；Include \"common.conf\" # 配置 tomcat 下的访问日志目录，注意前后缀需要与 tomcat 中的配置一致LogFile=\"D:/apache-tomcat-7.0.70-utf8(9081)/logs/localhost_access_log.%yyyy-%mm-%dd.txt\" # 配置日志格式，需要与 tomcat 访问日志的格式配置匹配# $TOMCAT_HOME$/conf/server.xml 中 pattern：配置日志的格式，可设置为 common （默认）或 combined ，也可自行配置格式。# common：%h %l %u %t &amp;quot;%r&amp;quot; %s %b# combined：%h %l %u %t %r %s %b %{Referer}i %{User-Agent}i# pattern=\"%h %l %u %t &amp;quot;%r&amp;quot; %s %b\"LogFormat = \"%host - %logname %time1 %methodurl %code %bytesd\"# pattern=\"%h %u %t &amp;quot;%r&amp;quot; %s %b %{Referer}i &amp;quot;%{User-Agent}i&amp;quot;;\"# LogFormat =“%host %logname %time1 %methodurl %code %bytesd %referer %uaquot”# 配置的域名SiteDomain=\"localhost\" # 配置的访问地址HostAliases=\"localhost 127.0.0.1\" # 默认进入 AWStats 的文件DefaultFile=\"index.jsp\" # 在 cgi-bin 建立 data 文件夹 # 此站点监控的统计数据的目录（！！需要手工创建！！）DirData=\"data\" DirCgi=\"/cgi-bin\" DirIcons=\"/awstats/icon\" # 允许在 web 页更新日志，默认为 0（命令行更新） # 1 为可在监控页面中点击更新，0 为不允许；AllowToUpdateStatsFromBrowser=1 LogFormat 配置说明如下： 123456789101112131415161718192021222324252627282930313233343536# %host Client hostname or IP address (or Sender host for mail log) # %host_r Receiver hostname or IP address (for mail log) # %lognamequot Authenticated login/user with format: \"john\" # %logname Authenticated login/user with format: john # %time1 Date and time with format: \\[dd/mon/yyyy:hh:mm:ss +0000\\] or \\[dd/mon/yyyy:hh:mm:ss\\] # %time2 Date and time with format: yyyy-mm-dd hh:mm:ss # %time3 Date and time with format: Mon dd hh:mm:ss or Mon dd hh:mm:ss yyyy # %time4 Date and time with unix timestamp format: dddddddddd # %methodurl Method and URL with format: \"GET /index.html HTTP/x.x\" # %methodurlnoprot Method and URL with format: \"GET /index.html\" # %method Method with format: GET # %url URL only with format: /index.html # %query Query string (used by URLWithQuery option) # %code Return code status (with format for web log: 999) # %bytesd Size of document in bytes # %refererquot Referer page with format: \"http://from.com/from.htm\" # %referer Referer page with format: http://from.com/from.htm # %uabracket User agent with format: \\[Mozilla/4.0 (compatible, ...)\\] # %uaquot User agent with format: \"Mozilla/4.0 (compatible, ...)\" # %ua User agent with format: Mozilla/4.0_(compatible...) # %gzipin mod_gzip compression input bytes: In:XXX # %gzipout mod_gzip compression output bytes &amp; ratio: Out:YYY:ZZpct. # %gzipratio mod_gzip compression ratio: ZZpct. # %deflateratio mod_deflate compression ratio with format: (ZZ) # %email EMail sender (for mail log) # %email_r EMail receiver (for mail log) # %virtualname Web sever virtual hostname. Use this tag when same log # contains data of several virtual web servers. AWStats # will discard records not in SiteDomain nor HostAliases # %cluster If log file is provided from several computers (merged by # logresolvemerge.pl), use this to define cluster id field. # %extraX Another field that you plan to use for building a # personalized report with ExtraSection feature (See later). # If your log format has some fields not included in this list, use: # %other Means another not used field # %otherquot Means another not used double quoted field 3 配置 Tomcat修改 $TOMCAT_HOME$/conf/context.xml ，在 Context 节点中追加：privileged=”true” 。 修改 $TOMCAT_HOME$/conf/server.xml ，找到 Host ，并修改或追加 VALUE 节点如下： 1234567891011121314&lt;Host appBase=\"webapps\" autoDeploy=\"true\" name=\"localhost\" unpackWARs=\"true\"&gt; &lt;!-- SingleSignOn valve, share authentication between web applications Documentation at: /docs/config/valve.html --&gt; &lt;!-- &lt;Valve className=\"org.apache.catalina.authenticator.SingleSignOn\" /&gt; --&gt; &lt;!-- Access log processes all example. Documentation at: /docs/config/valve.html Note: The pattern used is equivalent to using pattern=\"common\" --&gt; &lt;Valve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\" pattern=\"%h %l %u %t &amp;quot;%r&amp;quot; %s %b\" prefix=\"localhost_access_log.\" suffix=\".txt\"/&gt;&lt;/Host&gt; patter 配置说明如下： 1234567891011121314151617181920212223 A formatting layout identifying the various information fields from the request and response to be logged, or the word `common` or `combined` to select a standard format. See below for more information on configuring this attribute.%a - Remote IP address %A - Local IP address %b - Bytes sent, excluding HTTP headers, or '-' if zero %B - Bytes sent, excluding HTTP headers %h - Remote host name (or IP address if enableLookups for the connector is false) %H - Request protocol %l - Remote logical username from identd (always returns '-') %m - Request method (GET, POST, etc.) %p - Local port on which this request was received. See also %{xxx}p below. %q - Query string (prepended with a '?' if it exists) %r - First line of the request (method and request URI) %s - HTTP status code of the response %S - User session ID %t - Date and time, in Common Log Format %u - Remote user that was authenticated (if any), else '-' %U - Requested URL path %v - Local server name %D - Time taken to process the request, in millis %T - Time taken to process the request, in seconds %F - Time taken to commit the response, in millis %I - Current request thread name (can compare later with stacktraces) 4 启动及验证 启动 tomcat 后，输入：http://localhost:8080/awstats/cgi-bin/awstats.pl?config=localhostconfig 为需要查看的统计站点，与你配置相同即可；效果图如下： 手动点击“立即更新“或自己实现定时更新。如可以设置一个 crotab -e 进行配置：0 */10 * * * curl http://localhost:8080/awstats/cgi-bin/awstats.pl?&amp;config=localhost&amp;month=11&amp;year=2018&amp;framename=mainright&amp;update=1 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/11/23/other/tomcat-awstats/"},{"title":"Tomcat 管理和监控工具 - PSI Probe","text":"使用 PSI Probe 管理和监控 Tomcat 。 1 准备工作PSI Probe 是一个 Lambda Probe 的后续版本，主要是为了替换 Tomcat 自带的管理器，可方便的管理和监控 Tomcat 实例。主要特性： Requests: Monitor traffic in real-time, even on a per-application basis. Sessions: Browse/search attributes, view last IP, expire, estimate size. JSP: Browse, view source, compile. Data Sources: View pool usage, execute queries. Logs: View contents, download, change levels at runtime. Threads: View execution stack, kill. Connectors: Status, usage charts. Cluster: Status, usage charts. JVM: Memory usage charts, advise GC Java Service Wrapper: Restart JVM. System: CPU usage, memory usage, swap file usage. Tomcat 版本：apache-tomcat-8.0.53-windows-x64 JDK 版本：jdk-8u181-windows-x64 PSI Probe 版本：psi-probe-3.2.0 下载 probe.war：https://github.com/psi-probe/psi-probe/releases 安装并启动成功。 2 配置 Tomcat将打包或下载的 probe.war 放在 Tomcat 根目录 /webapps 目录下。 编辑 Tomcat 根目录下 /webapps/manager/META-INF/context.xml ，修改配置： 1234&lt;!-- 注释掉 Valve，如果不想注释，allow 可增加需要访问的 ip 地址即可 --&gt;&lt;!-- &lt;Valve className=\"org.apache.catalina.valves.RemoteAddrValve\" allow=\"127\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1\" /&gt;--&gt; 3 测试 通过 http://127.0.0.1:8080/probe/index.htm 访问，手动输入 tomcat-users.xml 中的用户名和密码登录后，查看页面截图如下： 4 二次开发 基于 psi-probe-3.2.0 二次开发，主要实现自动登录功能，使用 tomcat-users.xml 中的用户名和密码。 涉及 2 个子工程修改：psi-probe-web 和 psi-probe-core 。工程代码：https://github.com/cxy35/psi-probe 4.1 编辑 web.xml编辑 psi-probe-web 工程目录下 /WEB-INF/web.xml ，修改如下： 12345678910111213141516&lt;!-- 注释掉原来的 login-config 配置 --&gt;&lt;!-- &lt;login-config&gt; &lt;auth-method&gt;BASIC&lt;/auth-method&gt; &lt;realm-name&gt;PSI Probe&lt;/realm-name&gt;&lt;/login-config&gt;--&gt;&lt;!-- 增加自己的 login-config 配置 --&gt;&lt;!-- 配置认证方式为 form , 指定登陆页面 login.jsp 和登陆失败页面 loginError.jsp 。用户请求受保护资源时，会被容器踢回到 login.jsp ，获取用户名和密码自动提交给 j_security_check ，容器进行安全认证，方式是用户指定好的，认证成功后，马上进入到用户输入的受保护资源 --&gt;&lt;login-config&gt; &lt;auth-method&gt;FORM&lt;/auth-method&gt; &lt;form-login-config&gt; &lt;form-login-page&gt;/myjsp/login.jsp&lt;/form-login-page&gt; &lt;form-error-page&gt;/myjsp/loginError.jsp&lt;/form-error-page&gt; &lt;/form-login-config&gt;&lt;/login-config&gt; 4.2 编辑 decorators.xml编辑 psi-probe-web 工程目录下 /WEB-INF/decorators.xml ，修改如下： 1234567&lt;excludes&gt; &lt;pattern&gt;/*.xml.htm&lt;/pattern&gt; &lt;pattern&gt;/*.ajax*&lt;/pattern&gt; &lt;pattern&gt;/WEB-INF/*&lt;/pattern&gt; &lt;!-- 增加如下配置 --&gt; &lt;pattern&gt;/myjsp/*&lt;/pattern&gt;&lt;/excludes&gt; 4.3 新增 login.jsp在 psi-probe-web 工程目录下增加 /myjsp/login.jsp ，内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;%-- Licensed under the GPL License. You may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.gnu.org/licenses/old-licenses/gpl-2.0.html THIS PACKAGE IS PROVIDED \"AS IS\" AND WITHOUT ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR A PARTICULAR PURPOSE.--%&gt;&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" session=\"false\" %&gt;&lt;%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %&gt;&lt;%@ taglib uri=\"http://www.springframework.org/tags\" prefix=\"spring\" %&gt;&lt;%@ page import=\"org.apache.commons.lang3.StringUtils\"%&gt;&lt;%@ page import=\"myjava.*\"%&gt;&lt;% String param = request.getParameter(\"param\"); String username = \"\"; String password = \"\"; if(StringUtils.isNotBlank(param)){ // 明文格式：username=tomcat&amp;password=123456 param = AesUtils.decrypt(param, \"probe-3.2.0\"); if(param != null){ String[] paramArr = param.split(\"&amp;\"); if(paramArr != null &amp;&amp; paramArr.length &gt; 1){ for(int i=0; i&lt;paramArr.length; i++){ if(paramArr[i] == null){ continue; } String[] arr = paramArr[i].split(\"=\"); if(arr != null &amp;&amp; arr.length &gt; 1){ if(\"username\".equals(arr[0])){ username = arr[1]; } if(\"password\".equals(arr[0])){ password = arr[1]; } } } } } } boolean autoLogin = false; if(StringUtils.isNotBlank(username) &amp;&amp; StringUtils.isNotBlank(password)){ autoLogin = true; }%&gt;&lt;html&gt; &lt;head&gt;&lt;/head&gt; &lt;% if(autoLogin){ %&gt; &lt;body onload=\"document.getElementById('Login').submit();\"&gt; &lt;form class=\"form-signin\" method=\"post\" name=\"Login\" id=\"Login\" action=\"j_security_check\" style=\"opacity: 0;\"&gt; &lt;input type=\"text\" name=\"j_username\" value=\"&lt;%=username %&gt;\" &gt; &lt;input type=\"password\" name=\"j_password\" value=\"&lt;%=password %&gt;\"&gt; &lt;/form&gt; &lt;/body&gt; &lt;% }else{ %&gt; &lt;body&gt; &lt;div class=\"errorMessage\"&gt; &lt;p&gt; &lt;spring:message code=\"probe.jsp.noaccess\"/&gt; &lt;/p&gt; &lt;/div&gt; &lt;/body&gt; &lt;%}%&gt;&lt;/html&gt; 4.4 新增 loginError.jsp在 psi-probe-web 工程目录下增加 /myjsp/loginError.jsp ，内容如下： 123456789101112131415&lt;%-- Licensed under the GPL License. You may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.gnu.org/licenses/old-licenses/gpl-2.0.html THIS PACKAGE IS PROVIDED \"AS IS\" AND WITHOUT ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR A PARTICULAR PURPOSE.--%&gt;&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" session=\"false\" %&gt;&lt;jsp:forward page=\"/index.htm\"/&gt; 4.5 编辑 ProbeSecurityConfig.java编辑 psi-probe-core 工程目录下 /psiprobe/ProbeSecurityConfig.java ，并重新打包 psi-probe-core-3.2.0.jar ，修改如下： 12345678@Bean(name = \"filterChainProxy\")public FilterChainProxy getFilterChainProxy() { // 踢回登录页面 login.jsp SecurityFilterChain chain = new DefaultSecurityFilterChain(new AntPathRequestMatcher(\"/tihuidengluyemian\"), getSecurityContextPersistenceFilter(), getJ2eePreAuthenticatedProcessingFilter(), getLogoutFilter(), getExceptionTranslationFilter(), getFilterSecurityInterceptor()); return new FilterChainProxy(chain);} 4.6 新增 AesUtils.java在 psi-probe-core 工程目录下增加 /myjava/AesUtils.java ，并重新打包 psi-probe-core-3.2.0.jar ，内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151package myjava;/** * Licensed under the GPL License. You may not use this file except in compliance with the License. * You may obtain a copy of the License at * * https://www.gnu.org/licenses/old-licenses/gpl-2.0.html * * THIS PACKAGE IS PROVIDED \"AS IS\" AND WITHOUT ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, * WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR A PARTICULAR * PURPOSE. */import java.nio.charset.Charset;import java.security.SecureRandom;import java.util.logging.Level;import java.util.logging.Logger;import javax.crypto.Cipher;import javax.crypto.KeyGenerator;import javax.crypto.SecretKey;/** * AES 加密、解密工具类 * * @author cxy35 * @date 2019 年 6 月 20 日 下午 3:54:17 * */public class AesUtils { private static final String KEY_ALGORITHM = \"AES\"; /** AES 算法的密钥 **/ private static final String AES_KEY_DEFAULT = \"1234!@#$\"; private static final String DEFAULT_CIPHER_ALGORITHM = \"AES/ECB/PKCS5Padding\";// 默认的加密算法 /** * AES 加密操作 * * @param content * 待加密内容 * @param password * 加密密码 * @return 返回 Base64 转码后的加密数据 */ public static String encrypt(String content, String password) { try { Cipher cipher = Cipher.getInstance(DEFAULT_CIPHER_ALGORITHM);// 创建密码器 Charset charset = Charset.forName(\"utf-8\"); byte[] byteContent = content.getBytes(charset); cipher.init(Cipher.ENCRYPT_MODE, getSecretKey(password));// 初始化为加密模式的密码器 byte[] result = cipher.doFinal(byteContent);// 加密 String returnStr = parseByte2HexStr(result); return returnStr; } catch (Exception ex) { Logger.getLogger(AesUtils.class.getName()).log(Level.SEVERE, null, ex); } return null; } /** * AES 解密操作 * * @param content * @param password * @return */ public static String decrypt(String content, String password) { try { // 实例化 Cipher cipher = Cipher.getInstance(DEFAULT_CIPHER_ALGORITHM); // 使用密钥初始化，设置为解密模式 cipher.init(Cipher.DECRYPT_MODE, getSecretKey(password)); // 执行操作 byte[] result = cipher.doFinal(parseHexStr2Byte(content)); Charset charset = Charset.forName(\"utf-8\"); return new String(result, charset); } catch (Exception ex) { Logger.getLogger(AesUtils.class.getName()).log(Level.SEVERE, null, ex); } return null; } /** * 生成加密秘钥 * * @return */ private static SecretKey getSecretKey(String password) { try { KeyGenerator _generator = KeyGenerator.getInstance(KEY_ALGORITHM); SecureRandom secureRandom = SecureRandom.getInstance(\"SHA1PRNG\"); secureRandom.setSeed(password.getBytes()); _generator.init(128, secureRandom); return _generator.generateKey(); } catch (Exception e) { throw new RuntimeException(\"初始化密钥出现异常\"); } } /** * 将二进制转换成 16 进制 * * @param buf * @return */ public static String parseByte2HexStr(byte buf[]) { StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; buf.length; i++) { String hex = Integer.toHexString(buf[i] &amp; 0xFF); if (hex.length() == 1) { hex = '0' + hex; } sb.append(hex.toUpperCase()); } return sb.toString(); } /** * 将 16 进制转换为二进制 * * @param hexStr * @return */ public static byte[] parseHexStr2Byte(String hexStr) { if (hexStr.length() &lt; 1) return null; byte[] result = new byte[hexStr.length() / 2]; for (int i = 0; i &lt; hexStr.length() / 2; i++) { int high = Integer.parseInt(hexStr.substring(i * 2, i * 2 + 1), 16); int low = Integer.parseInt(hexStr.substring(i * 2 + 1, i * 2 + 2), 16); result[i] = (byte) (high * 16 + low); } return result; } public static void main(String[] args) { String data = \"username=tomcat&amp;password=123456\"; String key = AES_KEY_DEFAULT; key = \"probe-3.2.0\"; String encrypt = encrypt(data, key); System.out.println(encrypt); String decrypt = decrypt(encrypt, key); System.out.println(decrypt); }} 4.7 测试 部署后通过 http://127.0.0.1:8080/probe/?lang=zh_cn&amp;param=A53DF556F7D6896DF4ECF33687B846AF83424EE870656A4EF8192F66A6D382830ADFBF490E576219243CB47D1134E720 访问（该 param 对应的 password 不是 123456），可完成自动登录。其中 param 的值可通过约定的格式与加密规则获得，本文采用 AES 加密，使用 tomcat-users.xml 中的用户名和密码。如果 param 不传或者用户名密码错误，则都会在 login.jsp 中提示 probe.jsp.noaccess 对应的错误信息，如“您没有足够的权限来访问本页面. 请使用浏览工具栏来选择另一个区域或者点击浏览器中的 “后退” 按钮.”； 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/05/24/other/tomcat-psiprobe/"},{"title":"Spring Boot 整合 DevTools（实现热部署）","text":"Spring Boot 整合 DevTools ，实现类文件和静态资源文件的热部署，只需要添加 spring-boot-devtools 依赖就可以轻松实现。 1 自动编译配置 在 Eclipse 中文件修改后，保存就会自动编译，但在 IDEA 中没有显示的文件保存操作，因此默认情况下文件修改后不会自动编译，需要手动编译（快捷键： Ctrl + F9 ），从而触发项目自动重启。当然我们可以通过配置来实现 IDEA 中文件修改后的自动编译（可能会比较耗电脑资源），如下： 开启自动编译： Registry 配置（快捷键： Ctrl + Shift + Alt + / ）： 注意：在 Maven 项目的子 Module 内自动编译和自动重启貌似无效？ 2 创建项目 创建 Spring Boot 项目 spring-boot-devtools ，添加 Web/DevTools 依赖，最终的依赖如下： 123456789101112131415161718192021222324&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3 类文件热部署DevTools 针对类文件的热部署，主要由两个不同的 classloader 实现： base classloader 和 restart classloader 。其中 base classloader 用来加载那些不会变化的类，例如各种第三方依赖。而 restart classloader 则用来加载那些会发生变化的类，例如你自己写的代码。 Spring Boot 中热部署的原理就是当类文件发生变化时， base classloader 不变，而 restart classloader 则会被废弃，被另一个新的 restart classloader 代替。在整个过程中，因为只重新加载了变化的类，所以启动速度要比整个项目启动要快。 新建 HelloController 测试类，如下： 1234567@RestControllerpublic class HelloController { @GetMapping(\"/hello\") public String hello() { return \"Hello DevTools\"; }} 项目启动之后，访问 http://127.0.0.1:8080/hello ，接着修改内容，稍等一会观察控制台会发现类文件自动编译，且项目自动重启了，刷新页面后发现修改的内容也生效了。如果没有自动重启，可以尝试按一下 Ctrl + S 或切换一下视图离开 IDEA ，应该就会自动重启了。 4 静态资源文件热部署 4.1 配置项目自动重启（技术上可行） 在使用 DevTools 时，默认情况下当静态资源文件发生变化时，并不会触发项目自动重启，当然我们可以通过配置来实现（实际上没必要），有两种方式，如下： 12345# 配置 static 目录下的文件变化后（前提要手动 / 自动编译），触发项目自动重启# 方式 1spring.devtools.restart.exclude=classpath:/static/**# 方式 2# spring.devtools.restart.additional-paths=src/main/resources/static 在 src/main/resources/static 目录下新增 index.html ，如下： 12345678910&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1 style=\"color: #ff1a0e;\"&gt;hello devtools!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 项目启动之后，访问 http://127.0.0.1:8080/index.html ，接着修改 index.html 的内容，稍等一会观察控制台会发现项目自动重启了，刷新页面后发现修改的内容也生效了。如果没有自动重启，可以尝试按一下 Ctrl + S 或切换一下视图离开 IDEA ，应该就会自动重启了。 虽然技术上我们可以通过配置解决这一问题，但是没有必要。因为静态资源文件发生变化后不需要编译，按理说保存后刷新下就可以访问到了。那么如何才能实现静态资源文件发生变化时，不编译就能自动刷新呢？ LiveReload 可以帮助我们实现这一功能。 4.2 LiveReload 实现页面自动刷新（推荐）DevTools 中默认嵌入了 LiveReload 服务器， LiveReload 可以在静态资源文件发生变化时自动触发浏览器页面刷新， LiveReload 支持 Chrome、Firefox 以及 Safari 。以 Chrome 为例，在 Chrome 应用商店搜索 LiveReload 并添加到 Chrome 中（也可以通过离线安装），添加成功后，在 Chrome 右上角有一个 LiveReload 图标。 首先，注释掉上面关于静态资源文件触发项目自动重启的配置，如下： 12345# 配置 static 目录下的文件变化后（前提要手动 / 自动编译），触发项目自动重启# 方式 1# spring.devtools.restart.exclude=classpath:/static/**# 方式 2# spring.devtools.restart.additional-paths=src/main/resources/static 项目启动之后，访问 http://127.0.0.1:8080/index.html ，并在当前页面开启 LiveReload 。注意： LiveReload 是和浏览器的选项卡绑定在一起的，在哪个选项卡中开启了 LiveReload，就在哪个选项卡中访问页面，这样才有效果。 接着修改下 index.html 的内容，回到浏览器，不用做任何操作，就会 发现浏览器自动刷新了，页面已经更新了，整个过程中项目并没有重启。 LiveReload 默认是开启的，我们可以通过配置禁用 LiveReload ，如下： 12# 禁用 LiveReloadspring.devtools.livereload.enabled=false 5 其他配置 5.1 手动控制自动重启功能 默认情况下， DevTools 中的自动重启功能是由它自己控制的，每次文件变化都会触发。实际上没必要这么频繁，一般我们是在完成一个功能后才需要重启。下面通过配置来实现手动控制自动重启，有两种方式，如下： 方式 1：项目配置文件 12# 手动控制自动重启功能：项目文件变化，且 .trigger-file 文件变化，则项目自动重启spring.devtools.restart.trigger-file=.trigger-file 方式 2：全局配置 在当前用户目录下新建 .spring-boot-devtools.properties 文件，如下： 1spring.devtools.restart.trigger-file=.trigger-file 最后在 src/main/resources 目录下新建 .trigger-file 文件，当每次完成一个功能后，手动修改下这个文件（内容随意），项目才会自动重启。 5.2 关闭自动重启功能 引入了 spring-boot-devtools 依赖后，项目的自动重启功能默认是启用的，我们可以通过配置来关闭该功能，有两种方式，如下： 方式 1：配置文件 12# 方式 1：关闭自动重启功能spring.devtools.restart.enabled=false 方式 2：启动类 123456789@SpringBootApplicationpublic class SpringBootDevtoolsApplication { public static void main(String[] args) { // 方式 2：关闭自动重启功能 System.setProperty(\"spring.devtools.restart.enabled\", \"false\"); SpringApplication.run(SpringBootDevtoolsApplication.class, args); }} Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-devtools 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/04/06/springboot/spring-boot-devtools/"},{"title":"Spring Boot 自定义异常处理","text":"学习在 Spring Boot 如何实现自定义异常处理，及其中的原理。 在 Spring Boot 中，关于异常的统一处理，可以使用 @ControllerAdvice ，具体见 Spring Boot 使用 @ControllerAdvice，也可以自己来定义异常处理方案。 Spring Boot 有一个默认的异常页面，如下： 上面提到了 /error 路径，会去寻找默认的异常页面。我们可以自定义异常页面，这样就可以覆盖默认的页面。一般分为两种：静态异常页面、动态异常页面。 1 静态异常页面 自定义静态异常页面的默认位置为：classpath:/static/error/。命名方式一般分为两种： 使用 HTTP 响应码来命名页面，定义 404.html、405.html、500.html 等。 定义 4xx.html（对应 400-499 的响应码）、5xx.html（对应 500-5999 的响应码）。 优先级是第一种高于第二种，即如果抛出 500 错误，会优先展示 500.html ，而不是 5xx.html 。 在 src/main/resources/static/error 下新建 500.html ，如下： 12345678910&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;static/error/500&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 新建 HelloController 测试类，如下： 123456789@RestControllerpublic class HelloController { // 默认的错误页面查找顺序：发生了 500 错误 –&gt; 查找动态 500.html –&gt; 查找静态 500.html –&gt; 查找动态 5xx.html –&gt; 查找静态 5xx.html @GetMapping(\"/hello\") public String hello() { int i = 1 / 0; return \"hello\"; }} 启动项目，访问 http://120.0.0.1:8080/hello 来验证。 2 动态异常页面 自定义动态异常页面的默认位置为：classpath:/templates/error/，可以使用的页面模板有 thymeleaf、freemarker、jsp ，下面以 thymeleaf 为例。命名方式一般分为两种： 使用 HTTP 响应码来命名页面，定义 404.html、405.html、500.html 等。 定义 4xx.html（对应 400-499 的响应码）、5xx.html（对应 500-5999 的响应码）。一般采用这种，因为可以在页面中动态展示响应码，没必要按文件列出每种错误。 优先级是第一种高于第二种，即如果抛出 500 错误，会优先展示 500.html ，而不是 5xx.html 。 使用自定义动态异常页面时，我们只需要定义页面，不用自己去写 Controller ，因为 Spring Boot 自带的异常处理器会自动查找到异常页面。 在 src/main/resources/templates/error 下新建 5xx.html ，如下： 1234567891011121314151617181920212223242526272829303132&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;templates/error/5xx&lt;/h1&gt;&lt;table border=\"1\"&gt; &lt;tr&gt; &lt;td&gt;timestamp&lt;/td&gt; &lt;td th:text=\"${timestamp}\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;path&lt;/td&gt; &lt;td th:text=\"${path}\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;error&lt;/td&gt; &lt;td th:text=\"${error}\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;status&lt;/td&gt; &lt;td th:text=\"${status}\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;message&lt;/td&gt; &lt;td th:text=\"${message}\"&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/body&gt;&lt;/html&gt; 启动项目，访问 http://120.0.0.1:8080/hello 来验证。最终效果如下： 另外，如果静态 / 动态异常页面同时存在时，发生了 500 错误，优先级如下：查找动态 500.html –&gt; 查找静态 500.html –&gt; 查找动态 5xx.html –&gt; 查找静态 5xx.html 。 3 自定义异常数据 默认情况下，异常数据只包括：path/error/message/timestamp/status ，它们被定义在 org.springframework.boot.web.reactive.error.DefaultErrorAttributes 类的 getErrorAttributes 方法中，源码如下： 1234567891011121314@Overridepublic Map&lt;String, Object&gt; getErrorAttributes(ServerRequest request, boolean includeStackTrace) { Map&lt;String, Object&gt; errorAttributes = new LinkedHashMap&lt;&gt;(); errorAttributes.put(\"timestamp\", new Date()); errorAttributes.put(\"path\", request.path()); Throwable error = getError(request); HttpStatus errorStatus = determineHttpStatus(error); errorAttributes.put(\"status\", errorStatus.value()); errorAttributes.put(\"error\", errorStatus.getReasonPhrase()); errorAttributes.put(\"message\", determineMessage(error)); handleException(errorAttributes, determineException(error), includeStackTrace); return errorAttributes;} 上述 DefaultErrorAttributes 类是在 org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration 异常自动配置类中定义的，是 Spring Boot 默认提供的，我们可以自己提供 1 个 ErrorAttributes 实例来覆盖默认的，从而实现自定义异常数据，一般有两种方式： 实现 ErrorAttributes 接口。 继承 DefaultErrorAttributes （推荐），这样的话 DefaultErrorAttributes 原来的那些配置都还有效。 在 src/main/java 下新建 MyErrorAttributes ，如下： 123456789101112@Componentpublic class MyErrorAttribute extends DefaultErrorAttributes { @Override public Map&lt;String, Object&gt; getErrorAttributes(WebRequest webRequest, boolean includeStackTrace) { Map&lt;String, Object&gt; map = super.getErrorAttributes(webRequest, includeStackTrace); if ((Integer)map.get(\"status\") == 500) { map.put(\"message\", \"服务器内部错误!\"); } map.put(\"myMessage\", \"这是我新增的自定义异常信息！\"); return map; }} 在 src/main/resources/templates/error 下修改 5xx.html ，增加如下展示内容： 1234&lt;tr&gt; &lt;td&gt;myMessage&lt;/td&gt; &lt;td th:text=\"${myMessage}\"&gt;&lt;/td&gt;&lt;/tr&gt; 启动项目，访问 http://120.0.0.1:8080/hello 来验证。最终效果如下： 4 自定义异常视图 默认的异常视图加载逻辑在 org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController 类的 errorHtml 方法中，这个方法用来返回异常页面 + 数据，还有另外一个 error 方法，这个方法用来返回异常数据（如果是 ajax 请求，则该方法会被触发）。 12345678910@RequestMapping(produces = MediaType.TEXT_HTML_VALUE)public ModelAndView errorHtml(HttpServletRequest request, HttpServletResponse response) { HttpStatus status = getStatus(request); Map&lt;String, Object&gt; model = Collections.unmodifiableMap(getErrorAttributes( request, isIncludeStackTrace(request, MediaType.TEXT_HTML))); response.setStatus(status.value()); ModelAndView modelAndView = resolveErrorView(request, response, status, model); return (modelAndView != null) ? modelAndView : new ModelAndView(\"error\", model);} 在该方法中，首先会通过 getErrorAttributes 方法去获取异常数据（实际上会调用到 ErrorAttributes 实例的 getErrorAttributes 方法），然后调用 resolveErrorView 去创建一个 ModelAndView ，如果这里创建失败，那么用户将会看到默认的错误提示页面。正常情况下， resolveErrorView 方法会来到 DefaultErrorViewResolver 类中的 resolveErrorView 方法： 123456789@Overridepublic ModelAndView resolveErrorView(HttpServletRequest request, HttpStatus status, Map&lt;String, Object&gt; model) { ModelAndView modelAndView = resolve(String.valueOf(status.value()), model); if (modelAndView == null &amp;&amp; SERIES_VIEWS.containsKey(status.series())) { modelAndView = resolve(SERIES_VIEWS.get(status.series()), model); } return modelAndView;} 这里先以异常响应码作为视图名分别去查找动态页面和静态页面，如果没有查找到，则再以 4xx 或者 5xx 作为视图名分别查找动态或者静态页面。 上述 DefaultErrorViewResolver 类是在 org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration 异常自动配置类中定义的，是 Spring Boot 默认提供的，我们可以自己提供 1 个 ErrorViewResolver 实例来覆盖默认的，从而实现自定义异常视图。 在 src/main/java 下新建 MyErrorViewResolver ，如下： 123456789101112131415@Componentpublic class MyErrorViewResolver extends DefaultErrorViewResolver { public MyErrorViewResolver(ApplicationContext applicationContext, ResourceProperties resourceProperties) { super(applicationContext, resourceProperties); } @Override public ModelAndView resolveErrorView(HttpServletRequest request, HttpStatus status, Map&lt;String, Object&gt; model) { ModelAndView mv = new ModelAndView(); // 对应视图：src/main/resources/templates/cxy35.html mv.setViewName(\"cxy35\"); mv.addAllObjects(model); return mv; }} 其实在这里的 resolveErrorView 方法中也可以实现自定义异常数据。 在 src/main/resources/templates 下新建 cxy35.html ，如下： 123456789101112131415161718192021222324252627282930313233343536&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;templates/cxy35&lt;/h1&gt;&lt;table border=\"1\"&gt; &lt;tr&gt; &lt;td&gt;timestamp&lt;/td&gt; &lt;td th:text=\"${timestamp}\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;path&lt;/td&gt; &lt;td th:text=\"${path}\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;error&lt;/td&gt; &lt;td th:text=\"${error}\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;status&lt;/td&gt; &lt;td th:text=\"${status}\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;message&lt;/td&gt; &lt;td th:text=\"${message}\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;myMessage&lt;/td&gt; &lt;td th:text=\"${myMessage}\"&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/body&gt;&lt;/html&gt; 启动项目，访问 http://120.0.0.1:8080/hello 来验证。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-web/spring-boot-exception 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/11/24/springboot/spring-boot-exception/"},{"title":"Spring Boot 整合 Freemarker","text":"学习 Spring Boot 整合页面模板 Freemarker 。 1 Freemarker 简介Freemarker 是一个相当老牌的开源的免费的模版引擎。通过 Freemarker 模版，我们可以将数据渲染成 HTML 网页、电子邮件、配置文件以及源代码等。Freemarker 不是面向最终用户的，而是一个 Java 类库，我们可以将之作为一个普通的组件嵌入到我们的产品中。来看一张来自 Freemarker 官网的图片： 可以看到，Freemarker 可以将模版和数据渲染成 HTML 。 Freemarker 模版后缀为 .ftl(FreeMarker Template Language)。FTL 是一种简单的、专用的语言，它不是像 Java 那样成熟的编程语言。在模板中，你可以专注于如何展现数据，而在模板之外可以专注于要展示什么数据。 2 整合 Freemarker创建 Spring Boot 项目 spring-boot-freemarker ，增加 Web 和 Freemarker 依赖。 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; Freemarker 提供了一整套的自动化配置方案，对应的源码如下： org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration 1234567@Configuration@ConditionalOnClass({ freemarker.template.Configuration.class, FreeMarkerConfigurationFactory.class })@EnableConfigurationProperties(FreeMarkerProperties.class)@Import({ FreeMarkerServletWebConfiguration.class, FreeMarkerReactiveWebConfiguration.class, FreeMarkerNonWebConfiguration.class })public class FreeMarkerAutoConfiguration {} @Configuration 注解表示这是一个配置类。 @EnableConfigurationProperties 注解表示开启 ConfigurationProperties ，即使得 FreemarkerProperties 类上配置的 @ConfigurationProperties 生效。 @ConditionalOnClass 表示当项目 classpath 下存在 freemarker.template.Configuration 和 FreeMarkerConfigurationFactory 时，当前的自动化配置类才会生效。只要项目中引入了 Freemarker 相关的依赖，这个配置就会生效。 @Import 导入了 FreeMarkerServletWebConfiguration 配置。 org.springframework.boot.autoconfigure.freemarker.FreeMarkerServletWebConfiguration 123456789101112131415161718192021222324@Configuration@ConditionalOnWebApplication(type = ConditionalOnWebApplication.Type.SERVLET)@ConditionalOnClass({ Servlet.class, FreeMarkerConfigurer.class })@AutoConfigureAfter(WebMvcAutoConfiguration.class)class FreeMarkerServletWebConfiguration extends AbstractFreeMarkerConfiguration { protected FreeMarkerServletWebConfiguration(FreeMarkerProperties properties) { super(properties); } @Bean @ConditionalOnMissingBean(FreeMarkerConfig.class) public FreeMarkerConfigurer freeMarkerConfigurer() { FreeMarkerConfigurer configurer = new FreeMarkerConfigurer(); applyProperties(configurer); return configurer; } @Bean @ConditionalOnMissingBean(name = \"freeMarkerViewResolver\") @ConditionalOnProperty(name = \"spring.freemarker.enabled\", matchIfMissing = true) public FreeMarkerViewResolver freeMarkerViewResolver() { FreeMarkerViewResolver resolver = new FreeMarkerViewResolver(); getProperties().applyToMvcViewResolver(resolver); return resolver; }} @ConditionalOnWebApplication 表示当前配置在 web 环境下才会生效。 @ConditionalOnClass 表示当前配置在存在 Servlet 和 FreeMarkerConfigurer 时才会生效。 @AutoConfigureAfter 表示当前自动化配置在 WebMvcAutoConfiguration 之后完成。 在构造方法中，注入了 FreeMarkerProperties。 在代码中提供了两个 bean： FreeMarkerConfigurer 和 FreeMarkerViewResolver。 FreeMarkerConfigurer 是 Freemarker 的一些基本配置，例如 templateLoaderPath、defaultEncoding 等。 FreeMarkerViewResolver 是视图解析器的基本配置，包含了 viewClass、suffix、allowRequestOverride、allowSessionOverride 等属性。 org.springframework.boot.autoconfigure.freemarker.FreeMarkerProperties 12345678910@ConfigurationProperties(prefix = \"spring.freemarker\")public class FreeMarkerProperties extends AbstractTemplateViewResolverProperties { public static final String DEFAULT_TEMPLATE_LOADER_PATH = \"classpath:/templates/\"; public static final String DEFAULT_PREFIX = \"\"; public static final String DEFAULT_SUFFIX = \".ftl\"; /** * Well-known FreeMarker keys which are passed to FreeMarker's Configuration. */ private Map&lt;String, String&gt; settings = new HashMap&lt;&gt;();} 通过 @ConfigurationProperties 注解，将 application.properties 中前缀为 spring.freemarker 的配置和这个类中的属性绑定。 前三个 static 变量定义了默认的模板位置、视图解析器的前缀、后缀等。 从前三行配置中，可以看出来，Freemarker 模板的默认位置在 classpath:/templates/ 目录下，默认的后缀是 ftl 。 这些配置，如果开发者不自己提供，则使用默认的，如果自己提供，则在 application.properties 中以 spring.freemarker 开头进行相关的配置。 在 src/main/java 下相应的包中新建 User 类，如下： 12345678public class User { private Long id; private String username; private String address; private Integer gender; // getter/setter} 在 src/main/java 下相应的包中新建 UserController 类，如下： 1234567891011121314151617181920212223@Controllerpublic class UserController { @GetMapping(\"/user\") public String user(Model model) { List&lt;User&gt; users = new ArrayList&lt;&gt;(); Random random = new Random(); for (int i = 0; i &lt; 10; i++) { User user = new User(); user.setId((long) i); user.setUsername(\"cxy35 &gt;&gt;&gt;\" + i); user.setAddress(\"https://cxy35.com &gt;&gt;&gt;\" + i); // 0 表示 男 1 表示 女 其他数字表示未知 user.setGender(random.nextInt(3)); users.add(user); } model.addAttribute(\"users\", users); model.addAttribute(\"hello\", \"&lt;h1&gt;hello&lt;/h1&gt;\"); model.addAttribute(\"world\", \"&lt;h1&gt;world&lt;/h1&gt;\"); // 返回视图，默认为 src/main/resources/templates/user.ftl return \"user\"; }} 在 src/main/resources/templates 下新建 user.ftl ，如下： 1234567891011121314151617181920212223&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;table border=\"1\"&gt; &lt;tr&gt; &lt;td&gt;编号 &lt;/td&gt; &lt;td&gt; 用户名 &lt;/td&gt; &lt;td&gt; 用户地址&lt;/td&gt; &lt;/tr&gt; &lt;#list users as u&gt; &lt;tr&gt; &lt;td&gt;${u.id}&lt;/td&gt; &lt;td&gt;${u.username}&lt;/td&gt; &lt;td&gt;${u.address}&lt;/td&gt; &lt;/tr&gt; &lt;/#list&gt;&lt;/table&gt;&lt;/body&gt;&lt;/html&gt; 启动项目，访问 http://120.0.0.1:8080/user 来验证。 3 配置说明 在 application.properties 中配置，以 spring.freemarker 开头： 12345678910111213141516171819202122# 这里可以覆盖 freemarker 的默认配置# 模板文件位置，默认为 classpath:/templates/# spring.freemarker.template-loader-path=classpath:/templates/freemarker/# 是否开启缓存# spring.freemarker.cache=false# 模板文件后缀# spring.freemarker.suffix=.ftl# 模板文件编码# spring.freemarker.charset=UTF-8# 是否检查模板位置# spring.freemarker.check-template-location=true# Content-Type 的值# spring.freemarker.content-type=text/html# HttpServletRequest 的属性是否可以覆盖 controller 中 model 的同名项# spring.freemarker.allow-request-override=false# HttpSession 的 属性是否可以覆盖 controller 中 model 的同名项# spring.freemarker.allow-session-override=false# 是否将 HttpServletRequest 中的属性添加到 Model 中# spring.freemarker.expose-request-attributes=false# 是否将 HttpSession 中的 属性添加到 Model 中# spring.freemarker.expose-session-attributes=false# ...... Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-web//spring-boot-freemarker 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/11/15/springboot/spring-boot-freemarker/"},{"title":"Spring Boot 整合 JdbcTemplate","text":"学习在 Spring Boot 中使用 JdbcTemplate 来操作数据库。 JdbcTemplate 是 Spring 自带的，虽然功能没有 MyBatis 强大，但配置和使用简单。 1 创建工程并配置 创建 Spring Boot 项目 spring-boot-jdbctemplate ，添加 Web/JDBC/MySQL 依赖，如下： 之后手动在 pom 文件中添加 Druid 数据库连接池依赖（Spring Boot 版本），最终的依赖如下： 1234567891011121314151617181920212223242526272829303132&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;version&gt;5.1.27&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接着在 application.properties 配置文件中添加数据库相关信息的配置，如下： 1234spring.datasource.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.username=rootspring.datasource.password=000000spring.datasource.url=jdbc:mysql://127.0.0.1:3306/cxy35?useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true&amp;autoReconnectForPools=true 2 使用 新建 User 实体类，如下： 1234567public class User { private Integer id; private String username; private String address; // getter/setter} 新建 UserService ，注入 JdbcTemplate ，实现增删改查的业务代码，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Servicepublic class UserService { @Autowired JdbcTemplate jdbcTemplate; // 新增 public int addUser(User user) { return jdbcTemplate.update(\"insert into t_user (username,address) values (?,?);\", user.getUsername(), user.getAddress()); } // 新增，主键回填 public int addUser2(User user) { KeyHolder keyHolder = new GeneratedKeyHolder(); int r = jdbcTemplate.update(new PreparedStatementCreator() { @Override public PreparedStatement createPreparedStatement(Connection connection) throws SQLException { PreparedStatement ps = connection.prepareStatement(\"insert into t_user (username,address) values (?,?);\", Statement.RETURN_GENERATED_KEYS); ps.setString(1, user.getUsername()); ps.setString(2, user.getAddress()); return ps; } }, keyHolder); user.setId(keyHolder.getKey().intValue()); return r; } // 删除 public int deleteUserById(Integer id) { return jdbcTemplate.update(\"delete from t_user where id=?\", id); } // 修改 public int updateUserById(User user) { return jdbcTemplate.update(\"update t_user set username=?,address=? where id=?\", user.getUsername(), user.getAddress(), user.getId()); } // 查询，使用 RowMapper 手动实现数据库字段和对象属性的映射 public List&lt;User&gt; getAllUsers() { return jdbcTemplate.query(\"select * from t_user\", new RowMapper&lt;User&gt;() { @Override public User mapRow(ResultSet resultSet, int i) throws SQLException { User user = new User(); int id = resultSet.getInt(\"id\"); String username = resultSet.getString(\"username\"); String address = resultSet.getString(\"address\"); user.setId(id); user.setUsername(username); user.setAddress(address); return user; } }); } // 查询，使用 BeanPropertyRowMapper 简单实现，前提是数据库字段和对象属性名称一致 public List&lt;User&gt; getAllUsers2() { return jdbcTemplate.query(\"select * from t_user\", new BeanPropertyRowMapper&lt;&gt;(User.class)); }} JdbcTemplate API 说明： update ：实现新增 / 修改 / 删除操作。 query ：实现查询操作。 最后在测试类中注入 userService 完成测试，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@SpringBootTestclass SpringBootJdbctemplateApplicationTests { @Autowired UserService userService; @Test public void addUser() { User user = new User(); user.setUsername(\"zhangsan\"); user.setAddress(\"杭州\"); userService.addUser(user); System.out.println(user); } @Test public void addUser2() { User user = new User(); user.setUsername(\"lisi\"); user.setAddress(\"北京\"); userService.addUser2(user); System.out.println(user); } @Test public void deleteUserById() { userService.deleteUserById(2); } @Test public void updateUserById() { User user = new User(); user.setId(1); user.setUsername(\"zhangsan2\"); user.setAddress(\"上海\"); userService.updateUserById(user); } @Test public void getAllUsers() { List&lt;User&gt; allUsers = userService.getAllUsers(); System.out.println(allUsers); } @Test public void getAllUsers2() { List&lt;User&gt; allUsers = userService.getAllUsers2(); System.out.println(allUsers); }} 3 源码解读JdbcTemplate 对应的自动化配置类是 org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration ，源码如下： 123456789101112@Configuration( proxyBeanMethods = false)@ConditionalOnClass({DataSource.class, JdbcTemplate.class})@ConditionalOnSingleCandidate(DataSource.class)@AutoConfigureAfter({DataSourceAutoConfiguration.class})@EnableConfigurationProperties({JdbcProperties.class})@Import({JdbcTemplateConfiguration.class, NamedParameterJdbcTemplateConfiguration.class})public class JdbcTemplateAutoConfiguration { public JdbcTemplateAutoConfiguration() { }} 从上面的源码可以看到，当存在 DataSource 和 JdbcTemplate 类时， JdbcTemplateAutoConfiguration 的配置生效。另外引入了 JdbcTemplateConfiguration 和 NamedParameterJdbcTemplateConfiguration ，源码如下： 12345678910111213141516171819202122@Configuration( proxyBeanMethods = false)@ConditionalOnMissingBean({JdbcOperations.class})class JdbcTemplateConfiguration { JdbcTemplateConfiguration() { } @Bean @Primary JdbcTemplate jdbcTemplate(DataSource dataSource, JdbcProperties properties) { JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource); Template template = properties.getTemplate(); jdbcTemplate.setFetchSize(template.getFetchSize()); jdbcTemplate.setMaxRows(template.getMaxRows()); if (template.getQueryTimeout() != null) { jdbcTemplate.setQueryTimeout((int)template.getQueryTimeout().getSeconds()); } return jdbcTemplate; }} 如果自己没有提供 JdbcOperations 类型的 Bean ，系统就提供一个默认的 JdbcTemplate （ JdbcOperations 接口的一个实现）。 123456789101112131415@Configuration( proxyBeanMethods = false)@ConditionalOnSingleCandidate(JdbcTemplate.class)@ConditionalOnMissingBean({NamedParameterJdbcOperations.class})class NamedParameterJdbcTemplateConfiguration { NamedParameterJdbcTemplateConfiguration() { } @Bean @Primary NamedParameterJdbcTemplate namedParameterJdbcTemplate(JdbcTemplate jdbcTemplate) { return new NamedParameterJdbcTemplate(jdbcTemplate); }} Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-dao/spring-boot-jdbctemplate 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/12/04/springboot/spring-boot-jdbctemplate/"},{"title":"Spring Boot 整合 Jpa","text":"学习在 Spring Boot 中使用 Jpa 来操作数据库。在 Spring Boot 中，使用的 Jpa 实际上是 Spring Data Jpa ， Spring Data 是 Spring 家族的一个子项目，用于简化 SQL 和 NoSQL 的访问，在 Spring Data 中，只要你的 方法名称符合规范，它就知道你想干什么，不需要自己再去写 SQL 。 1 Jpa 简介Jpa(Java Persistence API) ， Java 持久化 API ，它是一套 ORM 规范，而不是具体的实现。 Jpa 类似于 JDBC ，只提供规范，所有的数据库厂商提供实现（即具体的数据库驱动），在 Java 领域，大家熟知的 ORM(Object Relational Mapping) 框架可能主要是 Hibernate ，实际上，除了 Hibernate 之外，还有很多其他的 ORM 框架，例如： Batoo JPA DataNucleus (formerly JPOX) EclipseLink (formerly Oracle TopLink) IBM, for WebSphere Application Server JBoss with Hibernate Kundera ObjectDB OpenJPA OrientDB from Orient Technologies Versant Corporation JPA (not relational, object database) Hibernate 只是 ORM 框架的一种，上面列出来的 ORM 框架都是支持 JPA 2.0 规范的。既然它是一个规范，不是具体的实现，那么必然就不能直接使用（类似于 JDBC 不能直接使用，必须要加了驱动才能用），我们使用的是具体的实现，在这里我们采用的实现实际上还是 Hibernate 。 2 创建工程并配置 创建 Spring Boot 项目 spring-boot-jpa ，添加 Web/JPA/MySQL 依赖，如下： 之后手动在 pom 文件中添加 Druid 数据库连接池依赖（Spring Boot 版本），最终的依赖如下： 1234567891011121314151617181920212223242526272829303132&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;version&gt;5.1.27&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接着在 application.properties 配置文件中添加数据库相关信息的配置和 Jpa 的基本配置，如下： 12345678910111213141516spring.datasource.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.username=rootspring.datasource.password=000000spring.datasource.url=jdbc:mysql://127.0.0.1:3306/cxy35?useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true&amp;autoReconnectForPools=true# JPA 配置# 数据库为 MySQLspring.jpa.database=mysql# 在控制台打印 SQLspring.jpa.show-sql=true# 数据库平台spring.jpa.database-platform=mysql# 每次启动项目时，数据库初始化策略spring.jpa.hibernate.ddl-auto=update# 指定默认的存储引擎为 InnoDB ，否则默认情况下，自动创建表的时候会使用 MyISAM 作为表的存储引擎spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL57Dialect 3 使用 使用 ORM 框架（对象关系映射）我们不必再去创建表，框架会自动根据当前项目中的实体类创建相应的数据表。因此，这里首先创建一个 Book 实体类，如下： 1234567891011@Entity(name = \"t_book\")public class Book { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer id; // @Column(name = \"c_name\") private String name; private String author; // getter/setter} 实体类说明： @Entity 注解: 表示这是一个实体类，在项目启动时会自动针对该类生成一张表，默认的表名为类名，可使用 name 属性自定义生成的表名。 @Id 注解: 表示这个字段是一个 id 。 @GeneratedValue 注解: 表示主键的自增长策略。 对于类中的其他属性，默认都会根据属性名在表中生成相应的字段，字段名和属性名相同。如果想要对字段进行定制，可以使用@Column 注解，去配置字段的名称，长度，是否为空等。 这时启动 Spring Boot 项目，会发现数据库中多了一个名为 t_book 的表。 下面开始定义接口操作数据库，新增 BookDao ，定义相关接口和 SQL ，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public interface BookDao extends JpaRepository&lt;Book, Integer&gt; { // 方法定义规范： // 1. 按照 Spring Data 的规范，查询方法以 find/get/read 开头 // 2. 涉及条件查询时，条件的属性用条件关键字连接，要注意的是：条件属性以首字母大写 // 3. 支持属性的级联查询. 若当前类有符合条件的属性, 则优先使用, 而不使用级联属性. 若需要使用级联属性, 则属性之间使用 _ 进行连接 // Book findById(Integer id);// 父类中定义了该方法 Book findBookById(Integer id); Book findByIdAndName(Integer id, String name); List&lt;Book&gt; findByIdGreaterThan(Integer id); List&lt;Book&gt; findByIdLessThanOrNameContaining(Integer id, String name); Book getById(Integer id); Book getBookById(Integer id); Book readById(Integer id); Book readBookById(Integer id); // @Query 注解： JPQL 或 SQL @Query(value = \"select b.* from t_book b where b.id&gt;?1 and b.name=?2\", nativeQuery = true) // 参数要按顺序 List&lt;Book&gt; getByParam(Integer id, String name); @Query(value = \"select b.* from t_book b where id&gt;:id and name=:name\", nativeQuery = true) // 使用 @Param ，参数可以不按顺序（推荐） List&lt;Book&gt; getByParam2(@Param(\"name\") String name, @Param(\"id\") Integer id); @Query(value = \"select * from t_book where id=(select max(id) from t_book)\", nativeQuery = true) Book getMaxIdBook(); // @Modifying 注解、 @Transactional 注解 @Query(value = \"insert into t_book(name,author) values(?1,?2)\", nativeQuery = true) @Modifying @Transactional // 参数要按顺序 Integer addBook(String name, String author); @Query(value = \"insert into t_book(name,author) values(:name,:author)\", nativeQuery = true) @Modifying @Transactional // 使用 @Param ，参数可以不按顺序（推荐） Integer addBook2(@Param(\"name\") String name, @Param(\"author\") String author);} 接口类说明： BookDao 接口继承自 JpaRepository ， JpaRepository 提供了一些基本的数据操作方法，例如：保存 / 更新 / 删除 / 列表查询 / 分页列表查询等。 在 BookDao 接口中也可以自己声明相关的方法，只需要 方法名称符合规范。在 Spring Data 中，只要按照既定的规范命名方法，Spring Data Jpa 就知道你想干嘛，这样就不用写 SQL 了。相关规范参考下图： 如果有特殊的查询，也可以自己定义方法名，使用 @Query 注解通过自定义 SQL 来实现。默认情况下，在注解中使用的查询语言不是 SQL ，而是 JPQL ，这是一种与数据库平台无关的面向对象的查询语言，有点定位类似于 Hibernate 中的 HQL 。当然可以通过在 @Query 注解中设置 nativeQuery = true 来表示使用原生查询，即大家所熟悉的 SQL 。 如果某个方法中的 SQL 涉及到数据操作，则需要使用 @Modifying 注解。 4 测试 最后在测试类中注入 bookDao 完成测试，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128@SpringBootTestclass SpringBootJpaApplicationTests { @Autowired BookDao bookDao; @Test public void save() { Book book = new Book(); book.setName(\"三国演义\"); book.setAuthor(\"罗贯中\"); bookDao.save(book); } @Test public void update() { Book book = new Book(); book.setId(1); book.setAuthor(\"三国演义 2\"); book.setName(\"罗贯中 2\"); bookDao.saveAndFlush(book); } @Test public void delete() { bookDao.deleteById(1); } @Test public void findById() { Optional&lt;Book&gt; byId = bookDao.findById(1); System.out.println(byId.get()); } @Test public void findAll() { List&lt;Book&gt; all = bookDao.findAll(); System.out.println(all); } @Test public void findAllSort() { List&lt;Book&gt; list = bookDao.findAll(Sort.by(Sort.Direction.DESC, \"id\")); System.out.println(list); } @Test public void findAllPage() { Pageable pageable = PageRequest.of(0, 2); Page&lt;Book&gt; page = bookDao.findAll(pageable); System.out.println(\"总记录数：\" + page.getTotalElements()); System.out.println(\"当前页记录数：\" + page.getNumberOfElements()); System.out.println(\"每页记录数：\" + page.getSize()); System.out.println(\"获取总页数：\" + page.getTotalPages()); System.out.println(\"查询结果：\" + page.getContent()); System.out.println(\"当前页（从 0 开始计）\" + page.getNumber()); System.out.println(\"是否为首页：\" + page.isFirst()); System.out.println(\"是否为尾页：\" + page.isLast()); } @Test public void findBookById() { Book book = bookDao.findBookById(1); System.out.println(book); } @Test public void findByIdAndName() { Book book = bookDao.findByIdAndName(1, \"三国演义\"); System.out.println(book); } @Test public void findByIdGreaterThan() { List&lt;Book&gt; list = bookDao.findByIdGreaterThan(2); System.out.println(list); } @Test public void findByIdLessThanOrNameContaining() { List&lt;Book&gt; list1 = bookDao.findByIdLessThanOrNameContaining(2, \"花\"); System.out.println(list1); } @Test public void getById() { Book book = bookDao.getById(1); System.out.println(book); } @Test public void getBookById() { Book book = bookDao.getBookById(1); System.out.println(book); } @Test public void getByParam() { List&lt;Book&gt; list1 = bookDao.getByParam(1, \"朝花夕拾\"); System.out.println(list1); } @Test public void getByParam2() { List&lt;Book&gt; list1 = bookDao.getByParam2(\"朝花夕拾\", 1); System.out.println(list1); } @Test public void getMaxIdBook() { Book book = bookDao.getMaxIdBook(); System.out.println(book); } @Test public void addBook() { Integer r1 = bookDao.addBook(\"朝花夕拾\", \"鲁迅\"); System.out.println(r1); } @Test public void addBook2() { Integer r2 = bookDao.addBook2(\"呐喊\", \"鲁迅\"); System.out.println(r2); }} Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-dao/spring-boot-jpa 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/12/10/springboot/spring-boot-jpa/"},{"title":"Spring Boot 构建 Rest 服务（Jpa）","text":"学习在 Spring Boot 中结合 Jpa 构建 Rest 服务，只需要几行代码就能快速实现一个 RESTful 风格的增删改查接口。 1 概述 在当前移动互联网大环境下，前后端分离开发越来越普及，一般是一套后台对应多个前端项目，此时 RESTful 就有了用武之地。 Spring Boot 中相关的注解主要有（其实在 Spring MVC 中也能使用）： @RestController @GetMapping @PutMapping @PostMapping @DeleteMapping @ResponseBody 2 创建工程并配置 创建 Spring Boot 项目 spring-boot-jparest ，添加 Web/JPA/MySQL/Rest Repositories 依赖，如下： 之后手动在 pom 文件中添加 Druid 数据库连接池依赖（Spring Boot 版本），最终的依赖如下： 123456789101112131415161718192021222324252627282930313233343536&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-rest&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;version&gt;5.1.27&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接着在 application.properties 配置文件中添加数据库相关信息的配置和 Jpa 的基本配置，如下： 12345678910111213141516spring.datasource.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.username=rootspring.datasource.password=000000spring.datasource.url=jdbc:mysql://127.0.0.1:3306/cxy35?useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true&amp;autoReconnectForPools=true# JPA 配置# 数据库为 MySQLspring.jpa.database=mysql# 在控制台打印 SQLspring.jpa.show-sql=true# 数据库平台spring.jpa.database-platform=mysql# 每次启动项目时，数据库初始化策略spring.jpa.hibernate.ddl-auto=update# 指定默认的存储引擎为 InnoDB ，否则默认情况下，自动创建表的时候会使用 MyISAM 作为表的存储引擎spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL57Dialect 3 使用 首先新建 Book 实体类，如下： 1234567891011@Entity(name = \"t_book\")public class Book { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer id; // @Column(name = \"c_name\") private String name; private String author; // getter/setter} 接着新建 BookDao 接口，如下： 123456789public interface BookDao extends JpaRepository&lt;Book, Integer&gt; { // 默认接口 // 新增：POST http://127.0.0.1:8080/books // 根据 id 删除：DELETE http://127.0.0.1:8080/books/{id} // 根据 id 编辑：PUT http://127.0.0.1:8080/books/{id} // 查询分页列表：GET http://127.0.0.1:8080/books // 根据 id 查询详情：GET http://127.0.0.1:8080/books/{id} // 查询自定义接口列表：GET http://127.0.0.1:8080/books/search} OK ，大功告成，一个 RESTful 风格的增删改查应用构建好了。惊讶，这么简单！关于 Jpa 的使用，可以参考 Spring Boot 整合 Jpa ，这里不再赘述。 4 默认接口 启动项目，用 HTTP 请求工具来测试（如 Postman ）。此时我们的服务具备了一些默认的接口，如下： 新增： POST http://127.0.0.1:8080/books 请求数据通过 JSON 的形式传递，新增成功之后，默认会返回新增成功的数据。 根据 id 删除： DELETE http://127.0.0.1:8080/books/{id} 删除成功后，是没有返回值的。 根据 id 编辑： PUT http://127.0.0.1:8080/books/{id} 编辑的参数也是通过 JSON 的形式传递，编辑成功之后，默认会返回编辑成功的数据。 查询分页列表： GET http://127.0.0.1:8080/books 默认请求路径是类名首字母小写，并且再加一个 s 后缀。没有传参数，表示查询第 1 页，每页 20 条数据。 查询结果中，除了该有的数据之外，也包含了分页数据： 分页数据说明： size 表示每页查询记录数。 totalElements 表示总记录数。 totalPages 表示总页数。 number 表示当前页数，从 0 开始计。 如果要分页或者排序查询，可以使用 _links 中的链接。http://127.0.0.1:8080/books?page=1&amp;size=3&amp;sort=id,desc 。 根据 id 查询详情： GET http://127.0.0.1:8080/books/{id} 查询自定义接口列表： GET http://127.0.0.1:8080/books/search 5 自定义接口 一般自定义查询接口比较多，在 BookDao 中增加对应的接口即可（关于 Jpa 的使用，可以参考 Spring Boot 整合 Jpa ），如下： 12345public interface BookDao extends JpaRepository&lt;Book, Integer&gt; { // 自定义查询：GET http://127.0.0.1:8080/books/search/findBookByNameContaining?name= 国 // @RestResource(path = \"byName\", rel = \"findByName\") List&lt;Book&gt; findBookByNameContaining(@Param(\"name\") String name);} 重启项目，通过 GET http://127.0.0.1:8080/books/search 查看和 book 相关的自定义接口。 调用自定义接口： GET http://127.0.0.1:8080/books/search/findBookByNameContaining?name= 国 @RestResource 注解说明： rel 表示接口查询中，这个方法的 key 。 path 表示请求路径。 exported 表示是否暴露接口，默认为 true ，表示暴露接口，即方法可以在前端调用，如果仅仅只是想定义一个方法，不需要在前端调用这个方法，可以设置 exported 属性为 false 。 如果不想暴露官方定义好的方法，例如根据 id 删除数据，只需要在自定义接口中重写该方法，然后在该方法上加 @RestResource注解并且配置相关属性 exported = false 即可，如： 123456public interface BookDao extends JpaRepository&lt;Book, Integer&gt; { // 避免暴露官方定义好的方法 // @Override // @RestResource(exported = false) // void deleteById(Long id);} 6 更多配置 请求路径和生成的 JSON 字符串中的相关名称配置。 123// @RepositoryRestResource(path = \"bs\", collectionResourceRel = \"bs\", itemResourceRel = \"b\")public interface BookDao extends JpaRepository&lt;Book, Integer&gt; {} Rest 基本参数配置 有两种方案： 在 application.properties 配置文件中增加相关配置（推荐），如下： 1234567891011121314151617# Rest 配置方式 1（推荐）：优先级低于自定义配置类# 给所有的接口添加统一的前缀，默认无# spring.data.rest.base-path=/api# 配置排序参数的 key ，默认 sort# spring.data.rest.sort-param-name=sort# 配置分页查询时页码的 key，默认 page# spring.data.rest.page-param-name=page# 配置分页查询时每页查询页数的 key，默认 size# spring.data.rest.limit-param-name=size# 配置每页最大查询记录数，默认 20spring.data.rest.max-page-size=2# 分页查询时默认的页码，默认 0# spring.data.rest.default-page-size=0# 更新成功时是否返回更新记录，默认 true# spring.data.rest.return-body-on-update=true# 添加成功时是否返回添加记录，默认 true# spring.data.rest.return-body-on-create=true 新增自定义配置类 RestConfig ，如下： 12345678// Rest 配置方式 2：自定义配置类，优先级高于配置文件@Configurationpublic class RestConfig implements RepositoryRestConfigurer { @Override public void configureRepositoryRestConfiguration(RepositoryRestConfiguration config) { // config.setBasePath(\"/api\").setDefaultPageSize(2); }} Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-rest/spring-boot-jparest 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/12/24/springboot/spring-boot-jparest/"},{"title":"Spring Boot 整合 JSON（Jackson / Gson / FastJson）","text":"学习 Spring Boot 整合 JSON（Jackson / Gson / FastJson） 。 1 Spring MVC 整合 JSON先来回顾下在 Spring MVC 中如何整合 JSON 。 Spring MVC 可以接收 JSON 参数，也可以返回 JSON 参数，这一切依赖于 HttpMessageConverter 。它可以将一个 JSON 字符串转为对象，也可以将一个对象转为 JSON 字符串，实际上它的底层还是依赖于具体的 JSON 库。因此所有的 JSON 库要在 Spring MVC 中自动返回或者接收 JSON ，都必须提供和自己相关的 HttpMessageConverter 。 Spring MVC 中，默认提供了 Jackson 和 Gson 的 HttpMessageConverter ，分别是： MappingJackson2HttpMessageConverter 和 GsonHttpMessageConverter 。正因为如此，我们在 Spring MVC 中，如果要使用 JSON ，对于 Jackson 和 Gson 我们只需要添加依赖，加完依赖就可以直接使用了。具体的配置是在 AllEncompassingFormHttpMessageConverter 类中完成的。 但是如果我们使用 FastJson ，默认情况下，Spring MVC 并没有提供 FastJson 的 HttpMessageConverter ，因此需要我们自己提供，如果是在 XML 配置中， FastJson 除了添加依赖，还要显式配置 HttpMessageConverter ，如下： 123456&lt;mvc:annotation-driven&gt; &lt;mvc:message-converters&gt; &lt;bean class=\"com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter\"&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt; 2 Spring Boot 整合 JSONSpring Boot 中关于 JSON 的默认解析方案是 Jackson ，会自动导入相关依赖。如果想要使用 Gson 或 FastJson ，则需要我们手动添加相关依赖，并排除掉默认的 JSON 依赖。 2.1 Jackson创建 Spring Boot 项目 spring-boot-jackson ，增加 Web 依赖。 123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在 src/main/java 下相应的包中新建 User 类，如下： 12345678public class User { private Integer id; private String username; private String address; private Date birthday; // getter/setter} 在 src/main/java 下相应的包中新建 UserController 类，如下： 12345678910111213141516@RestControllerpublic class UserController { @GetMapping(\"/user\") public List&lt;User&gt; getAllUser() { List&lt;User&gt; users = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) { User user = new User(); user.setUsername(\"cxy35 &gt;&gt;\" + i); user.setAddress(\"https://cxy35.com &gt;&gt;\" + i); user.setId(i); user.setBirthday(new Date()); users.add(user); } return users; }} 启动项目，访问 http://120.0.0.1:8080/user 来验证，此时就可以正常返回 json 了，但发现 birthday 的日期格式展示不是很友好，可以通过覆盖 Jackson 的默认 Bean ，并增加日期格式化相关代码来解决（这里只增加处理日期格式化的功能，如果有其他需求，增加相应的代码即可），有 2 种方法覆盖。 在 src/main/java 下相应的包中新建 WebMvcConfig 配置类，如下： 1234567891011121314151617181920212223@Configurationpublic class WebMvcConfig { // 实现日期格式化方法 1： // 覆盖 JacksonHttpMessageConvertersConfiguration 中默认的 MappingJackson2HttpMessageConverter /*@Bean MappingJackson2HttpMessageConverter mappingJackson2HttpMessageConverter() { MappingJackson2HttpMessageConverter converter = new MappingJackson2HttpMessageConverter(); ObjectMapper om = new ObjectMapper(); om.setDateFormat(new SimpleDateFormat(\"yyyy/MM/dd\")); converter.setObjectMapper(om); return converter; }*/ // 实现日期格式化方法 2（更小的粒度）： // 覆盖 JacksonHttpMessageConvertersConfiguration 中默认的 ObjectMapper（由 JacksonAutoConfiguration 中注入） @Bean ObjectMapper objectMapper() { ObjectMapper om = new ObjectMapper(); om.setDateFormat(new SimpleDateFormat(\"yyyy-MM-dd\")); return om; }} 另外还有 1 种方式可以实现日期格式化，通过在对应 pojo 的属性上加注解，如下： 123456789public class User { private Integer id; private String username; private String address; @JsonFormat(pattern = \"yyyy-MM-dd\") private Date birthday; // getter/setter} 启动项目，访问 http://120.0.0.1:8080/user 来验证。 2.2 Gson创建 Spring Boot 项目 spring-boot-gson ，增加 Web 和 Gson 依赖，并排除掉默认的 JSON 依赖。 123456789101112131415161718192021222324252627&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-json&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在 src/main/java 下相应的包中新建 User 类，如下： 12345678public class User { private Integer id; private String username; private String address; private Date birthday; // getter/setter} 在 src/main/java 下相应的包中新建 UserController 类，如下： 12345678910111213141516@RestControllerpublic class UserController { @GetMapping(\"/user\") public List&lt;User&gt; getAllUser() { List&lt;User&gt; users = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) { User user = new User(); user.setUsername(\"cxy35 &gt;&gt;\" + i); user.setAddress(\"https://cxy35.com &gt;&gt;\" + i); user.setId(i); user.setBirthday(new Date()); users.add(user); } return users; }} 启动项目，访问 http://120.0.0.1:8080/user 来验证，此时就可以正常返回 json 了，但发现 birthday 的日期格式展示不是很友好，可以通过覆盖 Gson 的默认 Bean ，并增加日期格式化相关代码来解决（这里只增加处理日期格式化的功能，如果有其他需求，增加相应的代码即可），有 2 种方法覆盖。 在 src/main/java 下相应的包中新建 WebMvcConfig 配置类，如下： 12345678910111213141516171819@Configurationpublic class WebMvcConfig { // 实现日期格式化方法 1： // 覆盖 GsonHttpMessageConvertersConfiguration 中默认的 GsonHttpMessageConverter /*@Bean GsonHttpMessageConverter gsonHttpMessageConverter() { GsonHttpMessageConverter converter = new GsonHttpMessageConverter(); converter.setGson(new GsonBuilder().setDateFormat(\"yyyy/MM/dd\").create()); return converter; }*/ // 实现日期格式化方法 2（更小的粒度）： // 覆盖 GsonHttpMessageConvertersConfiguration 中默认的 Gson（由 GsonAutoConfiguration 中注入） @Bean Gson gson() { return new GsonBuilder().setDateFormat(\"yyyy-MM-dd\").create(); }} 另外还有 1 种方式可以实现日期格式化，通过在对应 pojo 的属性上加注解，如下： 123456789public class User { private Integer id; private String username; private String address; @JsonFormat(pattern = \"yyyy-MM-dd\") private Date birthday; // getter/setter} 启动项目，访问 http://120.0.0.1:8080/user 来验证。 2.3 FastJson创建 Spring Boot 项目 spring-boot-fastjson ，增加 Web 和 FastJson 依赖，并排除掉默认的 JSON 依赖。 12345678910111213141516171819202122232425262728&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-json&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.60&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在 src/main/java 下相应的包中新建 User 类，如下： 12345678public class User { private Integer id; private String username; private String address; private Date birthday; // getter/setter} 在 src/main/java 下相应的包中新建 UserController 类，如下： 12345678910111213141516@RestControllerpublic class UserController { @GetMapping(\"/user\") public List&lt;User&gt; getAllUser() { List&lt;User&gt; users = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) { User user = new User(); user.setUsername(\"cxy35 &gt;&gt;\" + i); user.setAddress(\"https://cxy35.com &gt;&gt;\" + i); user.setId(i); user.setBirthday(new Date()); users.add(user); } return users; }} 启动项目，访问 http://120.0.0.1:8080/user 来验证，此时就可以正常返回 json 了，但发现 birthday 的日期格式展示不是很友好，可以通过覆盖 FastJson 的默认 Bean ，并增加日期格式化相关代码来解决（这里只增加处理日期格式化的功能，如果有其他需求，增加相应的代码即可）。 在 src/main/java 下相应的包中新建 WebMvcConfig 配置类，如下： 1234567891011121314@Configurationpublic class WebMvcConfig { // 实现日期格式化： // 提供自定义的 FastJsonHttpMessageConverter @Bean FastJsonHttpMessageConverter fastJsonHttpMessageConverter() { FastJsonHttpMessageConverter converter = new FastJsonHttpMessageConverter(); FastJsonConfig config = new FastJsonConfig(); config.setDateFormat(\"yyyy-MM-dd\"); converter.setFastJsonConfig(config); return converter; }} 另外还有 1 种方式可以实现日期格式化，通过在对应 pojo 的属性上加注解，如下： 123456789public class User { private Integer id; private String username; private String address; @JsonFormat(pattern = \"yyyy-MM-dd\") private Date birthday; // getter/setter} 启动项目，访问 http://120.0.0.1:8080/user 来验证。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-web/spring-boot-json 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/11/18/springboot/spring-boot-json/"},{"title":"Spring Boot 整合 MyBatis","text":"学习在 Spring Boot 中使用 MyBatis 来操作数据库。与 JdbcTemplate 相比，MyBatis 比较灵活，功能也很强大。在 Spring Boot 使用 MyBatis ，和 SSM 中相比简单的不得了。 1 创建工程并配置 创建 Spring Boot 项目 spring-boot-mybatis ，添加 Web/MyBatis/MySQL 依赖，如下： 之后手动在 pom 文件中添加 Druid 数据库连接池依赖（Spring Boot 版本），最终的依赖如下： 123456789101112131415161718192021222324252627282930313233&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;version&gt;5.1.27&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接着在 application.properties 配置文件中添加数据库相关信息的配置，如下： 1234spring.datasource.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.username=rootspring.datasource.password=000000spring.datasource.url=jdbc:mysql://127.0.0.1:3306/cxy35?useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true&amp;autoReconnectForPools=true 2 使用 新建 User 实体类，如下： 1234567public class User { private Integer id; private String username; private String address; // getter/setter} 有两种配置方式，分别如下： SQL 写在 XML 文件中 新建 UserMapper.java ，定义相关接口，如下： 1234567891011// 方式 1：在 XML 中写 SQL &gt;&gt; UserMapper.xml// @Mapper // 可在启动类中全局配置public interface UserMapper { Integer addUser(User user); Integer deleteUserById(Integer id); Integer updateUserById(User user); List&lt;User&gt; getAllUser();} 关于 UserMapper.java 文件的扫描配置说明： 在每个 XxxMapper.java 文件上都增加注解 @Mapper ，比较繁琐。 在 Spring Boot 启动类上增加注解 @MapperScan(basePackages = &quot;com.cxy35.sample.springboot.mybatis.mapper&quot;) 指定 XxxMapper.java 文件所在的目录，完成全局配置。（推荐） 新建 UserMapper.xml ，定义相关接口的 SQL , 如下： 12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"com.cxy35.sample.springboot.mybatis.mapper.UserMapper\"&gt; &lt;insert id=\"addUser\" parameterType=\"com.cxy35.sample.springboot.mybatis.pojo.User\"&gt; insert into t_user (username,address) values (#{username},#{address}); &lt;/insert&gt; &lt;delete id=\"deleteUserById\"&gt; delete from t_user where id=#{id} &lt;/delete&gt; &lt;update id=\"updateUserById\" parameterType=\"com.cxy35.sample.springboot.mybatis.pojo.User\"&gt; update t_user set username=#{username},address=#{address} where id=#{id} &lt;/update&gt; &lt;select id=\"getAllUser\" resultType=\"com.cxy35.sample.springboot.mybatis.pojo.User\"&gt; select * from t_user; &lt;/select&gt;&lt;/mapper&gt; 关于 UserMapper.xml 文件的位置说明： 放在 UserMapper.java 所在的包下面，会被自动扫描到。但在项目打包时会被忽略掉，因此需要在 pom.xml 中配置 Maven 构建时的资源路径。（推荐） 12345678910111213&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; 放在 src/main/resources/mapper 目录下，不能自动被扫描到，不用配置 Maven ，但需要在 application.properties 配置 mapper 路径。 12# 默认与 XxxMapper.java 在同一个目录下（推荐），这里自定义目录mybatis.mapper-locations=classpath:/mapper/*.xml SQL 写在 JAVA 文件中 新建 UserMapper2.java ，定义相关接口和 SQL ，如下： 12345678910111213141516171819202122232425262728// 方式 2：通过全注解的方式来写 SQL &gt;&gt; UserMapper2.java，不写 XML 文件// @Mapper // 可在启动类中全局配置public interface UserMapper2 { @Insert({\"insert into t_user(username,address) values(#{username},#{address})\"}) @SelectKey(statement = \"select last_insert_id()\", keyProperty = \"id\", before = false, resultType = Integer.class) Integer addUser(User user); @Delete(\"delete from t_user where id=#{id}\") Integer deleteUserById(Integer id); @Update(\"update t_user set username=#{username},address=#{address} where id=#{id}\") Integer updateUserById(User user); @Select(\"select * from t_user\") List&lt;User&gt; getAllUsers(); @Results({ @Result(property = \"id\", column = \"id\"), @Result(property = \"username\", column = \"u\"), @Result(property = \"address\", column = \"a\") }) @Select(\"select username as u,address as a,id as id from t_user where id=#{id}\") User getUserById(Long id); @Select(\"select * from t_user where username like concat('%',#{name},'%')\") List&lt;User&gt; getUsersByName(String name);} 最后在测试类中注入 userMapper 或 userMapper2 完成测试，如下： 1234567891011121314151617181920212223242526272829303132333435@SpringBootTestclass SpringBootMybatisApplicationTests { @Autowired UserMapper userMapper; @Test public void addUser() { User user = new User(); user.setUsername(\"zhangsan\"); user.setAddress(\"杭州\"); userMapper.addUser(user); } @Test public void deleteUserById() { userMapper.deleteUserById(1); } @Test public void updateUserById() { User user = new User(); user.setId(1); user.setUsername(\"zhangsan2\"); user.setAddress(\"上海\"); userMapper.updateUserById(user); } @Test public void getAllUsers() { List&lt;User&gt; allUsers = userMapper.getAllUser(); System.out.println(allUsers); }} 3 源码解读Mybatis 对应的自动化配置类是 org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration ，部分源码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Configuration@ConditionalOnClass({SqlSessionFactory.class, SqlSessionFactoryBean.class})@ConditionalOnSingleCandidate(DataSource.class)@EnableConfigurationProperties({MybatisProperties.class})@AutoConfigureAfter({DataSourceAutoConfiguration.class, MybatisLanguageDriverAutoConfiguration.class})public class MybatisAutoConfiguration implements InitializingBean { private static final Logger logger = LoggerFactory.getLogger(MybatisAutoConfiguration.class); private final MybatisProperties properties; private final Interceptor[] interceptors; private final TypeHandler[] typeHandlers; private final LanguageDriver[] languageDrivers; private final ResourceLoader resourceLoader; private final DatabaseIdProvider databaseIdProvider; private final List&lt;ConfigurationCustomizer&gt; configurationCustomizers; @Bean @ConditionalOnMissingBean public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception { SqlSessionFactoryBean factory = new SqlSessionFactoryBean(); factory.setDataSource(dataSource); // ...... return factory.getObject(); } @Bean @ConditionalOnMissingBean public SqlSessionTemplate sqlSessionTemplate(SqlSessionFactory sqlSessionFactory) { ExecutorType executorType = this.properties.getExecutorType(); return executorType != null ? new SqlSessionTemplate(sqlSessionFactory, executorType) : new SqlSessionTemplate(sqlSessionFactory); } @Configuration @Import({MybatisAutoConfiguration.AutoConfiguredMapperScannerRegistrar.class}) @ConditionalOnMissingBean({MapperFactoryBean.class, MapperScannerConfigurer.class}) public static class MapperScannerRegistrarNotFoundConfiguration implements InitializingBean { public MapperScannerRegistrarNotFoundConfiguration() { } public void afterPropertiesSet() { MybatisAutoConfiguration.logger.debug(\"Not found configuration for registering mapper bean using @MapperScan, MapperFactoryBean and MapperScannerConfigurer.\"); } } // ......} 在 SSM 中使用 Mybatis 一般需要自己提供 SqlSessionFactoryBean 和 MapperScannerConfigurer 两个 Bean ，从上述源码中可以看出 Spring Boot 提供了默认的，实现了开发者零配置使用。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-dao/spring-boot-mybatis 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/12/07/springboot/spring-boot-mybatis/"},{"title":"Spring Boot 整合 MyBatis 通用 Mapper（TkMybatis）","text":"学习在 Spring Boot 中整合 MyBatis 通用 Mapper（TkMybatis）。通用 Mapper 是一个可以实现任意 MyBatis 通用方法的框架，项目提供了常规的增删改查操作以及 Example 相关的单表操作。通用 Mapper 是为了解决 MyBatis 使用中 90% 的基本操作，使用它可以很方便的进行开发，可以节省开发人员大量的时间。 1 概述 通用 Mapper 都可以极大的方便开发人员。可以随意的按照自己的需要选择通用方法，还可以很方便的开发自己的通用方法。 极其方便的使用 MyBatis 单表的增删改查。 支持单表操作，不支持通用的多表联合查询。 使用通用 Mapper 可以无 xml 文件实现数据库操作，只需要继承 TkMybatis 中相关的 Mapper 接口即可。但如果有特殊需求，可以自定义 XXXMapper.xml 文件，实现复杂 sql 语句的操作。 为什么需要通用 Mapper ？ 我个人最早用 MyBatis 时，先是完全手写，然后用上了 MyBatis 代码生成器（简称为 MBG），在使用 MBG 过程中，发现一个很麻烦的问题，如果数据库字段变化很频繁，就需要反复重新生成代码，并且由于 MBG 覆盖生成代码和追加方式生成 XML，导致每次重新生成都需要大量的比对修改。除了这个问题外，还有一个问题，仅仅基础的增删改查等方法，就已经产生了大量的 XML 内容，还没有添加一个自己手写的方法，代码可能就已经几百行了，内容多，看着比较碍事。 因为很多人都在使用 MBG，MBG 中定义了很多常用的单表方法，为了解决前面提到的问题，也为了兼容 MBG 的方法避免项目重构太多，在 MBG 的基础上结合了部分 JPA 注解产生了通用 Mapper。通用 Mapper 可以很简单的让你获取基础的单表方法，也很方便扩展通用方法。使用通用 Mapper 可以极大的提高你的工作效率。 说明：我们也可以改造 MBG ，比如自动生成一套基本的 model/mapper/service 等，与表对应，不去做修改，自定义的都写在对应的另一个子类上，这样，当表字段修改后，只需全部重新生成上述基本的那些文件，再手动修改自定义的文件（如果有需要）即可。 2 基本使用 创建项目，引入依赖 创建 Spring Boot 项目 spring-boot-mybatis-tkmybatis ，添加 Web/MySQL Driver 依赖，如下： 之后手动在 pom 文件中添加 Druid/Mapper 依赖（Spring Boot 版本），最终的依赖如下： 123456789101112131415161718192021222324252627282930313233&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;version&gt;5.1.27&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接着在 application.properties 配置文件中添加数据库相关信息的配置，如下： 123456789spring.datasource.type=com.alibaba.druid.pool.DruidDataSourcespring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.username=rootspring.datasource.password=000000spring.datasource.url=jdbc:mysql://127.0.0.1:3306/cxy35?useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true&amp;autoReconnectForPools=truelogging.level.com.cxy35.sample.springboot.mybatis.tkmybatis.mapper=debug# [Mybatis 通用 Mapper 代码生成器](https://github.com/cxy35/generators/tree/master/generator-mapper) 新建实体类 手动新建或用代码生成器生成 User 实体类，并增加相关注解，如下： 1234567891011121314151617@Table(name = \"t_user\")public class User { @Id @GeneratedValue(strategy = GenerationType.IDENTITY, generator = \"JDBC\") private Integer id; private String username; private String password; private Boolean enabled; private Boolean locked; // @Column(name = \"c_address\") private String address; private String nickName; private Date createTime; private Date updateTime; // getter/setter} 注解说明： @Table：指定该实体类对应的表名，如果表名为 t_user ，类名为 TUser ，则可以不需要此注解（默认驼峰命名规则）。 @Column：指定该属性对应的列名，如果列名为 create_time ，属性名为 createTime ，则可以不需要此注解（默认驼峰命名规则）。 @Id：标识该字段对应数据库表的主键 id 。 @GeneratedValue：指定主键 id 生成规则，其中 strategy 表示使用数据库自带的主键生成策略， generator 配置为”JDBC”，在数据插入完毕之后，会自动将主键 id 填充到实体类中，类似普通 mapper.xml 中配置的 selectKey 标签。 新建 Mapper 接口 12public interface UserMapper extends Mapper&lt;User&gt; {} 这里继承 TkMybatis 中最基本的一个通用 Mapper 接口，这样就自动拥有了这个 Mapper 中的一些接口，不用写 XXXMapper.xml 文件。 相关接口如下： 除了 Mapper 接口，官方还提供了一些几个好用的通用 Mapper 接口，都可以用来继承使用，汇总如下： Mapper 接口： IdsMapper 接口： ConditionMapper 接口： MySqlMapper 接口： SqlServerMapper 接口： 当然，我们也可以根据自己的实际业务需求，抽取通用业务逻辑，自定义通用 Mapper 接口，参考：通用 Mapper 进阶实例：为什么好久都没更新了？ 。 配置 Mapper 接口的扫描 可以在启动类上或自定义 MyBatis 的配置类上，通过 @MapperScan 注解配置。 123456789@SpringBootApplication@tk.mybatis.spring.annotation.MapperScan(basePackages = \"com.cxy35.sample.springboot.mybatis.tkmybatis.mapper\")public class SpringBootMybatisTkmybatisApplication { public static void main(String[] args) { SpringApplication.run(SpringBootMybatisTkmybatisApplication.class, args); }} 测试 在测试类中注入 UserMapper 完成测试，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@SpringBootTestclass SpringBootMybatisTkmybatisApplicationTests { @Autowired UserMapper userMapper; @Test public void insertSelective() { User user = new User(); user.setUsername(\"zhangsan\"); user.setPassword(\"123456\"); user.setAddress(\"杭州\"); user.setNickName(\"zs\"); user.setCreateTime(new Date()); user.setUpdateTime(new Date()); userMapper.insertSelective(user); } @Test public void deleteByPrimaryKey() { userMapper.deleteByPrimaryKey(2); } @Test public void updateByPrimaryKeySelective() { User user = new User(); user.setId(2); user.setUsername(\"zhangsan2\"); user.setPassword(\"654321\"); user.setNickName(\"zs2\"); user.setAddress(\"上海\"); userMapper.updateByPrimaryKeySelective(user); } @Test public void selectByPrimaryKey() { User user = userMapper.selectByPrimaryKey(4); System.out.println(user); } @Test public void selectAll() { List&lt;User&gt; users = userMapper.selectAll(); System.out.println(users); } @Test public void selectByExample() { Example example = new Example(User.class); Example.Criteria criteria = example.createCriteria(); criteria.andLike(\"username\", \"zhangsan%\"); criteria.andEqualTo(\"address\", \"杭州\"); List&lt;User&gt; users = userMapper.selectByExample(example); System.out.println(users); }} 3 自定义 XXXMapper.xml（非必须）虽然大多数复杂的需求，都能通过 TkMyBatis 的组合完成操作。但如果有特殊需求，可以自定义 XXXMapper.xml 文件，实现复杂 sql 语句的操作，这里以联表查询为例。 在 UserMapper.java 所在包下新建 UserMapper.xml ，增加如下内容： 1234567891011121314&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;!-- 测试用，非必须 --&gt;&lt;mapper namespace=\"com.cxy35.sample.springboot.mybatis.tkmybatis.mapper.UserMapper\"&gt; &lt;select id=\"selectByRoleId\" parameterType=\"java.lang.Integer\" resultType=\"com.cxy35.sample.springboot.mybatis.tkmybatis.pojo.User\"&gt; SELECT u.* FROM t_user u INNER JOIN t_user_role ur ON u.id = ur.user_id WHERE ur.role_id = #{roleId, jdbcType=INTEGER}; &lt;/select&gt;&lt;/mapper&gt; 上述 xml 文件与普通 xml 文件的不同之处在于：这里不需要使用 resultMap 进行字段的映射。当然，如果想在返回的 Map 中新增返回字段映射，直接添加新的字段即可。 注意：不要在 xml 文件中写 TkMyBatis 中已经有的一些基础方法，否则会报错，提示方法重复。 接着，修改 UserMapper.java ，增加对应的接口： 1234public interface UserMapper extends Mapper&lt;User&gt; { // 测试用，非必须 List&lt;User&gt; selectByRoleId(Integer roleId);} 上述 UserMapper.xml 放在 UserMapper.java 所在的包下面，会被自动扫描到。但在项目打包时会被忽略掉，因此需要在 pom.xml 中配置 Maven 构建时的资源路径。 12345678910111213&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; 关于 XXXMapper.xml 文件位置，还有其他方案，这里不再赘述，具体可参考 Spring Boot 整合 MyBatis 。 最后在测试类中增加方法，完成测试： 12345@Testpublic void selectByRoleId() { List&lt;User&gt; users = userMapper.selectByRoleId(2); System.out.println(users);} 4 代码生成器 Mybatis 通用 Mapper 代码生成器 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-dao/spring-boot-mybatis-tkmybatis 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/05/20/springboot/spring-boot-mybatis-tkmybatis/"},{"title":"瞬间几千次的重复提交，我用 Spring Boot + Redis 扛住了（实现接口自动幂等）","text":"使用 Spring Boot + Redis + Interceptor + 自定义 Annotation 实现接口自动幂等，解决接口重复提交问题。转载自：https://www.jianshu.com/p/c806003a8530 1 前言 在实际的开发项目中, 一个对外暴露的接口往往会面临很多次请求，我们来解释一下幂等的概念：任意多次执行所产生的影响均与一次执行的影响相同。按照这个含义，最终的含义就是 对数据库的影响只能是一次性的，不能重复处理。如何保证其幂等性，通常有以下手段： 数据库建立唯一性索引，可以保证最终插入数据库的只有一条数据 token 机制，每次接口请求前先获取一个 token，然后再下次请求的时候在请求的 header 体中加上这个 token，后台进行验证，如果验证通过删除 token，下次请求再次判断 token 悲观锁或者乐观锁，悲观锁可以保证每次 for update 的时候其他 sql 无法 update 数据(在数据库引擎是 innodb 的时候,select 的条件必须是唯一索引, 防止锁全表) 先查询后判断，首先通过查询数据库是否存在数据，如果存在证明已经请求过了，直接拒绝该请求，如果没有存在，就证明是第一次进来，直接放行。 redis 实现自动幂等的原理图： 2 搭建 redis 的服务 Api 首先是搭建 redis 服务器。 引入 springboot 中到的 redis 的 stater，或者 Spring 封装的 jedis 也可以，后面主要用到的 api 就是它的 set 方法和 exists 方法, 这里我们使用 springboot 的封装好的 redisTemplate 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * redis 工具类 */@Componentpublic class RedisService { @Autowired private RedisTemplate redisTemplate; /** * 写入缓存 * @param key * @param value * @return */ public boolean set(final String key, Object value) { boolean result = false; try { ValueOperations&lt;Serializable, Object&gt; operations = redisTemplate.opsForValue(); operations.set(key, value); result = true; } catch (Exception e) { e.printStackTrace(); } return result; } /** * 写入缓存设置时效时间 * @param key * @param value * @return */ public boolean setEx(final String key, Object value, Long expireTime) { boolean result = false; try { ValueOperations&lt;Serializable, Object&gt; operations = redisTemplate.opsForValue(); operations.set(key, value); redisTemplate.expire(key, expireTime, TimeUnit.SECONDS); result = true; } catch (Exception e) { e.printStackTrace(); } return result; } /** * 判断缓存中是否有对应的 value * @param key * @return */ public boolean exists(final String key) { return redisTemplate.hasKey(key); } /** * 读取缓存 * @param key * @return */ public Object get(final String key) { Object result = null; ValueOperations&lt;Serializable, Object&gt; operations = redisTemplate.opsForValue(); result = operations.get(key); return result; } /** * 删除对应的 value * @param key */ public boolean remove(final String key) { if (exists(key)) { Boolean delete = redisTemplate.delete(key); return delete; } return false; }} 3 自定义注解 AutoIdempotent自定义一个注解，定义此注解的主要目的是把它添加在需要实现幂等的方法上，凡是某个方法注解了它，都会实现自动幂等。后台利用反射如果扫描到这个注解，就会处理这个方法实现自动幂等，使用元注解 ElementType.METHOD 表示它只能放在方法上，etentionPolicy.RUNTIME 表示它在运行时 12345@Target({ElementType.METHOD})@Retention(RetentionPolicy.RUNTIME)public @interface AutoIdempotent { } 4 token 创建和检验 token 服务接口 我们新建一个接口，创建 token 服务，里面主要是两个方法，一个用来创建 token，一个用来验证 token。创建 token 主要产生的是一个字符串，检验 token 的话主要是传达 request 对象，为什么要传 request 对象呢？主要作用就是获取 header 里面的 token, 然后检验，通过抛出的 Exception 来获取具体的报错信息返回给前端 12345678910111213141516public interface TokenService { /** * 创建 token * @return */ public String createToken(); /** * 检验 token * @param request * @return */ public boolean checkToken(HttpServletRequest request) throws Exception;} token 的服务实现类 token 引用了 redis 服务，创建 token 采用随机算法工具类生成随机 uuid 字符串, 然后放入到 redis 中(为了防止数据的冗余保留, 这里设置过期时间为 10000 秒, 具体可视业务而定)，如果放入成功，最后返回这个 token 值。checkToken 方法就是从 header 中获取 token 到值(如果 header 中拿不到，就从 paramter 中获取)，如若不存在, 直接抛出异常。这个异常信息可以被拦截器捕捉到，然后返回给前端。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Servicepublic class TokenServiceImpl implements TokenService { @Autowired private RedisService redisService; /** * 创建 token * * @return */ @Override public String createToken() { String str = RandomUtil.randomUUID(); StrBuilder token = new StrBuilder(); try { token.append(Constant.Redis.TOKEN_PREFIX).append(str); redisService.setEx(token.toString(), token.toString(),10000L); boolean notEmpty = StrUtil.isNotEmpty(token.toString()); if (notEmpty) { return token.toString(); } }catch (Exception ex){ ex.printStackTrace(); } return null; } /** * 检验 token * * @param request * @return */ @Override public boolean checkToken(HttpServletRequest request) throws Exception { String token = request.getHeader(Constant.TOKEN_NAME); if (StrUtil.isBlank(token)) {// header 中不存在 token token = request.getParameter(Constant.TOKEN_NAME); if (StrUtil.isBlank(token)) {// parameter 中也不存在 token throw new ServiceException(Constant.ResponseCode.ILLEGAL_ARGUMENT, 100); } } if (!redisService.exists(token)) { throw new ServiceException(Constant.ResponseCode.REPETITIVE_OPERATION, 200); } boolean remove = redisService.remove(token); if (!remove) { throw new ServiceException(Constant.ResponseCode.REPETITIVE_OPERATION, 200); } return true; }} 5 拦截器的配置 web 配置类，实现 WebMvcConfigurerAdapter，主要作用就是添加 autoIdempotentInterceptor 到配置类中，这样我们到拦截器才能生效，注意使用 @Configuration 注解，这样在容器启动是时候就可以添加进入 context 中 12345678910111213141516@Configurationpublic class WebConfiguration extends WebMvcConfigurerAdapter { @Resource private AutoIdempotentInterceptor autoIdempotentInterceptor; /** * 添加拦截器 * @param registry */ @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(autoIdempotentInterceptor); super.addInterceptors(registry); }} 拦截处理器：主要的功能是拦截扫描到 AutoIdempotent 到注解到方法, 然后调用 tokenService 的 checkToken()方法校验 token 是否正确，如果捕捉到异常就将异常信息渲染成 json 返回给前端 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * 拦截器 */@Componentpublic class AutoIdempotentInterceptor implements HandlerInterceptor { @Autowired private TokenService tokenService; /** * 预处理 * * @param request * @param response * @param handler * @return * @throws Exception */ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { if (!(handler instanceof HandlerMethod)) { return true; } HandlerMethod handlerMethod = (HandlerMethod) handler; Method method = handlerMethod.getMethod(); // 被 ApiIdempotment 标记的扫描 AutoIdempotent methodAnnotation = method.getAnnotation(AutoIdempotent.class); if (methodAnnotation != null) { try { return tokenService.checkToken(request);// 幂等性校验, 校验通过则放行, 校验失败则抛出异常, 并通过统一异常处理返回友好提示 }catch (Exception ex){ ResultVo failedResult = ResultVo.getFailedResult(101, ex.getMessage()); writeReturnJson(response, JSONUtil.toJsonStr(failedResult)); throw ex; } } // 必须返回 true, 否则会被拦截一切请求 return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { } /** * 返回的 json 值 * @param response * @param json * @throws Exception */ private void writeReturnJson(HttpServletResponse response, String json) throws Exception{ PrintWriter writer = null; response.setCharacterEncoding(\"UTF-8\"); response.setContentType(\"text/html; charset=utf-8\"); try { writer = response.getWriter(); writer.print(json); } catch (IOException e) { } finally { if (writer != null) writer.close(); } }} 6 测试用例 模拟业务请求类 首先我们需要通过 /get/token 路径通过 getToken()方法去获取具体的 token，然后我们调用 testIdempotence 方法，这个方法上面注解了 @AutoIdempotent，拦截器会拦截所有的请求，当判断到处理的方法上面有该注解的时候，就会调用 TokenService 中的 checkToken()方法，如果捕获到异常会将异常抛出调用者，下面我们来模拟请求一下： 123456789101112131415161718192021222324252627282930313233343536@RestControllerpublic class BusinessController { @Resource private TokenService tokenService; @Resource private TestService testService; @PostMapping(\"/get/token\") public String getToken(){ String token = tokenService.createToken(); if (StrUtil.isNotEmpty(token)) { ResultVo resultVo = new ResultVo(); resultVo.setCode(Constant.code_success); resultVo.setMessage(Constant.SUCCESS); resultVo.setData(token); return JSONUtil.toJsonStr(resultVo); } return StrUtil.EMPTY; } @AutoIdempotent @PostMapping(\"/test/Idempotence\") public String testIdempotence() { String businessResult = testService.testIdempotence(); if (StrUtil.isNotEmpty(businessResult)) { ResultVo successResult = ResultVo.getSuccessResult(businessResult); return JSONUtil.toJsonStr(successResult); } return StrUtil.EMPTY; }} 使用 postman 请求 首先访问 get/token 路径获取到具体到 token： 利用获取到到 token, 然后放到具体请求到 header 中, 可以看到第一次请求成功，接着我们请求第二次： 第二次请求，返回到是重复性操作，可见重复性验证通过，再多次请求到时候我们只让其第一次成功，第二次就是失败： 7 总结 本篇博客介绍了使用 springboot 和拦截器、redis 来优雅的实现接口幂等，对于幂等在实际的开发过程中是十分重要的，因为一个接口可能会被无数的客户端调用，如何保证其不影响后台的业务处理，如何保证其只影响数据一次是非常重要的，它可以防止产生脏数据或者乱数据，也可以减少并发量，实乃十分有益的一件事。而传统的做法是每次判断数据，这种做法不够智能化和自动化，比较麻烦。而今天的这种自动化处理也可以提升程序的伸缩性。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/04/22/springboot/spring-boot-redis-idempotent/"},{"title":"Spring Boot 整合 Shiro","text":"学习在 Spring Boot 中用两种方式整合 Shiro 。虽然在 Spring Boot 中的安全管理框架主流是使用 Spring Security ，但使用 Shiro 技术上也是可行的。 1 概述Spring Security 和 Shiro 的比较如下： Spring Security 是一个重量级的安全管理框架； Shiro 则是一个轻量级的安全管理框架。 Spring Security 概念复杂，配置繁琐； Shiro 概念简单、配置简单。 Spring Security 功能强大； Shiro 功能简单，但在一般的 SSM/SSH 项目中也够用了。 Spring Security 一般与 Spring Boot/Spring Cloud 项目组合使用； Shiro 一般与 SSM/SSH 项目结合使用。 虽然在 Spring Boot 项目中一般使用 Spring Security ，但也可以使用 Shiro ，有两种方式整合： 原生整合：将 SSM/SSH 项目中整合 Shiro 的配置用 Java 重写一遍。 Shiro Starter 整合：使用 Shiro 官方提供的 Starter 来配置。 2 原生整合 2.1 创建工程 创建 Spring Boot 项目 spring-boot-shirojava ，添加 Web 依赖。 创建成功之后手动在 pom 文件中添加 Shiro 相关的依赖，最终的依赖如下： 123456789101112131415161718192021222324252627&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-web&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.2 自定义核心组件 Realm新增 MyRealm ，如下： 1234567891011121314151617public class MyRealm extends AuthorizingRealm { // 授权 @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) { return null; } // 认证 @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { String username = (String) token.getPrincipal(); if (\"cxy35\".equals(username)) { return new SimpleAuthenticationInfo(username, \"123456\", getName()); } return null; }} 这里只在 Realm 中实现简单的认证操作（用户名和密码为 cxy35/123456 就能登录成功），不做授权，授权的具体写法和 SSM 中的 Shiro 一样，这里不再赘述。 2.3 配置 Shiro新建 ShiroConfig 配置类，如下： 1234567891011121314151617181920212223242526272829@Configurationpublic class ShiroConfig { @Bean MyRealm myRealm() { return new MyRealm(); } @Bean SecurityManager securityManager() { DefaultWebSecurityManager manager = new DefaultWebSecurityManager(); manager.setRealm(myRealm()); return manager; } @Bean ShiroFilterFactoryBean shiroFilterFactoryBean() { ShiroFilterFactoryBean bean = new ShiroFilterFactoryBean(); bean.setSecurityManager(securityManager()); bean.setLoginUrl(\"/login\");// 指定登录页面 bean.setSuccessUrl(\"/index\");// 指定登录成功的跳转页面 bean.setUnauthorizedUrl(\"/unauthorized\");// 指定访问未获授权的页面时，默认的跳转路径 // 配置路径拦截规则（注意顺序） Map&lt;String, String&gt; map = new LinkedHashMap&lt;&gt;(); map.put(\"/doLogin\", \"anon\"); map.put(\"/**\", \"authc\"); bean.setFilterChainDefinitionMap(map); return bean; }} 配置类说明： 配置一个 Realm 实例。 配置一个 SecurityManager ，指定 Realm 。 配置一个 ShiroFilterFactoryBean ，指定 SecurityManager 、登录页面、路径拦截规则等。 3 Shiro Starter 整合 3.1 创建工程 创建 Spring Boot 项目 spring-boot-shirostarter ，添加 Web 依赖。 创建成功之后手动在 pom 文件中添加 shiro-spring-boot-web-starter 依赖，最终的依赖如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring-boot-web-starter&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3.2 自定义核心组件 Realm新增 MyRealm ，如下： 1234567891011121314151617public class MyRealm extends AuthorizingRealm { // 授权 @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) { return null; } // 认证 @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { String username = (String) token.getPrincipal(); if (\"cxy35\".equals(username)) { return new SimpleAuthenticationInfo(username, \"123456\", getName()); } return null; }} 这里只在 Realm 中实现简单的认证操作（用户名和密码为 cxy35/123456 就能登录成功），不做授权，授权的具体写法和 SSM 中的 Shiro 一样，这里不再赘述。 3.3 配置 Shiro在 application.properties 配置文件中配置 Shiro 的基本信息，如下： 1234567891011121314# 是否允许将 sessionId 放到 cookie 中shiro.sessionManager.sessionIdCookieEnabled=true# 是否允许将 sessionId 放到 Url 地址拦中shiro.sessionManager.sessionIdUrlRewritingEnabled=true# 开启 shiroshiro.enabled=true# 开启 shiro webshiro.web.enabled=true# 指定登录页面shiro.loginUrl=/login# 指定登录成功的跳转页面shiro.successUrl=/index# 指定访问未获授权的页面时，默认的跳转路径shiro.unauthorizedUrl=/unauthorized 新建 ShiroConfig 配置类，如下： 12345678910111213141516171819202122232425262728293031@Configurationpublic class ShiroConfig { /*@Bean Realm realm() { TextConfigurationRealm realm = new TextConfigurationRealm(); realm.setUserDefinitions(\"cxy35=123456,user \\n admin=123456,admin\"); realm.setRoleDefinitions(\"user=read \\n admin=read,write\"); return realm; }*/ @Bean MyRealm myRealm() { return new MyRealm(); } @Bean DefaultWebSecurityManager securityManager() { DefaultWebSecurityManager manager = new DefaultWebSecurityManager(); manager.setRealm(myRealm()); return manager; } @Bean ShiroFilterChainDefinition shiroFilterChainDefinition() { // 配置路径拦截规则 DefaultShiroFilterChainDefinition definition = new DefaultShiroFilterChainDefinition(); definition.addPathDefinition(\"/doLogin\", \"anon\"); definition.addPathDefinition(\"/**\", \"authc\"); return definition; }} 配置类说明： 配置一个 Realm 实例。 配置一个 SecurityManager ，指定 Realm 。 配置一个 ShiroFilterChainDefinition ，指定路径拦截规则等。 4 测试 新增 HelloController 测试类，如下： 123456789101112131415161718192021222324@RestControllerpublic class HelloController { @GetMapping(\"/login\") public String login() { return \"please login\"; } @PostMapping(\"/doLogin\") public void doLogin(String username, String password) { Subject subject = SecurityUtils.getSubject(); try { subject.login(new UsernamePasswordToken(username, password)); System.out.println(\"登录成功!\"); } catch (AuthenticationException e) { e.printStackTrace(); System.out.println(\"登录失败!\" + e.getMessage()); } } @GetMapping(\"/hello\") public String hello() { return \"hello\"; }} 启动项目，用 HTTP 请求工具来测试（如 Postman ）。 首先访问 http://127.0.0.1:8080/hello ，因为未登录过，所以会跳到 http://127.0.0.1:8080/login 接口要求登录，如下： 接着调用 http://127.0.0.1:8080/doLogin 接口完成登录，如下： 最后再次访问 http://127.0.0.1:8080/hello 就可以正常访问了，如下： Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码（原生）：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-security/spring-boot-shirojava 本文示例代码（Shiro Starter）：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-security/spring-boot-shirostarter 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/01/05/springboot/spring-boot-shiro/"},{"title":"Spring Boot 整合 Spring Cache + Ehcache（实现数据缓存）","text":"学习在 Spring Boot 中整合 Spring Cache + Ehcache ，实现数据的缓存。 Spring Cache 统一了缓存江湖的门面，它提供统一的接口，实现可以是 Redis 或 Ehcache 或其他支持这种规范的缓存框架，他们的关系类似于 JDBC 与各种数据库驱动，本文使用 Ehcache 实现。 Ehcache 也是 Java 领域比较优秀的缓存方案之一，但在 Redis 一统江湖的时代， Ehcache 渐渐有点没落了。 1 创建工程 创建 Spring Boot 项目 spring-boot-springcache-ehcache ，添加 Web/Spring Cache 依赖，如下： 之后手动在 pom 文件中添加 ehcache 依赖，最终的依赖如下： 1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.sf.ehcache&lt;/groupId&gt; &lt;artifactId&gt;ehcache&lt;/artifactId&gt; &lt;version&gt;2.10.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2 Ehcache 配置 在 resources 目录下，新增配置文件 ehcache.xml ，如下： 12345678910111213141516171819202122232425262728293031323334&lt;ehcache&gt; &lt;!-- name：缓存名称。 maxElementsInMemory：缓存最大个数。 eternal：对象是否永久有效，一但设置了，timeout 将不起作用。 timeToIdleSeconds：设置对象在失效前的允许闲置时间（单位：秒）。仅当 eternal=false 对象不是永久有效时使用，可选属性，默认值是 0，也就是可闲置时间无穷大。 timeToLiveSeconds：设置对象在失效前允许存活时间（单位：秒）。最大时间介于创建时间和失效时间之间。仅当 eternal=false 对象不是永久有效时使用，默认是 0.，也就是对象存活时间无穷大。 overflowToDisk：当内存中对象数量达到 maxElementsInMemory 时，Ehcache 将会对象写到磁盘中。 diskSpoolBufferSizeMB：这个参数设置 DiskStore（磁盘缓存）的缓存区大小。默认是 30MB。每个 Cache 都应该有自己的一个缓冲区。 maxElementsOnDisk：硬盘最大缓存个数。 diskPersistent：是否缓存虚拟机重启期数据 Whether the disk store persists between restarts of the Virtual Machine. The default value is false. diskExpiryThreadIntervalSeconds：磁盘失效线程运行时间间隔，默认是 120 秒。 memoryStoreEvictionPolicy：当达到 maxElementsInMemory 限制时，Ehcache 将会根据指定的策略去清理内存。默认策略是 LRU（最近最少使用）。你可以设置为 FIFO（先进先出）或是 LFU（较少使用）。 clearOnFlush：内存数量最大时是否清除。 diskStore：则表示临时缓存的硬盘目录。 --&gt; &lt;diskStore path=\"java.io.tmpdir/ehcache\"/&gt; &lt;defaultCache maxElementsInMemory=\"10000\" eternal=\"false\" timeToIdleSeconds=\"120\" timeToLiveSeconds=\"120\" overflowToDisk=\"false\" diskPersistent=\"false\" diskExpiryThreadIntervalSeconds=\"120\" /&gt; &lt;cache name=\"cache-user\" maxElementsInMemory=\"10000\" eternal=\"false\" timeToIdleSeconds=\"120\" overflowToDisk=\"true\" diskPersistent=\"true\" diskExpiryThreadIntervalSeconds=\"600\"/&gt;&lt;/ehcache&gt; 配置说明见上文注释。 Ehcache 配置文件的默认位置在 classpath 下，默认名称为 ehcache.xml 。支持个性化，在 application.properties 配置文件中配置，如下： 12# 自定义 Ehcache 配置文件的位置和名称# spring.cache.ehcache.config=classpath:myEhcache.xml 3 使用 首先在项目启动类上增加 @EnableCaching 注解，开始缓存，如下： 123456789@SpringBootApplication@EnableCaching // 开启缓存public class SpringBootSpringcacheEhcacheApplication { public static void main(String[] args) { SpringApplication.run(SpringBootSpringcacheEhcacheApplication.class, args); }} 接着新建 User 实体类，如下： 1234567public class User implements Serializable { private Integer id; private String username; private String address; // getter/setter} 最后新增 UserService ，如下： 123456789101112131415161718192021222324252627282930313233@Service// 指定缓存名称@CacheConfig(cacheNames = \"cache-user\")public class UserService { // 注意要在启动类上配置开启缓存 @EnableCaching // 默认缓存的 key 为所有参数的值（可通过 key 或 keyGenerator 修改），缓存的 value 为方法的返回值 // cache-user::1 // 查询 @Cacheable // @Cacheable(key = \"#id\") // @Cacheable(key = \"#root.methodName\") // @Cacheable(keyGenerator = \"myKeyGenerator\") public User getUserById(Integer id) { System.out.println(\"getUserById &gt;&gt;&gt;\" + id); User user = new User(); user.setId(id); return user; } // 删除 @CacheEvict public void deleteUserById(Integer id) { System.out.println(\"deleteUserById &gt;&gt;&gt;\" + id); } // 更新 @CachePut(key = \"#user.id\") public User updateUserById(User user) { return user; }} 缓存注解说明： @CacheConfig 这个注解在 类上使用，用来指定该类中所有方法使用的全局缓存名称。 @Cacheable 这个注解一般在 查询方法 上使用，表示将一个方法的返回值缓存起来，默认缓存的 key 为所有参数的值（可通过 key 或 keyGenerator 修改），缓存的 value 为方法的返回值。 如果方法有多个参数时，默认就使用多个参数来做 key ，如果只需要其中某一个参数做 key ，则可以在 @Cacheable 注解中，通过 key 属性来指定，如 @Cacheable(key = &quot;#id&quot;) 。如果对 key 有复杂的要求，可以自定义 keyGenerator 。 Spring Cache 默认中提供了 root 对象，可以在不定义 keyGenerator 的情况下实现一些复杂的效果，如下： 也可以通过 keyGenerator 自定义 key ，如 @Cacheable(keyGenerator = &quot;myKeyGenerator&quot;) 。需要新增 MyKeyGenerator 配置类，如下： 12345678@Componentpublic class MyKeyGenerator implements KeyGenerator { @Override public Object generate(Object o, Method method, Object... objects) { // 自定义缓存的 key return method.getName() + \":\" + Arrays.toString(objects); }} @CacheEvict 这个注解一般在 删除方法 上使用，当数据库中的数据删除后，相关的缓存数据也要自动清除。当然也可以配置按照某种条件删除（ condition 属性）或者配置清除所有缓存（ allEntries 属性）。 @CachePut 这个注解一般在 更新方法 上使用，当数据库中的数据更新后，缓存中的数据也要跟着更新，使用该注解，可以将方法的返回值自动更新到已经存在的 key 上。 下面开始测试，在测试类中注入 UserService ，如下： 123456789101112131415161718192021222324@SpringBootTestclass SpringBootSpringcacheEhcacheApplicationTests { @Autowired UserService userService; @Test void contextLoads() { User u1 = userService.getUserById(1);// userService.deleteUserById(1);// User user = new User();// user.setId(1);// user.setUsername(\"zhangsan\");// user.setAddress(\"hangzhou\");// userService.updateUserById(user); User u2 = userService.getUserById(1); System.out.println(u1); System.out.println(u2); }} Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-cache/spring-boot-springcache-ehcache 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/12/28/springboot/spring-boot-springcache-ehcache/"},{"title":"Spring Boot 整合 Spring Cache + Redis（实现数据缓存）","text":"学习在 Spring Boot 中整合 Spring Cache + Redis ，实现数据的缓存。 Spring Cache 统一了缓存江湖的门面，它提供统一的接口，实现可以是 Redis 或 Ehcache 或其他支持这种规范的缓存框架，他们的关系类似于 JDBC 与各种数据库驱动，本文使用 Redis 实现。这种方式相对于自己手动通过 RedisTemplate 往 Redis 中缓存数据（参考 Spring Boot 整合 Redis ）来说比较简单。 1 创建工程并配置 创建 Spring Boot 项目 spring-boot-springcache-redis ，添加 Web/Spring Cache/Redis 依赖，如下： 之后手动在 pom 文件中添加 commos-pool2 依赖，最终的依赖如下： 1234567891011121314151617181920212223242526272829&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接着在 application.properties 配置文件中添加 Redis 相关信息的配置和 Redis 连接池的配置，还有缓存名称的配置，后续会用到，如下： 123456789101112131415# Redis 配置spring.redis.host=192.168.71.62spring.redis.port=6379spring.redis.database=0spring.redis.password=000000# 连接池配置， Spring Boot 默认用的是 lettuce ，而不是 Jedis ，需增加 commons-pool2 依赖spring.redis.lettuce.pool.min-idle=5spring.redis.lettuce.pool.max-idle=10spring.redis.lettuce.pool.max-active=8spring.redis.lettuce.pool.max-wait=1msspring.redis.lettuce.shutdown-timeout=100ms# 缓存名称spring.cache.cache-names=cache-user 2 使用 首先在项目启动类上增加 @EnableCaching 注解，开始缓存，如下： 123456789@SpringBootApplication@EnableCaching // 开启缓存public class SpringBootSpringcacheRedisApplication { public static void main(String[] args) { SpringApplication.run(SpringBootSpringcacheRedisApplication.class, args); }} 接着新建 User 实体类，如下： 1234567public class User implements Serializable { private Integer id; private String username; private String address; // getter/setter} 最后新增 UserService ，如下： 123456789101112131415161718192021222324252627282930313233@Service// 指定缓存名称，对应配置文件中 spring.cache.cache-names=cache-user@CacheConfig(cacheNames = \"cache-user\")public class UserService { // 注意要在启动类上配置开启缓存 @EnableCaching // 默认缓存的 key 为所有参数的值（可通过 key 或 keyGenerator 修改），缓存的 value 为方法的返回值 // cache-user::1 // 查询 @Cacheable // @Cacheable(key = \"#id\") // @Cacheable(key = \"#root.methodName\") // @Cacheable(keyGenerator = \"myKeyGenerator\") public User getUserById(Integer id) { System.out.println(\"getUserById &gt;&gt;&gt;\" + id); User user = new User(); user.setId(id); return user; } // 删除 @CacheEvict public void deleteUserById(Integer id) { System.out.println(\"deleteUserById &gt;&gt;&gt;\" + id); } // 更新 @CachePut(key = \"#user.id\") public User updateUserById(User user) { return user; }} 缓存注解说明： @CacheConfig 这个注解在 类上使用，用来指定该类中所有方法使用的全局缓存名称。 @Cacheable 这个注解一般在 查询方法 上使用，表示将一个方法的返回值缓存起来，默认缓存的 key 为所有参数的值（可通过 key 或 keyGenerator 修改），缓存的 value 为方法的返回值。 如果方法有多个参数时，默认就使用多个参数来做 key ，如果只需要其中某一个参数做 key ，则可以在 @Cacheable 注解中，通过 key 属性来指定，如 @Cacheable(key = &quot;#id&quot;) 。如果对 key 有复杂的要求，可以自定义 keyGenerator 。 Spring Cache 默认中提供了 root 对象，可以在不定义 keyGenerator 的情况下实现一些复杂的效果，如下： 也可以通过 keyGenerator 自定义 key ，如 @Cacheable(keyGenerator = &quot;myKeyGenerator&quot;) 。需要新增 MyKeyGenerator 配置类，如下： 12345678@Componentpublic class MyKeyGenerator implements KeyGenerator { @Override public Object generate(Object o, Method method, Object... objects) { // 自定义缓存的 key return method.getName() + \":\" + Arrays.toString(objects); }} @CacheEvict 这个注解一般在 删除方法 上使用，当数据库中的数据删除后，相关的缓存数据也要自动清除。当然也可以配置按照某种条件删除（ condition 属性）或者配置清除所有缓存（ allEntries 属性）。 @CachePut 这个注解一般在 更新方法 上使用，当数据库中的数据更新后，缓存中的数据也要跟着更新，使用该注解，可以将方法的返回值自动更新到已经存在的 key 上。 下面开始测试，在测试类中注入 UserService ，如下： 123456789101112131415161718192021222324@SpringBootTestclass SpringBootSpringcacheRedisApplicationTests { @Autowired UserService userService; @Test void contextLoads() { User u1 = userService.getUserById(1);// userService.deleteUserById(1);// User user = new User();// user.setId(1);// user.setUsername(\"zhangsan\");// user.setAddress(\"hangzhou\");// userService.updateUserById(user); User u2 = userService.getUserById(1); System.out.println(u1); System.out.println(u2); }} 3 源码解读Redis 缓存对应的自动化配置类是 org.springframework.boot.autoconfigure.cache.RedisCacheConfiguration ，部分源码如下： 12345678910111213141516171819202122232425262728@Configuration( proxyBeanMethods = false)@ConditionalOnClass({RedisConnectionFactory.class})@AutoConfigureAfter({RedisAutoConfiguration.class})@ConditionalOnBean({RedisConnectionFactory.class})@ConditionalOnMissingBean({CacheManager.class})@Conditional({CacheCondition.class})class RedisCacheConfiguration { RedisCacheConfiguration() { } @Bean RedisCacheManager cacheManager(CacheProperties cacheProperties, CacheManagerCustomizers cacheManagerCustomizers, ObjectProvider&lt;org.springframework.data.redis.cache.RedisCacheConfiguration&gt; redisCacheConfiguration, ObjectProvider&lt;RedisCacheManagerBuilderCustomizer&gt; redisCacheManagerBuilderCustomizers, RedisConnectionFactory redisConnectionFactory, ResourceLoader resourceLoader) { RedisCacheManagerBuilder builder = RedisCacheManager.builder(redisConnectionFactory).cacheDefaults(this.determineConfiguration(cacheProperties, redisCacheConfiguration, resourceLoader.getClassLoader())); List&lt;String&gt; cacheNames = cacheProperties.getCacheNames(); if (!cacheNames.isEmpty()) { builder.initialCacheNames(new LinkedHashSet(cacheNames)); } redisCacheManagerBuilderCustomizers.orderedStream().forEach((customizer) -&gt; { customizer.customize(builder); }); return (RedisCacheManager)cacheManagerCustomizers.customize(builder.build()); } // ......} 上述源码中提供了一个 RedisCacheManager 类型的 Bean ，它间接实现了 Spring Cache 的接口，有了它我们就可以直接使用 Spring 中的缓存注解和接口了，而缓存的数据则会被自动存储到 Redis 中。 注意：在单机的 Redis 中，系统会自动提供这个 Bean ，但如果是 Redis 集群，则需要我们自己来提供。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-cache/spring-boot-springcache-redis 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/12/27/springboot/spring-boot-springcache-redis/"},{"title":"Spring Boot 整合 Spring Security（配置登录 / 登出）","text":"Spring Boot 整合 Spring Security ，配置登录 / 登出，如：登录接口，登录成功或失败后的响应等。 1 创建工程 创建 Spring Boot 项目 spring-boot-springsecurity-login ，添加 Web/Spring Security 依赖，如下： 最终的依赖如下： 123456789101112131415161718192021222324252627&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2 配置 Spring Security新增 SecurityConfig 配置类，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter { @Bean PasswordEncoder passwordEncoder() {// return NoOpPasswordEncoder.getInstance();// 密码不加密 return new BCryptPasswordEncoder();// 密码加密 } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 在内存中配置 2 个用户 /*auth.inMemoryAuthentication() .withUser(\"admin\").password(\"123456\").roles(\"admin\") .and() .withUser(\"user\").password(\"123456\").roles(\"user\");// 密码不加密 */ auth.inMemoryAuthentication() .withUser(\"admin\").password(\"$2a$10$fB2UU8iJmXsjpdk6T6hGMup8uNcJnOGwo2.QGR.e3qjIsdPYaS4LO\").roles(\"admin\") .and() .withUser(\"user\").password(\"$2a$10$3TQ2HO/Xz1bVHw5nlfYTBON2TDJsQ0FMDwAS81uh7D.i9ax5DR46q\").roles(\"user\");// 密码加密 } @Override protected void configure(HttpSecurity http) throws Exception { // 开启登录配置 http.authorizeRequests() // 表示 admin 角色能访问 .antMatchers(\"/admin/**\").hasRole(\"admin\") // 表示 admin 或 user 角色都能访问 // .antMatchers(\"/user/**\").hasAnyRole(\"admin\", \"user\") // 表示 admin 或 user 角色都能访问 .antMatchers(\"/user/**\").access(\"hasAnyRole('admin','user')\") // 表示剩余的其他接口，登录之后就能访问 .anyRequest().authenticated() .and() .formLogin() // 表示登录页的地址，例如当你访问一个需要登录后才能访问的资源时，系统就会自动给你通过【重定向】跳转到这个页面上来 .loginPage(\"/login\") // 表示处理登录请求的接口地址，默认为 /login .loginProcessingUrl(\"/doLogin\") // 定义登录时，用户名的 key，默认为 username .usernameParameter(\"uname\") // 定义登录时，密码的 key，默认为 password .passwordParameter(\"passwd\") // 登录成功的处理器 .successHandler(new AuthenticationSuccessHandler() { @Override public void onAuthenticationSuccess(HttpServletRequest req, HttpServletResponse resp, Authentication authentication) throws IOException, ServletException { resp.setContentType(\"application/json;charset=utf-8\"); PrintWriter out = resp.getWriter(); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"status\", 200); map.put(\"msg\", authentication.getPrincipal()); out.write(new ObjectMapper().writeValueAsString(map)); out.flush(); out.close(); } }) // 登录失败的处理器 .failureHandler(new AuthenticationFailureHandler() { @Override public void onAuthenticationFailure(HttpServletRequest req, HttpServletResponse resp, AuthenticationException e) throws IOException, ServletException { resp.setContentType(\"application/json;charset=utf-8\"); PrintWriter out = resp.getWriter(); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"status\", 401); if (e instanceof LockedException) { map.put(\"msg\", \"账户被锁定，登录失败!\"); } else if (e instanceof BadCredentialsException) { map.put(\"msg\", \"用户名或密码输入错误，登录失败!\"); } else if (e instanceof DisabledException) { map.put(\"msg\", \"账户被禁用，登录失败!\"); } else if (e instanceof AccountExpiredException) { map.put(\"msg\", \"账户过期，登录失败!\"); } else if (e instanceof CredentialsExpiredException) { map.put(\"msg\", \"密码过期，登录失败!\"); } else { map.put(\"msg\", \"登录失败!\"); } out.write(new ObjectMapper().writeValueAsString(map)); out.flush(); out.close(); } }) // 和表单登录相关的接口统统都直接通过 .permitAll() .and() .logout() .logoutUrl(\"/logout\") // 登出成功的处理器 .logoutSuccessHandler(new LogoutSuccessHandler() { @Override public void onLogoutSuccess(HttpServletRequest req, HttpServletResponse resp, Authentication authentication) throws IOException, ServletException { resp.setContentType(\"application/json;charset=utf-8\"); PrintWriter out = resp.getWriter(); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"status\", 200); map.put(\"msg\", \"注销登录成功!\"); out.write(new ObjectMapper().writeValueAsString(map)); out.flush(); out.close(); } }) .permitAll() .and() .csrf().disable() .exceptionHandling() // 无访问权限的处理器 .accessDeniedHandler(new AccessDeniedHandler() { @Override public void handle(HttpServletRequest req, HttpServletResponse resp, AccessDeniedException e) throws IOException, ServletException { resp.setContentType(\"application/json;charset=utf-8\"); PrintWriter out = resp.getWriter(); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"status\", 403); map.put(\"msg\", \"无访问权限!\"); out.write(new ObjectMapper().writeValueAsString(map)); out.flush(); out.close(); } }) // 默认情况下用户直接访问一个需要认证之后才可以访问的请求时，会被重定向到.loginPage(\"/login\")，前后端分离时会导致跨域。 // 增加如下配置后，就不会发生重定向操作了，服务端会直接给浏览器一个 JSON 提示 .authenticationEntryPoint(new AuthenticationEntryPoint() { @Override public void commence(HttpServletRequest req, HttpServletResponse resp, AuthenticationException authException) throws IOException, ServletException { resp.setContentType(\"application/json;charset=utf-8\"); PrintWriter out = resp.getWriter(); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"status\", 401); if (authException instanceof InsufficientAuthenticationException) { map.put(\"msg\", \"访问失败，请先登录!\"); } else { map.put(\"msg\", \"访问失败!\"); } out.write(new ObjectMapper().writeValueAsString(map)); out.flush(); out.close(); } }); } @Override public void configure(WebSecurity web) throws Exception { // 配置不需要拦截的请求地址，即该地址不走 Spring Security 过滤器链 web.ignoring().antMatchers(\"/vercode\"); }} 3 测试 新增 HelloController 测试类，如下： 12345678910111213141516171819202122@RestControllerpublic class HelloController { @GetMapping(\"/hello\") public String hello() { return \"hello\"; } @GetMapping(\"/admin/hello\") public String admin() { return \"hello admin\"; } @GetMapping(\"/user/hello\") public String user() { return \"hello user\"; } @GetMapping(\"/login\") public String login() { return \"please login\"; }} 项目启动之后，用 Postman 完成测试，如下： 访问 /hello 接口，提示先登录。 访问 /doLogin 接口登录失败，因为 key 不对。 用自定义的 key 访问 /doLogin 接口登录成功。 再访问 /hello 接口，返回正常。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-security/spring-boot-springsecurity-login 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/01/18/springboot/spring-boot-springsecurity-login/"},{"title":"Spring Boot 整合 Spring Security（使用 JSON 格式数据登录）","text":"Spring Boot 整合 Spring Security ，默认的登录数据是通过 key/value 的形式来传递的，本文学习使用 JSON 格式数据登录。 1 源码分析 通过分析源码我们发现，默认的用户名密码提取在 UsernamePasswordAuthenticationFilter 过滤器中，部分源码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class UsernamePasswordAuthenticationFilter extends AbstractAuthenticationProcessingFilter { public static final String SPRING_SECURITY_FORM_USERNAME_KEY = \"username\"; public static final String SPRING_SECURITY_FORM_PASSWORD_KEY = \"password\"; private String usernameParameter = \"username\"; private String passwordParameter = \"password\"; private boolean postOnly = true; public UsernamePasswordAuthenticationFilter() { super(new AntPathRequestMatcher(\"/login\", \"POST\")); } public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException { if (this.postOnly &amp;&amp; !request.getMethod().equals(\"POST\")) { throw new AuthenticationServiceException(\"Authentication method not supported:\" + request.getMethod()); } else { String username = this.obtainUsername(request); String password = this.obtainPassword(request); if (username == null) { username = \"\"; } if (password == null) { password = \"\"; } username = username.trim(); UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken(username, password); this.setDetails(request, authRequest); return this.getAuthenticationManager().authenticate(authRequest); } } @Nullable protected String obtainPassword(HttpServletRequest request) { return request.getParameter(this.passwordParameter); } @Nullable protected String obtainUsername(HttpServletRequest request) { return request.getParameter(this.usernameParameter); } // ......} 从上述源码中可以看出，用户名和密码默认是通过 request.getParameter 来获取的，如果前台使用 JSON 格式传递数据，则可以自己提供一个过滤器，在里面改变默认的获取方式。 2 创建工程 创建 Spring Boot 项目 spring-boot-springsecurity-loginbyjson ，添加 Web/Spring Security 依赖，如下： 最终的依赖如下： 123456789101112131415161718192021222324252627&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3 自定义过滤器 新增 MyUsernamePasswordAuthenticationFilter 过滤器，继承自 UsernamePasswordAuthenticationFilter ，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142public class MyUsernamePasswordAuthenticationFilter extends UsernamePasswordAuthenticationFilter { // 覆盖父类的方法，增加 JSON 的登录方式 @Override public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException { if (!request.getMethod().equals(\"POST\")) { throw new AuthenticationServiceException(\"Authentication method not supported:\" + request.getMethod()); } if (request.getContentType().equals(MediaType.APPLICATION_JSON_VALUE)) { // 说明用户以 JSON 的形式传递的参数 String username = null; String password = null; try { Map&lt;String, String&gt; map = new ObjectMapper().readValue(request.getInputStream(), Map.class); username = map.get(\"username\"); password = map.get(\"password\"); } catch (IOException e) { e.printStackTrace(); } if (username == null) { username = \"\"; } if (password == null) { password = \"\"; } username = username.trim(); UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken( username, password); // Allow subclasses to set the \"details\" property setDetails(request, authRequest); return this.getAuthenticationManager().authenticate(authRequest); } return super.attemptAuthentication(request, response); }} 修改用户名和密码的获取方式，改成从 JSON 中获取。 4 配置 Spring Security新增 SecurityConfig 配置类，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter { @Bean PasswordEncoder passwordEncoder() {// return NoOpPasswordEncoder.getInstance();// 密码不加密 return new BCryptPasswordEncoder();// 密码加密 } @Bean MyUsernamePasswordAuthenticationFilter myAuthenticationFilter() throws Exception { MyUsernamePasswordAuthenticationFilter filter = new MyUsernamePasswordAuthenticationFilter(); filter.setAuthenticationSuccessHandler(new AuthenticationSuccessHandler() { @Override public void onAuthenticationSuccess(HttpServletRequest req, HttpServletResponse resp, Authentication authentication) throws IOException, ServletException { resp.setContentType(\"application/json;charset=utf-8\"); PrintWriter out = resp.getWriter(); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"status\", 200); map.put(\"msg\", authentication.getPrincipal()); out.write(new ObjectMapper().writeValueAsString(map)); out.flush(); out.close(); } }); filter.setAuthenticationFailureHandler(new AuthenticationFailureHandler() { @Override public void onAuthenticationFailure(HttpServletRequest req, HttpServletResponse resp, AuthenticationException e) throws IOException, ServletException { resp.setContentType(\"application/json;charset=utf-8\"); PrintWriter out = resp.getWriter(); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"status\", 401); if (e instanceof LockedException) { map.put(\"msg\", \"账户被锁定，登录失败!\"); } else if (e instanceof BadCredentialsException) { map.put(\"msg\", \"用户名或密码输入错误，登录失败!\"); } else if (e instanceof DisabledException) { map.put(\"msg\", \"账户被禁用，登录失败!\"); } else if (e instanceof AccountExpiredException) { map.put(\"msg\", \"账户过期，登录失败!\"); } else if (e instanceof CredentialsExpiredException) { map.put(\"msg\", \"密码过期，登录失败!\"); } else { map.put(\"msg\", \"登录失败!\"); } out.write(new ObjectMapper().writeValueAsString(map)); out.flush(); out.close(); } }); filter.setAuthenticationManager(authenticationManagerBean()); return filter; } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 在内存中配置 2 个用户 /*auth.inMemoryAuthentication() .withUser(\"admin\").password(\"123456\").roles(\"admin\") .and() .withUser(\"user\").password(\"123456\").roles(\"user\");// 密码不加密 */ auth.inMemoryAuthentication() .withUser(\"admin\").password(\"$2a$10$fB2UU8iJmXsjpdk6T6hGMup8uNcJnOGwo2.QGR.e3qjIsdPYaS4LO\").roles(\"admin\") .and() .withUser(\"user\").password(\"$2a$10$3TQ2HO/Xz1bVHw5nlfYTBON2TDJsQ0FMDwAS81uh7D.i9ax5DR46q\").roles(\"user\");// 密码加密 } @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests(). anyRequest().authenticated() .and() .formLogin() .permitAll() .and() .csrf().disable(); http.addFilterAt(myAuthenticationFilter(), UsernamePasswordAuthenticationFilter.class); }} 项目启动之后，用 Postman 完成测试，如下： Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-security/spring-boot-springsecurity-loginbyjson 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/01/20/springboot/spring-boot-springsecurity-loginbyjson/"},{"title":"Spring Boot 整合 Spring Security + OAuth2","text":"学习在 Spring Boot 中整合 Spring Security 和 OAuth2 。 1 OAuth2 概述 1.1 OAuth2 简介OAuth 是一个开放标准，该标准允许用户让第三方应用访问该用户在某一网站上存储的私密资源（如头像、照片、视频等），而在这个过程中无需将用户名和密码提供给第三方应用。实现这一功能是通过提供一个令牌(token)，而不是用户名和密码来访问他们存放在特定服务提供者的数据。采用令牌(token) 的方式可以让用户灵活的对第三方应用授权或者收回权限。 OAuth2 是 OAuth 协议的下一版本，但不向下兼容 OAuth 1.0 。传统的 Web 开发登录认证一般都是基于 session 的，但是在前后端分离的架构中继续使用 session 就会有许多不便，因为移动端（Android、iOS、微信小程序等）要么不支持 cookie （微信小程序），要么使用非常不便，对于这些问题，使用 OAuth2 认证都能解决。 1.2 OAuth2 授权模式OAuth 协议的授权模式共分为四种： 授权码模式：常见的第三方平台登录功能基本都是使用这种模式。 简化模式：简化模式是不需要客户端服务器参与，直接在浏览器中向授权服务器申请令牌(token)，一般如果网站是纯静态页面则可以采用这种方式。 密码模式：密码模式是用户把用户名密码直接告诉客户端，客户端使用说这些信息向授权服务器申请令牌(token)。这需要用户对客户端高度信任，例如客户端应用和服务提供商就是同一家公司。 客户端模式：客户端模式是指客户端使用自己的名义而不是用户的名义向服务提供者申请授权，严格来说，客户端模式并不能算作 OAuth 协议要解决的问题的一种解决方案，但是，对于开发者而言，在一些前后端分离应用或者为移动端提供的认证授权服务器上使用这种模式还是非常方便的。 这四种模式各有千秋，分别适用于不同的开发场景，开发者要根据实际情况进行选择，本文主要介绍 密码模式。 2 实战 2.1 创建工程并配置 创建 Spring Boot 项目 spring-boot-springsecurity-oauth2 ，添加 Web/Spring Security/Redis 依赖，如下： 之后手动在 pom 文件中添加 oauth2/commos-pool2 依赖，最终的依赖如下： 123456789101112131415161718192021222324252627282930313233343536373839&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security.oauth&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt; &lt;version&gt;2.3.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接着在 application.properties 配置文件中添加 Redis 相关信息的配置和 Redis 连接池的配置，如下： 1234567891011121314151617# 方法 1：通过配置文件配置用户 / 角色# spring.security.user.name=admin# spring.security.user.password=123456# spring.security.user.roles=admin# Redis 配置spring.redis.host=192.168.71.62spring.redis.port=6379spring.redis.database=0spring.redis.password=000000# 连接池配置， Spring Boot 默认用的是 lettuce ，而不是 Jedis ，需增加 commons-pool2 依赖spring.redis.lettuce.pool.min-idle=5spring.redis.lettuce.pool.max-idle=10spring.redis.lettuce.pool.max-active=8spring.redis.lettuce.pool.max-wait=1msspring.redis.lettuce.shutdown-timeout=100ms 2.2 配置 OAuth2 资源服务配置 123456789101112131415161718// 资源服务配置@Configuration@EnableResourceServerpublic class MyResourceServerConfigurer extends ResourceServerConfigurerAdapter { @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception { // 资源 id = rid resources.resourceId(\"rid\").stateless(true); } @Override public void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\"/admin/**\").hasRole(\"admin\") .antMatchers(\"/user/**\").hasRole(\"user\") .anyRequest().authenticated(); }} 授权服务配置 12345678910111213141516171819202122232425262728293031323334353637383940// 授权服务配置@Configuration@EnableAuthorizationServerpublic class MyAuthorizationServerConfigurer extends AuthorizationServerConfigurerAdapter { @Autowired AuthenticationManager authenticationManager; @Autowired RedisConnectionFactory redisConnectionFactory; @Autowired UserDetailsService userDetailsService; @Bean PasswordEncoder passwordEncoder() { // return NoOpPasswordEncoder.getInstance();// 密码不加密 return new BCryptPasswordEncoder();// 密码加密 } @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients.inMemory() .withClient(\"cid\")// 客户端 id .authorizedGrantTypes(\"password\", \"refresh_token\")// 授权方式 .accessTokenValiditySeconds(1800) .resourceIds(\"rid\")// 资源 id，与资源服务配置中的保持一致 .scopes(\"all\") .secret(\"$2a$10$kwLIAqAupvY87OM.O25.Yu1QKEXV1imAv7jWbDaQRFUFWSnSiDEwG\");// 客户端秘钥（123） } @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception { endpoints.tokenStore(new RedisTokenStore(redisConnectionFactory)) .authenticationManager(authenticationManager) .userDetailsService(userDetailsService); } @Override public void configure(AuthorizationServerSecurityConfigurer security) throws Exception { security.allowFormAuthenticationForClients(); }} 2.3 配置 Spring Security新增 SecurityConfig 配置类，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter { @Override @Bean protected AuthenticationManager authenticationManager() throws Exception { return super.authenticationManager(); } @Bean @Override protected UserDetailsService userDetailsService() { return super.userDetailsService(); } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 在内存中配置 2 个用户 /*auth.inMemoryAuthentication() .withUser(\"admin\").password(\"123456\").roles(\"admin\") .and() .withUser(\"user\").password(\"123456\").roles(\"user\");// 密码不加密 */ auth.inMemoryAuthentication() .withUser(\"admin\").password(\"$2a$10$fB2UU8iJmXsjpdk6T6hGMup8uNcJnOGwo2.QGR.e3qjIsdPYaS4LO\").roles(\"admin\") .and() .withUser(\"user\").password(\"$2a$10$3TQ2HO/Xz1bVHw5nlfYTBON2TDJsQ0FMDwAS81uh7D.i9ax5DR46q\").roles(\"user\");// 密码加密 } @Override protected void configure(HttpSecurity http) throws Exception { // 1. 先访问 http://127.0.0.1:8080/oauth/token [POST] 获取 token // 输入参数： /*client_id:cid client_secret:123 grant_type:password username:user password:123456 scope:all（这个貌似可以不用传）*/ // 输出参数： /*{ \"access_token\": \"bd0b8836-3b9b-41da-8b7b-75620e71c8a3\", \"token_type\": \"bearer\", \"refresh_token\": \"9ae500a7-7789-45df-bfa3-a9d14d351ab5\", \"expires_in\": 1799, \"scope\": \"all\" }*/ // 2. 再根据上面获取的 access_token 访问实际的请求 http://127.0.0.1:8080/user/hello?access_token=bd0b8836-3b9b-41da-8b7b-75620e71c8a3 [GET] // 另外可访问 http://127.0.0.1:8080/oauth/token [POST] 刷新 token // 输入参数： /*client_id:cid client_secret:123 grant_type:refresh_token refresh_token:9ae500a7-7789-45df-bfa3-a9d14d351ab5*/ // 输出参数： /*{ \"access_token\": \"4ba1a3c6-857b-444a-b8a2-e2c7ef06abe3\", \"token_type\": \"bearer\", \"refresh_token\": \"9ae500a7-7789-45df-bfa3-a9d14d351ab5\", \"expires_in\": 1799, \"scope\": \"all\" }*/ // 放过 /oauth/token 等请求 http.antMatcher(\"/oauth/**\") .authorizeRequests() .antMatchers(\"/oauth/**\").permitAll() .and() .csrf().disable(); }} 2.4 测试 新建 HelloController ，如下： 1234567891011121314151617@RestControllerpublic class HelloController { @GetMapping(\"/hello\") public String hello() { return \"hello\"; } @GetMapping(\"/admin/hello\") public String admin() { return \"hello admin\"; } @GetMapping(\"/user/hello\") public String user() { return \"hello user\"; }} 项目启动之后，用 Postman 完成测试。 先访问 http://127.0.0.1:8080/oauth/token [POST] 获取 token 。 再根据上面获取的 access_token 访问实际的请求 http://127.0.0.1:8080/user/hello?access_token=bd0b8836-3b9b-41da-8b7b-75620e71c8a3 [GET]。 另外可访问 http://127.0.0.1:8080/oauth/token [POST] 刷新 token 。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-security/spring-boot-springsecurity-oauth2 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/01/28/springboot/spring-boot-springsecurity-oauth2/"},{"title":"Spring Boot 整合 Spring Security（配置验证码）","text":"Spring Boot 整合 Spring Security ，配置验证码。 1 创建工程 创建 Spring Boot 项目 spring-boot-springsecurity-verifycode ，添加 Web/Spring Security 依赖，如下： 最终的依赖如下： 123456789101112131415161718192021222324252627&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2 准备验证码和接口 新增 VerifyCode 验证码生成工具类，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101// 生成验证码的工具类public class VerifyCode { private int width = 100;// 生成验证码图片的宽度 private int height = 50;// 生成验证码图片的高度 private String[] fontNames = {\"宋体\", \"楷体\", \"隶书\", \"微软雅黑\"}; private Color bgColor = new Color(255, 255, 255);// 定义验证码图片的背景颜色为白色 private Random random = new Random(); private String codes = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"; private String text;// 记录随机字符串 /** * 获取一个随意颜色 * * @return */ private Color randomColor() { int red = random.nextInt(150); int green = random.nextInt(150); int blue = random.nextInt(150); return new Color(red, green, blue); } /** * 获取一个随机字体 * * @return */ private Font randomFont() { String name = fontNames[random.nextInt(fontNames.length)]; int style = random.nextInt(4); int size = random.nextInt(5) + 24; return new Font(name, style, size); } /** * 获取一个随机字符 * * @return */ private char randomChar() { return codes.charAt(random.nextInt(codes.length())); } /** * 创建一个空白的 BufferedImage 对象 * * @return */ private BufferedImage createImage() { BufferedImage image = new BufferedImage(width, height, BufferedImage.TYPE_INT_RGB); Graphics2D g2 = (Graphics2D) image.getGraphics(); g2.setColor(bgColor);// 设置验证码图片的背景颜色 g2.fillRect(0, 0, width, height); return image; } public BufferedImage getImage() { BufferedImage image = createImage(); Graphics2D g2 = (Graphics2D) image.getGraphics(); StringBuffer sb = new StringBuffer(); for (int i = 0; i &lt; 4; i++) { String s = randomChar() + \"\"; sb.append(s); g2.setColor(randomColor()); g2.setFont(randomFont()); float x = i * width * 1.0f / 4; g2.drawString(s, x, height - 15); } this.text = sb.toString(); drawLine(image); return image; } /** * 绘制干扰线 * * @param image */ private void drawLine(BufferedImage image) { Graphics2D g2 = (Graphics2D) image.getGraphics(); int num = 5; for (int i = 0; i &lt; num; i++) { int x1 = random.nextInt(width); int y1 = random.nextInt(height); int x2 = random.nextInt(width); int y2 = random.nextInt(height); g2.setColor(randomColor()); g2.setStroke(new BasicStroke(1.5f)); g2.drawLine(x1, y1, x2, y2); } } public String getText() { return text; } public static void output(BufferedImage image, OutputStream out) throws IOException { ImageIO.write(image, \"JPEG\", out); }} 新增 VerifyCodeController ，提供验证码的获取接口，如下： 1234567891011121314@RestControllerpublic class VerifyCodeController { @GetMapping(\"/vercode\") public void code(HttpServletRequest req, HttpServletResponse resp, Model model) throws IOException { VerifyCode vc = new VerifyCode(); BufferedImage image = vc.getImage(); String text = vc.getText(); model.addAttribute(\"text\", text); System.out.println(\"text =\" + text); HttpSession session = req.getSession(); session.setAttribute(\"s_vercode\", text); VerifyCode.output(image, resp.getOutputStream()); }} 在 resources/static 下新增 vercode.html 展示验证码，如下： 12345678910&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;测试验证码&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;img src=\"/vercode\" alt=\"\"&gt;&lt;/body&gt;&lt;/html&gt; 访问 http://127.0.0.1:8080/vercode.html ，效果如下： 3 配置验证码过滤器 新增 VerifyCodeFilter 验证码过滤器 1234567891011121314151617181920212223// 验证码过滤器@Componentpublic class VerifyCodeFilter extends GenericFilterBean { private String defaultFilterProcessUrl = \"/doLogin\"; @Override public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException, AuthenticationServiceException { HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; if (\"POST\".equalsIgnoreCase(request.getMethod()) &amp;&amp; defaultFilterProcessUrl.equals(request.getServletPath())) { // 验证码验证 String requestCaptcha = request.getParameter(\"vercode\"); String genCaptcha = (String) request.getSession().getAttribute(\"s_vercode\"); if (StringUtils.isEmpty(requestCaptcha) || StringUtils.isEmpty(genCaptcha)) throw new AuthenticationServiceException(\"验证码不能为空!\"); if (!genCaptcha.toLowerCase().equals(requestCaptcha.toLowerCase())) { throw new AuthenticationServiceException(\"验证码错误!\"); } } chain.doFilter(request, response); }} 当请求方法是 POST ，并且请求地址是 /doLogin 时，获取参数中的 vercode 字段值，该字段保存了用户从前端页面传来的验证码，然后获取 session 中保存的验证码，如果用户没有传来验证码，则抛出“验证码不能为空”异常，如果用户传入了验证码，则判断验证码是否正确，如果不正确则抛出“验证码错误”异常，否则执行 chain.doFilter(request, response); 使请求继续向下走。 4 配置 Spring Security新增 SecurityConfig 配置类，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter { @Autowired VerifyCodeFilter verifyCodeFilter; // 验证码过滤器 @Bean PasswordEncoder passwordEncoder() { // return NoOpPasswordEncoder.getInstance();// 密码不加密 return new BCryptPasswordEncoder();// 密码加密 } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 在内存中配置 2 个用户 /*auth.inMemoryAuthentication() .withUser(\"admin\").password(\"123456\").roles(\"admin\") .and() .withUser(\"user\").password(\"123456\").roles(\"user\");// 密码不加密 */ auth.inMemoryAuthentication() .withUser(\"admin\").password(\"$2a$10$fB2UU8iJmXsjpdk6T6hGMup8uNcJnOGwo2.QGR.e3qjIsdPYaS4LO\").roles(\"admin\") .and() .withUser(\"user\").password(\"$2a$10$3TQ2HO/Xz1bVHw5nlfYTBON2TDJsQ0FMDwAS81uh7D.i9ax5DR46q\").roles(\"user\");// 密码加密 } @Override protected void configure(HttpSecurity http) throws Exception { http.addFilterBefore(verifyCodeFilter, UsernamePasswordAuthenticationFilter.class); http.authorizeRequests() .anyRequest().authenticated() .and() .formLogin() .loginProcessingUrl(\"/doLogin\") // 登录失败的处理器（VerifyCodeFilter 抛出的异常不会到这里？） .failureHandler(new AuthenticationFailureHandler() { @Override public void onAuthenticationFailure(HttpServletRequest req, HttpServletResponse resp, AuthenticationException e) throws IOException, ServletException { resp.setContentType(\"application/json;charset=utf-8\"); PrintWriter out = resp.getWriter(); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"status\", 401); map.put(\"msg\", e.getMessage()); out.write(new ObjectMapper().writeValueAsString(map)); out.flush(); out.close(); } }) .permitAll() .and() .csrf().disable(); // 其他配置可参考 spring-boot-springsecurity-login } @Override public void configure(WebSecurity web) throws Exception { // 配置不需要拦截的请求地址，即该地址不走 Spring Security 过滤器链 web.ignoring().antMatchers(\"/vercode\"); web.ignoring().antMatchers(\"/vercode.html\"); }} 配置之后，在登录时就要求传验证码了，如果不传或传错，控制台就会抛出异常。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-security/spring-boot-springsecurity-verifycode 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/01/16/springboot/spring-boot-springsecurity-verifycode/"},{"title":"Spring Boot 整合 Swagger2","text":"学习在 Spring Boot 中使用 Swagger2 实时生成在线接口文档，还支持接口测试。特别是在前后端分离开发时，可以说是一大神器。 1 创建工程 1.1 手动集成（老版本，无 Starter） 创建 Spring Boot 项目 spring-boot-swagger2 ，添加 Web 依赖。之后手动在 pom 文件中添加 Swagger2 相关的两个依赖，最终的依赖如下： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 1.5.21 版本覆盖默认的 1.5.20 版本，解决 @ApiModelProperty 的 example 默认值类型转换异常 BUG - java.lang.NumberFormatException: For input string: \"\"--&gt; &lt;dependency&gt; &lt;groupId&gt;io.swagger&lt;/groupId&gt; &lt;artifactId&gt;swagger-annotations&lt;/artifactId&gt; &lt;version&gt;1.5.21&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.swagger&lt;/groupId&gt; &lt;artifactId&gt;swagger-models&lt;/artifactId&gt; &lt;version&gt;1.5.21&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 1.2 自动集成（新版本，使用 Starter） 注：springfox 3.0.0 版本开始已经有对应的官方 Spring Boot Starter，在 Spring Boot 项目中使用就更方便了。 创建 Spring Boot 项目 spring-boot-swagger2 ，添加 Web 依赖。之后手动在 pom 文件中添加 Swagger2 相关的两个依赖，最终的依赖如下： 123456789101112131415161718192021222324252627282930313233343536&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 1.5.21 版本覆盖默认的 1.5.20 版本，解决 @ApiModelProperty 的 example 默认值类型转换异常 BUG - java.lang.NumberFormatException: For input string: \"\"--&gt; &lt;dependency&gt; &lt;groupId&gt;io.swagger&lt;/groupId&gt; &lt;artifactId&gt;swagger-annotations&lt;/artifactId&gt; &lt;version&gt;1.5.21&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.swagger&lt;/groupId&gt; &lt;artifactId&gt;swagger-models&lt;/artifactId&gt; &lt;version&gt;1.5.21&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2 Swagger2 配置 新增 Swagger2Config 配置类，如下： 1234567891011121314151617181920@Configuration@EnableSwagger2 // 启用 Swagger2public class Swagger2Config { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .pathMapping(\"/\") .select() .apis(RequestHandlerSelectors.basePackage(\"com.cxy35.sample.springboot.swagger2.controller\")) .paths(PathSelectors.any()) .build().apiInfo(new ApiInfoBuilder() .title(\"这是网站的标题...\") .description(\"这是网站的描述...\") .version(\"v1.0\") .contact(new Contact(\"这是联系人名称\", \"https://cxy35.com\", \"123456@qq.com\")) .license(\"这是网站使用的协议...\") .licenseUrl(\"https://www.baidu.com\") .build()); }} 启动项目，访问 http://127.0.0.1:8080/swagger-ui.html（老版本） 或 http://127.0.0.1:8080/swagger-ui/（新版本），查看效果如下： 注：在新版本中，支持在配置文件中完成一些配置，比如：springfox.documentation.enabled 配置可以控制是否启用 Swagger 文档生成功能（一般在开发环境开启，在生产环境关闭）。 1#springfox.documentation.enabled=false 其他配置如下： 3 使用 新增 UserController 测试接口，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@RestController@Api(tags = \"用户管理接口\")public class UserController { @GetMapping(\"/user\") @ApiOperation(value = \"查询用户\", notes = \"根据用户 id 查询用户\") @ApiImplicitParam(name = \"id\", value = \"用户 id\", required = true, defaultValue = \"99\") public User getUserById(Integer id) { User user = new User(); user.setId(id); user.setUsername(\"cxy35\"); user.setAddress(\"HZ\"); return user; } @PutMapping(\"/user\") @ApiOperation(value = \"更新用户\", notes = \"根据用户 id 更新用户名\") @ApiImplicitParams({ @ApiImplicitParam(name = \"id\", value = \"用户 id\", required = true, defaultValue = \"99\"), @ApiImplicitParam(name = \"username\", value = \"用户名\", required = true, defaultValue = \"cxy35\") }) // @ApiIgnore public User updateUsernameById(String username, Integer id) { User user = new User(); user.setId(id); user.setUsername(username); return user; } @PostMapping(\"/user\") @ApiOperation(value = \"添加用户\", notes = \"添加用户接口\") public User addUser(@RequestBody User user) { return user; } @DeleteMapping(\"/user/{id}\") @ApiOperation(value = \"删除用户\", notes = \"根据用户 id 删除用户\") @ApiImplicitParam(name = \"id\", value = \"用户 id\", required = true, defaultValue = \"99\") @ApiResponses({ @ApiResponse(code = 200, message = \"删除成功\"), @ApiResponse(code = 500, message = \"删除失败\") }) public void deleteUserById(@PathVariable Long id) { } @GetMapping(\"/hello\") public String hello(String name) { return \"hello\" + name + \"!\"; }} 注解说明： @Api 注解：用来描述一个 Controller 类。 @ApiOperation 注解：用来描述一个接口。 @ApiImplicitParam 注解：用来描述一个参数，可以配置参数的中文含义，也可以给参数设置默认值，这样在接口测试的时候可以避免手动输入。 @ApiImplicitParams 注解：如果有多个参数，则需要使用多个 @ApiImplicitParam 注解来描述，多个 @ApiImplicitParam 注解需要放在一个 @ApiImplicitParams 中。 需要注意的是， @ApiImplicitParam 注解中虽然可以指定参数是必填的，但是却不能代替 @RequestParam(required = true) ，前者的必填只是在 Swagger2 框架内必填，抛弃了 Swagger2 ，这个限制就没用了，所以假如开发者需要指定一个参数必填， @RequestParam(required = true) 注解还是不能省略。 如果参数是一个对象（例如上文的 addUser 接口），对于参数的描述也可以放在实体类中，比如： 1234567891011@ApiModel(value = \"用户实体类\",description = \"用户信息描述类\")public class User { @ApiModelProperty(value = \"用户 id\") private Integer id; @ApiModelProperty(value = \"用户名\") private String username; @ApiModelProperty(value = \"用户地址\") private String address; // getter/setter} 注解说明： @ApiModel 注解：用来描述一个实体类。 @ApiModelProperty 注解：用来描述一个实体类的字段。 重新启动项目，访问 http://127.0.0.1:8080/swagger-ui.html（老版本） 或 http://127.0.0.1:8080/swagger-ui/（新版本），查看效果如下： 4 Spring Security 中的配置 如果项目中集成了 Spring Security ，默认情况下 Swagger2 文档可能会被拦截，需要在 Spring Security 的配置类中重写 configure 方法，增加如下过滤配置： 1234567@Overridepublic void configure(WebSecurity web) throws Exception { web.ignoring() .antMatchers(\"/swagger-ui.html\") .antMatchers(\"/v2/**\") .antMatchers(\"/swagger-resources/**\");} Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-swagger2 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/12/22/springboot/spring-boot-swagger2/"},{"title":"Spring Boot 配置定时任务（@Scheduled / Quartz）","text":"学习在 Spring Boot 中如何配置定时任务。一般有两种方案，一种是使用 Spring 自带的定时任务处理器 @Scheduled 注解来实现（业务比较简单时），另一种是使用第三方框架 Quartz 来实现。 1 @Scheduled创建 Spring Boot 项目 spring-boot-scheduled ，添加 Web 依赖，最终的依赖如下： 1234567891011121314151617&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 首先在项目启动类上增加 @EnableScheduling 注解，开启定时任务，如下： 123456789@SpringBootApplication@EnableScheduling // 开启定时任务public class SpringBootScheduledApplication { public static void main(String[] args) { SpringApplication.run(SpringBootScheduledApplication.class, args); }} 最后新建 MyScheduled 类，配置定时任务，配置说明见代码注释，如下： 123456789101112131415161718192021222324252627@Componentpublic class MyScheduled { // @Scheduled 注解表示开启一个定时任务 // fixedRate 表示任务执行之间的时间间隔（单位是毫秒），具体是指两次任务的开始时间间隔，即第二次任务开始时，第一次任务可能还没结束。 @Scheduled(fixedRate = 2000) public void fixedRate() { System.out.println(\"fixedRate &gt;&gt;&gt;\" + new Date()); } // fixedDelay 表示任务执行之间的时间间隔（单位是毫秒），具体是指本次任务结束到下次任务开始之间的时间间隔。 @Scheduled(fixedDelay = 2000) public void fixedDelay() { System.out.println(\"fixedDelay &gt;&gt;&gt;\" + new Date()); } // initialDelay 表示首次任务启动的延迟时间（单位是毫秒）。 @Scheduled(initialDelay = 2000, fixedDelay = 2000) public void initialDelay() { System.out.println(\"initialDelay &gt;&gt;&gt;\" + new Date()); } // cron 表达式，每隔 5 秒触发一次 @Scheduled(cron = \"0/5 * * * * ?\") public void cron() { System.out.println(\"cron &gt;&gt;&gt;\" + new Date()); }} 启动项目，观察控制台来验证结果。 其中 cron 表达式的格式为： [秒] [分] [小时] [日] [月] [周] [年] ，具体取值如下： 序号 说明 是否必填 允许填写的值 允许的通配符 1 秒 是 0-59 - * / 2 分 是 0-59 - * / 3 时 是 0-23 - * / 4 日 是 1-31 - * ? / L W 5 月 是 1-12 or JAN-DEC - * / 6 周 是 1-7 or SUN-SAT - * ? / L # 7 年 否 1970-2099 - * / 注意：日期和周（星期）可能会起冲突，因此在配置时这两个得有一个是 ? 。 通配符的含义如下： ? 表示不指定值，即不关心某个字段的取值时使用，如配置日期和周（星期）时这两个得有一个是 ? 。 * 表示所有值，如配置秒为 * 时表示每一秒都会触发。 , 表示分开多个值，如配置周为 MON,WED,FRI 时表示周一三五都会触发。 - 表示区间，如配置小时为 8-10 时表示 8,9,10 点都会触发。 / 表示递增触发，如配置分为 5/15 时表示从 5 分开始，每增 15 分触发(5,20,35,50)。 # 表示序号（每月的第几个周几），如配置周为 6#3 时表示在每月的第 3 个周 6（非常适合母亲节和父亲节）。 周 字段的配置，不区分大小写，即 MON 与 mon 相同。 L 表示最后的意思，如配置日期时表示当月的最后一天（如果是二月还会自动判断是否是润年）, 配置周时表示星期六（相当于 “7” 或 “SAT” ，注意周日算是第一天）。如果在 “L” 前加上数字，则表示该数据的最后一个，如配置周为 6L 时表示本月最后一个星期五。 W 表示离指定日期的最近工作日（周一至周五），如配置日期为 15W 时表示离每月 15 号最近的那个工作日触发。如果 15 号正好是周六，则找最近的周五 (14 号) 触发, 如果 15 号是周未，则找最近的下周一 (16 号) 触发，如果 15 号正好在工作日(周一至周五)，则就在该天触发。如果指定格式为 1W ，则表示每月 1 号往后最近的工作日触发。如果 1 号正是周六，则将在 3 号下周一触发。(注，”W”前只能设置具体的数字，不允许区间 “-“)。 L 和 W 可以一组合使用。如果在日字段上设置 “LW” ，则表示在本月的最后一个工作日触发(一般指发工资)。 2 Quartz创建 Spring Boot 项目 spring-boot-quartz ，添加 Web/Quartz 依赖，如下： 最终的依赖如下： 123456789101112131415161718192021&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 首先在项目启动类上增加 @EnableScheduling 注解，开启定时任务，如下： 123456789@SpringBootApplication@EnableScheduling // 开启定时任务public class SpringBootQuartzApplication { public static void main(String[] args) { SpringApplication.run(SpringBootQuartzApplication.class, args); }} Quartz 主要有两个概念，一个是 JobDetail （要做的事情），另一个是 Trigger （触发器，即什么时候做），要定义 JobDetail ，需要先定义 Job ，Job 的定义有两种方式： 新建 MyJob1 ，如下： 1234567// Job 定义方式 1：直接定义一个 Bean 并注册到 Spring 容器中（无法传参）。@Componentpublic class MyJob1 { public void sayHello() { System.out.println(\"MyJob1&gt;&gt;&gt;\"+new Date()); }} 新建 MyJob2 ，如下： 12345678910111213// Job 定义方式 2：继承 QuartzJobBean 并实现默认的方法（支持传参）public class MyJob2 extends QuartzJobBean { private String name; public void setName(String name) { this.name = name; } @Override protected void executeInternal(JobExecutionContext jobExecutionContext) throws JobExecutionException { System.out.println(\"MyJob2 &gt;&gt;&gt;\" + name + \":\" + new Date()); }} Job 定义完成之后，就可以开始配置 JobDetail 和 Trigger 了，新建 QuartzConfig 配置类，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * 在 Quartz 配置类中，主要配置两个东西：1.JobDetail（要做的事情） 2.Trigger（什么时候做） * &lt;p&gt; * JobDetail 有两种不同的配置方式： * 1. MethodInvokingJobDetailFactoryBean * 2. JobDetailFactoryBean */@Configurationpublic class QuartzConfig { // JobDetail1 // JobDetail 配置方式 1：这里使用 MyJob1 测试，指定 bean 和方法，无法传参 @Bean MethodInvokingJobDetailFactoryBean methodInvokingJobDetailFactoryBean() { MethodInvokingJobDetailFactoryBean bean = new MethodInvokingJobDetailFactoryBean(); bean.setTargetBeanName(\"myJob1\"); bean.setTargetMethod(\"sayHello\"); return bean; } // JobDetail2 // JobDetail 配置方式 2：这里使用 MyJob2 测试，支持传参 @Bean JobDetailFactoryBean jobDetailFactoryBean() { JobDetailFactoryBean bean = new JobDetailFactoryBean(); JobDataMap map = new JobDataMap(); map.put(\"name\", \"cxy35\"); bean.setJobDataMap(map); bean.setJobClass(MyJob2.class); return bean; } // Trigger1：这里使用 JobDetail1 测试 @Bean SimpleTriggerFactoryBean simpleTriggerFactoryBean() { SimpleTriggerFactoryBean bean = new SimpleTriggerFactoryBean(); bean.setStartTime(new Date()); bean.setRepeatCount(5); bean.setJobDetail(methodInvokingJobDetailFactoryBean().getObject()); bean.setRepeatInterval(3000); return bean; } // Trigger2：这里使用 JobDetail2 测试 @Bean CronTriggerFactoryBean cronTriggerFactoryBean() { CronTriggerFactoryBean bean = new CronTriggerFactoryBean(); bean.setCronExpression(\"0/10 * * * * ?\"); bean.setJobDetail(jobDetailFactoryBean().getObject()); return bean; } // 注册 Trigger1 和 Trigger2 @Bean SchedulerFactoryBean schedulerFactoryBean() { SchedulerFactoryBean bean = new SchedulerFactoryBean(); bean.setTriggers(simpleTriggerFactoryBean().getObject(), cronTriggerFactoryBean().getObject()); return bean; }} 启动项目，观察控制台来验证结果。 配置类说明： JobDetail 的配置有两种方式：MethodInvokingJobDetailFactoryBean 和 JobDetailFactoryBean 。 使用 MethodInvokingJobDetailFactoryBean 可以配置目标 Bean 的名字和目标方法的名字，这种方式不支持传参。 使用 JobDetailFactoryBean 可以配置 JobDetail ，任务类继承自 QuartzJobBean ，这种方式支持传参，将参数封装在 JobDataMap 中进行传递。 Trigger 是指触发器，Quartz 中定义了多个触发器，这里向大家展示其中两种的用法，SimpleTrigger 和 CronTrigger 。 SimpleTrigger 有点类似于前面说的 @Scheduled 的基本用法。 CronTrigger 则有点类似于 @Scheduled 中 cron 表达式的用法。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码（@Scheduled）：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-task/spring-boot-scheduled 本文示例代码（Quartz）：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-task/spring-boot-quartz 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/12/20/springboot/spring-boot-task/"},{"title":"Spring Cloud Alibaba Nacos 服务配置中心和注册中心","text":"学习在 Spring Cloud 中使用 Nacos 实现服务配置中心和注册中心，类似 Spring Cloud Config 和 Spring Cloud Netflix Eureka 提供的功能。 1 概述Spring Cloud Alibaba 是阿里巴巴提供的一套微服务开发一站式解决方案。 主要提供的功能： 分布式配置中心 服务注册与发现 服务限流降级 消息驱动 分布式事务 阿里云对象存储（绑定阿里云） 阿里云短信（绑定阿里云） 提供的组件： Nacos：主要提供了服务动态配置、服务及元数据管理、服务注册与发现、动态 DNS 服务。 Sentinel：熔断、限流等。 优势： 中文文档。 没有另起炉灶，可以方便的集成到现有项目中。 阿里本身在高并发、高性能上的经验，让我们有理由相信这些组件足够可靠。 2 安装 下载安装包： Linux：https://github.com/alibaba/nacos/releases/download/1.3.0-beta/nacos-server-1.3.0-BETA.tar.gz Windows：https://github.com/alibaba/nacos/releases/download/1.3.0-beta/nacos-server-1.3.0-BETA.zip 解压后启动： Windows：在 bin 目录下双击 startup.cmd Linux：在 bin 目录下执行 sh startup.sh -m standalone 注意：需要 java 和 javac 两个命令，可以先测试下。 Nacos 启动成功后，访问 http://127.0.0.1:8848/nacos 就能看到后台页面。如果有登录页面，登录的默认用户名 / 密码都是 nacos 。 3 配置中心Nacos 做配置中心，可以代替 Spring Cloud Config 。 创建 Spring Boot 项目 nacos-config ，添加 Web/Nacos Configuration 依赖，如下： 最终的依赖如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 首先，在 Nacos 服务端后台配置，页面上依次点击 配置管理 -&gt; 配置列表 -&gt; + ，这里主要配置三个东西，Data ID（nacos-config.properties）、Group 以及要配置的内容。其中 Data ID 的格式为 ${prefix}-${spring.profile.active}.${file-extension} ： ${preﬁx}：默认为 spring.application.name 的值，如 nacos-config 。 ${spring.proﬁle.active}：表示项目当前所处的环境，如 dev/test/prod 。 ${ﬁle-extension}：表示配置文件的扩展名，如 properties 。 然后，新建 bootstrap.properties 配置文件，配置 Nacos 相关信息： 12345spring.application.name=nacos-configserver.port=8080spring.cloud.nacos.server-addr=127.0.0.1:8848spring.cloud.nacos.config.file-extension=properties 最后，提供一个 hello 接口，注意要添加 @RefreshScope 注解。 1234567891011@RestController@RefreshScopepublic class HelloController { @Value(\"${name}\") String name; @GetMapping(\"/hello\") public String hello() { return \"hello :\" + name; }} 启动项目，访问 http://127.0.0.1:8080/hello 可以正常获取到 Nacos 服务端后台配置的配置文件中的属性值。在 Nacos 后台修改属性值，保存后可以实时生效。 4 注册中心Nacos 做注册中心，可以代替 Spring Cloud Netflix Eureka 。 4.2 服务注册 创建 Spring Boot 项目 nacos-client-provider ，作为我们的 服务提供者，添加 Web/Nacos Service Discovery 依赖，如下： 最终的依赖如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，修改 application.properties 配置文件，如下： 1234spring.application.name=nacos-client-providerserver.port=9000spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848 然后，启动项目，在 Nacos 后台页面上可以看到这个实例。 当然 provider 也可以集群化部署，下面对 nacos-client-provider 进行打包，之后我们在命令行启动两个 provider 实例： 12java -jar nacos-client-provider-0.0.1-SNAPSHOT.jar --server.port=9000java -jar nacos-client-provider-0.0.1-SNAPSHOT.jar --server.port=9001 启动成功后，在 Nacos 后台页面上可以看到这 2 个实例。 最后，在 provider 提供一个 hello 接口，用于后续服务消费者 consumer 来消费，如下： 12345678910@RestControllerpublic class ProviderController { @Value(\"${server.port}\") Integer port; // 支持启动多个实例，做负载均衡，用端口区分 @GetMapping(\"/hello\") public String hello() { return \"hello cxy35:\" + port; }} 4.2 服务消费 创建 Spring Boot 项目 nacos-client-consumer ，作为我们的 服务消费者，添加 Web/Nacos Service Discovery 依赖，如下： 最终的依赖如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，修改 application.properties 配置文件，如下： 1234spring.application.name=nacos-client-consumerserver.port=9002spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848 然后，启动项目，在 Nacos 后台页面上可以看到这个实例。 接着，在项目启动类中添加 RestTemplate ，如下： 12345678910111213@SpringBootApplicationpublic class NacosClientConsumerApplication { public static void main(String[] args) { SpringApplication.run(NacosClientConsumerApplication.class, args); } @Bean @LoadBalanced // 开启负载均衡 RestTemplate restTemplate() { return new RestTemplate(); }} 最后在 consumer 中新增测试接口，去实现服务调用，从而消费 provider 中提供的接口，如下： 12345678910@RestControllerpublic class ConsumerController { @Autowired RestTemplate restTemplate; @GetMapping(\"/hello\") public String hello() { return restTemplate.getForObject(\"http://nacos-client-provider/hello\", String.class); }} 访问 http://127.0.0.1:9002/hello 完成测试。 Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 本文示例代码：https://github.com/cxy35/spring-cloud-samples/tree/master/spring-cloud-alibaba-nacos 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/05/23/springcloud/spring-cloud-alibaba-nacos/"},{"title":"Spring Cloud Consul 服务注册与发现","text":"学习在 Spring Cloud 中使用 Consul 实现服务注册与发现，它是 Eureka 之外的另一种选择。 1 概述 在 Spring Cloud 中，大部分组件都有备选方案，例如服务注册中心，除了常见 Eureka 之外，还有 Zookeeper 和 Consul 等。 Consul 是 HashiCorp 公司推出来的开源产品，主要提供了 服务发现、服务隔离、服务配置 等功能。 相比于 Eureka 和 Zookeeper ，Consul 配置更加一站式 ，因为它内置了很多微服务常见的需求，比如： 服务发现与注册、分布式一致性协议实现、健康检查、键值对存储、多数据中心 等，我们不再需要借助第三方组件来实现这些功能。 2 安装 不同于 Eureka ， Consul 使用 Go 语言开发，所以，使用 Consul ，我们需要先 下载 并安装软件，作为我们的 Consul Server ，即服务注册中心。 Linux 12345678# 下载wget https://releases.hashicorp.com/consul/1.6.2/consul_1.6.2_linux_amd64.zip# 解压，解压完成后，我们在当前目录下就可以看到 consul 文件unzip consul_1.6.2_linux_amd64.zip# 启动./consul agent -dev -ui -node=consul-dev -client=127.0.0.1 Windows 12345# 下载# consul_1.7.2_windows_amd64.zip# 启动consul.exe agent -dev -ui -node=consul-dev -client=127.0.0.1 启动成功后，通过 http://127.0.0.1:8500 访问 Consul 的后台管理页面，如下： 3 使用 3.1 服务注册 创建 Spring Boot 项目 consul-client-provider ，作为我们的 服务提供者，添加 Web/Consul/Actuator 依赖，如下： 最终的依赖如下： 1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，修改 application.properties 配置文件，将 provider 注册到 Consul 服务上，如下： 1234567spring.application.name=consul-client-providerserver.port=2000# Consul 相关配置spring.cloud.consul.host=127.0.0.1spring.cloud.consul.port=8500spring.cloud.consul.discovery.service-name=consul-client-provider 接着，在项目启动类上添加 @EnableDiscoveryClient 注解，开启服务发现的功能，如下： 123456789@SpringBootApplication@EnableDiscoveryClient // 开启服务发现的功能public class ConsulClientProviderApplication { public static void main(String[] args) { SpringApplication.run(ConsulClientProviderApplication.class, args); }} 接下来，启动项目，访问 http://127.0.0.1:8500 可以看到 provider 的注册信息。 当然 provider 也可以集群化部署，下面对 consul-client-provider 进行打包，之后我们在命令行启动两个 provider 实例： 12java -jar consul-client-provider-0.0.1-SNAPSHOT.jar --server.port=2000java -jar consul-client-provider-0.0.1-SNAPSHOT.jar --server.port=2001 启动成功后，再去 Consul 后台管理页面，就可以看到有两个实例了： 最后在 provider 中提供一个 hello 接口，用于后续服务消费者 consumer 来消费，如下： 12345678910@RestControllerpublic class ProviderController { @Value(\"${server.port}\") Integer port; // 支持启动多个实例，做负载均衡，用端口区分 @GetMapping(\"/hello\") public String hello() { return \"hello cxy35:\" + port; }} 3.2 服务消费 创建 Spring Boot 项目 consul-client-consumer ，作为我们的 服务消费者，添加 Web/Consul/Actuator 依赖，如下： 最终的依赖如下： 1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，修改 application.properties 配置文件，将 consumer 注册到 Consul 服务上，如下： 1234567spring.application.name=consul-client-consumerserver.port=2002# Consul 相关配置spring.cloud.consul.host=127.0.0.1spring.cloud.consul.port=8500spring.cloud.consul.discovery.service-name=consul-client-consumer 接着，在项目启动类上添加 @EnableDiscoveryClient 注解，开启服务发现的功能，并添加 RestTemplate ，如下： 12345678910111213@SpringBootApplication@EnableDiscoveryClient // 开启服务发现的功能public class ConsulClientConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsulClientConsumerApplication.class, args); } @Bean RestTemplate restTemplate() { return new RestTemplate(); }} 最后在 consumer 中新增测试接口，去实现服务调用，从而消费 provider 中提供的接口，如下： 12345678910111213141516@RestControllerpublic class ConsumerController { @Autowired LoadBalancerClient loadBalancerClient; @Autowired RestTemplate restTemplate; @GetMapping(\"/testConsul\") public String testConsul() { ServiceInstance choose = loadBalancerClient.choose(\"consul-client-provider\"); System.out.println(\"服务地址：\" + choose.getUri()); System.out.println(\"服务名称：\" + choose.getServiceId()); String s = restTemplate.getForObject(choose.getUri() + \"/hello\", String.class); return s; }} 我们通过 LoadBalancerClient 实例，可以获取要调用的 ServiceInstance 。获取到调用地址之后，再用 RestTemplate 去调用。 访问 http://127.0.0.1:2002/testConsul 完成测试，这个请求自带负载均衡功能。 Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 本文示例代码：https://github.com/cxy35/spring-cloud-samples/tree/master/spring-cloud-consul 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/04/15/springcloud/spring-cloud-consul/"},{"title":"Spring Cloud Gateway 服务网关","text":"学习在 Spring Cloud 中使用 Gateway 实现服务网关，包括基本使用、自动代理、 Predicate 、 Filter 等功能。 1 概述Gateway 的主要功能如下： 限流 路径重写 动态路由 集成 Spring Cloud DiscoveryClient 集成 Hystrix 断路器 和 Zuul 相比，有如下区别： Zuul 是 Netﬂix 公司的开源产品， Spring Cloud Gateway 是 Spring 家族中的产品，可以和 Spring 家族中的其他组件更好的融合。 Zuul 不支持长连接（版本一），例如 Websocket 。 Spring Cloud Gateway 支持限流。 Spring Cloud Gateway 基于 Netty 来开发，实现了异步和非阻塞，占用资源更小，性能强于 Zuul 。 2 准备工作 2.1 服务注册 创建 Spring Boot 项目 gateway-client-provider ，作为我们的 服务提供者，添加 Web/Eureka Client 依赖，如下： 最终的依赖如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，修改 application.properties 配置文件，将 gateway-client-provider 注册到 Eureka Server 上（服务注册中心使用 Eureka Server ），如下： 1234567# 当前服务的名称spring.application.name=gateway-client-provider# 当前服务的端口server.port=7000# 服务注册中心地址eureka.client.service-url.defaultZone=http://127.0.0.1:1111/eureka 接下来，启动 Eureka Server ，待服务注册中心启动成功后，再启动 gateway-client-provider ，两者都启动成功后，访问 http://127.0.0.1:1111 可以看到 gateway-client-provider 的注册信息。 当然 gateway-client-provider 也可以集群化部署，下面对 gateway-client-provider 进行打包，之后我们在命令行启动两个 provider 实例： 12java -jar gateway-client-provider-0.0.1-SNAPSHOT.jar --server.port=7000java -jar gateway-client-provider-0.0.1-SNAPSHOT.jar --server.port=7001 最后在 gateway-client-provider 提供 hello 和 hello2 接口，用于后续服务消费者 gateway-client-consumer 来消费，如下： 123456789101112131415@RestControllerpublic class ProviderController { @Value(\"${server.port}\") Integer port; // 支持启动多个实例，做负载均衡，用端口区分 @GetMapping(\"/hello\") public String hello() { return \"hello cxy35:\" + port; } @GetMapping(\"/hello2\") public String hello2(String name) { return \"hello\" + name; }} 2.2 服务消费 创建 Spring Boot 项目 gateway-client-consumer ，作为我们的 服务消费者，添加 Eureka Client/Gateway 依赖，如下： 最终的依赖如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，新建 application.yml 配置文件，将 gateway-client-consumer 注册到 Eureka Server 上（服务注册中心使用 Eureka Server ），如下： 12345678910111213# 当前服务的名称spring: application: name: gateway-client-consumer# 当前服务的端口server: port: 7002# 服务注册中心地址eureka: client: service-url: defaultZone: http://127.0.0.1:1111/eureka 接下来，启动 gateway-client-consumer ，访问 http://127.0.0.1:1111 可以看到 gateway-client-consumer 的注册信息。 3 基本使用 Spring Cloud Gateway 支持两种不同的配置方法： 编码配置、 YML 配置。 编码配置 在 gateway-client-consumer 项目启动类上配置一个 RouteLocator 类型的 Bean，就可以实现请求转发，如下： 123456789101112131415@SpringBootApplicationpublic class GatewayClientConsumerApplication { public static void main(String[] args) { SpringApplication.run(GatewayClientConsumerApplication.class, args); } @Bean RouteLocator routeLocator(RouteLocatorBuilder builder) { return builder.routes() .route(\"cxy35_route\", r -&gt; r.path(\"/get\").uri(\"http://httpbin.org\")) // 这是一个测试的地址 .build(); }} 配置完成后，重启项目，访问 http://127.0.0.1:7002/get 完成测试。 YML 配置 注释掉上述 Java 代码，再修改 gateway-client-consumer 中的 application.yml 配置文件： 1234567891011121314151617181920# 当前服务的名称spring: application: name: gateway-client-consumer cloud: gateway: routes: - id: cxy35_route uri: http://httpbin.org # 这是一个测试的地址 predicates: - Path=/get# 当前服务的端口server: port: 7002# 服务注册中心地址eureka: client: service-url: defaultZone: http://127.0.0.1:1111/eureka 配置完成后，重启项目，访问 http://127.0.0.1:7002/get 完成测试。 4 结合微服务使用 修改 gateway-client-consumer 中的 application.yml 配置文件： 123456789101112131415161718192021222324252627# 当前服务的名称spring: application: name: gateway-client-consumer cloud: gateway: routes: - id: cxy35_route uri: http://httpbin.org # 这是一个测试的地址 predicates: - Path=/get discovery: locator: enabled: true # 开启自动代理# 当前服务的端口server: port: 7002# 服务注册中心地址eureka: client: service-url: defaultZone: http://127.0.0.1:1111/eurekalogging: level: org.springframework.cloud.gateway: debug 接下来，就可以通过 Gateway 访问到其他注册在 Eureka 上的服务了，如 http://127.0.0.1:7002/GATEWAY-CLIENT-PROVIDER/hello ，注意大小写问题。 5 Predicate路由配置 Route 中的 Predicate 支持多种配置方式： 通过时间匹配： After （表示在某个时间点之前进行请求转发）/ Before （表示在某个时间点之前进行请求转发）/ Between （表示在两个时间点之间，两个时间点用 , 隔开）。 12345678spring: cloud: gateway: routes: - id: cxy35_route2 uri: http://httpbin.org predicates: - After=2021-01-01T01:01:01+08:00[Asia/Shanghai] 通过请求方法匹配： Method 。 12345678spring: cloud: gateway: routes: - id: cxy35_route2 uri: http://httpbin.org predicates: - Method=GET 通过请求路径匹配： Path 。 12345678spring: cloud: gateway: routes: - id: cxy35_route2 uri: http://httpbin.org predicates: - Path=/2020/01/{segment} 上述配置表示路径满足 /2020/01/ 这个规则，都会被进行转发。 通过请求参数名或值匹配： Query 。 12345678spring: cloud: gateway: routes: - id: cxy35_route2 uri: http://httpbin.org predicates: - Query=name 上述配置表示请求中一定要有 name 参数才会进行转发，否则不会进行转发。 也可以同时指定参数名和参数值，例如参数的 key 为 name ， value 必须要以 java 开始： 12345678spring: cloud: gateway: routes: - id: cxy35_route2 uri: http://httpbin.org predicates: - Query=name,java.* 多种匹配方式组合使用。 12345678910spring: cloud: gateway: routes: - id: cxy35_route2 uri: http://httpbin.org predicates: - After=2021-01-01T01:01:01+08:00[Asia/Shanghai] - Method=GET - Query=name,java.* 6 FilterSpring Cloud Gateway 中的过滤器分为两大类： GatewayFilter / GlobalFilter 。 比如 AddRequestParameter 过滤器会在请求转发路由的时候，自动额外添加参数，如： 12345678910spring: cloud: gateway: routes: - id: cxy35_route3 uri: lb://gateway-client-provider filters: - AddRequestParameter=name,cxy35 predicates: - Method=GET 配置完成后，重启项目，访问 http://127.0.0.1:7002/hello2 完成测试。 Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 本文示例代码：https://github.com/cxy35/spring-cloud-samples/tree/master/spring-cloud-gateway 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/05/04/springcloud/spring-cloud-gateway/"},{"title":"Spring Cloud Netflix Eureka Client 服务注册与发现","text":"学习在 Spring Cloud 中使用 Eureka Client 实现服务注册与发现。 1 服务注册 服务注册就是把一个微服务注册到 Eureka Server 服务注册中心上，这样，当其他服务需要调用该服务时，只需要从 Eureka Server 上查询该服务的信息即可。 创建 Spring Boot 项目 eureka-client-provider ，作为我们的 服务提供者，添加 Web/Eureka Client 依赖，如下： 最终的依赖如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，修改 application.properties 配置文件，将 provider 注册到 Eureka Server 上，如下： 1234567# 当前服务的名称spring.application.name=provider# 当前服务的端口server.port=1113# 服务注册中心地址eureka.client.service-url.defaultZone=http://127.0.0.1:1111/eureka 接下来，启动 Eureka Server ，待服务注册中心启动成功后，再启动 provider ，两者都启动成功后，访问 http://127.0.0.1:1111 可以看到 provider 的注册信息。 最后在 provider 提供一个 hello 接口，用于后续服务消费者 consumer 来消费，如下： 12345678910@RestControllerpublic class ProviderController { @Value(\"${server.port}\") Integer port; // 支持启动多个实例，做负载均衡，用端口区分 @GetMapping(\"/hello\") public String hello() { return \"hello cxy35:\" + port; }} 2 服务消费 创建 Spring Boot 项目 eureka-client-consumer ，作为我们的 服务消费者，添加 Web/Eureka Client 依赖，如下： 最终的依赖如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，修改 application.properties 配置文件，将 consumer 注册到 Eureka Server 上，如下： 1234567# 当前服务的名称spring.application.name=consumer# 当前服务的端口server.port=1115# 服务注册中心地址eureka.client.service-url.defaultZone=http://127.0.0.1:1111/eureka 接下来，启动 consumer ，访问 http://127.0.0.1:1111 可以看到 consumer 的注册信息。 下面开始演示在服务消费者 consumer 中新增测试接口，分别用两种 Http 请求工具（ HttpURLConnection 和 RestTemplate ）去实现服务调用，从而消费 provider 中提供的接口。 2.1 服务调用 - HttpURLConnection 通过 HttpURLConnection（ JDK 自带，类似于 HttpClient ） 调用 provider 中的接口，写死 provider 的地址，整个调用过程不会涉及到 Eureka Server 。 1234567891011121314151617181920// 通过 HttpURLConnection（ JDK 自带，类似于 HttpClient ） 调用 provider 中的接口，写死 provider 的地址@GetMapping(\"/testByHttpURLConnection\")public String testByHttpURLConnection() { HttpURLConnection con = null; try { URL url = new URL(\"http://127.0.0.1:1113/hello\"); con = (HttpURLConnection) url.openConnection(); if (con.getResponseCode() == 200) { BufferedReader br = new BufferedReader(new InputStreamReader(con.getInputStream())); String s = br.readLine(); br.close(); return s; } } catch (MalformedURLException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } return \"error\";} 上述代码中 provider 和 consumer 高度绑定在一起，这个不符合微服务的思想。 consumer 要能够获取到 provider 这个接口的地址，他就需要去 Eureka Server 中查询，如果直接在 consumer 中写死 provider 地址，意味着这两个服务之间的耦合度就太高了，我们要降低耦合度。可以借助 Eureka Client 提供的 DiscoveryClient 工具，利用这个工具，我们可以根据 服务名 从 Eureka Server 上查询到一个服务的详细信息。 访问 http://127.0.0.1:1115/testByHttpURLConnection 完成测试。 通过 HttpURLConnection（ JDK 自带，类似于 HttpClient ） 调用 provider 中的接口，通过 DiscoveryClient 动态获取 provider 的地址。 123456789101112131415161718192021222324252627282930313233@AutowiredDiscoveryClient discoveryClient;// 通过 HttpURLConnection（ JDK 自带，类似于 HttpClient ） 调用 provider 中的接口，通过 DiscoveryClient 动态获取 provider 的地址@GetMapping(\"/testByHttpURLConnection2\")public String testByHttpURLConnection2() { List&lt;ServiceInstance&gt; list = discoveryClient.getInstances(\"provider\"); ServiceInstance instance = list.get(0); String host = instance.getHost(); int port = instance.getPort(); StringBuffer sb = new StringBuffer(); sb.append(\"http://\") .append(host) .append(\":\") .append(port) .append(\"/hello\"); HttpURLConnection con = null; try { URL url = new URL(sb.toString()); con = (HttpURLConnection) url.openConnection(); if (con.getResponseCode() == 200) { BufferedReader br = new BufferedReader(new InputStreamReader(con.getInputStream())); String s = br.readLine(); br.close(); return s; } } catch (MalformedURLException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } return \"error\";} 注意： DiscoveryClient 查询到的服务列表是一个集合，因为服务在部署的过程中， provider 可能是集群化部署，集合中的每一项就是一个实例。 下面对 eureka-client-provider 进行打包，之后我们在命令行启动两个 provider 实例： 12java -jar eureka-client-provider-0.0.1-SNAPSHOT.jar --server.port=1113java -jar eureka-client-provider-0.0.1-SNAPSHOT.jar --server.port=1114 启动完成后，检查 Eureka Server 上，这两个 provider 是否成功注册上来。注册成功后，在 consumer 中再去调用 provider ，这样 DiscoveryClient 集合中，获取到的就不是一个实例了，而是两个实例，可以做客户端负载均衡。 访问 http://127.0.0.1:1115/testByHttpURLConnection2 完成测试。 通过 HttpURLConnection（ JDK 自带，类似于 HttpClient ） 调用 provider 中的接口，通过 DiscoveryClient 动态获取 provider 的地址，并手动实现客户端线性负载均衡。 12345678910111213141516171819202122232425262728293031// 通过 HttpURLConnection（ JDK 自带，类似于 HttpClient ） 调用 provider 中的接口，通过 DiscoveryClient 动态获取 provider 的地址，并手动实现客户端线性负载均衡int count = 0;@GetMapping(\"/testByHttpURLConnection3\")public String testByHttpURLConnection3() { List&lt;ServiceInstance&gt; list = discoveryClient.getInstances(\"provider\"); ServiceInstance instance = list.get((count++) % list.size()); String host = instance.getHost(); int port = instance.getPort(); StringBuffer sb = new StringBuffer(); sb.append(\"http://\") .append(host) .append(\":\") .append(port) .append(\"/hello\"); HttpURLConnection con = null; try { URL url = new URL(sb.toString()); con = (HttpURLConnection) url.openConnection(); if (con.getResponseCode() == 200) { BufferedReader br = new BufferedReader(new InputStreamReader(con.getInputStream())); String s = br.readLine(); br.close(); return s; } } catch (MalformedURLException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } return \"error\";} 访问 http://127.0.0.1:1115/testByHttpURLConnection3 完成测试。 2.2 服务调用 - RestTemplate（推荐）上面 HttpURLConnection 的调用过程有点繁琐，我们可以使用 Spring 提供的 RestTemplate 来实现。更多使用说明可参考 Spring Cloud 中 RestTemplate 的使用说明 。 首先，在 consumer 的启动类中提供两个 RestTemplate 类型的 bean ，其中一个支持负载均衡，如下： 123456789101112131415161718@SpringBootApplicationpublic class EurekaClientConsumerApplication { public static void main(String[] args) { SpringApplication.run(EurekaClientConsumerApplication.class, args); } @Bean RestTemplate restTemplate() { return new RestTemplate(); } @Bean @LoadBalanced // 开启负载均衡 RestTemplate restTemplateLoadBalanced() { return new RestTemplate(); }} 【推荐】通过 RestTemplate 调用 provider 中的接口，通过 DiscoveryClient 动态获取 provider 的地址。 1234567891011121314151617181920// 【推荐】通过 RestTemplate 调用 provider 中的接口，通过 DiscoveryClient 动态获取 provider 的地址@Autowired@Qualifier(\"restTemplate\")RestTemplate restTemplate;@GetMapping(\"/testByRestTemplate\")public String testByRestTemplate() { List&lt;ServiceInstance&gt; list = discoveryClient.getInstances(\"provider\"); ServiceInstance instance = list.get(0); String host = instance.getHost(); int port = instance.getPort(); StringBuffer sb = new StringBuffer(); sb.append(\"http://\") .append(host) .append(\":\") .append(port) .append(\"/hello\"); String s = restTemplate.getForObject(sb.toString(), String.class); return s;} 访问 http://127.0.0.1:1115/testByRestTemplate 完成测试。 【推荐】通过 RestTemplate 调用 provider 中的接口，通过 DiscoveryClient 动态获取 provider 的地址，并使用 @LoadBalanced 实现客户端负载均衡。 123456789// 【推荐】通过 RestTemplate 调用 provider 中的接口，通过 DiscoveryClient 动态获取 provider 的地址，并使用 @LoadBalanced 实现客户端负载均衡@Autowired@Qualifier(\"restTemplateLoadBalanced\")RestTemplate restTemplateLoadBalanced;@GetMapping(\"/testByRestTemplate2\")public String testByRestTemplate2() { return restTemplateLoadBalanced.getForObject(\"http://provider/hello\", String.class);} 访问 http://127.0.0.1:1115/testByRestTemplate 完成测试。 Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 本文示例代码：https://github.com/cxy35/spring-cloud-samples/tree/master/spring-cloud-netflix-eureka 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/04/10/springcloud/spring-cloud-netflix-eureka-client/"},{"title":"Spring Cloud Netflix Eureka Server 搭建服务注册中心","text":"学习在 Spring Cloud 中使用 Eureka Server 搭建服务注册中心，手把手带你实现单机和集群两种模式。 Eureka 本身是使用 Java 来开发的， Spring Cloud 使用 Spring Boot 技术对 Eureka 进行了封装，所以，在 Spring Cloud 中使用 Eureka 非常方便，只需要引入 spring-cloud-starter-netflix-eureka-server 这个依赖即可，然后就可以像启动一个普通的 Spring Boot 项目一样启动 Eureka 。 1 单机模式 创建 Spring Boot 项目 eureka-server ，添加 Eureka Server 依赖，如下： 最终的依赖如下： 123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 项目创建成功后，在项目启动类上添加 @EnableEurekaServer 注解，标记该项目是一个 Eureka Server ，如下： 123456789@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); }} 接下来，在 application.properties 配置文件中添加基本配置信息，如下： 12345678910# 给当前服务取一个名字spring.application.name=eureka# 设置端口号server.port=1111# Eureka Server 也是一个普通的微服务，所以当它还是一个注册中心的时候，他会有两层身份：1. 注册中心；2. 普通服务。# 默认情况下，会把自己注册到自己上面来，设置为 false 时，表示当前项目不要注册到注册中心上eureka.client.register-with-eureka=false# 表示是否从 Eureka Server 上获取注册信息eureka.client.fetch-registry=false 配置完成后，就可以启动项目了。如果在项目启动时，遇到 java.lang.TypeNotPresentException: Type javax.xml.bind.JAXBContext not present 异常，这是因为 JDK9 以上，移除了 JAXB ，只需要我们手动引入 JAXB 即可。 1234567891011121314151617181920&lt;dependency&gt; &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.sun.xml.bind&lt;/groupId&gt; &lt;artifactId&gt;jaxb-impl&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.glassfish.jaxb&lt;/groupId&gt; &lt;artifactId&gt;jaxb-runtime&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;javax.activation&lt;/groupId&gt; &lt;artifactId&gt;activation&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt;&lt;/dependency&gt; 项目启动成功后，访问 http://127.0.0.1:1111 就可以查看 Eureka 后台管理页面了： 2 集群模式 使用了注册中心之后，所有的服务都要通过服务注册中心来进行信息交换。服务注册中心的稳定性就非常重要了，一旦服务注册中心掉线，会影响到整个系统的稳定性。所以，在实际开发中，服务注册中心一般都是以集群的形式出现的。Eureka 集群，实际上就是启动多个 Eureka 实例，多个 Eureka 实例之间，互相注册，互相同步数据，共同组成一个 Eureka 集群。 搭建 Eureka 集群，首先我们需要一点准备工作，修改电脑的 hosts 文件（ C:\\Windows\\System32\\drivers\\etc\\hosts ）： 127.0.0.1 eureka-a eureka-b 创建 Spring Boot 项目 eureka-servercluster ，添加 Eureka Server 依赖，如下： 最终的依赖如下： 123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 项目创建成功后，在项目启动类上添加 @EnableEurekaServer 注解，标记该项目是一个 Eureka Server ，如下： 123456789@SpringBootApplication@EnableEurekaServerpublic class EurekaServerclusterApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerclusterApplication.class, args); }} 在 src/main/resources 目录下，新增两个配置文件，分别如下： application-a.properties： 12345678910111213# 给当前服务取一个名字spring.application.name=eureka# 设置端口号server.port=1111eureka.instance.hostname=eureka-a# Eureka Server 也是一个普通的微服务，所以当它还是一个注册中心的时候，他会有两层身份：1. 注册中心；2. 普通服务。# 默认情况下，会把自己注册到自己上面来，设置为 false 时，表示当前项目不要注册到注册中心上eureka.client.register-with-eureka=true# 表示是否从 Eureka Server 上获取注册信息eureka.client.fetch-registry=true# a 服务要注册到 b 上面eureka.client.service-url.defaultZone=http://eureka-b:1112/eureka application-b.properties： 12345678910111213# 给当前服务取一个名字spring.application.name=eureka# 设置端口号server.port=1112eureka.instance.hostname=eureka-b# Eureka Server 也是一个普通的微服务，所以当它还是一个注册中心的时候，他会有两层身份：1. 注册中心；2. 普通服务。# 默认情况下，会把自己注册到自己上面来，设置为 false 时，表示当前项目不要注册到注册中心上eureka.client.register-with-eureka=true# 表示是否从 Eureka Server 上获取注册信息eureka.client.fetch-registry=true# b 服务要注册到 a 上面eureka.client.service-url.defaultZone=http://eureka-a:1111/eureka 配置完成后，对当前项目打包，在命令行启动两个 Eureka 实例。两个启动命令分别如下： 12java -jar eureka-servercluster-0.0.1-SNAPSHOT.jar --spring.profiles.active=ajava -jar eureka-servercluster-0.0.1-SNAPSHOT.jar --spring.profiles.active=b 项目启动成功后，就可以查看 Eureka 后台管理页面了，两个服务之间互相注册，共同给组成一个集群。 eureka-a：http://127.0.0.1:1111 eureka-b：http://127.0.0.1:1112 Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 本文示例代码：https://github.com/cxy35/spring-cloud-samples/tree/master/spring-cloud-netflix-eureka 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/04/09/springcloud/spring-cloud-netflix-eureka-server/"},{"title":"Spring Cloud Netflix Zuul 服务网关","text":"学习在 Spring Cloud 中使用 Zuul 实现服务网关，包括基本使用、请求过滤、忽略路径、前缀等功能。它是 Netflix 家族成员之一。 1 概述 由于每一个微服务的地址都有可能发生变化，无法直接对外公布这些服务地址，基于安全以及高内聚低耦合等设计，我们有必要将内部系统和外部系统做一个切割。 一个专门用来处理外部请求的组件，就是服务网关，常用功能： 权限问题统一处理 数据剪裁和聚合 简化客户端的调用 可以针对不同的客户端提供不同的网关支持 在 Spring Cloud 中，网关主要有两种实现方案： Zuul 和 Spring Cloud Gateway 。 Zuul 是 Netﬂix 公司提供的网关服务，主要有如下功能： 权限控制，可以做认证和授权 监控 动态路由 负载均衡 静态资源处理 Zuul 中的功能基本上都是基于 过滤器 来实现，它的过滤器有几种不同的类型： PRE ROUTING POST ERROR 2 准备工作 2.1 服务注册 创建 Spring Boot 项目 zuul-client-provider ，作为我们的 服务提供者，添加 Web/Eureka Client 依赖，如下： 最终的依赖如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，修改 application.properties 配置文件，将 zuul-client-provider 注册到 Eureka Server 上（服务注册中心使用 Eureka Server ），如下： 1234567# 当前服务的名称spring.application.name=zuul-client-provider# 当前服务的端口server.port=6000# 服务注册中心地址eureka.client.service-url.defaultZone=http://127.0.0.1:1111/eureka 接下来，启动 Eureka Server ，待服务注册中心启动成功后，再启动 zuul-client-provider ，两者都启动成功后，访问 http://127.0.0.1:1111 可以看到 zuul-client-provider 的注册信息。 当然 zuul-client-provider 也可以集群化部署，下面对 zuul-client-provider 进行打包，之后我们在命令行启动两个 provider 实例： 12java -jar zuul-client-provider-0.0.1-SNAPSHOT.jar --server.port=6000java -jar zuul-client-provider-0.0.1-SNAPSHOT.jar --server.port=6001 最后在 zuul-client-provider 提供一个 hello 接口，用于后续服务消费者 zuul-client-consumer 来消费，如下： 12345678910@RestControllerpublic class ProviderController { @Value(\"${server.port}\") Integer port; // 支持启动多个实例，做负载均衡，用端口区分 @GetMapping(\"/hello\") public String hello() { return \"hello cxy35:\" + port; }} 2.2 服务消费 创建 Spring Boot 项目 zuul-client-consumer ，作为我们的 服务消费者，添加 Web/Eureka Client/Zuul 依赖，如下： 最终的依赖如下： 1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，修改 application.properties 配置文件，将 zuul-client-consumer 注册到 Eureka Server 上（服务注册中心使用 Eureka Server ），如下： 1234567# 当前服务的名称spring.application.name=zuul-client-consumer# 当前服务的端口server.port=6002# 服务注册中心地址eureka.client.service-url.defaultZone=http://127.0.0.1:1111/eureka 接着，在项目启动类上添加 @EnableZuulProxy 注解，开启网关代理，如下： 123456789@SpringBootApplication@EnableZuulProxy // 开启网关代理public class ZuulClientConsumerApplication { public static void main(String[] args) { SpringApplication.run(ZuulClientConsumerApplication.class, args); }} 接下来，启动 zuul-client-consumer ，访问 http://127.0.0.1:1111 可以看到 zuul-client-consumer 的注册信息。 3 基本使用 配置完成后，访问 http://127.0.0.1:6002/zuul-client-provider/hello ，会自动通过 Zuul 的代理访问到 zuul-client-provider 中对应的的接口，无需知道其真实的地址。在这个访问地址中， zuul-client-provider 就是要访问的服务名称， /hello 则是要访问的服务接口。 当然， Zuul 中的路由规则也可以自己配置，如下： 123456# Zuul 中的路由规则配置# zuul.routes.cxy35.path=/cxy35/**# zuul.routes.cxy35.service-id=zuul-client-provider# 简化配置zuul.routes.zuul-client-provider=/cxy35/** 上面配置表示满足 /cxy35/** 这个匹配规则的请求，将被转发到 zuul-client-provider 实例上。比如：http://127.0.0.1:6002/cxy35/hello 4 请求过滤 对于来自客户端的请求，可以在 Zuul 中进行预处理，例如 权限判断 等。 在 zuul-client-consumer 中定义一个简单的权限过滤器，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@Componentpublic class PermissionFilter extends ZuulFilter { /** * 过滤器类型，权限判断一般是 pre * * @return */ @Override public String filterType() { return \"pre\"; } /** * 过滤器优先级 * * @return */ @Override public int filterOrder() { return 0; } /** * 是否过滤 * * @return */ @Override public boolean shouldFilter() { return true; } /** * 核心的过滤逻辑写在这里 * * @return 这个方法虽然有返回值，但是这个返回值目前无所谓 * @throws ZuulException */ @Override public Object run() throws ZuulException { RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest();// 获取当前请求 String username = request.getParameter(\"username\"); String password = request.getParameter(\"password\"); if (!\"cxy35\".equals(username) || !\"123456\".equals(password)) { // 如果请求条件不满足的话，直接从这里给出响应 ctx.setSendZuulResponse(false); ctx.setResponseStatusCode(401); ctx.addZuulResponseHeader(\"content-type\", \"text/html;charset=utf-8\"); ctx.setResponseBody(\"非法访问，无权限\"); } return null; }} 重启 zuul-client-consumer ，接下来，发送请求必须带上 username 和 password 参数，否则请求不通过，比如：http://127.0.0.1:6002/cxy35/hello?username=cxy35&amp;password=123456 5 其他配置 5.1 匹配规则 例如有两个服务，一个叫 provider ，另一个叫 provider-hello ，在做路由规则设置时，假如出现了如下配置： 123zuul.routes.provider=/provider/**zuul.routes.provider-hello=/provider/hello/** 此时，如果访问一个地址：http://127.0.0.1:6002/provider/hello/123 ，会出现冲突。实际上，这个地址是希望和 provider-hello 这个服务匹配的，这个时候，只需要把配置文件改为 yml 格式就可以了，因为 yml 格式的配置是有序的。 5.2 忽略路径 默认情况下，Zuul 注册到 Eureka 上之后， Eureka 上的所有注册服务都会被自动代理。如果不想给某一个服务做代理，可以忽略该服务，配置如下： 1zuul.ignored-services=provider2 上面这个配置表示忽略 provider2 服务，此时就不会自动代理 provider2 服务了。 当然，也可以忽略某一类地址，配置如下： 1zuul.ignored-patterns=/**/hello/** 这个表示请求路径中如果包含 hello ，则不做代理。 5.3 前缀 可以统一给路由加前缀，配置如下： 1zuul.prefix=/cxy35 这样，以后所有的请求地址自动多了前缀 /cxy35 。 Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 本文示例代码：https://github.com/cxy35/spring-cloud-samples/tree/master/spring-cloud-netflix-zuul 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/05/03/springcloud/spring-cloud-netflix-zuul/"},{"title":"Spring Cloud 中 RestTemplate 的使用说明","text":"本文整理在 Spring Cloud 中 RestTemplate 的使用说明，包括 GET/POST/PUT/DELETE 请求以及一些通用的请求执行方法 exchange/execute ，结合 @LoadBalanced 注解可以实现客户端负载均衡。 1 概述Java 中的 HTTP 请求工具有 HttpURLConnection（ JDK 自带）/HttpClient/OkHttp 等，此外还有一个 RestTemplate ，由 Spring 提供（但大家之前可能没怎么用过），它与 Spring Boot 和 Spring Cloud 都无关。 RestTemplate 提供了常见的 REST 请求方法模板，例如 GET/POST/PUT/DELETE 请求以及一些通用的请求执行方法 exchange/execute ，结合 @LoadBalanced 注解可以实现客户端负载均衡。 RestTemplate 本身实现了 RestOperations 接口，而在 RestOperations 接口中，定义了常见的 RESTful 操作，这些操作在 RestTemplate 中都得到了很好的实现。 RestTemplate 一般在 consumer 中使用，用来调用 provider 中的接口。 2 使用说明 在 eureka-client-provider 中新增 ProviderController2 用于测试 RestTemplate ，如下： 123@Controllerpublic class ProviderController2 {} 2.1 GET首先，我们在 provider 中定义一个 GET 接口： 123456789@GetMapping(\"/user\")@ResponseBodypublic User findUser(String username) { User user = new User(); user.setId(12); user.setUsername(username); user.setPassword(\"123456\"); return user;} 接下来，在 consumer 去访问这个接口，这个接口是一个 GET 请求，所以，访问方式就是调用 RestTemplate 中的 GET 请求。可以看到，在 RestTemplate 中，关于 GET 请求，一共有如下两大类方法： 这两大类方法实际上是重载的，唯一不同的就是返回值类型。 getForObject 返回的是一个对象，这个对象就是服务端返回的具体值。 getForEntity 返回的是一个 ResponseEntity ，这个 ResponseEntity 中除了服务端返回的具体数据外，还保留了 HTTP 响应头的数 据。 12345678910111213141516171819@GetMapping(\"/testGet\")public void testGet() { User user = restTemplateLoadBalanced.getForObject(\"http://provider/user?username={1}\", User.class, \"cxy35\"); System.out.println(user); ResponseEntity&lt;User&gt; responseEntity = restTemplateLoadBalanced.getForEntity(\"http://provider/user?username={1}\", User.class, \"cxy35\"); user = responseEntity.getBody(); System.out.println(\"body:\" + user); HttpStatus statusCode = responseEntity.getStatusCode(); System.out.println(\"HttpStatus:\" + statusCode); int statusCodeValue = responseEntity.getStatusCodeValue(); System.out.println(\"statusCodeValue:\" + statusCodeValue); HttpHeaders headers = responseEntity.getHeaders(); Set&lt;String&gt; keySet = headers.keySet(); System.out.println(\"--------------header-----------\"); for (String s : keySet) { System.out.println(s + \":\" + headers.get(s)); }} 启动 Eureka Server、provider 以及 consumer 之后，访问 http://127.0.0.1:1115/testGet 完成测试。 验证之后发现， getForObject 直接拿到了服务的返回值， getForEntity 不仅仅拿到服务的返回值，还拿到 http 响应的状态码。 getForObject 和 getForEntity 分别有三个重载方法，两者的三个重载方法基本都是一致的。三个重载方法，其实代表了三种不同的传参方式，这里以 getForObject 为例，如下： 123456789101112131415161718@GetMapping(\"/testGet2\")public void testGet2() throws UnsupportedEncodingException { // 传参方式：字符串 User user = restTemplateLoadBalanced.getForObject(\"http://provider/user?username={1}\", User.class, \"cxy35\"); System.out.println(user); // 传参方式：Map Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"username\", \"zhangsan\"); user = restTemplateLoadBalanced.getForObject(\"http://provider/user?username={username}\", User.class, map); System.out.println(user); // 传参方式：URI String url = \"http://provider/user?username=\" + URLEncoder.encode(\"张三\", \"UTF-8\"); URI uri = URI.create(url); user = restTemplateLoadBalanced.getForObject(uri, User.class); System.out.println(user);} 访问 http://127.0.0.1:1115/testGet2 完成测试。 2.2 POST首先，在 provider 中提供两个 POST 接口： 1234567891011@PostMapping(\"/user\")@ResponseBodypublic User addUser(User user) { return user;}@PostMapping(\"/user2\")@ResponseBodypublic User addUser2(@RequestBody User user) { return user;} 两个方法代表了两种不同的传参方式。第一种方法是以 key/value 形式来传参，第二种方法是以 JSON 形式来传参。定义完成后，接下来，我们在 consumer 中调用这两个 POST 接口。 可以看到，这里的 post 和前面的 get 非常像，只是多出来了三个方法，就是 postForLocation ，另外两个 postForObject 和 postForEntiy 和前面 get 基本一致，所以这里我们主要来看 postForObject ，看完之后，我们再来看这个额外的 postForLocation 。 123456789101112131415@GetMapping(\"/testPost\")public void testPost() { // 传参方式：key/value MultiValueMap&lt;String, Object&gt; map = new LinkedMultiValueMap&lt;&gt;(); map.add(\"username\", \"cxy35\"); map.add(\"password\", \"123\"); map.add(\"id\", 99); User user = restTemplateLoadBalanced.postForObject(\"http://provider/user\", map, User.class); System.out.println(user); // 传参方式：JSON user.setId(98); user = restTemplateLoadBalanced.postForObject(\"http://provider/user2\", user, User.class); System.out.println(user);} 访问 http://127.0.0.1:1115/testPost 完成测试。 post 参数到底是 key/value 形式还是 JSON 形式，主要看第二个参数，如果第二个参数是 MultiValueMap ，则参数是以 key/value 形式来传递的，如果是一个普通对象，则参数是以 JSON 形式来传递的。最后再看一下 postForLocation 。有的时候，当我执行完一个 post 请求之后，立马要进行重定向，一个非常常见的场景就是注册，注册是一个 post 请求，注册完成之后，立马重定向到登录页面去登录。对于这种场景，我们就可以使用 postForLocation 。 首先，我们在 provider 上提供一个用户注册接口，也是 POST 类型： 12345678910@PostMapping(\"/register\")public String register(User user) { return \"redirect:http://provider/loginPage?username=\" + user.getUsername();}@GetMapping(\"/loginPage\")@ResponseBodypublic String loginPage(String username) { return \"loginPage:\" + username;} 注意：这里的 post 接口，响应一定要是 302 ，否则 postForLocation 无效。重定向的地址，一定要写成绝对路径，不要写相对路径，否则在 consumer 中调用时会出问题。 接着在 consumer 中新增接口，调用上述 provider 中的接口。 12345678910111213@GetMapping(\"/testPost2\")public void testPost2() { // postForLocation 实现重定向 MultiValueMap&lt;String, Object&gt; map = new LinkedMultiValueMap&lt;&gt;(); map.add(\"username\", \"cxy35\"); map.add(\"password\", \"123\"); map.add(\"id\", 99); URI uri = restTemplateLoadBalanced.postForLocation(\"http://provider/register\", map); System.out.println(uri); String s = restTemplateLoadBalanced.getForObject(uri, String.class); System.out.println(s);} 这就是 postForLocation ，调用该方法返回的是一个 URI ，这个 URI 就是重定向的地址（里边也包含了重定向的参数），拿到 URI 之后，就可以直接发送新的请求了。 访问 http://127.0.0.1:1115/testPost2 完成测试。 2.3 PUTPUT 请求比较简单，重载的方法也比较少。我们首先在 provider 中提供两个 PUT 接口： 1234567891011@PutMapping(\"/user\")@ResponseBodypublic void updateUser(User user) { System.out.println(\"updateUser:\" + user);}@PutMapping(\"/user2\")@ResponseBodypublic void updateUser2(@RequestBody User user) { System.out.println(\"updateUser2:\" + user);} 注意， PUT 接口传参其实和 POST 很像，也接受两种类型的参数， key/value 形式以及 JSON 形式。在 consumer 中，我们来调用该接口： 12345678910111213141516@GetMapping(\"/testPut\")public void testPut() { // 传参方式：key/value MultiValueMap&lt;String, Object&gt; map = new LinkedMultiValueMap&lt;&gt;(); map.add(\"username\", \"cxy35\"); map.add(\"password\", \"123\"); map.add(\"id\", 99); restTemplateLoadBalanced.put(\"http://provider/user\", map); // 传参方式：JSON User user = new User(); user.setId(98); user.setUsername(\"zhangsan\"); user.setPassword(\"456\"); restTemplateLoadBalanced.put(\"http://provider/user2\", user);} 访问 http://127.0.0.1:1115/testPut 完成测试。 consumer 中的写法基本和 POST 类似，也是两种方式，可以传递两种不同类型的参数。 2.4 DELETEDELETE 也比较容易，我们有两种方式来传递参数， key/value 形式或者 PathVariable（参数放在路径中），首先我们在 provider 中定义两个 DELETE 方法： 1234567891011@DeleteMapping(\"/user\")@ResponseBodypublic void deleteUser(Integer id) { System.out.println(\"deleteUser:\" + id);}@DeleteMapping(\"/user2/{id}\")@ResponseBodypublic void deleteUser2(@PathVariable Integer id) { System.out.println(\"deleteUser2:\" + id);} 然后在 consumer 中调用这两个删除的接口： 123456@GetMapping(\"/testDelete\")public void testDelete() { restTemplateLoadBalanced.delete(\"http://provider/user?id={1}\", 99); restTemplateLoadBalanced.delete(\"http://provider/user2/{1}\", 99);} 访问 http://127.0.0.1:1115/testDelete 完成测试。 delete 中参数的传递，也支持 map ，这块实际上和 get 是一样的。 3 客户端负载均衡 我们知道在 RestTemplate 上添加 @LoadBalanced 注解可以实现负载均衡功能，这里实现的其实是 客户端负载均衡，客户端负载均衡是相对服务端负载均衡而言的。 平时我们用 Nginx 实现的叫 服务端负载均衡。它的一个特点是，就是调用的客户端并不知道具体是哪一个 Server 提供的服务，它也不关心，反正请求发送给 Nginx ， Nginx 再将请求转发给 Tomcat ，客户端只需要记着 Nginx 的地址即可，如下： 客户端负载均衡则是另外一种情形，调用的客户端本身是知道所有 Server 的详细信息的，当需要调用 Server 上的接口的时候，客户端从自身所维护的 Server 列表中，根据提前配置好的负载均衡策略，自己挑选一个 Server 来调用，此时，客户端知道它所调用的是哪一个 Server ，如下： 在 Spring Cloud 中，要想使用负载均衡功能，只需要给 RestTemplate 实例上添加一个 @LoadBalanced 注解即可，此时， RestTemplate 就会自动具备负载均衡功能，这个负载均衡就是客户端负载均衡。 上述功能的实现主要分为三步： 服务消费方 / 调用方（ consumer ）从 Eureka Client 本地缓存的服务注册信息中，选择一个可以调用的服务（ provider ）。 根据 1 中所选择的服务，重构请求 URL 地址。 将 1、2 步的功能嵌入到 RestTemplate 中。 Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 本文示例代码：https://github.com/cxy35/spring-cloud-samples/tree/master/spring-cloud-netflix-eureka/eureka-client-consumer 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/04/13/springcloud/spring-cloud-resttemplate/"},{"title":"Spring Cloud Sleuth 链路追踪","text":"学习在 Spring Cloud 中使用 Sleuth 实现链路追踪，包括基本使用、异步任务、定时任务等功能，并结合 Zipkin 展示收集到的信息。 1 概述 在大规模的分布式系统中，一个完整的系统是由很多种不同的服务来共同支撑的。不同的系统可能分布在上千台服务器上，横跨多个数据中心。一旦系统出问题，此时问题的定位就比较麻烦。在微服务环境下，一次客户端请求，可能会引起数十次、上百次服务端服务之间的调用。一旦请求出问题了，我们需要考虑很多东西： 如何快速定位问题？ 如果快速确定此次客户端调用，都涉及到哪些服务？ 到底是哪一个服务出问题了？ 要解决这些问题，就涉及到 分布式链路追踪 。分布式链路追踪系统主要用来跟踪服务调用记录的，一般来说，一个分布式链路追踪系统，有三个部 分功能： 数据收集。 数据存储。 数据展示。 Spring Cloud Sleuth 是 Spring Cloud 提供的一套分布式链路追踪系统，有 3 个核心概念： Trace：从请求到达系统开始，到给请求做出响应，这样一个过程成为 Trace 。 Span：每次调用服务时，埋入的一个调用记录，成为 Span 。 Annotation：相当于 Span 的语法，描述 Span 所处的状态。 2 基本使用 创建 Spring Boot 项目 sleuth ，添加 Web/Sleuth 依赖，如下： 最终的依赖如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，在 application.properties 配置文件中配置服务名称，这个名称在输出的日志中会体现出来： 1spring.application.name=sleuth 接下来创建一个 HelloController ，定义 hello 接口，打印日志测试（日志与 Sleuth 会自动整合）： 12345678910@RestControllerpublic class HelloController { private static final Logger logger = LoggerFactory.getLogger(HelloController.class); @GetMapping(\"/hello\") public String hello() { logger.info(\"Hello Spring Cloud Sleuth\"); return \"Hello Spring Cloud Sleuth\"; }} 启动应用，访问 http://127.0.0.1:8080/hello 接口，结果如下： 可以看到 Spring Cloud Sleuth 的输出，其中 [sleuth,9309020b37b78ad7,9309020b37b78ad7,false] 表示：服务名称,Trace Id,Span Id, 是否暴露。 然后，在启动类中定义 RestTemplate ，用于服务之间调用： 12345678910111213@SpringBootApplicationpublic class SpringCloudSleuthApplication { public static void main(String[] args) { SpringApplication.run(SpringCloudSleuthApplication.class, args); } @Bean RestTemplate restTemplate() { return new RestTemplate(); }} 再定义两个接口，在 hello2 中调用 hello3，形成调用链： 12345678910111213@GetMapping(\"/hello2\")public String hello2() throws InterruptedException { logger.info(\"hello2\"); Thread.sleep(500); return restTemplate.getForObject(\"http://127.0.0.1:8080/hello3\", String.class);}@GetMapping(\"/hello3\")public String hello3() throws InterruptedException { logger.info(\"hello3\"); Thread.sleep(500); return \"hello3\";} 重新启动应用，访问 http://127.0.0.1:8080/hello2 接口，结果如下： 可以看到一个 Trace 由多个 Span 组成，一个 Trace 相当于就是一个调用链，而一个 Span 则是这个链中的每一次调用过程。 3 异步任务Spring Cloud Sleuth 中也可以收集到异步任务中的信息。 首先，在启动类上通过 @EnableAsync 注解开启异步任务： 1234567891011121314@SpringBootApplication@EnableAsync // 开启异步任务public class SpringCloudSleuthApplication { public static void main(String[] args) { SpringApplication.run(SpringCloudSleuthApplication.class, args); } @Bean RestTemplate restTemplate() { return new RestTemplate(); }} 接着，创建一个 HelloService ，提供一个异步任务方法： 12345678910@Servicepublic class HelloService { private static final Logger logger = LoggerFactory.getLogger(HelloService.class); @Async public String backgroundFun() { logger.info(\"backgroundFun\"); return \"backgroundFun\"; }} 然后，在 HelloController 中调用该异步方法： 123456@GetMapping(\"/hello4\")public String hello4() { logger.info(\"hello4\"); helloService.backgroundFun(); return \"hello4\";} 重新启动应用，访问 http://127.0.0.1:8080/hello4 接口，结果如下： 可以看到异步任务会有一个单独的 Span Id 。 4 定时任务Spring Cloud Sleuth 也可以收集定时任务的信息。 首先，在启动类上通过 @EnableScheduling 注解开启异步任务： 123456789101112131415@SpringBootApplication@EnableAsync // 开启异步任务@EnableScheduling // 开启定时任务public class SpringCloudSleuthApplication { public static void main(String[] args) { SpringApplication.run(SpringCloudSleuthApplication.class, args); } @Bean RestTemplate restTemplate() { return new RestTemplate(); }} 然后在 HelloSerivce 中，添加定时任务，去调用 background 方法。 123456@Scheduled(cron = \"0/10 * * * * ?\")public void sche1() { logger.info(\"start:\"); backgroundFun(); logger.info(\"end:\");} 重新启动应用，结果如下： 可以看到在定时任务中，每一次定时任务都会产生一个新的 Trace ，并且在调用过程中， Span Id 都是一致的，这个和普通的调用不一样。 5 ZipkinZipkin 本身是一个由 Twitter 公司开源的分布式追踪系统，分为 Server 端和 Client 端， Server 用来展示数据， Client 用来收集 + 上报数据。 5.1 准备工作Zipkin 要先把数据存储起来，这里我们使用 Elasticsearch 来存储，首先安装 es 和 es-head（可视化工具，也可以使用 Kibana ）。 es 安装命令：docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; elasticsearch:7.1.0 es-head 安装有三种方式： 直接下载软件安装。 通过 Docker 安装 安装 Chrome/Firefox 插件。 RabbitMQ 安装：略。 Zipkin 安装：docker run -d -p 9411:9411 --name zipkin -e ES_HOSTS=127.0.0.1 -e STORAGE_TYPE=elasticsearch -e ES_HTTP_LOGGING=BASIC -e RABBIT_URI=amqp://guest:guest@127.0.0.1:5672 openzipkin/zipkin Zipkin 安装的参数说明： ES_HOSTS：es 的地址。 STORAGE_TYPE：数据存储方式。 RABBIT_URI：要连接的 Rabbit 的地址。 5.2 实践 创建 Spring Boot 项目 sleuth-zipkin ，添加 Web/Sleuth/Zipkin Client/RabbitMQ/Cloud Stream 依赖，如下： 最终的依赖如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-test-support&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，在 application.properties 配置文件中配置 Sleuth/Zipkin Client/RabbitMQ 等相关信息： 12345678910111213141516171819spring.application.name=sleuth-zipkin# 开启链路追踪spring.sleuth.web.client.enabled=true# 配置采样比例，默认为 0.1spring.sleuth.sampler.probability=1# 开启 zipkinspring.zipkin.enabled=true# zipkin 地址spring.zipkin.base-url=http://127.0.0.1:9411# 追踪消息的发送类型spring.zipkin.sender.type=rabbit# 配置 RabbitMQspring.rabbitmq.host=127.0.0.1spring.rabbitmq.port=5672spring.rabbitmq.username=guestspring.rabbitmq.password=guest 接下来提供一个测试的 HelloController： 12345678910@RestControllerpublic class HelloController { private static final Logger logger = LoggerFactory.getLogger(HelloController.class); @GetMapping(\"/hello\") public String hello(String name) { logger.info(\"sleuth-zipkin-hello\"); return \"hello\" + name + \"!\"; }} 同理，再创建一个类似的 Spring Boot 项目 sleuth-zipkin2 ，设置不同端口 server.port=8081 ，并提供一个 /hello 接口通过 RestTemplate 调用 sleuth-zipkin 中的 /hello 接口，如下： 123456789101112@RestControllerpublic class HelloController { private static final Logger logger = LoggerFactory.getLogger(HelloController.class); @Autowired RestTemplate restTemplate; @GetMapping(\"/hello\") public void hello(String name) { String s = restTemplate.getForObject(\"http://127.0.0.1:8080/hello?name={1}\", String.class, \"cxy35\"); logger.info(s); }} 启动 sleuth-zipkin 和 sleuth-zipkin2 ，访问 http://127.0.0.1:8081/hello 之后，可以查看控制台 Sleuth 的输出信息、 Zipkin Server 端的信息 (http://127.0.0.1:9411/zipkin)、 es-head (软件或插件) 或 Kibana (http://127.0.0.1:5601/) 中的信息、 RabbitMQ 中的信息 (http://127.0.0.1:15672/)。 Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 本文示例代码：https://github.com/cxy35/spring-cloud-samples/tree/master/spring-cloud-sleuth 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/05/17/springcloud/spring-cloud-sleuth/"},{"title":"Spring Cloud Stream 构建消息驱动的微服务","text":"学习在 Spring Cloud 中使用 Stream 构建消息驱动的微服务，包括基本使用、自定义消息通道、消息分组、消息分区、定时任务等功能。 1 概述Spring Cloud Stream 提供了一个微服务和消息中间件之间的粘合剂，这个粘合剂叫做 Binder ， Binder 负责与消息中间件进行交互。而开发者则通过 inputs 或者 outputs 这样的消息通道与 Binder 进行交互。 2 基本使用 创建 Spring Boot 项目 spring-cloud-stream ，添加 Web/RabbitMQ/Cloud Stream 依赖，如下： 最终的依赖如下： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-test-support&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，在 application.properties 配置文件中配置 RabbitMQ 的基本配置信息： 1234spring.rabbitmq.host=127.0.0.1spring.rabbitmq.port=5672spring.rabbitmq.username=guestspring.rabbitmq.password=guest 接下来，创建一个简单的消息接收器： 123456789@EnableBinding(Sink.class) // @EnableBinding 表示绑定 Sink 这个默认的消息通道public class MsgReceiver { public final static Logger logger = LoggerFactory.getLogger(MsgReceiver.class); @StreamListener(Sink.INPUT) public void receive(Object payload) { logger.info(\"MsgReceiver:\" + payload + \"&gt;&gt;&gt;\" + new Date()); }} 启动 RabbitMQ 和项目，再访问 http://127.0.0.1:15672 ，在 RabbitMQ 后台管理页面发送一条消息，上述消息接收器中可以正常收到消息。 3 自定义消息通道 首先，创建一个名为 MyChannel 的接口，作为我们的消息通道： 1234567891011// 自定义消息通道public interface MyChannel { String INPUT = \"cxy35-input\"; String OUTPUT = \"cxy35-output\"; @Output(OUTPUT) MessageChannel output(); @Input(INPUT) SubscribableChannel input();} 注意： 两个消息通道的名字是不一样的。 从 F 版开始，默认使用通道的名称作为实例命令，所以这里的通道名字不可以相同（早期版本可以相同），这样的话，为了能够正常收发消息，需要我们在 application.properties 中做一些额外配置。 123# 绑定消息通道spring.cloud.stream.bindings.cxy35-input.destination=cxy35-topicspring.cloud.stream.bindings.cxy35-output.destination=cxy35-topic 接下来，自定义一个消息接收器，用来接收自己的消息通道里的消息： 123456789@EnableBinding(MyChannel.class) // @EnableBinding 表示绑定 MyMsgReceiver 这个自定义的消息通道public class MyMsgReceiver { public final static Logger logger = LoggerFactory.getLogger(MyMsgReceiver.class); @StreamListener(MyChannel.INPUT) public void receive(Object payload) { logger.info(\"MyMsgReceiver:\" + payload + \"&gt;&gt;&gt;\" + new Date()); }} 再定义一个 HelloController 进行测试： 12345678910@RestControllerpublic class HelloController { @Autowired MyChannel myChannel; @GetMapping(\"/hello\") public void hello() { myChannel.output().send(MessageBuilder.withPayload(\"Hello Stream\").build()); }} 重启项目，访问 http://127.0.0.1:8080/hello ，上述自定义的消息接收器中可以正常收到消息。 4 消息分组 默认情况下，如果消费者是一个集群，一条消息会被多次消费。通过消息分组，我们可以解决这个问题。只需要添加如下配置即可： 123# 设置消息分组spring.cloud.stream.bindings.cxy35-input.group=g1spring.cloud.stream.bindings.cxy35-output.group=g1 接下来，项目打包，启动两个实例。 12java -jar spring-cloud-stream-0.0.1-SNAPSHOT.jar --server.port=8080java -jar spring-cloud-stream-0.0.1-SNAPSHOT.jar --server.port=8081 重启项目，访问 http://127.0.0.1:8080/hello ，发现一条消息只会被其中某一个实例消费。 5 消息分区 通过消息分区可以实现相同特征的消息总是被同一个消费者（实例）处理。只需要添加如下配置即可： 123456789101112# 设置消息分区# 配置消费者：开启消息分区spring.cloud.stream.bindings.cxy35-input.consumer.partitioned=true# 配置消费者：消费者实例个数spring.cloud.stream.instance-count=2# 配置消费者：当前实例的下标，这里指定了一个，多实例启动时指定另一个spring.cloud.stream.instance-index=0# 配置生产者：消息被下标为 1 的消费者（实例）消费spring.cloud.stream.bindings.cxy35-output.producer.partition-key-expression=1# 配置生产者：消费端的节点数量spring.cloud.stream.bindings.cxy35-output.producer.partition-count=2 接下来，项目打包，启动两个实例，启动时要动态修改 spring.cloud.stream.instance-index 参数的值。 12java -jar spring-cloud-stream-0.0.1-SNAPSHOT.jar --server.port=8080 --spring.cloud.stream.instance-index=0java -jar spring-cloud-stream-0.0.1-SNAPSHOT.jar --server.port=8081 --spring.cloud.stream.instance-index=1 重启项目，访问 http://127.0.0.1:8080/hello ，发现的消息只会被 8081 那个实例消费。 6 定时任务 每天定时执行的任务，可以使用 cron 表达式，但有一种比较特殊的定时任务，例如几分钟后执行，这种可以使用 Spring Cloud Stream + RabbitMQ 来实现。先下载 RabbitMQ 相关插件：https://dl.bintray.com/rabbitmq/community-plugins/3.7.x/rabbitmq_delayed_message_exchange/rabbitmq_delayed_message_exchange-20171201-3.7.x.zip 。 执行如下命令： 12345678910# 解压下载的文件unzip rabbitmq_delayed_message_exchange-20171201-3.7.x.zip# 将解压后的文件，拷贝到 Docker 容器中docker cp /root/rabbitmq_delayed_message_exchange-20171201-3.7.x.ez cxy35-rabbit:/plugins# 进入到容器中docker exec -it cxy35-rabbit /bin/bash# 启用插件rabbitmq-plugins enable rabbitmq_delayed_message_exchange# 查看是否启用成功rabbitmq-plugins list 接着，修改配置文件，开启消息延迟功能： 123# 开启消息延迟功能spring.cloud.stream.rabbit.bindings.cxy35-input.consumer.delayed-exchange=truespring.cloud.stream.rabbit.bindings.cxy35-output.producer.delayed-exchange=true 修改消息输入输出通道的 destination 定义： 12spring.cloud.stream.bindings.cxy35-input.destination=delay_msgspring.cloud.stream.bindings.cxy35-output.destination=delay_msg 然后，增加 hello2 接口，在消息发送时，设置消息延迟时间为 3 秒： 123456789101112131415161718@RestControllerpublic class HelloController { public final static Logger logger = LoggerFactory.getLogger(HelloController.class); @Autowired MyChannel myChannel; @GetMapping(\"/hello\") public void hello() { myChannel.output().send(MessageBuilder.withPayload(\"Hello Stream\").build()); } @GetMapping(\"/hello2\") public void hello2() { logger.info(\"send msg:\" + new Date()); myChannel.output().send(MessageBuilder.withPayload(\"Hello Stream 2\").setHeader(\"x-delay\", 3000).build()); }} 重启项目，访问 http://127.0.0.1:8080/hello2 ，发现消息在被发送 3 秒后才会被接收消费。 Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 本文示例代码：https://github.com/cxy35/spring-cloud-samples/tree/master/spring-cloud-stream 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/05/16/springcloud/spring-cloud-stream/"},{"title":"Git 常用命令","text":"Git 常用命令，参考 https://gitee.com/all-about-git 。 概念： 工作区 – git add –&gt; 暂存区 / 缓存区 – git commit –&gt; 本地仓库 – git push –&gt; 远程仓库 1 配置 1234567891011# 显示当前的 Git 配置 $ git config --list# 编辑 Git 配置文件 $ git config -e [--global]# 设置提交代码时的用户信息 $ git config [--global] user.name \"[name]\"$ git config [--global] user.email \"[email address]\"# 配置会保存在当前用户目录下的 .gitconfig 文件中 2 仓库 12345678# 在当前目录新建一个 Git 代码库 $ git init# 新建一个目录，将其初始化为 Git 代码库 $ git init [project-name]# 下载一个项目和它的整个代码历史 $ git clone [url] 3 增加 / 删除文件 123456789101112131415161718192021# 添加指定文件到暂存区 $ git add [file1] [file2] ...# 添加指定目录到暂存区，包括子目录 $ git add [dir]# 添加当前目录的所有文件到暂存区 $ git add .# 添加每个变化前，都会要求确认 # 对于同一个文件的多处变化，可以实现分次提交 $ git add -p# 删除工作区文件，并且将这次删除放入暂存区 $ git rm [file1] [file2] ...# 停止追踪指定文件，但该文件会保留在工作区 $ git rm --cached [file]# 改名文件，并且将这个改名放入暂存区 $ git mv [file-original] [file-renamed] 4 代码提交 123456789101112131415161718# 提交暂存区到仓库区 $ git commit -m [message]# 提交暂存区的指定文件到仓库区 $ git commit [file1] [file2] ... -m [message]# 提交工作区自上次 commit 之后的变化，直接到仓库区 $ git commit -a# 提交时显示所有 diff 信息 $ git commit -v# 使用一次新的 commit，替代上一次提交 # 如果代码没有任何新变化，则用来改写上一次 commit 的提交信息 $ git commit --amend -m [message]# 重做上一次 commit，并包括指定文件的新变化 $ git commit --amend [file1] [file2] ... 5 分支 123456789101112131415161718192021222324252627282930313233343536373839404142# 列出所有本地分支 $ git branch# 列出所有远程分支 $ git branch -r# 列出所有本地分支和远程分支 $ git branch -a# 新建一个分支，但依然停留在当前分支 $ git branch [branch-name]# 新建一个分支，并切换到该分支 $ git checkout -b [branch]# 新建一个分支，指向指定 commit$ git branch [branch] [commit]# 新建一个分支，与指定的远程分支建立追踪关系 $ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区 $ git checkout [branch-name]# 切换到上一个分支 $ git checkout -# 建立追踪关系，在现有分支与指定的远程分支之间 $ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支 $ git merge [branch]# 选择一个 commit，合并进当前分支 $ git cherry-pick [commit]# 删除分支 $ git branch -d [branch-name]# 删除远程分支 $ git push origin --delete [branch-name]$ git branch -dr [remote/branch] 6 标签 1234567891011121314151617181920212223242526# 列出所有 tag$ git tag# 新建一个 tag 在当前 commit$ git tag [tag]# 新建一个 tag 在指定 commit$ git tag [tag] [commit]# 删除本地 tag$ git tag -d [tag]# 删除远程 tag$ git push origin :refs/tags/[tagName]# 查看 tag 信息 $ git show [tag]# 提交指定 tag$ git push [remote] [tag]# 提交所有 tag$ git push [remote] --tags# 新建一个分支，指向某个 tag$ git checkout -b [branch] [tag] 7 查看信息 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# 显示有变更的文件 $ git status# 显示当前分支的版本历史 / 提交日志 $ git log# 显示简略信息 $ git log --pretty=short# 指定文件 $ git log [file]# 显示指定文件相关的每一次变化 diff$ git log -p [file]# 显示 commit 历史，以及每次 commit 发生变更的文件 $ git log --stat# 搜索提交历史，根据关键词 $ git log -S [keyword]# 显示某个 commit 之后的所有变动，每个 commit 占据一行 $ git log [tag] HEAD --pretty=format:%s# 显示某个 commit 之后的所有变动，其 \"提交说明\" 必须符合搜索条件 $ git log [tag] HEAD --grep feature# 显示某个文件的版本历史，包括文件改名 $ git log --follow [file]$ git whatchanged [file]# 显示过去 5 次提交 $ git log -5 --pretty --oneline# 显示所有提交过的用户，按提交次数排序 $ git shortlog -sn# 显示指定文件是什么人在什么时间修改过 $ git blame [file]# 显示工作区和暂存区的差异 $ git diff# 显示工作区和当前分支最新 commit 之间的差异（本地仓库）$ git diff HEAD# 显示暂存区和上一个 commit 的差异 $ git diff --cached [file]# 显示两次提交之间的差异 $ git diff [first-branch]...[second-branch]# 显示今天你写了多少行代码 $ git diff --shortstat \"@{0 day ago}\"# 显示某次提交的元数据和内容变化 $ git show [commit]# 显示某次提交发生变化的文件 $ git show --name-only [commit]# 显示某次提交时，某个文件的内容 $ git show [commit]:[filename]# git reflog 命令可以显示整个本地仓库的 commit, 包括所有 branch 的 commit, 甚至包括已经撤销的 commit, 只要 HEAD 发生了变化, 就会在 reflog 里面看得到。# 而 git log 只显示当前分支的 commit，并且不显示删除掉的 commit。$ git reflog 8 远程同步 123456789101112131415161718192021222324252627# 下载远程仓库的所有变动 $ git fetch [remote]# 显示所有远程仓库 $ git remote -v# 显示某个远程仓库的信息 $ git remote show [remote]# 增加一个新的远程仓库，并命名 $ git remote add [shortname] [url]# 取回远程仓库的变化，并与本地分支合并 $ git pull [remote] [branch]# 上传本地仓库的指定分支到远程仓库 $ git push [remote] [branch]# 上传本地仓库的指定分支到远程仓库，同时设置 upstream，方便后续操作 # -u 参数可以在推送的同时，将 origin 仓库的 master 分支设置为本地仓库当前分支的 upstream（上游），这个参数也只用在第一次 push 时加上，以后直接运行 git push 命令即可。同 git push --set-upstream origin master$ git push -u [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突 $ git push [remote] --force# 推送所有分支到远程仓库 $ git push [remote] --all 9 撤销 12345678910111213141516171819202122232425262728293031# 恢复暂存区的指定文件到工作区 $ git checkout [file]# 恢复某个 commit 的指定文件到暂存区和工作区 $ git checkout [commit] [file]# 恢复暂存区的所有文件到工作区 $ git checkout .# 重置暂存区的指定文件，与上一次 commit 保持一致，但工作区不变 $ git reset [file]# 重置暂存区与工作区，与上一次 commit 保持一致 $ git reset --hard# 重置当前分支的指针为指定 commit，同时重置暂存区，但工作区不变 $ git reset [commit]# 重置当前分支的 HEAD 为指定 commit，同时重置暂存区和工作区，与指定 commit 一致 $ git reset --hard [commit]# 重置当前 HEAD 为指定 commit，但保持暂存区和工作区不变 $ git reset --keep [commit]# 新建一个 commit，用来撤销指定 commit# 后者的所有变化都将被前者抵消，并且应用到当前分支 $ git revert [commit]# 暂时将未提交的变化移除，稍后再移入 $ git stash$ git stash pop 10 其他 12# 生成一个可供发布的压缩包 $ git archive 11 场景 1：推送到远程仓库 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# 初始化本地仓库 testgitgit init testgit# 查看仓库状态，显示 nothing to be commit# git status# 工作区做文件夹 / 文件的增删改查操作 # ......# 查看仓库状态，显示 Untracked files# git status# 添加工作区当前目录的所有文件到暂存区 git add .# 查看仓库状态，显示 Changes to be committed# git status# 提交暂存区的文件到本地仓库 git commit -m \"本次提交的备注信息\"# 查看仓库状态，显示 nothing to be commit# git status# 查看提交日志 # git log# 显示所有远程仓库，显示空 # git remote -v# 在 GitHub 上创建远程仓库 testgit# ......# 关联本地仓库和上述远程仓库，并将远程仓库的名字设置为 origin，方便后续操作 # 只需关联一次，后续提交分支等都不需要再执行了 git remote add origin https://github.com/cxy35/testgit.git# 显示所有远程仓库，显示 origin https://github.com/cxy35/testgit.git# git remote -v# 推送本地仓库的指定分支（这里是 master）到远程仓库 # git push origin master# 推送本地仓库的指定分支（这里是 master）到远程仓库，同时设置 upstream，方便后续操作 # -u 参数可以在推送的同时，将 origin 仓库的 master 分支设置为本地仓库当前分支的 upstream（上游），这个参数也只用在第一次 push 时加上，以后直接运行 git push 命令即可。同 git push --set-upstream origin mastergit push -u origin master# git push# 列出所有本地分支，显示 master# git branch# 列出所有远程分支，显示 origin/master# git branch -r# 列出所有本地分支和远程分支，显示 master、remotes/origin/master# git branch -a# 新建一个分支，但依然停留在当前分支 # git branch fa# 新建一个分支，并切换到该分支 # git checkout -b fa# 切换分支，注意不同分支切换时工作区储藏 Stashing 问题 # git checkout fa# 推送本地仓库的指定分支（这里是 fa）到远程仓库 # git push -u origin fa 12 场景 2：从远程仓库获取 123456789101112131415161718192021222324252627# 克隆一个远程仓库（默认是 master）到本地仓库，放在当前目录下的 testgit 目录中 git clone https://github.com/cxy35/testgit.git testgit# 列出所有本地分支，显示 master# git branch# 列出所有远程分支，显示 origin/fa、origin/master# git branch -r# 列出所有本地分支和远程分支，显示 master、remotes/origin/fa、remotes/origin/master# git branch -a# 根据远程仓库的 fa 分支创建一个本地仓库的 fa 分支，创建完成之后进行切换 git checkout -b fa origin/fa# 根据远程仓库的 fa 分支创建一个本地仓库的 fa 分支，只创建不切换 # git branch fa origin/fa# fa 分支做文件夹 / 文件的增删改查操作 # ......# 提交 fa 分支 # 注意由于 fa 分支就是从远程仓库克隆下来的，所以这里可以不添加 -u 参数 git push# 从远程仓库更新 # git pull 13 场景 3：fork 了别人的项目后，再同步更新别人的提交 12345678910111213141516171819202122# 查看所有远程仓库（origin）git remote -v # 添加远程仓库，指向上游源仓库 git remote add upstream git@github.com:xxx/xxx.git# 查看所有远程仓库（origin、upstream）git remote -v # 下载源仓库所有分支的代码 git fetch upstream# 切换到本地 master 分支 git checkout master# 合并源仓库 master 分支到本地 master 分支 git merge upstream/master# 如果合并时有冲突的话，可以忽略本地分支的改动：git reset --hard upstream/master# 推送本地分支到自己的仓库 # git push origin mastergit push # 更新其他分支的操作类似 # git checkout 其他分支名 # git merge upstream/ 其他分支名 # git push origin 其他分支名 Git 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/02/07/tool/git-command/"},{"title":"Hexo 主题配置 - Icarus","text":"hexo-theme-icarus 主题配置大全，图文并茂，持续更新中。 官方效果图： 我的站点：https://cxy35.com 1 安装 Icarus 主题 参考 hexo-theme-icarus 主题官网 1.1 下载 Icarus 主题 建议你使用 克隆最新版本 的方式，之后的更新可以通过 git pull 来快速更新， 而不用再次下载压缩包替换。 12cd bloggit clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus 1.2 启用 Icarus 主题 与所有 Hexo 主题启用的模式一样。 当 克隆 / 下载 完成后，打开 站点配置文件， 找到 theme 字段，并将其值更改为 icarus。 1234# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: icarus 到此，Icarus 主题安装完成。下一步我们将验证主题是否正确启用。在切换主题之后、验证之前， 我们最好使用 hexo clean 来清除 Hexo 的缓存。 2 配置 Icarus 主题 2.1 设置站点信息 编辑 站点配置文件“，具体配置参考 Hexo 搭建个人博客网站 。 2.2 设置页面文章的篇数 编辑 站点配置文件，具体配置参考 Hexo 搭建个人博客网站 。 2.3 主题配置文件 编辑 主题配置文件，具体配置参考 themes/icarus/_config.yml。 1# ...... 2.4 网站访问量与访客量统计 编辑 主题配置文件，修改配置如下： 1234# BuSuanZi site/page view counter# https://busuanzi.ibruce.info# 网站访问量与访客量统计busuanzi: true 编辑 /themes/icarus/layout/common/footer.ejs 文件，修改如下： 12345678910111213141516171819202122# 注释掉原来的&lt;!-- &lt;% if (busuanzi) { %&gt;&lt;br&gt;&lt;span id=\"busuanzi_container_site_uv\"&gt;&lt;%- _p('plugin.visitor', '&lt;span id=\"busuanzi_value_site_uv\"&gt;0&lt;/span&gt;') %&gt;&lt;/span&gt;&lt;% } %&gt; --&gt;# 新增新的，换了显示的位置&lt;div style=\"text-align: center;\"&gt; &lt;br&gt; &lt;p class=\"is-size-7\"&gt; &lt;% if (busuanzi) { %&gt; &lt;span id=\"busuanzi_container_site_uv\"&gt; &lt;i class=\"fa fa-user\"&gt;&lt;/i&gt; 本站访客数 &lt;span id=\"busuanzi_value_site_uv\"&gt;&lt;/span&gt; 人次 &lt;/span&gt; &lt;span id=\"busuanzi_container_site_pv\"&gt; | &lt;i class=\"fa fa-eye\"&gt;&lt;/i&gt; 本站总访问量 &lt;span id=\"busuanzi_value_site_pv\"&gt;&lt;/span&gt; 次 &lt;/span&gt; &lt;% } %&gt; &lt;/p&gt;&lt;/div&gt; 2.5 网站运行时间统计 编辑 /themes/icarus/layout/common/footer.ejs 文件，修改如下： 1234567891011121314151617&lt;span id=\"timeDate\"&gt;载入天数...&lt;/span&gt;&lt;span id=\"times\"&gt;载入时分秒...&lt;/span&gt;&lt;script&gt; var now = new Date(); function createtime() { var grt= new Date(\"1/2/2020 08:00:00\");// 此处修改你的建站时间或者网站上线时间 now.setTime(now.getTime()+250); days = (now - grt) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); hours = (now - grt) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); if(String(hnum).length ==1 ){hnum = \"0\" + hnum;} minutes = (now - grt) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = \"0\" + mnum;} seconds = (now - grt) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); snum = Math.round(seconds); if(String(snum).length ==1 ){snum = \"0\" + snum;} document.getElementById(\"timeDate\").innerHTML = \"本站已安全运行\"+dnum+\"天\"; document.getElementById(\"times\").innerHTML = hnum + \"小时\" + mnum + \"分\" + snum + \"秒\"; } setInterval(\"createtime()\",250);&lt;/script&gt; 2.6 侧边栏社交链接 编辑 主题配置文件，具体配置参考文件中 widgets - profile - social_links。 2.7 文章首页 / 详情页显示文章缩略图 编辑 主题配置文件，具体配置参考文件中 article - thumbnail。 需要对应的文章顶部 Front-matter 中需要增加参数 thumbnail: /gallery/thumbnails/desert.jpg。 12345---title: Getting Started with Icarusthumbnail: /gallery/thumbnails/desert.jpg---Post content... 2.8 文章详情页时在侧边栏显示目录 编辑 主题配置文件，具体配置参考文件中 widgets - profile - toc。 文章详情页时在侧边栏显示，需要对应的文章顶部 Front-matter 中需要增加参数 toc: true。 12345---title: Table of Contents Exampletoc: true---Post content... 2.9 文章详情页和 page 页布局修改 由于 Icarus 主题的文章详情页和 page 页默认与主页布局一致，皆为三栏布局。但是三栏布局限制了文章内容的展示，因此试图将其改为两栏布局。 编辑 /themes/icarus/layout/layout.ejs 文件，修改如下： 1234567891011121314151617181920# 新增 col() 函数&lt;% function col() { if(!is_post() &amp;&amp; !is_page()) { return main_column_class(); } else { return 'is-6-tablet is-6-desktop is-9-widescreen'; } } %&gt;# 修改 section ，将 main_column_class() 改为 col()&lt;section class=\"section\"&gt; &lt;div class=\"container\"&gt; &lt;div class=\"columns\"&gt; &lt;!-- 将 main_column_class() 改为 col() --&gt; &lt;div class=\"column &lt;%= col() %&gt; has-order-2 column-main\"&gt;&lt;%- body %&gt;&lt;/div&gt; &lt;%- partial('common/widget', { position: 'left' }) %&gt; &lt;%- partial('common/widget', { position: 'right' }) %&gt; &lt;/div&gt; &lt;/div&gt;&lt;/section&gt; 通过上面的修改，发现文章详情页的文章栏确实放大了，但是右侧的部件栏被挤出了屏幕外一部分，极不美观。 编辑 /themes/icarus/layout/common/widget.ejs 文件，修改如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;!-- 原始代码，处理非 post 页面和非 page 页面文章详情页 --&gt;&lt;% if (get_widgets(position).length &amp;&amp; !is_post() &amp;&amp; !is_page()) { %&gt; &lt;!-- 修改，增加 &amp;&amp; !is_post() &amp;&amp; !is_page() 判断 --&gt;&lt;% function side_column_class() { switch (column_count()) { case 2: return 'is-4-tablet is-4-desktop is-4-widescreen'; case 3: return 'is-4-tablet is-4-desktop is-3-widescreen'; } return '';} %&gt;&lt;% function visibility_class() { if (column_count() === 3 &amp;&amp; position === 'right') { return'is-hidden-touch is-hidden-desktop-only'; } return'';} %&gt;&lt;% function order_class() { return position === 'left' ? 'has-order-1' : 'has-order-3';} %&gt;&lt;% function sticky_class(position) { return get_config('sidebar.' + position + '.sticky', false) ? 'is-sticky' : '';} %&gt;&lt;div class=\"column &lt;%= side_column_class() %&gt; &lt;%= visibility_class() %&gt; &lt;%= order_class() %&gt; column-&lt;%= position %&gt; &lt;%= sticky_class(position) %&gt;\"&gt; &lt;% get_widgets(position).forEach(widget =&gt; {%&gt; &lt;%- _partial('widget/'+ widget.type, { widget }) %&gt; &lt;% }) %&gt; &lt;% if (position === 'left') { %&gt; &lt;div class=\"column-right-shadow is-hidden-widescreen &lt;%= sticky_class('right') %&gt;\"&gt; &lt;% get_widgets('right').forEach(widget =&gt; {%&gt; &lt;%- _partial('widget/'+ widget.type, { widget }) %&gt; &lt;% }) %&gt; &lt;/div&gt; &lt;% } %&gt;&lt;/div&gt;&lt;% } %&gt;&lt;!-- 粘贴的部分，处理 post 页面和 page 页面 --&gt;&lt;% if (position === 'left' &amp;&amp; (is_post() || is_page())) { %&gt; &lt;!-- 修改，可选保留的栏，这里是左栏 --&gt;&lt;% function side_column_class() { switch (column_count()) { case 2: return'is-4-tablet is-4-desktop is-4-widescreen'; case 3: return'is-4-tablet is-4-desktop is-3-widescreen'; } return'';} %&gt;&lt;% function visibility_class() { if (column_count() === 3 &amp;&amp; position === 'right') { return 'is-hidden-touch is-hidden-desktop-only'; } return '';} %&gt;&lt;% function order_class() { return position === 'left' ?'has-order-1':'has-order-3';} %&gt;&lt;% function sticky_class(position) { return get_config('sidebar.'+ position +'.sticky', false) ?'is-sticky':'';} %&gt;&lt;div class=\"column &lt;%= side_column_class() %&gt; &lt;%= visibility_class() %&gt; &lt;%= order_class() %&gt; column-&lt;%= position %&gt; &lt;%= sticky_class(position) %&gt;\"&gt; &lt;% get_widgets(position).forEach(widget =&gt; {%&gt; &lt;%- _partial('widget/' + widget.type, { widget }) %&gt; &lt;% }) %&gt; &lt;% if (position === 'left') { %&gt; &lt;div class=\"column-right-shadow is-hidden-widescreen &lt;%= sticky_class('right') %&gt;\"&gt; &lt;% get_widgets('right').forEach(widget =&gt; {%&gt; &lt;%- _partial('widget/' + widget.type, { widget }) %&gt; &lt;% }) %&gt; &lt;/div&gt; &lt;% } %&gt;&lt;/div&gt;&lt;% } %&gt; 2.10 文章详情页分享功能 编辑 主题配置文件，具体配置参考文件中 share - type - ...。 官方分享插件汇总 2.11 文章详情页评论功能 编辑 主题配置文件，具体配置参考文件中 comment - type - ...。 官方评论插件汇总 Gitment注意：开启文章的 Gitment 评论需要在对应的文章详情页登录后点击 Initialize Comments 按钮。当然也可用脚本自动触发。 问题 1：文章详情页登录时报错，跳到： 1https://yoursite.com/?error=redirect_uri_mismatch&amp;error_description=The+redirect_uri+MUST+match+the+registered+callback+URL+for+this+application.&amp;error_uri=https%3A%2F%2Fdeveloper.github.com%2Fapps%2Fmanaging-oauth-apps%2Ftroubleshooting-authorization-request-errors%2F%23redirect-uri-mismatch 原因 1：请求地址 url 中的文件名有空格（标题没影响），可以用 - 隔开。原因 2：申请或配置 GitHub - OAuth Apps 时 Authorization callback URL 的值填写错误，比如 http 和 https 等。 问题 2：文章详情页登录授权之后回调提示 [object ProgressEvent] 编辑 /themes/icarus/layout/comment/gitment.ejs 文件，修改如下： 123456789101112# 搜索&lt;link rel=\"stylesheet\" href=\"https://imsun.github.io/gitment/style/default.css\"&gt;&lt;script src=\"https://imsun.github.io/gitment/dist/gitment.browser.js\"&gt;&lt;/script&gt;# 修改成：&lt;link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/gh/theme-next/theme-next-gitment@1/default.css\"/&gt;&lt;script src=\"https://cdn.jsdelivr.net/gh/theme-next/theme-next-gitment@1/gitment.browser.js\"&gt;&lt;/script&gt;# 或&lt;link rel=\"stylesheet\" href=\"https://wzxjayce.github.io/gitment.css\"&gt;&lt;script src=\"https://wzxjayce.github.io/gitment.js\"&gt;&lt;/script&gt;# 或（汉化）&lt;link rel=\"stylesheet\" href=\"https://billts.site/extra_css/gitment.css\"&gt;&lt;script src=\"https://billts.site/js/gitment.js\"&gt;&lt;/script&gt; 2.12 文章详情页结尾处增加固定的内容 编辑 /themes/icarus/layout/common/articles.ejs 文件，修改如下： 123456789# 在标签 tag 的表单之后增加自己的表单 &lt;% if (!index &amp;&amp; post.layout === 'post') { %&gt;&lt;div class=\"level is-size-6\" style=\"margin-bottom:0px\"&gt; &lt;p&gt; 扫码关注微信公众号 &lt;b&gt;程序员 35&lt;/b&gt; ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。&lt;/p&gt;&lt;/div&gt;&lt;div class=\"level is-size-7\"&gt; &lt;img src=\"/images/config/cxy35.jpg\"&gt;&lt;/div&gt;&lt;% } %&gt; 2.13 TODO - 添加雪花飘落效果2.14 TODO - 鼠标点击特效2.15 TODO - 看板娘插件 Hexo 教程合集 （微信左下方 阅读全文 可直达）。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/01/20/tool/hexo-theme-icarus/"},{"title":"Hexo 搭建个人博客网站","text":"你的门面你做主，手把手带你使用 Hexo 搭建个人博客网站。 1 什么是 Hexo？Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。详见 文档 、 主题。 2 安装 参考 官方文档 2.1 安装前提 安装 Hexo 相当简单。然而在安装前，您必须检查电脑中是否已安装下列应用程序： Node.js (Node.js 版本需不低于 8.6，建议使用 Node.js 10.0 及以上版本) Git 2.2 安装 Git Windows：下载并安装 git，如 Git-2.23.0-64-bit.exe 从上面的链接下载 git for windows 最好挂上一个代理，否则下载速度十分缓慢。也可以参考这个页面，收录了存储于百度云的下载地址。 Linux (Ubuntu, Debian)：sudo apt-get install git-core Linux (Fedora, Red Hat, CentOS)：sudo yum install git-core 2.3 安装 Node.js Windows：对于 windows 用户来说，建议使用 安装程序 进行安装，安装时，请勾选Add to PATH 选项。 另外，您也可以使用 Git Bash，这是 git for windows 自带的一组程序，提供了 Linux 风格的 shell，在该环境下，您可以直接用下面的命令来安装 Node.js。打开它的方法很简单，在任意位置单击右键，选择“Git Bash Here”即可。由于 Hexo 的很多操作都涉及到命令行，您可以考虑始终使用Git Bash 来进行操作。 Linux：安装 Node.js 的最佳方式是使用 nvm。nvm 的开发者提供了一个自动安装 nvm 的简单脚本： curl：$ curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | sh wget：$ wget -qO- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | sh 安装完成后，重启终端并执行下列命令即可安装 Node.js：$ nvm install stable 2.4 安装 Hexo所有必备的应用程序安装完成后，即可使用 npm 安装 Hexo。 1$ npm install -g hexo-cli 3 建站 参考 官方文档 3.1 建站 安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 123$ hexo init blog$ cd blog$ npm install 新建完成后，指定文件夹的目录如下： 12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes _config.yml：网站的 配置 信息，如网站的 title，描述，关键字、图标等。也称做 站点配置文件 ，注意区分 主题配置文件。 package.json：应用程序的信息。EJS, Stylus 和 Markdown renderer 已默认安装，您可以自由移除。 scaffolds：模版 文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件。Hexo 的模板是指在新建的文章文件中默认填充的内容。例如，如果您修改 scaffold/post.md 中的 Front-matter 内容，那么每次新建一篇文章时都会包含这个修改。 source：资源文件夹是存放用户资源的地方。除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。 themes：主题 文件夹。Hexo 会根据主题来生成静态页面。 配置完成后，定位到 blog 目录，执行 hexo s 就可以在本地启动项目了，启动成功后，浏览器中输入 http://127.0.0.1:4000 就可以看到网站了。 3.2 命令 命令 简写 中文含义 hexo server hexo s 本地启动 hexo generate hexo g 生成静态文件 hexo deploy hexo d 部署网站 hexo clean 清除缓存和已经生成的静态文件 3.3 配置 在 Hexo 中有两份主要的配置文件，其名称都是 _config.yml。 其中，一份位于站点根目录下，主要包含 Hexo 本身的配置；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。 为了描述方便，在以下说明中，将前者称为 站点配置文件 ， 后者称为 主题配置文件。 Hexo 默认使用的主题是 landscape，对应 ./themes 目录下的 landscape 文件夹。可切换成其他 主题，选好之后，先将对应的主题 clone 到或下载好拷贝到 ./themes 目录下，再启用即可。建议使用 clone ，使用 clone ，假如有一天这个主题更新了，只需要 pull 一下就可以获取到最新样式了。 网站 编辑 站点配置文件， 设置站点标题 title 、子标题 subtitle 、描述 description 、关键字 keywords 、作者 author 、语言 language 等。 12345678# Sitetitle: 微博客 subtitle: 微博客官方网站上线了 description: 微博客官方网站上线了，微信 / 微博同步上线，欢迎订阅 keywords: 微博客, 博客 author: 微博客language: zh-Hanstimezone: language 支持的语言：zh-Hans / zh-CN / zh-hk / zh-tw / en / ja / ……，取决于你的主题目录下的 languages 中要有 zh-Hans.yml / zh-CN.yml / …… 。 文章12# 安装插件npm install --save hexo-filter-auto-spacing 编辑 站点配置文件，增加这项配置：auto_spacing: true，默认为 false。 12345# Writingnew_post_name: :title.md # File name of new postsdefault_layout: postauto_spacing: truetitlecase: false # Transform title into titlecase 分页 在 Hexo 里可以为首页和归档页面设置不同的文章篇数，但可能需要安装 Hexo 插件。详细步骤如下。 使用 npm install –save 命令来安装需要的 Hexo 插件。 123npm install --save hexo-generator-indexnpm install --save hexo-generator-archivenpm install --save hexo-generator-tag 等待扩展全部安装完成后，在 站点配置文件 中，设定如下选项（per_page 即文章的数量）： 12345678910111213141516# Home page setting# path: Root path for your blogs index page. (default = '')# per_page: Posts displayed per page. (0 = disable pagination)# order_by: Posts order. (Order by date descending by default)index_generator: path: '' per_page: 10 order_by: -datearchive_generator: per_page: 10 yearly: true monthly: truetag_generator: per_page: 10 Hexo 主题配置之 Next具体配置见：Hexo 主题配置 - NexT（微信左下方 阅读全文 可直达 Hexo 教程合集）。 Hexo 主题配置之 Icarus具体配置见：Hexo 主题配置 - Icarus（微信左下方 阅读全文 可直达 Hexo 教程合集）。 3.4 写作【重要】注意：请求地址 url 中的文件名不能有空格（标题没影响），可以用 - 隔开，否则会出问题，比如使用评论插件 Gitment 时会导致登陆时跳到首页。 增加博客后台管理功能 之后也可在后台写作，http://127.0.0.1:4000/admin 你可以执行下列命令来创建一篇新文章或者新的页面。 1$ hexo new [layout] &lt;title&gt; 您可以在命令中指定文章的布局（layout），默认为 post，可以通过修改 _config.yml 中的 default_layout 参数来指定默认布局。 新建页面：hexo new page about 新建文章：hexo new 文章标题 = hexo new post 文章标题 布局（Layout）Hexo 有三种默认布局：post、page 和 draft。在创建者三种不同类型的文件时，它们将会被保存到不同的路径；而您自定义的其他布局和 post 相同，都将储存到 source/_posts 文件夹。 布局 路径 post source/_posts page source draft source/_drafts 如果你不想你的文章被处理，你可以将 Front-Matter 中的layout: 设为 false 。 文件名称Hexo 默认以标题做为文件名称，但您可编辑 new_post_name 参数来改变默认的文件名称，举例来说，设为 :year-:month-:day-:title.md 可让您更方便的通过日期来管理文章。 变量 描述 :title 标题（小写，空格将会被替换为短杠） :year 建立的年份，比如， 2015 :month 建立的月份（有前导零），比如， 04 :i_month 建立的月份（无前导零），比如， 4 :day 建立的日期（有前导零），比如， 07 :i_day 建立的日期（无前导零），比如， 7 草稿 刚刚提到了 Hexo 的一种特殊布局：draft，这种布局在建立时会被保存到 source/_drafts 文件夹，您可通过 publish 命令将草稿移动到 source/_posts 文件夹，该命令的使用方式与 new 十分类似，您也可在命令中指定 layout 来指定布局。 1$ hexo publish [layout] &lt;title&gt; 草稿默认不会显示在页面中，您可在执行时加上 --draft 参数，或是把 render_drafts 参数设为 true 来预览草稿。 模版（Scaffold）在新建文章时，Hexo 会根据 scaffolds 文件夹内相对应的文件来建立文件，例如： 1$ hexo new photo \"My Gallery\" 在执行这行指令时，Hexo 会尝试在 scaffolds 文件夹中寻找 photo.md，并根据其内容建立文章，以下是您可以在模版中使用的变量： 变量 描述 layout 布局 title 标题 date 文件建立日期 4 绑定到 GitHub大家可能已经迫不及待想要把博客上传到 GitHub 了，绑定到 Github 步骤也很简单，首先以 自己的 GitHub ID.github.io 为名创建一个 public 仓库，例如我的 ID 为 abc，创建的仓库为 abc.github.io。 可能需要安装 git 开发者插件： 1npm install --save hexo-deployer-git 创建成功之后，编辑 站点配置文件，配置 GitHub 地址，如下： 1234deploy: type: git repo: git@github.com:abc/abc.github.io.git branch: master 这里根据自己的地址来配置即可，配置完成后，执行如下命令： 12hexo ghexo d 执行完成后，就可以将数据上传到 GitHub 了（当然这里需要大家提前配置一下 GitHub 的公钥，具体可以参考 Git 配置 SSH keys）。 上传成功后，访问 https://cxy35.github.io 就可以看到自己的个人站点了。 如果你对 GitHub 提供的域名不满意，也可以自己申请一个域名，分分钟就配置好了。 5 绑定到域名 域名申请成功之后，接下来的配置，也分为两部分。 5.1 GitHub 配置 首先在博客所在目录下的 source 目录中，创建一个 CNAME 文件，文件内容就是你的域名，如下：www.cxy35.com。 然后执行 hexo d 命令将这个文件上传到 GitHub 就可以了。 5.2 域名解析配置 添加两条 A 记录，指向 GitHub 的 IP 地址，再添加一条 CNAME ，指向你的 GitHub 域名就可以了。 配置成功后，访问 https://www.cxy35.com 就可以看到自己的个人站点了。 Hexo 教程合集 （微信左下方 阅读全文 可直达）。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/09/19/tool/hexo/"},{"title":"Markdown 语法","text":"用 Markdown 写作效率杠杠滴，手把手带你学习 Markdown 语法。 1 通用语法 1.1 标题 示例： 1234567891011# 这是一级标题## 这是二级标题### 这是三级标题#### 这是四级标题##### 这是五级标题###### 这是六级标题 1.2 文本样式 示例 / 效果： 1234567891011121314* 这是倾斜的文字 *** 这是加粗的文字 ***** 这是斜体加粗的文字 ***~~ 这是加删除线的文字~~== 这是高亮的文字（Markdown 标准中不存在）==段落: 段落之间空一行 换行符: 一行结束时输入两个空格 这里换行了 1.3 引用 示例： 12345&gt; 这是引用的内容&gt;&gt; 这是引用的内容&gt;&gt;&gt; 这是引用的内容 效果： 这是引用的内容 这是引用的内容 这是引用的内容 1.4 分割线 示例： 123# 三个或者三个以上的 - 或者 * 都可以：---*** 效果： 1.5 图片 示例： 1![这是图片的描述](https://gss2.bdstatic.com/0.jpg \"这是图片的 title\") 效果： 1.6 超链接 示例： 12[简书](https://jianshu.com)[百度](https://baidu.com \"这是超链接的 title\") 效果： 简书 百度 1.7 列表 示例： 123456789101112131415# 无序列表用 - + * 任何一种都可以：- 无序列表 1- 无序列表 1+ 无序列表 2+ 无序列表 2* 无序列表 3* 无序列表 3# 有序列表用数字加点：1. 有序列表2. 有序列表 2.1. 列表嵌套 2.2. 列表嵌套 效果： 无序列表 1 无序列表 1 无序列表 2 无序列表 2 无序列表 3 无序列表 3 有序列表 有序列表2.1. 列表嵌套2.2. 列表嵌套 1.8 表格 示例： 123456789101112| 姓名 | 技能 | 排行 ||:-|:-:|-:|| 文字默认居左 |- 两边加: 表示文字居中 |- 右边加: 表示文字居右 || 刘备 | 哭哭哭 | 大哥 || 关羽 | 打打打 | 二哥 || 张飞 | 骂骂骂 | 三弟 |第二行分割表头和内容。- 有一个就行，为了对齐，可多加几个 文字默认居左- 两边加：表示文字居中- 右边加：表示文字居右 效果： 姓名 技能 排行 文字默认居左 - 两边加: 表示文字居中 - 右边加: 表示文字居右 刘备 哭哭哭 大哥 关羽 打打打 二哥 张飞 骂骂骂 三弟 1.9 代码 示例： 1234567891011121314151617181920212223242526272829303132333435# 单行代码：代码之间分别用一个反引号包起来：` 这是单行代码 `# 代码块：代码之间分别用三个反引号包起来，且两边的反引号单独占一行：# 注：为了防止冲突前后加了 a，实际上没有。a```javaa// 下面是多行 java 代码// FileName: HelloWorld.javapublic class HelloWorld { // Java 入口程序，程序从此入口 public static void main(String[] args) { System.out.println(\"Hello,World!\"); // 向控制台打印一条语句 }}a```a# 支持以下语言种类：bashclojure，cpp，cs，cssdart，dockerfile, differlanggo，gradle，groovyhaskelljava，javascript，json，juliakotlinlisp，luamakefile，markdown，matlabobjectivecperl，php，pythonr，ruby，rustscala，shell，sql，swifttex，typescriptverilog，vhdlxmlyaml 效果： 这是单行代码 12345678// 下面是多行 java 代码// FileName: HelloWorld.javapublic class HelloWorld { // Java 入口程序，程序从此入口 public static void main(String[] args) { System.out.println(\"Hello,World!\"); // 向控制台打印一条语句 }} 2 特殊语法 来源 https://mdnice.com/ 2.1 脚注 支持平台：微信公众号、知乎。 示例： 12345# 脚注与链接的区别如下所示：链接：[文字](链接)脚注：[正文中显示的脚注文字](脚注中显示的脚注解释 \"脚注中显示的脚注名称\")# 脚注的效果拉到文章最下面观看。 效果： 正文中显示的脚注文字 2.2 代码块 支持平台：微信代码主题仅支持微信公众号！其他主题无限制。 如果在一个行内需要引用代码，只要用反引号引起来就好，如下： Use the printf() function. 在需要高亮的代码块的前一行及后一行使用三个反引号，同时 第一行反引号后面表示代码块所使用的语言，如下： 1234567// FileName: HelloWorld.javapublic class HelloWorld { // Java 入口程序，程序从此入口 public static void main(String[] args) { System.out.println(\"Hello,World!\"); // 向控制台打印一条语句 }} 支持以下语言种类： 123456789101112131415161718bashclojure，cpp，cs，cssdart，dockerfile, differlanggo，gradle，groovyhaskelljava，javascript，json，juliakotlinlisp，luamakefile，markdown，matlabobjectivecperl，php，pythonr，ruby，rustscala，shell，sql，swifttex，typescriptverilog，vhdlxmlyaml 如果想要更换代码主题，可在上方挑选，不支持代码主题自定义。 其中 微信代码主题与微信官方一致，有以下注意事项： 带行号且不换行，代码大小与官方一致 需要在代码块处标志语言，否则无法高亮 粘贴到公众号后，用鼠标点代码块内外一次，完成高亮 diff 不能同时和其他语言的高亮同时显示，且需要调整代码主题为微信代码主题以外的代码主题才能看到 diff 效果，使用效果如下: 12+ 新增项- 删除项 其他主题不带行号，可自定义是否换行，代码大小与当前编辑器一致 2.3 数学公式 支持平台：微信公众号、知乎。 行内公式使用方法，比如这个化学公式：$\\ce{Hg^2+ -&gt;[I-] HgI2 -&gt;[I-] [Hg^{II}I4]^2-}$ 块公式使用方法如下： $$H(D_2) = -\\left(\\frac{2}{4}\\log_2 \\frac{2}{4} + \\frac{2}{4}\\log_2 \\frac{2}{4}\\right) = 1$$ 矩阵： $$ \\begin{pmatrix} 1 &amp; a_1 &amp; a_1^2 &amp; \\cdots &amp; a_1^n \\ 1 &amp; a_2 &amp; a_2^2 &amp; \\cdots &amp; a_2^n \\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\ 1 &amp; a_m &amp; a_m^2 &amp; \\cdots &amp; a_m^n \\ \\end{pmatrix}$$ 公式由于微信不支持，目前的解决方案是转成 svg 放到微信中，无需调整，矢量不失真。 目前测试如果公式量过大，在 Chrome 下会存在粘贴后无响应，但是在 Firefox 中始终能够成功。 2.4 TOC 支持平台：微信公众号、知乎。 示例： 123# TOC 全称为 Table of Content，列出全部标题。由于示例标题过多，需要使用将下方代码段去除即可。# 由于微信只支持到二级列表，本工具仅支持二级标题和三级标题的显示。[[TOC]] 效果： [[TOC]] 2.5 注音符号 支持平台：微信公众号。 示例： 1Markdown Nice 这么好用，简直是 { 喜大普奔 |hē hē hē hē} 呀！ 效果： Markdown Nice 这么好用，简直是 {喜大普奔 |hē hē hē hē} 呀！ 2.6 横屏滑动幻灯片 支持平台：微信公众号。 示例： 12# 通过 `&lt;![](url),![](url)&gt;` 这种语法设置横屏滑动滑动片，具体用法如下：&lt;![蓝 1](https://my-wechat.mdnice.com/mdnice/%E8%93%9D1_20191109174052.jpg),![绿 2](https://my-wechat.mdnice.com/mdnice/%E7%BB%BF2_20191109174052.jpg),![红 3](https://my-wechat.mdnice.com/mdnice/%E7%BA%A23_20191109174052.jpg)&gt; 效果： &lt;),),&gt; 3 其他语法 来源 https://mdnice.com/ 3.1 HTML示例： 123# 支持原生 HTML 语法，请写内联样式，如下：&lt;span style=\"display:block;text-align:right;color:orangered;\"&gt; 橙色居右 &lt;/span&gt;&lt;span style=\"display:block;text-align:center;color:orangered;\"&gt; 橙色居中 &lt;/span&gt; 效果： 橙色居右 橙色居中 3.2 UML不支持，推荐使用开源工具 https://draw.io/ 制作后再导入图片 3.3 组件图床 组件目前共支持 3 种图床和 1 种自定义图床，主要特点如下： 图床 费用 有效期 失败率 SM.MS 免费 长期 高 阿里云 付费 自定义 低 七牛云 10G 免费 自定义 低 自定义 高昂 自定义 自定义 4 个图床的缺点： 图床 缺点 SM.MS 失败率高可用性很差 阿里云 配置繁琐，费用昂贵 七牛云 配置繁琐，需购买长期域名 自定义 搭建后台繁琐 3.4 更多文档 更多文档请参考 markdown-nice-docs 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/10/24/tool/markdown-grammar/"},{"title":"Sublime Text 常用插件","text":"工欲善其事，必先利其器。本文收集 Sublime Text 常用插件，持续更新中…… Package Control 为插件管理包，通过快捷键 Ctrl + Shift + P 打开，之后可以很方便的浏览、安装和卸载 Sublime Text 中的插件。 插件安装：输入 install 后选择 Package Control: Install Package 插件列表：输入 list 后选择 Package Control: List Packages 插件删除：输入 remove 后选择 Package Control: Remove Packages ConvertToUTF8 功能说明：ConvertToUTF8 能将除 UTF8 编码之外的其他编码文件在 Sublime Text 中转换成 UTF8 编码，在打开文件的时候一开始会显示乱码，然后一刹那就自动显示出正常的字体，当然，在保存文件之后原文件的编码格式不会改变。 BracketHighlighter 功能说明：高亮显示匹配的括号、引号和标签。 插件地址：https://github.com/facelessuser/BracketHighlighter/tree/BH2ST3 Emmet 功能说明：Emmet 的前身是大名鼎鼎的 Zen codin。前端开发必备，HTML、CSS 代码快速编写神器。 使用方法：默认快捷键 Tab 插件地址：https://github.com/sergeche/emmet-sublime 辅助工具：PyV8 下载地址：https://github.com/emmetio/pyv8-binaries 注意：Emmet 插件需要 PyV8 插件的支持，所以在安装 Emmet 时，会自动安装 PyV8 插件，如果安装后 Emmet 不能正常使用，很有可能是因为 PyV8 没有安装完全，Sublime Text 2 和 3 容易出现这个问题。你可以删除它，然后手动下载，采用方法二安装 PyV8 插件。 使用方法示例：书写代码 ul#nav&gt;li.item$*8&gt;a{Item $}，然后把光标定在这行代码的最后面，按 Tab 键，就会自动生成。更多更详细的使用方法，请查阅 Emmet 官网：http://docs.emmet.io/ JsFormat 功能说明：JavaScript 代码格式化。 使用方法：在打开的 JavaScript 文件里点右键，选择 JsFormat。 插件地址：https://github.com/jdc0589/jsformat Compact Expand CSS Command 功能说明：使 CSS 属性展开及收缩，格式化 CSS 代码。 使用方法：按 Ctrl+Alt+[ 收缩 CSS 代码为一行显示，按 Ctrl+Alt+] 展开 CSS 代码为多行显示。 插件地址：https://gist.github.com/vitaLee/2863474 或者：https://github.com/TooBug/CompactExpandCss Color Highlighter 功能说明：显示所选颜色值的颜色，并集成了 ColorPicker 使用方法：在 16 进制的颜色值上点右键，选择 Choose color ，会弹出颜色拾色器，在需要的色块上单击。 插件地址：https://github.com/Monnoroch/ColorHighlighter SublimeTmpl 功能说明：快速生成文件模板。 使用方法：SublimeTmp l 默认的快捷键如下，如果快捷键设置冲突可能无效。 Ctrl+Alt+H：新建 html 文件 Ctrl+Alt+J：新建 javascript 文件 Ctrl+Alt+C：新建 css 文件 Ctrl+Alt+P：新建 php 文件 Ctrl+Alt+R：新建 ruby 文件 Ctrl+Alt+Shift+P：新建 python 文件 插件地址：https://github.com/kairyou/SublimeTmpl 新增语言：你还可以增加模板文件夹中没有的文件模板，并做相应的设置来使用这一功能。具体可以参考它的中文文档：http://www.fantxi.com/blog/archives/sublime-template-engine-sublimetmpl/ Alignment 功能说明：使代码格式的自动对齐。 使用方法：快捷键 Ctrl+Alt+A，可能与 QQ 截图冲突，二者中的一个要重置快捷键。 插件地址：[https://github.com/kevinsperrine/sublime_alignment])(https://github.com/kevinsperrine/sublime_alignment) AutoFileName 功能说明：自动补全文件（目录）名。 使用方法：安装好后就可以来测试如何使用 AutoFileName，先以 &lt;link href=&quot;&quot;&gt; 档案来示范，当输入 href=&quot;&quot; 的同时，Sublime Text 就会将现在编辑档案的路径为中心，判断该路径内的所有档案。其他的也类似，如：&lt;img src=&quot;&quot;&gt; 等。 插件地址：https://github.com/BoundInCode/AutoFileName DocBlockr 功能说明：快速生成 JavaScript (including ES6), PHP, ActionScript, Haxe, CoffeeScript, TypeScript, Java, Groovy, Objective C, C, C++ and Rust 语言函数注释。 使用方法：在函数上面输入 /** , 然后按 Tab 就会自动生成注释。 插件地址：https://github.com/spadgos/sublime-jsdocs SublimeCodeIntel 功能说明：智能提示。 插件地址：https://github.com/SublimeCodeIntel/SublimeCodeIntel HTML-CSS-JS Prettify 功能说明：HTML、CSS、JS 格式化。 插件地址：https://github.com/victorporof/Sublime-HTMLPrettify 安装方法：安裝这个套件前必须先安裝 node.js，指定 node.exe 的执行档所在位置。进而安装 HTML-CSS-JS Prettify。 使用方法一：View -&gt; Show console 或者使用快捷键（Ctrl + ），在命令列的地方輸入：view.run_command(“htmlprettify”)，然后按下 Enter`。 使用方法二：默认快捷键：Ctrl+Shift+H。你也可以自行设置快捷键，如：设置成 Ctrl+Shfit+O，选择菜单 Preferences---&gt; Key Bindings – User 里新增： 1234{ &quot;keys&quot;: [&quot;ctrl+shift+o&quot;], &quot;command&quot;: &quot;htmlprettify&quot; } SideBarEnhancements 功能说明：侧栏菜单扩充功能。 插件地址：https://github.com/titoBouzout/SideBarEnhancements/tree/st3 View In Browser 功能说明：Sublime Text 保存后网页自动同步更新。 插件地址：https://github.com/adampresley/sublime-view-in-browser 使用方法：在打开的文档任一处点右键，选择 View In Browser，就会用默认的浏览器自动打开该文件。同时 Chrome 浏览器也要安装 LiveReload 的扩展插件。 LiveReload 功能说明：调试网页实时自动更新。 使用说明：快捷键 Ctr+Alt+V 插件地址：https://github.com/dz0ny/LiveReload-sublimetext2 TortoiseSVN 功能说明：版本控制工具。 插件地址：https://github.com/dexbol/sublime-TortoiseSVN 其他说明：win 下需要安装有 TortoiseSVN 客户端支持 Theme-Soda 功能说明：最受欢迎的 Sublime Text 主题之一。 使用说明：安装完成后，点菜单 Preferences -&gt; Settings - User，根据需要的主题效果，添加对应的配置。 插件地址：https://github.com/buymeasoda/soda-theme Theme-Flatland 功能说明：最受欢迎的 Sublime Text 主题之一。 插件地址：https://github.com/thinkpixellab/flatland Theme-Nexus 功能说明：最受欢迎的 Sublime Text 主题之一。 插件地址：https://github.com/EleazarCrusader/nexus-theme 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/11/02/tool/sublime-plugins/"},{"title":"MySQL 备份与恢复","text":"多种姿势实现 MySQL 备份与恢复。 1 备份1.1 mysqldump 命令12345678910111213141516171819202122# 备份本机中所有数据库/usr/local/mysql/bin/mysqldump -uroot -p123456 --all-databases &gt; /usr/local/mysqldata/bak/allDbs.sql# 备份本机中多个数据库，空格分隔/usr/local/mysql/bin/mysqldump -uroot -p123456 --databases db1 db2 &gt; /usr/local/mysqldata/bak/dbs.sql# 备份本机中 1 个数据库 db1/usr/local/mysql/bin/mysqldump -uroot -p123456 --databases db1 &gt; /usr/local/mysqldata/bak/db1.sql# 备份本机中 1 个数据库 db1 中的多张表，空格分隔/usr/local/mysql/bin/mysqldump -uroot -p123456 db1 tb1 tb2 &gt; /usr/local/mysqldata/bak/tbs.sql# 备份本机中 1 个数据库 db1 中的 1 张表 tb1/usr/local/mysql/bin/mysqldump -uroot -p123456 db1 tb1 &gt; /usr/local/mysqldata/bak/tb1.sql# 备份远程机器中 1 个数据库 db1 中的 1 张表 tb1/usr/local/mysql/bin/mysqldump -h192.168.71.23 -P3306 -uroot -p123456 db1 tb1 &gt; /usr/local/mysqldata/bak/tb1.sql# 备份远程机器中 1 个数据库 db1 中的 1 张表 tb1，带 where 查询条件：/usr/local/mysql/bin/mysqldump -h192.168.71.23 -P3306 -uroot -p123456 db1 tb1 --where=\"id='1'or id='2'\" &gt; /usr/local/mysqldata/bak/tb1.sql 常用参数： –single-transaction 和 –master-data=2：要实现点对点的备份恢复，或者对于某点的数据完整备份，必须使用这两个参数。 –single-transaction：用了该参数不锁表？？对于数据库的影响时间比较长，影响范围比较大，但是加入该参数后，对于多张大表的备份速度肯定会加快。 更多参数说明见下文。 1.2 select into outfile12345678-- 登录 mysql/usr/local/mysql/bin/mysql -uroot -p123456 -S /usr/local/mydata/tmp/mysql.sockuse db1;select * from tb1 into outfile '/usr/local/mysqldata/bak/tb1.data' fields terminated by '|' enclosed by '\"' lines terminated by '\\r\\n';-- select * into outfile'/usr/local/mysqldata/bak/tb1.data'fields terminated by'|'enclosed by'\"' lines terminated by '\\r\\n' from tb1; 这种方法的好处是，导出的数据可以自己规定格式，并且导出的是纯数据，不存在建表信息，你可以直接导入另外一个同数据库的不同表中，相对于 mysqldump 比较灵活机动。注意 terminated by 的格式导出与导入时要保持一致。 2 恢复2.1 mysql 命令12345# 恢复本机中 1 个数据库 db1 中的数据/usr/local/mysql/bin/mysql -uroot -p123456 db1 &lt; /usr/local/mysqldata/bak/tb1.sql# 恢复远程机器中 1 个数据库 db1 中的数据/usr/local/mysql/bin/mysql -h192.168.71.23 -P3306 -uroot -p123456 db1 &lt; /usr/local/mysqldata/bak/tb1.sql 2.2 source 命令123456789-- 登录 mysql/usr/local/mysql/bin/mysql -uroot -p123456 -S /usr/local/mydata/tmp/mysql.sockuse db1;-- 这里的字符集跟你的将要导入的数据库的字符集一致set names utf8;source /usr/local/mysqldata/bak/tb1.sql 2.3 load data infile123456-- 登录 mysql/usr/local/mysql/bin/mysql -uroot -p123456 -S /usr/local/mydata/tmp/mysql.sockuse db1;load data infile '/usr/local/mysqldata/bak/tb1.data' into table tb1 fields terminated by '|' enclosed by '\"' lines terminated by '\\r\\n' ; 3 mysqldump 参数说明 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344--all-databases , -A 导出全部数据库。mysqldump -uroot -p --all-databases--all-tablespaces , -Y导出全部表空间。mysqldump -uroot -p --all-databases --all-tablespaces--no-tablespaces , -y不导出任何表空间信息。mysqldump -uroot -p --all-databases --no-tablespaces--add-drop-database每个数据库创建之前添加 drop 数据库语句。mysqldump -uroot -p --all-databases --add-drop-database--add-drop-table每个数据表创建之前添加 drop 数据表语句。(默认为打开状态，使用 --skip-add-drop-table 取消选项)mysqldump -uroot -p --all-databases (默认添加 drop 语句)mysqldump -uroot -p --all-databases –skip-add-drop-table (取消 drop 语句)--add-locks在每个表导出之前增加 LOCK TABLES 并且之后 UNLOCK TABLE。(默认为打开状态，使用 --skip-add-locks 取消选项)mysqldump -uroot -p --all-databases (默认添加 LOCK 语句)mysqldump -uroot -p --all-databases –skip-add-locks (取消 LOCK 语句)--allow-keywords允许创建是关键词的列名字。这由表名前缀与每个列名做到。mysqldump -uroot -p --all-databases --allow-keywords--apply-slave-statements在 'CHANGE MASTER' 前添加 'STOP SLAVE'，并且在导出的最后添加 'START SLAVE'。mysqldump -uroot -p --all-databases --apply-slave-statements--character-sets-dir字符集文件的目录 mysqldump -uroot -p --all-databases --character-sets-dir=/usr/local/mysql/share/mysql/charsets--comments 附加注释信息。默认为打开，可以用 --skip-comments 取消 mysqldump -uroot -p --all-databases (默认记录注释)mysqldump -uroot -p --all-databases --skip-comments (取消注释)--compatible 导出的数据将和其它数据库或旧版本的 MySQL 相兼容。值可以为 ansi、mysql323、mysql40、postgresql、oracle、mssql、db2、maxdb、no_key_options、no_tables_options、no_field_options 等，要使用几个值，用逗号将它们隔开。它并不保证能完全兼容，而是尽量兼容。mysqldump -uroot -p --all-databases --compatible=ansi--compact导出更少的输出信息 (用于调试)。去掉注释和头尾等结构。可以使用选项：--skip-add-drop-table --skip-add-locks --skip-comments --skip-disable-keysmysqldump -uroot -p --all-databases --compact--complete-insert, -c 使用完整的 insert 语句 (包含列名称)。这么做能提高插入效率，但是可能会受到 max_allowed_packet 参数的影响而导致插入失败。mysqldump -uroot -p --all-databases --complete-insert--compress, -C 在客户端和服务器之间启用压缩传递所有信息 mysqldump -uroot -p --all-databases --compress--create-options, -a 在 CREATE TABLE 语句中包括所有 MySQL 特性选项。(默认为打开状态)mysqldump -uroot -p --all-databases--databases, -B导出几个数据库。参数后面所有名字参量都被看作数据库名。mysqldump -uroot -p --databases test mysql--debug输出 debug 信息，用于调试。默认值为：d:t:o,/tmp/mysqldump.tracemysqldump -uroot -p --all-databases --debugmysqldump -uroot -p --all-databases --debug=” d:t:o,/tmp/debug.trace”--debug-check检查内存和打开文件使用说明并退出。mysqldump -uroot -p --all-databases --debug-check--debug-info输出调试信息并退出 mysqldump -uroot -p --all-databases --debug-info--default-character-set 设置默认字符集，默认值为 utf8mysqldump -uroot -p --all-databases --default-character-set=latin1--delayed-insert采用延时插入方式（INSERT DELAYED）导出数据 mysqldump -uroot -p --all-databases --delayed-insert--delete-master-logsmaster 备份后删除日志. 这个参数将自动激活 --master-data。mysqldump -uroot -p --all-databases --delete-master-logs--disable-keys 对于每个表，用 /*!40000 ALTER TABLE tbl_name DISABLE KEYS */; 和 /*!40000 ALTER TABLE tbl_name ENABLE KEYS */; 语句引用 INSERT 语句。这样可以更快地导入 dump 出来的文件，因为它是在插入所有行后创建索引的。该选项只适合 MyISAM 表，默认为打开状态。mysqldump -uroot -p --all-databases --dump-slave该选项将导致主的 binlog 位置和文件名追加到导出数据的文件中。设置为 1 时，将会以 CHANGE MASTER 命令输出到数据文件；设置为 2 时，在命令前增加说明信息。该选项将会打开 --lock-all-tables，除非 --single-transaction 被指定。该选项会自动关闭 --lock-tables 选项。默认值为 0。mysqldump -uroot -p --all-databases --dump-slave=1mysqldump -uroot -p --all-databases --dump-slave=2--events, -E导出事件。mysqldump -uroot -p --all-databases --events--extended-insert, -e使用具有多个 VALUES 列的 INSERT 语法。这样使导出文件更小，并加速导入时的速度。默认为打开状态，使用 --skip-extended-insert 取消选项。mysqldump -uroot -p --all-databasesmysqldump -uroot -p --all-databases--skip-extended-insert (取消选项)--fields-terminated-by导出文件中忽略给定字段。与 --tab 选项一起使用，不能用于 --databases 和 --all-databases 选项 mysqldump -uroot -p test test --tab=”/home/mysql” --fields-terminated-by=”#”--fields-enclosed-by 输出文件中的各个字段用给定字符包裹。与 --tab 选项一起使用，不能用于 --databases 和 --all-databases 选项 mysqldump -uroot -p test test --tab=”/home/mysql” --fields-enclosed-by=”#”--fields-optionally-enclosed-by 输出文件中的各个字段用给定字符选择性包裹。与 --tab 选项一起使用，不能用于 --databases 和 --all-databases 选项 mysqldump -uroot -p test test --tab=”/home/mysql” --fields-enclosed-by=”#” --fields-optionally-enclosed-by =”#”--fields-escaped-by 输出文件中的各个字段忽略给定字符。与 --tab 选项一起使用，不能用于 --databases 和 --all-databases 选项 mysqldump -uroot -p mysql user --tab=”/home/mysql” --fields-escaped-by=”#”--flush-logs 开始导出之前刷新日志。请注意：假如一次导出多个数据库 (使用选项 --databases 或者 --all-databases)，将会逐个数据库刷新日志。 除使用 --lock-all-tables 或者 --master-data 外。在这种情况下，日志将会被刷新一次，相应的所以表同时被锁定。因此，如果打算同时导出和刷新日志应该使用 --lock-all-tables 或者 --master-data 和 --flush-logs。mysqldump -uroot -p --all-databases --flush-logs--flush-privileges在导出 mysql 数据库之后，发出一条 FLUSH PRIVILEGES 语句。为了正确恢复，该选项应该用于导出 mysql数据库和依赖 mysql 数据库数据的任何时候。mysqldump -uroot -p --all-databases --flush-privileges--force在导出过程中忽略出现的 SQL 错误。mysqldump -uroot -p --all-databases --force--help显示帮助信息并退出。mysqldump --help--hex-blob使用十六进制格式导出二进制字符串字段。如果有二进制数据就必须使用该选项。影响到的字段类型有 BINARY、VARBINARY、BLOB。mysqldump -uroot -p --all-databases --hex-blob--host, -h需要导出的主机信息 mysqldump -uroot -p --host=localhost --all-databases--ignore-table 不导出指定表。指定忽略多个表时，需要重复多次，每次一个表。每个表必须同时指定数据库和表名。例如：--ignore-table=database.table1 --ignore-table=database.table2 ……mysqldump -uroot -p --host=localhost --all-databases --ignore-table=mysql.user--include-master-host-port在 --dump-slave 产生的 'CHANGE MASTER TO..' 语句中增加 'MASTER_HOST=&lt;host&gt;，MASTER_PORT=&lt;port&gt;' mysqldump -uroot -p --host=localhost --all-databases --include-master-host-port--insert-ignore在插入行时使用 INSERT IGNORE 语句.mysqldump -uroot -p --host=localhost --all-databases --insert-ignore--lines-terminated-by输出文件的每行用给定字符串划分。与 --tab 选项一起使用，不能用于 --databases 和 --all-databases 选项。mysqldump -uroot -p --host=localhost test test --tab=”/tmp/mysql” --lines-terminated-by=”##”--lock-all-tables, -x提交请求锁定所有数据库中的所有表，以保证数据的一致性。这是一个全局读锁，并且自动关闭 --single-transaction 和 --lock-tables 选项。mysqldump -uroot -p --host=localhost --all-databases --lock-all-tables--lock-tables, -l开始导出前，锁定所有表。用 READ LOCAL 锁定表以允许 MyISAM 表并行插入。对于支持事务的表例如 InnoDB 和 BDB，--single-transaction 是一个更好的选择，因为它根本不需要锁定表。请注意当导出多个数据库时，--lock-tables 分别为每个数据库锁定表。因此，该选项不能保证导出文件中的表在 数据库之间的逻辑一致性。不同数据库表的导出状态可以完全不同。mysqldump -uroot -p --host=localhost --all-databases --lock-tables--log-error附加警告和错误信息到给定文件 mysqldump -uroot -p --host=localhost --all-databases --log-error=/tmp/mysqldump_error_log.err--master-data 该选项将 binlog 的位置和文件名追加到输出文件中。如果为 1，将会输出 CHANGE MASTER 命令；如果为 2，输出的 CHANGE MASTER 命令前添加注释信息。该选项将打开 --lock-all-tables 选项，除非 --single-transaction 也被指定（在这种情况下，全局读锁在开始导出时获得很短的时间；其他内容参考下面的 --single-transaction 选项）。该选项自动关闭 --lock-tables 选项。mysqldump -uroot -p --host=localhost --all-databases --master-data=1;mysqldump -uroot -p --host=localhost --all-databases --master-data=2;--max_allowed_packet服务器发送和接受的最大包长度。mysqldump -uroot -p --host=localhost --all-databases --max_allowed_packet=10240--net_buffer_lengthTCP/IP 和 socket 连接的缓存大小。mysqldump -uroot -p --host=localhost --all-databases --net_buffer_length=1024--no-autocommit使用 autocommit/commit 语句包裹表。mysqldump -uroot -p --host=localhost --all-databases --no-autocommit--no-create-db, -n只导出数据，而不添加 CREATE DATABASE 语句。mysqldump -uroot -p --host=localhost --all-databases --no-create-db--no-create-info, -t只导出数据，而不添加 CREATE TABLE 语句。mysqldump -uroot -p --host=localhost --all-databases --no-create-info--no-data, -d不导出任何数据，只导出数据库表结构。mysqldump -uroot -p --host=localhost --all-databases --no-data--no-set-names, -N等同于 --skip-set-charsetmysqldump -uroot -p --host=localhost --all-databases --no-set-names--opt等同于 --add-drop-table, --add-locks, --create-options, --quick, --extended-insert, --lock-tables, --set-charset, --disable-keys 该选项默认开启, 可以用 --skip-opt 禁用.mysqldump -uroot -p --host=localhost --all-databases --opt--order-by-primary如果存在主键，或者第一个唯一键，对每个表的记录进行排序。在导出 MyISAM 表到 InnoDB 表时有效，但会使得导出工作花费很长时间。 mysqldump -uroot -p --host=localhost --all-databases --order-by-primary--password, -p连接数据库密码 --pipe(windows 系统可用) 使用命名管道连接 mysqlmysqldump -uroot -p --host=localhost --all-databases --pipe--port, -P连接数据库端口号 --protocol 使用的连接协议，包括：tcp, socket, pipe, memory.mysqldump -uroot -p --host=localhost --all-databases --protocol=tcp--quick, -q不缓冲查询，直接导出到标准输出。默认为打开状态，使用 --skip-quick 取消该选项。mysqldump -uroot -p --host=localhost --all-databases mysqldump -uroot -p --host=localhost --all-databases --skip-quick--quote-names,-Q使用（`）引起表和列名。默认为打开状态，使用 --skip-quote-names 取消该选项。mysqldump -uroot -p --host=localhost --all-databasesmysqldump -uroot -p --host=localhost --all-databases --skip-quote-names--replace使用 REPLACE INTO 取代 INSERT INTO.mysqldump -uroot -p --host=localhost --all-databases --replace--result-file, -r直接输出到指定文件中。该选项应该用在使用回车换行对（\\\\r\\\\n）换行的系统上（例如：DOS，Windows）。该选项确保只有一行被使用。mysqldump -uroot -p --host=localhost --all-databases --result-file=/tmp/mysqldump_result_file.txt--routines, -R导出存储过程以及自定义函数。mysqldump -uroot -p --host=localhost --all-databases --routines--set-charset添加 'SET NAMES default_character_set' 到输出文件。默认为打开状态，使用 --skip-set-charset 关闭选项。mysqldump -uroot -p --host=localhost --all-databases mysqldump -uroot -p --host=localhost --all-databases --skip-set-charset--single-transaction该选项在导出数据之前提交一个 BEGIN SQL 语句，BEGIN 不会阻塞任何应用程序且能保证导出时数据库的一致性状态。它只适用于多版本存储引擎，仅 InnoDB。本选项和 --lock-tables 选项是互斥的，因为 LOCK TABLES 会使任何挂起的事务隐含提交。要想导出大表的话，应结合使用 --quick 选项。mysqldump -uroot -p --host=localhost --all-databases --single-transaction--dump-date将导出时间添加到输出文件中。默认为打开状态，使用 --skip-dump-date 关闭选项。mysqldump -uroot -p --host=localhost --all-databasesmysqldump -uroot -p --host=localhost --all-databases --skip-dump-date--skip-opt禁用–opt 选项.mysqldump -uroot -p --host=localhost --all-databases --skip-opt--socket,-S指定连接 mysql 的 socket 文件位置，默认路径 /tmp/mysql.sockmysqldump -uroot -p --host=localhost --all-databases --socket=/tmp/mysqld.sock--tab,-T为每个表在给定路径创建 tab 分割的文本文件。注意：仅仅用于 mysqldump 和 mysqld 服务器运行在相同机器上。mysqldump -uroot -p --host=localhost test test --tab=&quot;/home/mysql&quot;--tables覆盖 --databases (-B)参数，指定需要导出的表名。mysqldump -uroot -p --host=localhost --databases test --tables test--triggers导出触发器。该选项默认启用，用 --skip-triggers 禁用它。mysqldump -uroot -p --host=localhost --all-databases --triggers--tz-utc在导出顶部设置时区 TIME_ZONE='+00:00' ，以保证在不同时区导出的 TIMESTAMP 数据或者数据被移动其他时区时的正确性。mysqldump -uroot -p --host=localhost --all-databases --tz-utc--user, -u指定连接的用户名。--verbose, --v输出多种平台信息。--version, -V输出 mysqldump 版本信息并退出 --where, -w 只转储给定的 WHERE 条件选择的记录。请注意如果条件包含命令解释符专用空格或字符，一定要将条件引用起来。mysqldump -uroot -p --host=localhost --all-databases --where=” user=’root’”--xml, -X导出 XML 格式.mysqldump -uroot -p --host=localhost --all-databases --xml--plugin_dir客户端插件的目录，用于兼容不同的插件版本。mysqldump -uroot -p --host=localhost --all-databases --plugin_dir=”/usr/local/lib/plugin”--default_auth客户端插件默认使用权限。mysqldump -uroot -p --host=localhost --all-databases --default-auth=”/usr/local/lib/plugin/&lt;PLUGIN&gt;” 4 第三方工具 - mydumper详细使用参考：MySQL 备份与恢复 - mydumper 5 第三方工具 - xtrabackup详细使用参考：MySQL 备份与恢复 - xtrabackup 6 扩展阅读MySQL 大量数据快速导入导出：http://blog.csdn.net/xiaobaismiley/article/details/41015783 学会用各种姿势备份 MySQL 数据库：http://www.cnblogs.com/liangshaoye/p/5464794.html MySQL 教程合集 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/10/12/mysql/mysql-bak-mysqldump/"},{"title":"Redis 基本数据类型（字符串、列表、集合、散列、有序集合）","text":"Redis 中的数据都是以 key/value 的形式存储的，key 都是字符串，value 支持多种不同的数据类型，其中基本数据类型有：String(含 Bit)、List、Set、Hash、ZSet。 1 StringString 是 redis 中最基本的数据类型，redis 中的 String 类型是二进制安全的，即它可以包含任何数据，比如一个序列化的对象甚至一张 jpg 图片，要注意的是 redis 中的字符串大小上限是 512M 。 String 是动态字符串，内部可以修改，像 Java 中的 StringBuﬀer ，它采用分配冗余空间的方式来减少内存的频繁分配。在 Redis 内部结构中，一般实际分配的内存会大于需要的内存，当字符串小于 1M 的时候，扩容都是在现有的空间基础上加倍，扩容每次扩 1M 空间，最大 512M 。 1.1 String set 给一个 key 设置 value 。 12127.0.0.1:6379&gt; set k1 helloOK get 获取对应 key 的 value，如果 key 不存在则返回 nil 。 123456127.0.0.1:6379&gt; set k1 helloOK127.0.0.1:6379&gt; get k1\"hello\"127.0.0.1:6379&gt; get k2(nil) getrange 用来返回 key 对应的 value 的子串，类似于 Java 里的 substring 。子串由 start 和 end 决定，从左往右计算，如果下标是负数，则从右往左计算，其中 -1 表示最后一个字符， -2 是倒数第二个… 12345678127.0.0.1:6379&gt; set k1 helloredisOK127.0.0.1:6379&gt; getrange k1 0 4\"hello\"127.0.0.1:6379&gt; getrange k1 0 -1\"helloredis\"127.0.0.1:6379&gt; getrange k1 -5 -1\"redis\" setrange 用来覆盖一个已经存在的 key 的 value 。 12345678127.0.0.1:6379&gt; set k1 helloredisOK127.0.0.1:6379&gt; get k1\"helloredis\"127.0.0.1:6379&gt; setrange k1 5 world(integer) 10127.0.0.1:6379&gt; get k1\"helloworld\" mset/mget 用来批量设置值和批量获取值。 123456127.0.0.1:6379&gt; mset k1 java k2 php k3 c++OK127.0.0.1:6379&gt; mget k1 k2 k31) \"java\"2) \"php\"3) \"c++\" getset 获取 key 所对应的 value ，并对 key 进行重置 。 12345678127.0.0.1:6379&gt; set k1 helloOK127.0.0.1:6379&gt; get k1\"hello\"127.0.0.1:6379&gt; getset k1 helloredis\"hello\"127.0.0.1:6379&gt; get k1\"helloredis\" append 使用 append 命令时，如果 key 已经存在，则直接在对应的 value 后追加值，否则就创建新的键值对。 12345678127.0.0.1:6379&gt; append k1 hello(integer) 5127.0.0.1:6379&gt; get k1\"hello\"127.0.0.1:6379&gt; append k1 redis(integer) 10127.0.0.1:6379&gt; get k1\"helloredis\" strlen 用来计算 key 的 value 的长度。 1234127.0.0.1:6379&gt; set k1 helloredisOK127.0.0.1:6379&gt; strlen k1(integer) 10 setnx 是 set if not exists 的简写，set 命令在执行时，如果 key 已经存在，则新值会覆盖掉旧值，而对于 setnx 命令，如果 key 已经存在，则不做任何操作，如果 key 不存在，则效果等同于 set 命令。 123456789101112127.0.0.1:6379&gt; set k1 helloredisOK127.0.0.1:6379&gt; get k1\"helloredis\"127.0.0.1:6379&gt; setnx k1 helloworld(integer) 0127.0.0.1:6379&gt; get k1\"helloredis\"127.0.0.1:6379&gt; setnx k2 helloworld(integer) 1127.0.0.1:6379&gt; get k2\"helloworld\" msetnx 兼具了 setnx 和 mset 的特性，但在执行时，如果有一个 key 存在，则所有的都不会执行。 12345678910127.0.0.1:6379&gt; set k1 javaOK127.0.0.1:6379&gt; get k1\"java\"127.0.0.1:6379&gt; msetnx k1 php k2 c++(integer) 0127.0.0.1:6379&gt; get k1\"java\"127.0.0.1:6379&gt; get k2(nil) ttl/pttl 查看 key 的有效期（秒 / 毫秒）， -1 表示一直有效， -2 表示已过期，默认为 -1 。 setex 用来给 key 设置 value ，同时设置过期时间（单位是秒），等效于先给 key 设置 value ，再给 key 设置过期时间。 12345678127.0.0.1:6379&gt; setex k1 10 helloredisOK127.0.0.1:6379&gt; ttl k1(integer) 8127.0.0.1:6379&gt; pttl k1(integer) 3040127.0.0.1:6379&gt; get k1(nil) psetex 作用和 setex 类似，不同的是，这里设置过期时间的单位是毫秒。 123456127.0.0.1:6379&gt; psetex k1 10000 helloredisOK127.0.0.1:6379&gt; ttl k1(integer) 8127.0.0.1:6379&gt; pttl k1(integer) 3575 incr/decr 可以对指定 key 的 value 执行加 / 减 1 操作，如果指定的 key 不存在，那么在加 / 减 1 操作之前，会先将 key 的 value 设置为 0 ，如果 key 的 value 不是数字，则会报错。 1234127.0.0.1:6379&gt; incr k1(integer) 1127.0.0.1:6379&gt; incr k1(integer) 2 incrby/decrby 和 incr/decr 功能类似，不同的是可以指定步长。 12345678127.0.0.1:6379&gt; incrby k1 5(integer) 5127.0.0.1:6379&gt; incrby k1 5(integer) 10127.0.0.1:6379&gt; incrby k2 -2(integer) -2127.0.0.1:6379&gt; incrby k2 -2(integer) -4 incrbyﬂoat 和 incrby 类似，但是自增的步长可以设置为浮点数。 12345678127.0.0.1:6379&gt; incrbyfloat k1 0.6\"0.6\"127.0.0.1:6379&gt; incrbyfloat k1 0.6\"1.2\"127.0.0.1:6379&gt; incrbyfloat k2 -0.8\"-0.8\"127.0.0.1:6379&gt; incrbyfloat k2 -0.8\"-1.6\" 1.2 Bit在 Redis 中，字符串都是以二进制的方式来存储的。例如 set k1 a ， a 对应的 ASCII 码是 97 ，转为二进制是 01100001 ，BIT 相关的命令就是对二进制进行操作的。 getbit 可以返回 key 对应的 value 在 offset 处的 bit 值，以上文提到的 k1 为例， a 对应的二进制数据是 01100001 ，所以当 offset 为 0 时，对应的 bit 值为 0 ； offset 为 1 时，对应的 bit 值为 1 ； offset 为 2 时，对应的 bit 值为 1 ；offset 为 3 时，对应的 bit 值为 0，依此类推… 123456789101112131415161718127.0.0.1:6379&gt; set k1 aOK127.0.0.1:6379&gt; getbit k1 0(integer) 0127.0.0.1:6379&gt; getbit k1 1(integer) 1127.0.0.1:6379&gt; getbit k1 2(integer) 1127.0.0.1:6379&gt; getbit k1 3(integer) 0127.0.0.1:6379&gt; getbit k1 4(integer) 0127.0.0.1:6379&gt; getbit k1 5(integer) 0127.0.0.1:6379&gt; getbit k1 6(integer) 0127.0.0.1:6379&gt; getbit k1 7(integer) 1 setbit 可以用来修改二进制数据，比如 a 对应的 ASCII 码为 97，c 对应的 ASCII 码为 99，97 转为二进制是 01100001 ，99 转为二进制是 01100011 ，两个的差异在于第六位一个是 0 一个是 1 ，通过 SETBIT 命令，我们可以将 k1 的第六位的 0 改为 1 （第六位是从 0 开始算）。 123456127.0.0.1:6379&gt; set k1 aOK127.0.0.1:6379&gt; setbit k1 6 1(integer) 0127.0.0.1:6379&gt; get k1\"c\" 此时，k1 中存储的字符也就变为了 c 。 setbit 在执行时所返回的数字，表示该位上原本的 bit 值。 bitcount 可以用来统计这个二进制数据中 1 的个数。 1234127.0.0.1:6379&gt; set k1 aOK127.0.0.1:6379&gt; bitcount k1(integer) 3 关于 bitcount ， redis 官网上有一个非常有意思的案例：用户上线次数统计。节选部分原文如下： 举个例子，如果今天是网站上线的第 100 天，而用户 peter 在今天阅览过网站，那么执行命令 setbit peter 100 1 ；如果明天 peter 也继续阅览网站，那么执行命令 setbit peter 101 1 ，以此类推。当要计算 peter 总共以来的上线次数时，就使用 bitcount 命令：执行 bitcount peter ，得出的结果就是 peter 上线的总天数。 这种统计方式最大的好处就是节省空间并且运算速度快。每天占用一个 bit，一年也就 365 个 bit，10 年也就 10*365 个 bit ，也就是 456 个字节，对于这么大的数据，bit 的操作速度非常快。 bitop 可以对一个或者多个二进制位串执行并 (and)、或 (or)、异或 (xor) 以及非 (not) 运算，如下：a 对应的 ASCII 码转为二进制是 01100001 ，c 对应的二进制位串是 01100011 。对这两个二进制位串分别执行 and\\or\\xor 的结果如下： 12345678910111213141516127.0.0.1:6379&gt; set k1 aOK127.0.0.1:6379&gt; set k2 cOK127.0.0.1:6379&gt; bitop and k3 k1 k2(integer) 1127.0.0.1:6379&gt; get k3\"a\"127.0.0.1:6379&gt; bitop or k3 k1 k2(integer) 1127.0.0.1:6379&gt; get k3\"c\"127.0.0.1:6379&gt; bitop xor k3 k1 k2(integer) 1127.0.0.1:6379&gt; get k3\"\\x02\" 另外， bitop 也可以执行 not 运算，但是注意参数个数，如下： 12127.0.0.1:6379&gt; bitop not k3 k4(integer) 1 这里会对 k4 的二进制位串取反，将取反结果交给 k3 。 bitpos 用来获取二进制位串中第一个 1 或者 0 的位置。 123456127.0.0.1:6379&gt; set k1 aOK127.0.0.1:6379&gt; bitpos k1 1(integer) 1127.0.0.1:6379&gt; bitpos k1 0(integer) 0 也可以在后面设置一个范围，不过后面的范围是字节的范围，而不是二进制位串的范围。 2 ListList 是一个简单的 字符串列表，按照插入顺序进行排序，我们可以从 List 的头部 (LEFT) 或者尾部 (RIGHT) 插入或弹出一个元素。 lpush/rpush 将一个或多个值 value 插入到列表 key 的表头，如果有多个 value 值，那么各个 value 值按从左到右 / 从右到左的顺序依次插入到表头，类似入栈。如果 key 不存在，那么在进行 push 操作前会创建一个空列表。 如果 key 对应的值不是一个 list 的话，那么会返回一个错误。 123456789101112127.0.0.1:6379&gt; lpush k1 aa bb cc(integer) 3127.0.0.1:6379&gt; lrange k1 0 -11) \"cc\"2) \"bb\"3) \"aa\"127.0.0.1:6379&gt; rpush k2 aa bb cc(integer) 3127.0.0.1:6379&gt; lrange k2 0 -11) \"aa\"2) \"bb\"3) \"cc\" lrange 返回列表 key 中指定区间内的元素，区间以偏移量 start 和 stop 指定，下标 (index) 参数 start 和 stop 都以 0 为底，即 0 表示列表的第一个元素，1 表示列表的第二个元素，以此类推。我们也可以使用负数下标，以 -1 表示列表的最后一个元素， -2 表示列表的倒数第二个元素，以此类推。 123456789127.0.0.1:6379&gt; lpush k1 aa bb cc(integer) 3127.0.0.1:6379&gt; lrange k1 0 11) \"cc\"2) \"bb\"127.0.0.1:6379&gt; lrange k1 0 -11) \"cc\"2) \"bb\"3) \"aa\" lindex 可以返回列表 key 中，下标为 index 的元素，正数下标 0 表示第一个元素，也可以使用负数下标，-1 表示倒数第一个元素。 12345678910127.0.0.1:6379&gt; lpush k1 aa bb cc(integer) 3127.0.0.1:6379&gt; lrange k1 0 -11) \"cc\"2) \"bb\"3) \"aa\"127.0.0.1:6379&gt; lindex k1 0\"cc\"127.0.0.1:6379&gt; lindex k1 -1\"aa\" ltrim 可以对一个列表进行修剪，即让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。下标与之前介绍的写法都一致，这里不赘述。 1234567891011127.0.0.1:6379&gt; lpush k1 aa bb cc(integer) 3127.0.0.1:6379&gt; lrange k1 0 -11) \"cc\"2) \"bb\"3) \"aa\"127.0.0.1:6379&gt; ltrim k1 0 1OK127.0.0.1:6379&gt; lrange k1 0 -11) \"cc\"2) \"bb\" lpop/rpop 可以移除并返回列表 key 的头 / 尾元素。 123456789101112131415127.0.0.1:6379&gt; lpush k1 aa bb cc(integer) 3127.0.0.1:6379&gt; lrange k1 0 -11) \"cc\"2) \"bb\"3) \"aa\"127.0.0.1:6379&gt; lpop k1\"cc\"127.0.0.1:6379&gt; lrange k1 0 11) \"bb\"2) \"aa\"127.0.0.1:6379&gt; rpop k1\"aa\"127.0.0.1:6379&gt; lrange k1 0 11) \"bb\" blpop/brpop 阻塞式列表的弹出原语。它是命令 lpop/rpop 的阻塞版本，当给定列表内没有任何元素可供弹出的时候，连接将被该命令阻塞。当给定多个 key 参数时，按参数 key 的先后顺序依次检查各个列表，弹出第一个非空列表的头元素。同时，在使用该命令时也需要指定阻塞的时长，时长单位为秒，在该时长内如果没有元素可供弹出，则阻塞结束。返回的结果是 key 和 value 的组合。 123456789101112131415161718127.0.0.1:6379&gt; lpush k1 aa bb cc(integer) 3127.0.0.1:6379&gt; lrange k1 0 -11) \"cc\"2) \"bb\"3) \"aa\"127.0.0.1:6379&gt; blpop k1 101) \"k1\"2) \"cc\"127.0.0.1:6379&gt; blpop k1 101) \"k1\"2) \"bb\"127.0.0.1:6379&gt; blpop k1 101) \"k1\"2) \"aa\"127.0.0.1:6379&gt; blpop k1 10(nil)(10.06s) 3 SetSet 是 String 类型的无序集合 ，不同于 List ，Set 中的元素 不可以重复。 sadd 添加一个或多个指定的 member 元素到集合的 key 中，指定的一个或者多个元素 member 如果已经在集合 key 中存在则忽略，如果集合 key 不存在，则新建集合 key ，并添加 member 元素到集合 key 中。 12127.0.0.1:6379&gt; sadd k1 aa bb cc(integer) 3 smembers 返回 key 集合所有的元素。 123456127.0.0.1:6379&gt; sadd k1 aa bb cc(integer) 3127.0.0.1:6379&gt; smembers k11) \"cc\"2) \"bb\"3) \"aa\" srem 在 key 集合中移除指定的元素，如果指定的元素不是 key 集合中的元素则忽略。如果 key 集合不存在则被视为一个空的集合，该命令返回 0 。 123456789127.0.0.1:6379&gt; sadd k1 aa bb cc(integer) 3127.0.0.1:6379&gt; srem k1 aa(integer) 1127.0.0.1:6379&gt; srem k1 dd(integer) 0127.0.0.1:6379&gt; smembers k11) \"cc\"2) \"bb\" sismember 返回成员 member 是否是存储的集合 key 的成员。 123456127.0.0.1:6379&gt; sadd k1 aa bb cc(integer) 3127.0.0.1:6379&gt; sismember k1 aa(integer) 1127.0.0.1:6379&gt; sismember k1 dd(integer) 0 scard 返回 key 对应的集合中成员的数量。 1234127.0.0.1:6379&gt; sadd k1 aa bb cc(integer) 3127.0.0.1:6379&gt; scard k1(integer) 3 srandmember 仅需我们提供 key 参数，它就会随机返回 key 集合中的一个元素，从 Redis 2.6 开始，该命令也可以接受一个可选的 count 参数，如果 count 是整数且小于元素的个数，则返回 count 个随机元素，如果 count 是整数且大于集合中元素的个数时，则返回集合中的所有元素，当 count 是负数，则会返回一个包含 count 的绝对值的个数元素的数组，如果 count 的绝对值大于元素的个数，则返回的结果集里会出现一个元素出现多次的情况。 12345678910111213141516171819127.0.0.1:6379&gt; sadd k1 aa bb cc(integer) 3127.0.0.1:6379&gt; srandmember k1\"aa\"127.0.0.1:6379&gt; srandmember k1 21) \"aa\"2) \"bb\"127.0.0.1:6379&gt; srandmember k1 51) \"cc\"2) \"aa\"3) \"bb\"127.0.0.1:6379&gt; srandmember k1 -11) \"cc\"127.0.0.1:6379&gt; srandmember k1 -51) \"cc\"2) \"aa\"3) \"aa\"4) \"aa\"5) \"cc\" spop 用法和 srandmember 类似，不同的是， spop 每次选择一个随机的元素之后，该元素会出栈，而 srandmember 则不会出栈，只是将该元素展示出来。 1234567127.0.0.1:6379&gt; sadd k1 aa bb cc(integer) 3127.0.0.1:6379&gt; spop k1\"cc\"127.0.0.1:6379&gt; smembers k11) \"bb\"2) \"aa\" smove 将 source 集合中的一个 member 从 source 集合移动到 destination 集合中。 123456789127.0.0.1:6379&gt; sadd k1 aa bb cc(integer) 3127.0.0.1:6379&gt; smove k1 k2 aa(integer) 1127.0.0.1:6379&gt; smembers k11) \"cc\"2) \"bb\"127.0.0.1:6379&gt; smembers k21) \"aa\" sdiﬀ/sinter/sunion 用来返回一个集合与给定集合的差集 / 交集 / 并集的元素。 12345678910111213141516127.0.0.1:6379&gt; sadd k1 aa bb cc(integer) 3127.0.0.1:6379&gt; sadd k2 bb cc dd(integer) 3127.0.0.1:6379&gt; sdiff k1 k21) \"aa\"127.0.0.1:6379&gt; sdiff k2 k11) \"dd\"127.0.0.1:6379&gt; sinter k1 k21) \"cc\"2) \"bb\"127.0.0.1:6379&gt; sunion k1 k21) \"aa\"2) \"bb\"3) \"dd\"4) \"cc\" sdiﬀstore/sinterstore/sunionstore 与 sdiﬀ/sinter/sunion 命令基本一致，不同的是会将结果保存在一个集合中。 1234567891011121314151617181920127.0.0.1:6379&gt; sadd k1 aa bb cc(integer) 3127.0.0.1:6379&gt; sadd k2 bb cc dd(integer) 3127.0.0.1:6379&gt; sdiffstore k3 k1 k2(integer) 1127.0.0.1:6379&gt; smembers k31) \"aa\"127.0.0.1:6379&gt; sinterstore k4 k1 k2(integer) 2127.0.0.1:6379&gt; smembers k41) \"cc\"2) \"bb\"127.0.0.1:6379&gt; sunionstore k5 k1 k2(integer) 4127.0.0.1:6379&gt; smembers k51) \"aa\"2) \"bb\"3) \"dd\"4) \"cc\" 4 HashHash 类似于 Java 中的 Map ，是一个 键值对集合，在 Redis 中可以用来存储对象。很多时候， Hash 就像一个微缩版的 Redis 。 在 Hash 结构中， key 是一个字符串， value 则是一个 key/value 键值对。 hset 用来设置 key 指定的哈希集中指定字段的值。 12127.0.0.1:6379&gt; hset k1 name cxy35(integer) 1 hget 用来返回 key 指定的哈希集中该字段所关联的值。 1234127.0.0.1:6379&gt; hset k1 name cxy35(integer) 1127.0.0.1:6379&gt; hget k1 name\"cxy35\" hmset/hmget 批量设置 / 返回 key 指定的哈希集中指定字段的值。 123456127.0.0.1:6379&gt; hmset k1 name cxy35 age 18 city HZOK127.0.0.1:6379&gt; hmget k1 name age city1) \"cxy35\"2) \"18\"3) \"HZ\" hvals 返回 key 指定的哈希集中所有字段的值。 123456127.0.0.1:6379&gt; hmset k1 name cxy35 age 18 city HZOK127.0.0.1:6379&gt; hvals k11) \"cxy35\"2) \"18\"3) \"HZ\" hkeys 返回 key 指定的哈希集中所有字段的名字 123456127.0.0.1:6379&gt; hmset k1 name cxy35 age 18 city HZOK127.0.0.1:6379&gt; hkeys k11) \"name\"2) \"age\"3) \"city\" hgetall 返回 key 指定的哈希集中所有的字段和值。返回值中，每个字段名的下一个是它的值，所以返回值的长度是哈希集大小的两倍。 123456789127.0.0.1:6379&gt; hmset k1 name cxy35 age 18 city HZOK127.0.0.1:6379&gt; hgetall k11) \"name\"2) \"cxy35\"3) \"age\"4) \"18\"5) \"city\"6) \"HZ\" hdel 从 key 指定的哈希集中移除指定的域 ﬁeld ，在哈希集中不存在的域将被忽略。 123456789101112127.0.0.1:6379&gt; hmset k1 name cxy35 age 18 city HZOK127.0.0.1:6379&gt; hmget k1 name age city1) \"cxy35\"2) \"18\"3) \"HZ\"127.0.0.1:6379&gt; hdel k1 city(integer) 1127.0.0.1:6379&gt; hmget k1 name age city1) \"cxy35\"2) \"18\"3) (nil) hsetnx 只在 key 指定的哈希集中不存在指定的字段时，设置字段的值，如果字段已存在，该操作无效果。 12345678910111213127.0.0.1:6379&gt; hmset k1 name cxy35 age 18OK127.0.0.1:6379&gt; hmget k1 name age1) \"cxy35\"2) \"18\"127.0.0.1:6379&gt; hsetnx k1 age 20(integer) 0127.0.0.1:6379&gt; hsetnx k1 city HZ(integer) 1127.0.0.1:6379&gt; hmget k1 name age city1) \"cxy35\"2) \"18\"3) \"HZ\" hexists 返回 hash 里面 field 是否存在。 123456127.0.0.1:6379&gt; hmset k1 name cxy35 age 18OK127.0.0.1:6379&gt; hexists k1 name(integer) 1127.0.0.1:6379&gt; hexists k1 city(integer) 0 hincrby 增加 key 指定的哈希集中指定字段的数值。如果 key 不存在，会创建一个新的哈希集并与 key 关联。如果字段不存在，则字段的值在该操作执行前被设置为 0 ， hincrby 支持的值的范围限定在 64 位有符号整数。 123456789101112127.0.0.1:6379&gt; hmset k1 name cxy35 age 18OK127.0.0.1:6379&gt; hincrby k1 age 5(integer) 23127.0.0.1:6379&gt; hget k1 age\"23\"127.0.0.1:6379&gt; hincrby k2 age 3(integer) 3127.0.0.1:6379&gt; hincrby k2 age 3(integer) 6127.0.0.1:6379&gt; hget k2 age\"6\" hincrbyﬂoat 与 hincrby 用法基本一致，只不过这里允许 float 类型的数据，不赘述。 12127.0.0.1:6379&gt; hincrbyfloat k2 age 2.5\"8.5\" hlen 返回 key 指定的哈希集包含的字段的数量。 1234127.0.0.1:6379&gt; hmset k1 name cxy35 age 18OK127.0.0.1:6379&gt; hlen k1(integer) 2 hstrlen 返回 hash 指定 field 的 value 的字符串长度，如果 hash 或者 field 不存在，返回 0 。 123456127.0.0.1:6379&gt; hmset k1 name cxy35 age 18OK127.0.0.1:6379&gt; hstrlen k1 name(integer) 5127.0.0.1:6379&gt; hstrlen k1 city(integer) 0 5 ZSetZSet 和 Set 一样，也是 String 类型的有序集合 ，不同的是 ZSet 中的每个元素都会关联一个 double 类型的分数 score ，里面的元素总是通过 score 进行着排序。 ZSet 中的 成员都是唯一的，但是所关联的分数可以重复。 zadd 将所有指定成员添加到键为 key 的有序集合里面。添加时可以指定多个分数 / 成员（score/member）对。 如果指定添加的成员已经是有序集合里面的成员，则会更新该成员的分数（scrore）并更新到正确的排序位置。 12127.0.0.1:6379&gt; zadd k1 10 v1(integer) 1 zscore 返回有序集 key 中，成员 member 的 score 值。 1234127.0.0.1:6379&gt; zadd k1 10 v1(integer) 1127.0.0.1:6379&gt; zscore k1 v1\"10\" zrange/zrevrange 根据 index 返回 member ，该命令在执行时加上 withscores 参数可以连同 score 一起返回。 zrevrange 与 zrange 类似，但是倒叙。 1234567891011121314151617181920127.0.0.1:6379&gt; zadd k1 10 v1 20 v2 30 v3(integer) 3127.0.0.1:6379&gt; zrange k1 0 11) \"v1\"2) \"v2\"127.0.0.1:6379&gt; zrevrange k1 0 11) \"v3\"2) \"v2\"127.0.0.1:6379&gt; zrange k1 0 1 withscores1) \"v1\"2) \"10\"3) \"v2\"4) \"20\"127.0.0.1:6379&gt; zrange k1 0 -1 withscores1) \"v1\"2) \"10\"3) \"v2\"4) \"20\"5) \"v3\"6) \"30\" zrangebyscore 按照 score 范围返回 member ，加上 withscores 可以连 score 一起返回。 12345678910127.0.0.1:6379&gt; zadd k1 10 v1 20 v2 30 v3(integer) 3127.0.0.1:6379&gt; zrangebyscore k1 10 201) \"v1\"2) \"v2\"127.0.0.1:6379&gt; zrangebyscore k1 10 20 withscores1) \"v1\"2) \"10\"3) \"v2\"4) \"20\" zrangebylex 返回有序集合中指定成员之间的成员。 123456789127.0.0.1:6379&gt; zadd k1 10 v1 20 v2 30 v3(integer) 3127.0.0.1:6379&gt; zrangebylex k1 - +1) \"v1\"2) \"v2\"3) \"v3\"127.0.0.1:6379&gt; zrangebylex k1 [v1 [v21) \"v1\"2) \"v2\" 注意：可以用 - 和 + 表示得分最小值和最大值，如果使用成员名的话，一定要在成员名之前加上 [。 zrem 从集合中弹出一个元素。 123456789127.0.0.1:6379&gt; zadd k1 10 v1 20 v2 30 v3(integer) 3127.0.0.1:6379&gt; zrem k1 v1(integer) 1127.0.0.1:6379&gt; zrange k1 0 -1 withscores1) \"v2\"2) \"20\"3) \"v3\"4) \"30\" zcard 返回 key 的有序集元素个数。 1234127.0.0.1:6379&gt; zadd k1 10 v1 20 v2 30 v3(integer) 3127.0.0.1:6379&gt; zcard k1(integer) 3 zcount 返回有序集 key 中， score 值在 min 和 max 之间（默认闭区间）的成员数量。 123456127.0.0.1:6379&gt; zadd k1 10 v1 20 v2 30 v3(integer) 3127.0.0.1:6379&gt; zcount k1 10 20(integer) 2127.0.0.1:6379&gt; zcount k1 (10 20(integer) 1 zlexcount 返回有序集合中指定成员之间的成员数量。 123456127.0.0.1:6379&gt; zadd k1 10 v1 20 v2 30 v3(integer) 3127.0.0.1:6379&gt; zlexcount k1 - +(integer) 3127.0.0.1:6379&gt; zlexcount k1 [v1 [v2(integer) 2 注意：可以用 - 和 + 表示得分最小值和最大值，如果使用成员名的话，一定要在成员名之前加上 [。 zrank/zrevrank 返回有序集 key 中成员 member 的排名。其中有序集成员按 score 值递增（从小到大 / 从大到小）顺序排列。排名以 0 为基数，即 score 值最小的成员排名为 0 。 12345678127.0.0.1:6379&gt; zadd k1 10 v1 20 v2 30 v3(integer) 3127.0.0.1:6379&gt; zrank k1 v1(integer) 0127.0.0.1:6379&gt; zrank k1 v3(integer) 2127.0.0.1:6379&gt; zrevrank k1 v3(integer) 0 zincrby 为有序集 key 的成员 member 的 score 值加上增量 increment 。如果 key 中不存在 member ，就在 key 中添加一个 member ，score 是 increment（就好像它之前的 score 是 0.0）。如果 key 不存在，就创建一个只含有指定 member 成员的有序集合。 12345678910127.0.0.1:6379&gt; zadd k1 10 v1 20 v2 30 v3(integer) 3127.0.0.1:6379&gt; zincrby k1 6 v1\"16\"127.0.0.1:6379&gt; zscore k1 v1\"16\"127.0.0.1:6379&gt; zincrby k2 3 v1\"3\"127.0.0.1:6379&gt; zscore k2 v1\"3\" zinterstore 计算给定的 numkeys 个有序集合的交集，并且把结果放到 destination 中。 在给定要计算的 key 和其它参数之前，必须先给定 key 个数 numberkeys 。该命令也可以在执行的过程中给原 score 乘以 weights 后再求和。 1234567891011121314151617181920212223242526127.0.0.1:6379&gt; zadd k2 2 v1(integer) 1127.0.0.1:6379&gt; zadd k2 3 v2(integer) 1127.0.0.1:6379&gt; zadd k2 4 v3(integer) 1127.0.0.1:6379&gt; zadd k3 9 v2(integer) 1127.0.0.1:6379&gt; zadd k3 10 v3(integer) 1127.0.0.1:6379&gt; zadd k3 11 v4(integer) 1127.0.0.1:6379&gt; zinterstore k4 2 k2 k3(integer) 2127.0.0.1:6379&gt; zrange k4 0 -1 withscores1) \"v2\"2) \"12\"3) \"v3\"4) \"14\"127.0.0.1:6379&gt; zinterstore k5 2 k2 k3 weights 3 1(integer) 2127.0.0.1:6379&gt; zrange k5 0 -1 withscores1) \"v2\"2) \"18\"3) \"v3\"4) \"22\" Redis 教程合集 （微信左下方 阅读全文 可直达）。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/05/31/redis/redis-datatype/"},{"title":"Spring Boot 整合 Elasticsearch","text":"学习在 Spring Boot 中使用 Elasticsearch。在 Spring Boot 中，使用的 Elasticsearch 实际上是 Spring Data Elasticsearch ， Spring Data 是 Spring 家族的一个子项目，用于简化 SQL 和 NoSQL 的访问，在 Spring Data 中，只要你的 方法名称符合规范，它就知道你想干什么，不需要自己再去写 SQL 。 1 概述1.1 简介Elasticsearch 是一个基于 Lucene 的搜索服务器。它提供了一个分布式的全文搜索引擎，基于 restful web 接口。Elasticsearch 是用 Java 语言开发的，基于 Apache 协议的开源项目，是目前最受欢迎的企业搜索引擎。Elasticsearch 广泛运用于云计算中，能够达到实时搜索，具有稳定，可靠，快速的特点。 1.2 基本概念 Near Realtime（近实时）：Elasticsearch 是一个近乎实时的搜索平台，这意味着从索引文档到可搜索文档之间只有一个轻微的延迟(通常是一秒钟)。 Cluster（集群）：集群是一个或多个节点的集合，它们一起保存整个数据，并提供跨所有节点的联合索引和搜索功能。每个集群都有自己的唯一集群名称，节点通过名称加入集群。 Node（节点）：节点是指属于集群的单个 Elasticsearch 实例，存储数据并参与集群的索引和搜索功能。可以将节点配置为按集群名称加入特定集群，默认情况下，每个节点都设置为加入一个名为 elasticsearch 的集群。 Index（索引）：索引是一些具有相似特征的文档集合，类似于 MySQL 中数据库的概念。 Type（类型）：类型是索引的逻辑类别分区，通常，为具有一组公共字段的文档类型，类似于 MySQL 中表的概念。注意：由于一些原因，在 Elasticsearch 6.0 以后，一个 Index 只能含有一个 Type。这其中的原因是：相同 index 的不同映射 type 中具有相同名称的字段是相同；在 Elasticsearch 索引中，不同映射 type 中具有相同名称的字段在 Lucene 中被同一个字段支持。在默认的情况下是 _doc 。在未来 8.0 的版本中，type 将被彻底删除。 Document（文档）：文档是可被索引的基本信息单位，以 JSON 形式表示，类似于 MySQL 中行的概念。 Field（字段）：类似于 MySQL 中列的概念。 Shards（分片）：当索引存储大量数据时，可能会超出单个节点的硬件限制，为了解决这个问题，Elasticsearch 提供了将索引细分为分片的概念。分片机制赋予了索引水平扩容的能力，并允许跨分片分发和并行化操作，从而提高性能和吞吐量。 Replicas（副本）：在可能出现故障的网络环境中，需要有一个故障切换机制，Elasticsearch 提供了将索引的分片复制为一个或多个副本的功能，副本在某些节点失效的情况下提供高可用性。 Elasticsearch 数据库 索引 Index 数据库 Database 类型 Type 表 Table 文档 Document 行 Row 字段 Field 列 Column 1.3 常用命令 详情见 Elasticsearch 常用命令 2 创建工程并配置 创建 Spring Boot 项目 spring-boot-elasticsearch ，添加 Web/Elasticsearch 依赖，如下： 最终的依赖如下： 123456789101112131415161718192021&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接着在 application.properties 配置文件中添加 Elasticsearch 的基本配置，如下： 12345spring.data.elasticsearch.repositories.enabled=truespring.elasticsearch.rest.uris=http://localhost:9200spring.elasticsearch.rest.username=elasticspring.elasticsearch.rest.password=000000 3 使用 首先创建一个 EsUser 实体类，如下： 1234567891011121314151617181920212223242526@Document(indexName = \"user\", shards = 1, replicas = 0)public class EsUser implements Serializable { private static final long serialVersionUID = -1L; @Id private Integer id; @Field(type = FieldType.Text, analyzer = \"ik_max_word\", searchAnalyzer = \"ik_smart\") private String username; @Field(type = FieldType.Keyword) private String password; @Field(type = FieldType.Boolean) private Boolean enabled = true; @Field(type = FieldType.Boolean) private Boolean locked = false; @Field(type = FieldType.Text, analyzer = \"ik_max_word\", searchAnalyzer = \"ik_smart\") private String address; @Field(type = FieldType.Text, analyzer = \"ik_max_word\", searchAnalyzer = \"ik_smart\") private String nickName; // @Field(type = FieldType.Date, format = DateFormat.date_hour_minute_second) // @JsonFormat(shape = JsonFormat.Shape.STRING, pattern =\"yyyy-MM-dd'T'HH:mm:ss\") private Date createTime; // @Field(type = FieldType.Date, format = DateFormat.date_hour_minute_second) // @JsonFormat(shape = JsonFormat.Shape.STRING, pattern =\"yyyy-MM-dd'T'HH:mm:ss\") private Date updateTime; // getter/setter} 实体类说明： @Document 注解: 标识映射到 Elasticsearch 文档上的领域对象。 @Id 注解: 标识文档的 id 。 @Field 注解: 标识字段，可以指定各字段的类型、分析器等，最终会体现在对应 index 的 mappings 上。类型如下： 123456789101112131415161718192021222324252627282930313233public enum FieldType { Auto, // 自动判断，默认值 Text, // 会进行分词 Keyword, // 不会进行分词 Long, Integer, Short, Byte, Double, Float, Half_Float, Scaled_Float, Date, Date_Nanos, Boolean, Binary, Integer_Range, Float_Range, Long_Range, Double_Range, Date_Range, Ip_Range, Object, Nested, // 嵌套对象 Ip, TokenCount, Percolator, Flattened, Search_As_You_Type; private FieldType() { }} 下面开始定义接口操作 Elasticsearch ，新增 EsUserRepository ，定义相关接口，如下： 12345678910111213141516public interface EsUserRepository extends ElasticsearchRepository&lt;EsUser, Integer&gt; { // 方法定义规范： // 1. 按照 Spring Data 的规范，查询方法以 find/get/read 开头 // 2. 涉及条件查询时，条件的属性用条件关键字连接，要注意的是：条件属性以首字母大写 // 3. 支持属性的级联查询. 若当前类有符合条件的属性, 则优先使用, 而不使用级联属性. 若需要使用级联属性, 则属性之间使用 _ 进行连接 EsUser findByIdAndUsername(Integer id, String username); Page&lt;EsUser&gt; findByIdGreaterThan(Integer id, Pageable pageable); List&lt;EsUser&gt; findByIdLessThanOrUsernameContaining(Integer id, String username); // 使用 @Query 注解可以用 Elasticsearch 的 DSL 语句进行查询 @Query(\"{\\\"bool\\\": {\\\"must\\\": {\\\"match\\\": {\\\"address\\\": \\\"?0\\\"}}}}\") Page&lt;EsUser&gt; findByAddress(String address, Pageable pageable);} 接口类说明： EsUserRepository 接口继承自 ElasticsearchRepository ， ElasticsearchRepository 提供了一些基本的数据操作方法，例如：保存 / 更新 / 删除 / 列表查询 / 分页列表查询等。 在 EsUserRepository 接口中也可以自己声明相关的方法，只需要 方法名称符合规范。在 Spring Data 中，只要按照既定的规范命名方法，Spring Data Elasticsearch 就知道你想干嘛，这样就不用写 DSL 语句了。相关规范参考下图： 如果有特殊的查询，也可以自己定义方法名，使用 @Query 注解通过自定义 DSL 语句来实现。 这时启动 Spring Boot 项目，会自动创建一个名为 user 的索引。 4 测试 最后在测试类中注入 esUserRepository 完成测试，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258@SpringBootTestclass SpringBootElasticsearchApplicationTests { @Autowired EsUserRepository esUserRepository; // 用于自定义复杂查询 @Autowired private ElasticsearchRestTemplate elasticsearchRestTemplate; @Test public void save() { EsUser esUser = new EsUser(); esUser.setId(1); esUser.setUsername(\"zhangsan\"); esUser.setPassword(\"123456\"); esUser.setAddress(\"浙江杭州\"); esUser.setNickName(\"张三\"); esUser.setCreateTime(new Date()); esUser.setUpdateTime(new Date()); EsUser esUserResult = esUserRepository.save(esUser); System.out.println(esUserResult); } @Test public void saveAll() { List&lt;EsUser&gt; esUserList = new ArrayList&lt;&gt;(); for (int i = 2; i &lt;= 11; i++) { EsUser esUser = new EsUser(); esUser.setId(i); esUser.setUsername(\"lisi\" + i); esUser.setPassword(\"123456\"); esUser.setAddress(\"浙江宁波\"); esUser.setNickName(\"李四\" + i); esUser.setCreateTime(new Date()); esUser.setUpdateTime(new Date()); esUserList.add(esUser); } Iterable&lt;EsUser&gt; list = esUserRepository.saveAll(esUserList); System.out.println(list); } @Test public void deleteById() { esUserRepository.deleteById(5); } @Test public void delete() { EsUser esUser = new EsUser(); esUser.setId(6); esUserRepository.delete(esUser); } @Test public void deleteAll() { esUserRepository.deleteAll(); } @Test public void findById() { Optional&lt;EsUser&gt; esUser = esUserRepository.findById(1); System.out.println(esUser.get()); } @Test public void findAllById() { List&lt;Integer&gt; idList = new ArrayList&lt;&gt;(); idList.add(1); idList.add(2); Iterable&lt;EsUser&gt; list = esUserRepository.findAllById(idList); System.out.println(list); } @Test public void findAll() { Iterable&lt;EsUser&gt; list = esUserRepository.findAll(); System.out.println(list); } @Test public void findAllSort() { Iterable&lt;EsUser&gt; list = esUserRepository.findAll(Sort.by(Sort.Direction.DESC, \"id\")); System.out.println(list); } @Test public void findAllPage() { Pageable pageable = PageRequest.of(0, 2); Page&lt;EsUser&gt; page = esUserRepository.findAll(pageable); System.out.println(\"总记录数：\" + page.getTotalElements()); System.out.println(\"当前页记录数：\" + page.getNumberOfElements()); System.out.println(\"每页记录数：\" + page.getSize()); System.out.println(\"总页数：\" + page.getTotalPages()); System.out.println(\"查询结果：\" + page.getContent()); System.out.println(\"当前页（从 0 开始计）：\" + page.getNumber()); System.out.println(\"是否为首页：\" + page.isFirst()); System.out.println(\"是否为尾页：\" + page.isLast()); } /** * more_like_this query */ @Test public void searchSimilar() { EsUser esUser = new EsUser(); esUser.setId(2); Pageable pageable = PageRequest.of(0, 2); Page&lt;EsUser&gt; page = esUserRepository.searchSimilar(esUser, new String[]{\"address\"}, pageable); System.out.println(\"总记录数：\" + page.getTotalElements()); System.out.println(\"当前页记录数：\" + page.getNumberOfElements()); System.out.println(\"每页记录数：\" + page.getSize()); System.out.println(\"总页数：\" + page.getTotalPages()); System.out.println(\"查询结果：\" + page.getContent()); System.out.println(\"当前页（从 0 开始计）：\" + page.getNumber()); System.out.println(\"是否为首页：\" + page.isFirst()); System.out.println(\"是否为尾页：\" + page.isLast()); } @Test public void existsById() { boolean b = esUserRepository.existsById(1); System.out.println(b); } @Test public void count() { long count = esUserRepository.count(); System.out.println(count); } /*=============== 自定义简单查询 - 开始 ===============*/ @Test public void findByIdAndUsername() { EsUser esUser = esUserRepository.findByIdAndUsername(2, \"lisi\"); System.out.println(esUser); } @Test public void findByIdGreaterThan() { Pageable pageable = PageRequest.of(0, 2); Page&lt;EsUser&gt; page = esUserRepository.findByIdGreaterThan(4, pageable); System.out.println(\"总记录数：\" + page.getTotalElements()); System.out.println(\"当前页记录数：\" + page.getNumberOfElements()); System.out.println(\"每页记录数：\" + page.getSize()); System.out.println(\"总页数：\" + page.getTotalPages()); System.out.println(\"查询结果：\" + page.getContent()); System.out.println(\"当前页（从 0 开始计）：\" + page.getNumber()); System.out.println(\"是否为首页：\" + page.isFirst()); System.out.println(\"是否为尾页：\" + page.isLast()); } @Test public void findByIdLessThanOrUsernameContaining() { List&lt;EsUser&gt; list = esUserRepository.findByIdLessThanOrUsernameContaining(10, \"si\"); System.out.println(list); } @Test public void findByAddress() { Pageable pageable = PageRequest.of(0, 2); Page&lt;EsUser&gt; page = esUserRepository.findByAddress(\"宁波\", pageable); System.out.println(\"总记录数：\" + page.getTotalElements()); System.out.println(\"当前页记录数：\" + page.getNumberOfElements()); System.out.println(\"每页记录数：\" + page.getSize()); System.out.println(\"总页数：\" + page.getTotalPages()); System.out.println(\"查询结果：\" + page.getContent()); System.out.println(\"当前页（从 0 开始计）：\" + page.getNumber()); System.out.println(\"是否为首页：\" + page.isFirst()); System.out.println(\"是否为尾页：\" + page.isLast()); } /*=============== 自定义简单查询 - 结束 ===============*/ /*=============== 自定义复杂查询（ElasticsearchRestTemplate）- 开始 ===============*/ /** * 根据关键字搜索用户名或昵称，再增加过滤、聚合、排序、分页 */ @Test public void search() { Boolean enabled = true; Boolean locked = false; String keyword = \"四\"; Integer sort = 1; PageImpl&lt;EsUser&gt; page = null; NativeSearchQueryBuilder nativeSearchQueryBuilder = new NativeSearchQueryBuilder(); // 搜索 if (StringUtils.isEmpty(keyword)) { nativeSearchQueryBuilder.withQuery(QueryBuilders.matchAllQuery()); } else { // nativeSearchQueryBuilder.withQuery(QueryBuilders.multiMatchQuery(keyword, \"username\", \"nickName\")); List&lt;FunctionScoreQueryBuilder.FilterFunctionBuilder&gt; filterFunctionBuilders = new ArrayList&lt;&gt;(); filterFunctionBuilders.add(new FunctionScoreQueryBuilder.FilterFunctionBuilder(QueryBuilders.matchQuery(\"username\", keyword), ScoreFunctionBuilders.weightFactorFunction(10))); filterFunctionBuilders.add(new FunctionScoreQueryBuilder.FilterFunctionBuilder(QueryBuilders.matchQuery(\"nickName\", keyword), ScoreFunctionBuilders.weightFactorFunction(2))); FunctionScoreQueryBuilder.FilterFunctionBuilder[] builders = new FunctionScoreQueryBuilder.FilterFunctionBuilder[filterFunctionBuilders.size()]; filterFunctionBuilders.toArray(builders); FunctionScoreQueryBuilder functionScoreQueryBuilder = QueryBuilders.functionScoreQuery(builders) .scoreMode(FunctionScoreQuery.ScoreMode.SUM) .setMinScore(2); nativeSearchQueryBuilder.withQuery(functionScoreQueryBuilder); } // 过滤 if (enabled != null || locked != null) { BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery(); if (enabled != null) { boolQueryBuilder.must(QueryBuilders.termQuery(\"enabled\", enabled)); } if (locked != null) { boolQueryBuilder.must(QueryBuilders.termQuery(\"locked\", locked)); } nativeSearchQueryBuilder.withFilter(boolQueryBuilder); } // 聚合，对应的字段一般设置为 FieldType.Keyword // nativeSearchQueryBuilder.addAggregation(AggregationBuilders.terms(\"passwords\").field(\"password\")); // nativeSearchQueryBuilder.addAggregation(AggregationBuilders.terms(\"addresses\").field(\"address\")); // 排序 if (sort == 1) { // 按 id 降序 nativeSearchQueryBuilder.withSort(SortBuilders.fieldSort(\"id\").order(SortOrder.DESC)); } else if (sort == 2) { // 按更新时间降序 nativeSearchQueryBuilder.withSort(SortBuilders.fieldSort(\"updateTime\").order(SortOrder.DESC)); } else if (sort == 3) { // 按地址升序 nativeSearchQueryBuilder.withSort(SortBuilders.fieldSort(\"address\").order(SortOrder.ASC)); } else { // 按相关度 nativeSearchQueryBuilder.withSort(SortBuilders.scoreSort().order(SortOrder.DESC)); } // 分页 Pageable pageable = PageRequest.of(0, 2); nativeSearchQueryBuilder.withPageable(pageable); NativeSearchQuery searchQuery = nativeSearchQueryBuilder.build(); System.out.println(\"DSL:\" + searchQuery.getQuery().toString()); SearchHits&lt;EsUser&gt; searchHits = elasticsearchRestTemplate.search(searchQuery, EsUser.class); if (searchHits.getTotalHits() &lt;= 0) { page = new PageImpl&lt;&gt;(Collections.emptyList(), pageable, 0); } List&lt;EsUser&gt; esUserList = searchHits.stream().map(SearchHit::getContent).collect(Collectors.toList()); page = new PageImpl&lt;&gt;(esUserList, pageable, searchHits.getTotalHits()); System.out.println(\"总记录数：\" + page.getTotalElements()); System.out.println(\"当前页记录数：\" + page.getNumberOfElements()); System.out.println(\"每页记录数：\" + page.getSize()); System.out.println(\"总页数：\" + page.getTotalPages()); System.out.println(\"查询结果：\" + page.getContent()); System.out.println(\"当前页（从 0 开始计）：\" + page.getNumber()); System.out.println(\"是否为首页：\" + page.isFirst()); System.out.println(\"是否为尾页：\" + page.isLast()); } /*=============== 自定义复杂查询（ElasticsearchRestTemplate）- 结束 ===============*/} Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-dao/spring-boot-elasticsearch 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/10/16/springboot/spring-boot-elasticsearch/"},{"title":"Spring Boot 整合邮件发送","text":"学习在 Spring Boot 中发送邮件，使用对应的自动化配置类，实现非常方便。 1 邮件概述 常用的邮件协议有 SMTP、POP3、IMAP 。现在假设从 aaa@qq.com 发送邮件到 111@163.com ，邮件投递过程如下： aaa@qq.com 先将邮件投递到腾讯的邮件服务器。 腾讯的邮件服务器将我们的邮件投递到网易的邮件服务器。 111@163.com 登录网易的邮件服务器查看邮件。 SMTP 协议全称为 Simple Mail Transfer Protocol，译作简单邮件传输协议，它定义了邮件客户端软件与 SMTP 服务器之间，以及 SMTP 服务器与 SMTP 服务器之间的通信规则。SMTP 是一个基于 TCP/IP 的应用层协议，江湖地位有点类似于 HTTP ， SMTP 服务器默认监听的端口号为 25 。 aaa@qq.com 用户先将邮件投递到腾讯的 SMTP 服务器这个过程就使用了 SMTP 协议，然后腾讯的 SMTP 服务器将邮件投递到网易的 SMTP 服务器这个过程也依然使用了 SMTP 协议，SMTP 服务器就是用来收邮件。 POP3 协议全称为 Post Office Protocol ，译作邮局协议，它定义了邮件客户端与 POP3 服务器之间的通信规则，那么该协议在什么场景下会用到呢？当邮件到达网易的 SMTP 服务器之后， 111@163.com 用户需要登录服务器查看邮件，这个时候就该协议就用上了。邮件服务商都会为每一个用户提供专门的邮件存储空间，SMTP 服务器收到邮件之后，就将邮件保存到相应用户的邮件存储空间中，如果用户要读取邮件，就需要通过邮件服务商的 POP3 邮件服务器来完成。 IMAP 协议是对 POP3 协议的扩展，功能更强，作用类似，这里不再赘述。 2 准备工作 目前国内大部分的邮件服务商都不允许直接使用用户名和密码的方式在代码中发送邮件，都是要先申请 授权码，这里以 QQ 邮箱为例，演示授权码的申请流程。 首先登录 QQ 邮箱网页版，点击左上方的设置按钮： 然后点击账户选项卡： 在账户选项卡中找到开启 POP3/SMTP 选项，如下： 点击开启，开启相关功能，开启过程需要手机号码验证，开启成功之后，即可获取一个授权码，保存好，下面会用到。 3 实战 3.1 创建工程并配置 创建 Spring Boot 项目 spring-boot-mail ，添加 Web/Mail 依赖，另外后面会演示使用 Thymeleaf 和 Freemarker 模板发送邮件，所以额外增加了这两个依赖，如下： 最终的依赖如下： 1234567891011121314151617181920212223242526272829&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接着在 application.properties 配置文件中添加邮件相关信息的配置，如下： 123456789101112131415# 邮件服务配置# SMTP 服务器地址spring.mail.host=smtp.qq.com# SMTP 服务器的端口spring.mail.port=587# 邮箱用户名spring.mail.username=799737179@qq.com# 邮箱开通 POP3/SMTP 服务时所给的授权码，换成自己申请的spring.mail.password=voeswedefedvcahabc# 默认的邮件编码spring.mail.default-encoding=UTF-8# SSL 加密工厂spring.mail.properties.mail.smtp.socketFactory.class=javax.net.ssl.SSLSocketFactory# 开启 DEBUG 模式，邮件发送过程的日志会在控制台打印出来，方便排查错误spring.mail.properties.mail.debug=true 3.2 测试 下面的测试代码都写在 SpringBootMailApplicationTests 测试类中，先注入相关 Bean ： 1234@AutowiredJavaMailSender javaMailSender;@AutowiredMailProperties mailProperties; 发送简单邮件 简单邮件就是指邮件内容是一个普通的文本文档。 123456789101112@Testpublic void sendSimpleMail() { SimpleMailMessage msg = new SimpleMailMessage(); msg.setSubject(\"这是测试邮件主题\"); // 邮件主题 msg.setFrom(mailProperties.getUsername()); // 邮件发送者 msg.setTo(\"799737179@qq.com\"); // 邮件接收者，可以有多个 msg.setCc(\"799737179@qq.com\"); // 邮件抄送人，可以有多个 msg.setBcc(\"799737179@qq.com\"); // 隐秘抄送人，可以有多个 msg.setSentDate(new Date()); // 邮件发送日期 msg.setText(\"这是测试邮件内容\"); // 邮件正文 javaMailSender.send(msg);} 最终效果如下： 发送带附件的邮件 邮件的附件可以是图片，也可以是普通文件，都是支持的。 1234567891011121314@Testpublic void sendAttachFileMail() throws MessagingException { MimeMessage msg = javaMailSender.createMimeMessage(); MimeMessageHelper helper = new MimeMessageHelper(msg, true); helper.setSubject(\"这是测试邮件主题(带附件)\"); helper.setFrom(mailProperties.getUsername()); helper.setTo(\"799737179@qq.com\"); // helper.setCc(\"799737179@qq.com\"); // helper.setBcc(\"799737179@qq.com\"); helper.setSentDate(new Date()); helper.setText(\"这是测试邮件内容(带附件)\"); helper.addAttachment(\"1.png\", new File(\"D:\\\\1.png\")); javaMailSender.send(msg);} 最终效果如下： 发送带图片资源的邮件 图片资源和附件有什么区别呢？图片资源是放在邮件正文中的，即一打开邮件，就能看到图片。但是一般来说，不建议使用这种方式，一些公司会对邮件内容的大小有限制（因为这种方式是将图片一起发送的）。 123456789101112131415@Testpublic void sendImgResMail() throws MessagingException { MimeMessage msg = javaMailSender.createMimeMessage(); MimeMessageHelper helper = new MimeMessageHelper(msg, true); helper.setSubject(\"这是测试邮件主题(带图片)\"); helper.setFrom(mailProperties.getUsername()); helper.setTo(\"799737179@qq.com\"); // helper.setCc(\"799737179@qq.com\"); // helper.setBcc(\"799737179@qq.com\"); helper.setSentDate(new Date()); helper.setText(\"这是测试邮件内容(带图片)，这是第一张图片：&lt;img src='cid:p01'/&gt;，这是第二张图片：&lt;img src='cid:p02'/&gt;\", true); helper.addInline(\"p01\", new FileSystemResource(new File(\"D:\\\\1.png\"))); helper.addInline(\"p02\", new FileSystemResource(new File(\"D:\\\\2.png\"))); javaMailSender.send(msg);} 最终效果如下： 使用 Freemarker 作邮件模板 先在 resources/templates 目录下创建 mail.ftl 作为邮件发送模板，内容如下： 1234567891011121314151617181920212223242526272829303132&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; hello ${username}，欢迎加入 XXX 大家庭！ &lt;/div&gt; 您的入职信息如下： &lt;table border=\"1\"&gt; &lt;tr&gt; &lt;td&gt;职位 &lt;/td&gt; &lt;td&gt;${position}&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; 职称 &lt;/td&gt; &lt;td&gt;${joblevel}&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; 薪水 &lt;/td&gt; &lt;td&gt;${salary}&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; 部门 &lt;/td&gt; &lt;td&gt;${dep}&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;div style=\"color: #ff1a0e;font-size: 20px\"&gt; 希望在未来的日子里，携手共进！&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 接下来，将邮件模板渲染成 HTML ，然后发送即可。 1234567891011121314151617181920212223242526272829@Testpublic void sendFreemarkerMail() throws MessagingException, IOException, TemplateException { MimeMessage msg = javaMailSender.createMimeMessage(); MimeMessageHelper helper = new MimeMessageHelper(msg, true); helper.setSubject(\"这是测试邮件主题(Freemarker 模板)\"); helper.setFrom(mailProperties.getUsername()); helper.setTo(\"799737179@qq.com\"); // helper.setCc(\"799737179@qq.com\"); // helper.setBcc(\"799737179@qq.com\"); helper.setSentDate(new Date()); // 构建 Freemarker 的基本配置 Configuration configuration = new Configuration(Configuration.VERSION_2_3_28); // 配置模板位置 configuration.setClassLoaderForTemplateLoading(this.getClass().getClassLoader(), \"templates\"); // 加载模板 Template template = configuration.getTemplate(\"mail.ftl\"); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(\"username\", \"zhangsan\"); map.put(\"position\", \"Java 工程师\"); map.put(\"dep\", \"产品研发部\"); map.put(\"salary\", 999999); map.put(\"joblevel\", \"高级工程师\"); StringWriter out = new StringWriter(); // 模板渲染，渲染的结果将被保存到 out 中 ，将 out 中的 html 字符串发送即可 template.process(map, out); helper.setText(out.toString(), true); javaMailSender.send(msg);} 需要注意的是，虽然引入了 Freemarker 的自动化配置，但是我们在这里是直接 new Configuration 来重新配置 Freemarker 的，所以 Freemarker 默认的配置这里不生效，因此要手动配置模板位置为 templates 。 最终效果如下： 使用 Thymeleaf 作邮件模板（推荐在 Spring Boot 中使用 Thymeleaf 来构建邮件模板） 推荐在 Spring Boot 中使用 Thymeleaf 来构建邮件模板。因为 Thymeleaf 的自动化配置提供了一个 TemplateEngine ，通过 TemplateEngine 可以方便的将 Thymeleaf 模板渲染为 HTML ，同时，Thymeleaf 的自动化配置在这里是继续有效的。 先在 resources/templates 目录下创建 mail.html 作为邮件发送模板，内容如下： 1234567891011121314151617181920212223242526272829303132&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; hello &lt;span th:text=\"${username}\"&gt;&lt;/span&gt;，欢迎加入 XXX 大家庭！ &lt;/div&gt; 您的入职信息如下： &lt;table border=\"1\"&gt; &lt;tr&gt; &lt;td&gt;职位 &lt;/td&gt; &lt;td th:text=\"${position}\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; 职称 &lt;/td&gt; &lt;td th:text=\"${joblevel}\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; 薪水 &lt;/td&gt; &lt;td th:text=\"${salary}\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; 部门 &lt;/td&gt; &lt;td th:text=\"${dep}\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;div style=\"color: #ff1a0e;font-size: 20px\"&gt; 希望在未来的日子里，携手共进！&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 12345678910111213141516171819202122232425262728@AutowiredTemplateEngine templateEngine;@Testpublic void sendThymeleafMail() throws MessagingException { MimeMessage msg = javaMailSender.createMimeMessage(); MimeMessageHelper helper = new MimeMessageHelper(msg, true); try { helper.setSubject(\"这是测试邮件主题(Thymeleaf 模板)\"); helper.setFrom(mailProperties.getUsername()); helper.setTo(\"799737179@qq.com\"); // helper.setCc(\"799737179@qq.com\"); // helper.setBcc(\"799737179@qq.com\"); helper.setSentDate(new Date()); Context context = new Context(); context.setVariable(\"username\", \"zhangsan\"); context.setVariable(\"position\", \"Java 工程师\"); context.setVariable(\"dep\", \"产品研发部\"); context.setVariable(\"salary\", 999999); context.setVariable(\"joblevel\", \"高级工程师\"); String process = templateEngine.process(\"mail.html\", context); helper.setText(process, true); javaMailSender.send(msg); } catch (MessagingException e) { e.printStackTrace(); }} 最终效果如下： 4 源码解读 邮件发送对应的自动化配置类是 org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration ，源码如下： 123456789101112131415161718192021222324252627282930313233343536@Configuration( proxyBeanMethods = false)@ConditionalOnClass({MimeMessage.class, MimeType.class, MailSender.class})@ConditionalOnMissingBean({MailSender.class})@Conditional({MailSenderAutoConfiguration.MailSenderCondition.class})@EnableConfigurationProperties({MailProperties.class})@Import({MailSenderJndiConfiguration.class, MailSenderPropertiesConfiguration.class})public class MailSenderAutoConfiguration { public MailSenderAutoConfiguration() { } static class MailSenderCondition extends AnyNestedCondition { MailSenderCondition() { super(ConfigurationPhase.PARSE_CONFIGURATION); } @ConditionalOnProperty( prefix = \"spring.mail\", name = {\"jndi-name\"} ) static class JndiNameProperty { JndiNameProperty() { } } @ConditionalOnProperty( prefix = \"spring.mail\", name = {\"host\"} ) static class HostProperty { HostProperty() { } } }} 上述代码中导入了另外一个配置 MailSenderPropertiesConfiguration 类，提供了邮件发送相关的工具类，源码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Configuration( proxyBeanMethods = false)@ConditionalOnProperty( prefix = \"spring.mail\", name = {\"host\"})class MailSenderPropertiesConfiguration { MailSenderPropertiesConfiguration() { } @Bean @ConditionalOnMissingBean({JavaMailSender.class}) JavaMailSenderImpl mailSender(MailProperties properties) { JavaMailSenderImpl sender = new JavaMailSenderImpl(); this.applyProperties(properties, sender); return sender; } private void applyProperties(MailProperties properties, JavaMailSenderImpl sender) { sender.setHost(properties.getHost()); if (properties.getPort() != null) { sender.setPort(properties.getPort()); } sender.setUsername(properties.getUsername()); sender.setPassword(properties.getPassword()); sender.setProtocol(properties.getProtocol()); if (properties.getDefaultEncoding() != null) { sender.setDefaultEncoding(properties.getDefaultEncoding().name()); } if (!properties.getProperties().isEmpty()) { sender.setJavaMailProperties(this.asProperties(properties.getProperties())); } } private Properties asProperties(Map&lt;String, String&gt; source) { Properties properties = new Properties(); properties.putAll(source); return properties; }} 其中 JavaMailSenderImpl 是 JavaMailSender 的一个实现，我们将使用 JavaMailSenderImpl 来完成邮件的发送工作。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-mail 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/01/31/springboot/spring-boot-mail/"},{"title":"Spring Boot 整合 Spring Security + JWT（实现无状态登录）","text":"学习在 Spring Boot 中整合 Spring Security 和 JWT ，实现无状态登录，可做为前后端分离时的解决方案，技术上没问题，但实际上还是推荐使用 OAuth2 中的 password 模式。 1 登录概述 1.1 有状态登录 有状态服务，即服务端需要记录每次会话的客户端信息，从而识别客户端身份，根据用户身份进行请求的处理，如 Tomcat 中的 Session 。例如：用户登录后，我们把用户的信息保存在服务端 session 中，并且给用户一个 cookie 值，记录对应的 session ，然后下次请求，用户携带 cookie 值来（这一步由浏览器自动完成），我们就能识别到对应 session ，从而找到用户的信息。这种方式目前来看最方便，但是也有一些缺陷，如下： 服务端保存大量数据，增加服务端压力。 服务端保存用户状态，不支持集群化部署。 1.2 无状态登录 微服务集群中的每个服务，对外提供的都使用 RESTful 风格的接口。而 RESTful 风格的一个最重要的规范就是：服务的无状态性，即： 服务端不保存任何客户端请求者信息。 客户端的每次请求必须具备自描述信息，通过这些信息识别客户端身份。 优势： 客户端请求不依赖服务端的信息，多次请求不需要必须访问到同一台服务器。 服务端的集群和状态对客户端透明。 服务端可以任意的迁移和伸缩（可以方便的进行集群化部署）。 减小服务端存储压力。 1.3 无状态登录的流程 无状态登录的流程： 首先客户端发送账户名 / 密码到服务端进行认证。 认证通过后，服务端将用户信息加密并且编码成一个 token ，返回给客户端。 以后客户端每次发送请求，都需要携带认证的 token 。 服务端对客户端发送来的 token 进行解密，判断是否有效，并且获取用户登录信息。 2 JWT 概述2.1 JWT 简介JWT (Json Web Token)，是一种 JSON 风格的轻量级的授权和身份认证规范，可实现无状态、分布式的 Web 应用授权。官网：https://jwt.io/ JWT 作为一种规范，并没有和某一种语言绑定在一起，常用的 Java 实现是 GitHub 上的开源项目 jjwt ，地址如下：https://github.com/jwtk/jjwt 2.2 JWT 数据格式JWT 包含三部分数据： Header ：头部，通常头部有两部分信息： 声明类型，这里是 JWT 。 加密算法，自定义。 我们会对头部进行 Base64 编码（可解码），得到第一部分数据。 Payload ：载荷，就是有效数据，在官方文档中(RFC7519)，这里给了 7 个示例信息： iss (issuer)：表示签发人。 exp (expiration time)：表示 token 过期时间。 sub (subject)：主题。 aud (audience)：受众。 nbf (Not Before)：生效时间。 iat (Issued At)：签发时间。 jti (JWT ID)：编号。 这部分也会采用 Base64 编码，得到第二部分数据。 Signature ：签名，是整个数据的认证信息。一般根据前两步的数据，再加上服务端的密钥 secret （密钥保存在服务端，不能泄露给客户端），通过 Header 中配置的加密算法生成，用于验证整个数据的完整性和可靠性。 比如，生成的数据格式： eyJhbGciOiJIUzUxMiJ9.eyJhdXRob3JpdGllcyI6IlJPTEVfdXNlciwiLCJzdWIiOiJ1c2VyIiwiZXhwIjoxNTc0NzczNTkyfQ.FuPIltzXi5j14t_gSL1GoIMUZxTHKK0FvB3gds6eTZFDkQr1ZxWVxdqZ5YFbCxdkwQ_VXtPK-GgcW5Kzzx3wvw 注意，这里的数据通过 . 隔开成了三部分，分别对应前面提到的三部分： Header ：头部（声明类型、加密算法），采用 Base64 编码，如：eyJhbGciOiJIUzUxMiJ9 。 Payload ：载荷，就是有效数据，采用 Base64 编码，如：eyJhdXRob3JpdGllcyI6IlJPTEVfdXNlciwiLCJzdWIiOiJ1c2VyIiwiZXhwIjoxNTc0NzczNTkyfQ Signature ：签名，如：FuPIltzXi5j14t_gSL1GoIMUZxTHKK0FvB3gds6eTZFDkQr1ZxWVxdqZ5YFbCxdkwQ_VXtPK-GgcW5Kzzx3wvw 。 2.3 JWT 交互流程 应用程序或客户端向授权服务器请求授权。 获取到授权后，授权服务器会向应用程序返回访问令牌。 应用程序使用访问令牌来访问受保护资源（如 API ）。 因为 JWT 签发的 token 中已经包含了用户的身份信息，并且每次请求都会携带，这样服务端就无需保存用户信息，甚至无需去数据库查询，这样就完全符合了 RESTful 的无状态规范。 2.4 JWT 问题 说了这么多， JWT 也不是天衣无缝，由客户端维护登录状态带来的一些问题在这里依然存在，如下： 续签问题，这是被很多人诟病的问题之一，传统的 cookie + session 的方案天然的支持续签，但是 JWT 由于服务端不保存用户状态，因此很难完美解决续签问题，如果引入 Redis ，虽然可以解决问题，但是 JWT 也变得不伦不类了。 注销问题，由于服务端不再保存用户信息，所以一般可以通过修改 secret 来实现注销，服务端 secret 修改后，已经颁发的未过期的 token 就会认证失败，进而实现注销，不过毕竟没有传统的注销方便。 密码重置，密码重置后，原本的 token 依然可以访问系统，这时候也需要强制修改 secret 。 基于第 2 点和第 3 点，一般建议不同用户取不同 secret 。 3 实战 3.1 创建工程 创建 Spring Boot 项目 spring-boot-springsecurity-jwt ，添加 Web/Spring Security 依赖，如下： 之后手动在 pom 文件中添加 jjwt 依赖，最终的依赖如下： 12345678910111213141516171819202122232425262728293031&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3.2 创建接口 新建实体类 User 实现 UserDetails 接口，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class User implements UserDetails { private String username; private String password; private List&lt;GrantedAuthority&gt; authorities; @Override public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() { return authorities; } @Override public String getPassword() { return password; } @Override public String getUsername() { return username; } @Override public boolean isAccountNonExpired() { return true; } @Override public boolean isAccountNonLocked() { return true; } @Override public boolean isCredentialsNonExpired() { return true; } @Override public boolean isEnabled() { return true; } public void setUsername(String username) { this.username = username; } public void setPassword(String password) { this.password = password; } public void setAuthorities(List&lt;GrantedAuthority&gt; authorities) { this.authorities = authorities; }} 新建 HelloController ，如下： 1234567891011121314151617@RestControllerpublic class HelloController { @GetMapping(\"/hello\") public String hello() { return \"hello\"; } @GetMapping(\"/admin/hello\") public String admin() { return \"hello admin\"; } @GetMapping(\"/user/hello\") public String user() { return \"hello user\"; }} 3.3 配置过滤器 这里主要配置两个过滤器： 用户登录的过滤器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// 过滤器 1：用户登录的过滤器，在用户的登录的过滤器中校验用户是否登录成功，// 如果登录成功，则生成一个 token 返回给客户端，登录失败则给前端一个登录失败的提示public class JwtLoginFilter extends AbstractAuthenticationProcessingFilter { public JwtLoginFilter(String defaultFilterProcessesUrl, AuthenticationManager authenticationManager) { super(new AntPathRequestMatcher(defaultFilterProcessesUrl)); setAuthenticationManager(authenticationManager); } @Override public Authentication attemptAuthentication(HttpServletRequest req, HttpServletResponse httpServletResponse) throws AuthenticationException, IOException { // 这里只支持 JSON 的登录方式 // 如果想表单方式也支持，可参考 spring-boot-springsecurity-loginbyjson 中的 MyAuthenticationFilter // 获取输入参数，如 {\"username\":\"user\",\"password\":\"123456\"} User user = new ObjectMapper().readValue(req.getInputStream(), User.class); // 进行登录校验，如果校验成功，会到 successfulAuthentication 的回调中，否则到 unsuccessfulAuthentication 的回调中 return getAuthenticationManager().authenticate(new UsernamePasswordAuthenticationToken(user.getUsername(), user.getPassword())); } @Override protected void successfulAuthentication(HttpServletRequest request, HttpServletResponse resp, FilterChain chain, Authentication authResult) throws IOException, ServletException { // 获取登录用户的角色 Collection&lt;? extends GrantedAuthority&gt; authorities = authResult.getAuthorities(); StringBuffer sb = new StringBuffer(); for (GrantedAuthority authority : authorities) { sb.append(authority.getAuthority()).append(\",\"); } // 生成 token 并返回 // 数据格式：分 3 部分用 . 隔开，如：eyJhbGciOiJIUzUxMiJ9.eyJhdXRob3JpdGllcyI6IlJPTEVfdXNlciwiLCJzdWIiOiJ1c2VyIiwiZXhwIjoxNTc0NzczNTkyfQ.FuPIltzXi5j14t_gSL1GoIMUZxTHKK0FvB3gds6eTZFDkQr1ZxWVxdqZ5YFbCxdkwQ_VXtPK-GgcW5Kzzx3wvw // 1.Header：头部（声明类型、加密算法），采用 Base64 编码，如：eyJhbGciOiJIUzUxMiJ9 // 2.Payload：载荷，就是有效数据，采用 Base64 编码，如：eyJhdXRob3JpdGllcyI6IlJPTEVfdXNlciwiLCJzdWIiOiJ1c2VyIiwiZXhwIjoxNTc0NzczNTkyfQ // 3.Signature：签名，是整个数据的认证信息。一般根据前两步的数据，再加上服务的的密钥 secret （密钥保存在服务端，不能泄露给客户端），通过 Header 中配置的加密算法生成。用于验证整个数据完整和可靠性。 String jwt = Jwts.builder() .claim(\"authorities\", sb) // 配置用户角色 .setSubject(authResult.getName()) // 配置主题 .setExpiration(new Date(System.currentTimeMillis() + 60 * 60 * 1000)) // 配置过期时间 .signWith(SignatureAlgorithm.HS512, \"abc@123\") // 配置加密算法和密钥 .compact(); resp.setContentType(\"application/json;charset=utf-8\"); Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put(\"token\", jwt); map.put(\"msg\", \"登录成功\"); PrintWriter out = resp.getWriter(); out.write(new ObjectMapper().writeValueAsString(map)); out.flush(); out.close(); } @Override protected void unsuccessfulAuthentication(HttpServletRequest req, HttpServletResponse resp, AuthenticationException failed) throws IOException, ServletException { resp.setContentType(\"application/json;charset=utf-8\"); Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put(\"msg\", \"登录失败\"); PrintWriter out = resp.getWriter(); out.write(new ObjectMapper().writeValueAsString(map)); out.flush(); out.close(); }} 校验 token 的过滤器 12345678910111213141516171819202122// 过滤器 2：当其他请求发送来，校验 token 的过滤器，如果校验成功，就让请求继续执行// 请求时注意认证方式选择 Bearer Tokenpublic class JwtFilter extends GenericFilterBean { @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { HttpServletRequest req = (HttpServletRequest) servletRequest; // 获取 token ，注意获取方式要跟前台传的方式保持一致 // 这里请求时注意认证方式选择 Bearer Token，会用 header 传递 String jwtToken = req.getHeader(\"authorization\"); // 注意 \"abc@123\" 要与生成 token 时的保持一致 Jws&lt;Claims&gt; jws = Jwts.parser().setSigningKey(\"abc@123\") .parseClaimsJws(jwtToken.replace(\"Bearer\", \"\")); Claims claims = jws.getBody(); // 获取用户名 String username = claims.getSubject(); // 获取用户角色，注意\"authorities\"要与生成 token 时的保持一致 List&lt;GrantedAuthority&gt; authorities = AuthorityUtils.commaSeparatedStringToAuthorityList((String) claims.get(\"authorities\")); UsernamePasswordAuthenticationToken token = new UsernamePasswordAuthenticationToken(username, null, authorities); SecurityContextHolder.getContext().setAuthentication(token); filterChain.doFilter(servletRequest, servletResponse); }} 3.4 配置 Spring Security新增 SecurityConfig 配置类，如下： 1234567891011121314151617181920212223242526272829303132333435@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter { @Bean PasswordEncoder passwordEncoder() { // return NoOpPasswordEncoder.getInstance();// 密码不加密 return new BCryptPasswordEncoder();// 密码加密 } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 在内存中配置 2 个用户 /*auth.inMemoryAuthentication() .withUser(\"admin\").password(\"123456\").roles(\"admin\") .and() .withUser(\"user\").password(\"123456\").roles(\"user\");// 密码不加密 */ auth.inMemoryAuthentication() .withUser(\"admin\").password(\"$2a$10$fB2UU8iJmXsjpdk6T6hGMup8uNcJnOGwo2.QGR.e3qjIsdPYaS4LO\").roles(\"admin\") .and() .withUser(\"user\").password(\"$2a$10$3TQ2HO/Xz1bVHw5nlfYTBON2TDJsQ0FMDwAS81uh7D.i9ax5DR46q\").roles(\"user\");// 密码加密 } @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\"/admin/**\").hasRole(\"admin\") .antMatchers(\"/user/**\").access(\"hasAnyRole('user','admin')\") .antMatchers(HttpMethod.POST, \"/login\").permitAll() .anyRequest().authenticated() .and() .addFilterBefore(new JwtLoginFilter(\"/login\", authenticationManager()), UsernamePasswordAuthenticationFilter.class) .addFilterBefore(new JwtFilter(), UsernamePasswordAuthenticationFilter.class) .csrf().disable(); }} 3.5 测试 项目启动之后，用 Postman 完成测试。 取出 token 的第 1 部分， Base64 解码得到 Header ，如下： 取出 token 的第 2 部分， Base64 解码得到 Payload ，如下： 因为 Base64 是一种编码方案，并不是加密方案，因此不建议将用户的敏感信息放在 token 中。 最后拿着上述 token 访问 /user/hello ，可正常访问。注意：认证方式 Authorization 选择 Bearer Token 。 Spring Boot 教程合集 （微信左下方 阅读全文 可直达）。 Spring Boot 教程合集示例代码：https://github.com/cxy35/spring-boot-samples 本文示例代码：https://github.com/cxy35/spring-boot-samples/tree/master/spring-boot-security/spring-boot-springsecurity-jwt 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/01/25/springboot/spring-boot-springsecurity-jwt/"},{"title":"Spring Cloud Config 分布式配置中心","text":"学习在 Spring Cloud 中使用 Config 实现分布式配置中心，包括基本使用、配置文件位置、配置文件加解密、Config Server 安全管理、结合注册中心、配置文件动态刷新、请求失败重试等功能。 1 概述 常见的分布式配置中心的解决方案有：Spring Cloud Conﬁg、QConf（360）、diamond（淘宝）、disconf（百度）、Apache Commons Conﬁguration、owner、cfg4j 等。 Spring Cloud Conﬁg 是一个分布式系统配置管理的解决方案，它包含了 Server 和 Client 。配置文件放在 Server 端，通过接口的形式提供给 Client ，主要功能如下： 集中管理各个环境、各个微服务的配置文件。 提供服务端和客户端支持。 配置文件修改后，可以快速生效。 配置文件通过 Git/SVN 进行管理，天然支持版本回退功能。 支持高并发查询、也支持多种开发语言。 2 基本使用 2.1 准备工作 首先，本地准备好开发 / 测试 / 生产环境对应的配置文件 config-client-dev.properties/config-client-test.properties/config-client-prod.properties ，内容 f 分别如下： 12345678# devcxy35=dev-123456# testcxy35=test-123456# prodcxy35=prod-123456 最后提交到 GitHub 上 spring-cloud-config 仓库 https://github.com/cxy35/spring-cloud-config 下的 config-client 目录下。 2.2 Conﬁg Server创建 Spring Boot 项目 config-server ，添加 Web/Config Server 依赖，如下： 最终的依赖如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，项目启动类上添加 @EnableConfigServer 注解，开启 Conﬁg Server 功能： 123456789@SpringBootApplication@EnableConfigServer // 开启 Conﬁg Server 功能public class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); }} 然后在 application.properties 配置文件中配置 Git 仓库的基本信息： 12345678910spring.application.name=config-serverserver.port=8080# 配置文件仓库地址spring.cloud.config.server.git.uri=https://github.com/cxy35/spring-cloud-config# 仓库中配置文件的目录spring.cloud.config.server.git.search-paths=config-client# 仓库的用户名密码spring.cloud.config.server.git.username=799737179@qq.comspring.cloud.config.server.git.password= 启动项目，通过 http://127.0.0.1:8080/config-client/dev/master 就可以访问到对应的配置文件了。访问地址有如下规则： 123/{application}/{proﬁle}/[{label}]/{application}-{proﬁle}.properties/{label}/{application}-{proﬁle}.properties applicaiton：表示配置文件名，如：config-client proﬁle：表示配置文件 proﬁle ，如：dev/dev/prod label：表示 git 分支，此参数可选，默认为 master 接下来，可以修改配置文件，并且重新提交到 GitHub ，重新访问就可以看到最新的配置内容。 2.3 Conﬁg Client创建 Spring Boot 项目 config-client ，添加 Web/Config Client 依赖，如下： 最终的依赖如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，在 resources 目录下，添加 bootstrap.properties 配置文件（比 application.properties 先加载），内容如下： 12345678910# 对应 config-server 中的 {application} 占位符spring.application.name=config-clientserver.port=8082# 对应 config-server 中的 {profile} 占位符spring.cloud.config.profile=dev# 对应 config-server 中的 {label} 占位符spring.cloud.config.label=master# config-server 的地址spring.cloud.config.uri=http://127.0.0.1:8080 接下来创建一个 HelloController 进行测试： 12345678910@RestControllerpublic class HelloController { @Value(\"${cxy35}\") String cxy35; @GetMapping public String hello(){ return cxy35; }} 最后访问 http://127.0.0.1:8082/hello 可以访问到对应的配置文件。 3 配置文件位置 {application} 占位符动态控制 在 conﬁg-server 中修改配置文件，使用 {application} 占位符动态控制配置文件的目录： 12# 仓库中配置文件的目录，动态# spring.cloud.config.server.git.search-paths={application} 这里的 {application} 占位符，表示连接上来的 config-client 中 spring.application.name 属性的值。同理， {proﬁle} 和 {label} 分别对应 config-client 中 spring.cloud.conﬁg.proﬁle 和 spring.cloud.conﬁg.label 属性的值。 classpath 或本地磁盘查找（不常用） 在 conﬁg-server 中修改配置文件，添加如下配置： 1234# classpath 下查找，而不是去 Git 仓库中查找# spring.profiles.active=native# 本地磁盘下查找# spring.cloud.config.server.native.search-locations=file:/E:/properties/ 4 配置文件加解密 上述 Git 仓库中配置文件的内容都是明文，不安全，需要加密处理。 4.1 介绍 常见的加密方案有：不可逆加密 和可逆加密。不可逆加密是指理论上无法根据加密后的密文推算出明文的一种加密方式，一般用在密码加密上，常见的算法有：MD5 消息摘要算法、SHA 安全散列算法。可逆加密是指可以根据加密后的密文推算出明文的一种加密方式，可逆加密一般又分为两种： 对称加密：加密的密钥和解密的密钥是一样的，常见算法有：des、3des、aes 。 非对称加密：加密的密钥和解密的密钥不一样，加密的叫做公钥，可以告诉任何人，解密的叫做私钥，只有自己知道，常见算法有： RSA 。 首先，下载不限长度的 JCE ：https://www.oracle.com/java/technologies/javase-jce8-downloads.html 。将下载的文件解压，解压出来的 jar 拷贝到 Java 安装目录中，如：D:\\Java\\jdk1.8.0_181\\lib\\security 。 4.2 对称加密 在 conﬁg-server 中新增 bootstrap.properties 配置文件，添加如下内容配置密钥： 12# 配置对称加密的密钥encrypt.key=cxy35 重新启动 config-server ，访问 http://127.0.0.1:8080/encrypt/status ，查看密钥配置是否成功。 然后，访问 http://127.0.0.1:8080/encrypt（POST 请求），可以对一段明文进行加密，把加密后的密文保存到 Git 仓库下的对应的配置文件中，注意要加一个 {cipher} 前缀。 12# cxy35=dev-123456cxy35={cipher}fd4c57fa240a3ca16a43cd60c1365645c9ebdb60e765a20719bc2c282fa7fc5a 再次访问 http://127.0.0.1:8080/config-client/dev/master（config-server） 或 http://127.0.0.1:8082/hello（config-client）可以看到返回的内容是 明文。 4.3 非对称加密 使用非对称加密，我们需要先生成一个密钥对，在命令行使用 密钥和证书管理工具命令 keytool 生成： 1keytool -genkeypair -alias config-server -keyalg RSA -keypass 111111 -keystore D:\\config-server.jks -storepass 111111 命令执行完成后，拷贝生成的 config-server.jks 文件到 conﬁg-server 的 resources 目录下。然后在 conﬁg-server 的 bootstrap.properties 配置文件中，添加如下配置： 12345# 配置非对称加密encrypt.key-store.location=classpath:config-server.jksencrypt.key-store.alias=config-serverencrypt.key-store.password=111111encrypt.key-store.secret=111111 注意，需要在 pom.xml 的 build 节点中，添加如下配置，防止 jks 文件被过滤掉。 123456789&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.jks&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt;&lt;/resources&gt; 重新启动 config-server ，访问 http://127.0.0.1:8080/encrypt/status ，查看密钥配置是否成功。 然后，访问 http://127.0.0.1:8080/encrypt（POST 请求），可以对一段明文进行加密，把加密后的密文保存到 Git 仓库下的对应的配置文件中，注意要加一个 {cipher} 前缀。 123# cxy35=dev-123456# cxy35={cipher}fd4c57fa240a3ca16a43cd60c1365645c9ebdb60e765a20719bc2c282fa7fc5acxy35={cipher}AQBPxgHh1+yoTT1q/xcd5S77xJVZduSnYSzb0keKbkckHjFIxYmVcbPpdfVyKRlB7JSp23xATAWNYsXS7wywfYIG2OeO/HIufqyM+t0pm/tqycn8/jjPMu447rvFVMLcF6TUgr2Xqo5Is1C73u/rGYyO3OuLXhq9J3Rp4DOn6CJnZdMNKjGl0fvLDFoujRk/avfag0aR4SKFPrTUabJIFVTKyMyLSS42N1X8QOlm4YXbIGQ9oCIJYpBTf/0R+HZ44lFnj7fMs5LpKBqqZvhd6mx+auXU2AzX6jQCkHmet+D74UHQG2jdH2UqC9MnH6O5sn6phwSApQElbTG+CY61wFPZDO7YFenXtWNeGWv7F3ZozIgPiM8oDiAaR9Ob+Tad6kc= 再次访问 http://127.0.0.1:8080/config-client/dev/master（config-server） 或 http://127.0.0.1:8082/hello（config-client）可以看到返回的内容是 明文。 5 Config Server 安全管理 为了防止用户直接通过访问 conﬁg-server 看到配置文件内容，我们可以用 Spring Security 来保护 conﬁg-server 接口。 首先在 conﬁg-server 中添加 Spring Security 依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 在 conﬁg-server 的 bootstrap.properties 配置文件中，添加如下配置，配置用户名密码： 123# 配置 Spring Security 的用户和密码spring.security.user.name=cxy35spring.security.user.password=123456 这样 conﬁg-server 中的接口就被保护起来了，需要登录才能访问了。但需要让 conﬁg-client 知道，否则 conﬁg-client 无法获取配置文件。 在 conﬁg-client 的 bootstrap.properties 配置文件中，添加如下配置： 123# 配置 conﬁg-server 中 Spring Security 的用户和密码spring.cloud.config.username=cxy35spring.cloud.config.password=123456 6 结合注册中心 前面的配置都是直接在 conﬁg-client 中写死 conﬁg-server 的地址，下面开始结合注册中心 Eureka。 首先，在 conﬁg-server 和 conﬁg-client 中添加 Eureka Client 依赖，让它们都能注册到 Eureka Server 上，如下： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 然后，修改 conﬁg-server 中的 application.properties 配置文件，配置注册信息： 12# 服务注册中心地址eureka.client.service-url.defaultZone=http://127.0.0.1:1111/eureka 然后，修改 conﬁg-client 中的 bootstrap.properties 配置文件，配置注册信息，并配置 config-server 的服务名称，不再写死 config-server 的地址： 123456789101112131415161718192021# 对应 config-server 中的 {application} 占位符spring.application.name=config-clientserver.port=8082# 对应 config-server 中的 {profile} 占位符spring.cloud.config.profile=dev# 对应 config-server 中的 {label} 占位符spring.cloud.config.label=master# config-server 的地址# spring.cloud.config.uri=http://127.0.0.1:8080# 开启通过 eureka 获取 config-server 的功能spring.cloud.config.discovery.enabled=true# 配置 config-server 服务名称spring.cloud.config.discovery.service-id=config-server# 配置 conﬁg-server 中 Spring Security 的用户和密码spring.cloud.config.username=cxy35spring.cloud.config.password=123456# 服务注册中心地址eureka.client.service-url.defaultZone=http://127.0.0.1:1111/eureka 最后，启动 Eureka Server/config-server/config-client，再次访问 http://127.0.0.1:8080/config-client/dev/master（config-server） 或 http://127.0.0.1:8082/hello（config-client）也可以正常返回。 7 配置文件动态刷新 当配置文件发生变化之后，conﬁg-server 可以及时感知到变化，但是 conﬁg-client 不会及时感知到变化，默认情况下， conﬁg-client 只有重启才能加载到最新的配置文件。这里我们可以结合 actuator 中的 refresh 来实现，更好的方案是结合消息总线来实现。 首先，给 conﬁg-client 添加如下依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 然后，修改 conﬁg-client 中的 bootstrap.properties 配置文件，使 refresh 端点暴露出来： 12# 暴露 refresh 端点management.endpoints.web.exposure.include=refresh 最后，再给 conﬁg-client 使用了配置文件的地方加上 @RefreshScope 注解，这样，当配置改变后，只需要调用 refresh 端点， conﬁg-client 中的配置就可以自动刷新。 1234567891011@RestController@RefreshScopepublic class HelloController { @Value(\"${cxy35}\") String cxy35; @GetMapping(\"/hello\") public String hello(){ return cxy35; }} 重启 config-client , 以后，如果配置文件发生变化，只要调用 http://127.0.0.1:8082/actuator/refresh [POST]，配置文件就会自动刷新了。 8 请求失败重试conﬁg-client 在调用 conﬁg-server 时，一样也可能发生请求失败的问题，这个时候，我们可以配置一个请求重试的功能。 首先，给 conﬁg-client 添加如下依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt; &lt;artifactId&gt;spring-retry&lt;/artifactId&gt;&lt;/dependency&gt; 然后，修改 conﬁg-client 中的 bootstrap.properties 配置文件，开启失败快速响应（启动就报错，无需等使用时才报错）： 12# 开启失败快速响应spring.cloud.config.fail-fast=true 测试时可以注释掉配置文件的用户名和密码，重启 conﬁg-client ，观察控制台，此时加载配置文件失败，就会自动重试。 另外，也可以增加如下配置保证服务的可用性： 12345678910# 开启失败快速响应spring.cloud.config.fail-fast=true# 请求重试的初始间隔时间spring.cloud.config.retry.initial-interval=1000# 最大重试次数spring.cloud.config.retry.max-attempts=6# 重试时间间隔乘数spring.cloud.config.retry.multiplier=1.1# 最大间隔时间spring.cloud.config.retry.max-interval=2000 Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 本文示例代码：https://github.com/cxy35/spring-cloud-samples/tree/master/spring-cloud-config 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/05/11/springcloud/spring-cloud-config/"},{"title":"Spring Cloud OpenFeign 声明式服务调用","text":"学习在 Spring Cloud 中使用 OpenFeign 实现声明式服务调用，包括简单调用、参数传递、继承特性、日志配置、数据压缩、服务降级 / 容错等功能。 1 概述 前面无论是基本调用，还是 Hystrix ，我们实际上都是通过手动调用 RestTemplate 来实现远程调用的。使用 RestTemplate 比较繁琐，每一个请求的参数、请求地址、返回数据类型不同，其他都是一样的，所以我们希望能够对请求进行简化，简化方案就是 OpenFeign 。 一开始这个组件叫 Feign/Netﬂix Feign ，但是 Netﬂix 中的组件，现在已经停止开源工作， OpenFeign 是 Spring Cloud 团队在 Netflix Feign 的基础上开发出来的 声明式服务调用 组件。关于 OpenFeign 组件的 Issue 见 https://github.com/OpenFeign/feign/issues/373 。 2 准备工作 2.1 服务注册 创建 Spring Boot 项目 openfeign-client-provider ，作为我们的 服务提供者，添加 Web/Eureka Client 依赖，如下： 最终的依赖如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，修改 application.properties 配置文件，将 openfeign-client-provider 注册到 Eureka Server 上（服务注册中心使用 Eureka Server ），如下： 1234567# 当前服务的名称spring.application.name=openfeign-client-provider# 当前服务的端口server.port=4000# 服务注册中心地址eureka.client.service-url.defaultZone=http://127.0.0.1:1111/eureka 接下来，启动 Eureka Server ，待服务注册中心启动成功后，再启动 openfeign-client-provider ，两者都启动成功后，访问 http://127.0.0.1:1111 可以看到 openfeign-client-provider 的注册信息。 当然 openfeign-client-provider 也可以集群化部署，下面对 openfeign-client-provider 进行打包，之后我们在命令行启动两个 provider 实例： 12java -jar openfeign-client-provider-0.0.1-SNAPSHOT.jar --server.port=4000java -jar openfeign-client-provider-0.0.1-SNAPSHOT.jar --server.port=4001 最后在 openfeign-client-provider 提供一个 hello 接口，用于后续服务消费者 openfeign-client-consumer 来消费，如下： 12345678910@RestControllerpublic class ProviderController { @Value(\"${server.port}\") Integer port; // 支持启动多个实例，做负载均衡，用端口区分 @GetMapping(\"/hello\") public String hello() { return \"hello cxy35:\" + port; }} 2.2 服务消费 创建 Spring Boot 项目 openfeign-client-consumer ，作为我们的 服务消费者，添加 Web/Eureka Client/OpenFeign 依赖，如下： 最终的依赖如下： 1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，修改 application.properties 配置文件，将 openfeign-client-consumer 注册到 Eureka Server 上（服务注册中心使用 Eureka Server ），如下： 1234567# 当前服务的名称spring.application.name=openfeign-client-consumer# 当前服务的端口server.port=4002# 服务注册中心地址eureka.client.service-url.defaultZone=http://127.0.0.1:1111/eureka 接着，在项目启动类上添加 @EnableFeignClients 注解，开启 OpenFeign 功能，如下： 123456789@SpringBootApplication@EnableFeignClients // 开启 OpenFeign 功能public class OpenfeignClientConsumerApplication { public static void main(String[] args) { SpringApplication.run(OpenfeignClientConsumerApplication.class, args); }} 接下来，启动 openfeign-client-consumer ，访问 http://127.0.0.1:1111 可以看到 openfeign-client-consumer 的注册信息。 最后在 openfeign-client-consumer 中新增测试业务类和接口，去实现服务调用，从而消费 openfeign-client-provider 中提供的接口，如下： 约定：本文中的服务调用失败（测试服务降级 / 容错），可以采用关闭某个 openfeign-client-provider 来模拟，短时间内会报错（因为 provider 地址会缓存 consumer 上一段时间），从而达到我们的目的。 3 简单调用 新建测试业务类 ConsumerService ，如下： 123456@FeignClient(\"openfeign-client-provider\")public interface ConsumerService { @GetMapping(\"/hello\") String hello(); // 这里的方法名无所谓，随意取} 新建测试接口 ConsumerController ，如下： 12345678910@RestControllerpublic class ConsumerController { @Autowired ConsumerService consumerService; @GetMapping(\"/hello\") public String hello() { return consumerService.hello(); }} 访问 http://127.0.0.1:4002/hello 完成测试。 4 参数传递OpenFeign 中的请求参数传递与普通请求参数传递的区别如下： 参数一定要绑定参数名。 如果通过 header 来传递参数，一定记得中文要转码。 修改 ProviderController ，增加测试接口，如下： 12345678910111213141516171819202122232425262728293031@RestControllerpublic class ProviderController { @Value(\"${server.port}\") Integer port; // 支持启动多个实例，做负载均衡，用端口区分 @GetMapping(\"/hello\") public String hello() { return \"hello cxy35:\" + port; } @GetMapping(\"/hello2\") public String hello2(String name) { System.out.println(new Date()); return \"hello\" + name + \":\" + port; } @PostMapping(\"/user\") public User addUser(@RequestBody User user) { return user; } @DeleteMapping(\"/user/{id}\") public void deleteUser(@PathVariable Integer id) { System.out.println(id); } @GetMapping(\"/user\") public void getUserByName(@RequestHeader String name) throws UnsupportedEncodingException { System.out.println(URLDecoder.decode(name, \"UTF-8\")); }} 修改 ConsumerService ，增加各种类型的测试接口，如下： 123456789101112131415161718@FeignClient(\"openfeign-client-provider\")public interface ConsumerService { @GetMapping(\"/hello\") String hello(); // 这里的方法名无所谓，随意取 @GetMapping(\"/hello2\") String hello2(@RequestParam(\"name\") String name); @PostMapping(\"/user\") User addUser(@RequestBody User user); @DeleteMapping(\"/user/{id}\") void deleteUser(@PathVariable(\"id\") Integer id); @GetMapping(\"/user\") void getUserByName(@RequestHeader(\"name\") String name);} 注意，凡是 key/value 形式的参数，一定要标记参数的名称。 修改 ConsumerController ，增加测试接口，如下： 1234567891011121314151617181920212223242526272829303132@RestControllerpublic class ConsumerController { @Autowired ConsumerService consumerService; @GetMapping(\"/hello\") public String hello() { return consumerService.hello(); } @GetMapping(\"/testOpenFeign\") public String testOpenFeign() throws UnsupportedEncodingException { String s = consumerService.hello(); String s2 = consumerService.hello2(\"程序员 35\"); System.out.println(s2); User user = new User(); user.setId(1); user.setUsername(\"cxy35\"); user.setPassword(\"123\"); User u = consumerService.addUser(user); System.out.println(u); consumerService.deleteUser(1); consumerService.getUserByName(URLEncoder.encode(\"程序员 35\", \"UTF-8\")); return s; }} 访问 http://127.0.0.1:4002/testOpenFeign 完成测试。 注意：放在 header 中的中文参数，一定要编码之后传递。 5 继承特性 修改 spring-cloud-common 模块，增加一个公共的接口，给 openfeign-client-provider 和 openfeign-client-consumer 使用。但是由于这个模块要用到 Spring MVC 的东西，因此添加 Web 依赖，最终的依赖如下： 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在 spring-cloud-common 中新增 OpenFeignService 接口，里面的内容就是上文中 ConsumerService 接口的内容，如下： 12345678910111213141516public interface OpenFeignService { @GetMapping(\"/hello\") String hello(); // 这里的方法名无所谓，随意取 @GetMapping(\"/hello2\") String hello2(@RequestParam(\"name\") String name); @PostMapping(\"/user\") User addUser(@RequestBody User user); @DeleteMapping(\"/user/{id}\") void deleteUser(@PathVariable(\"id\") Integer id); @GetMapping(\"/user\") void getUserByName(@RequestHeader(\"name\") String name) throws UnsupportedEncodingException;} 在 openfeign-client-provider 中新增 ProviderController2 类，实现 OpenFeignService 接口，并实现全部方法，如下： 12345678910111213141516171819202122232425262728293031@RestControllerpublic class ProviderController2 implements OpenFeignService { @Value(\"${server.port}\") Integer port; // 支持启动多个实例，做负载均衡，用端口区分 @Override public String hello() { return \"hello2 cxy35:\" + port; } @Override public String hello2(String name) { System.out.println(new Date()); return \"hello2\" + name + \":\" + port; } @Override public User addUser(@RequestBody User user) { return user; } @Override public void deleteUser(@PathVariable Integer id) { System.out.println(id); } @Override public void getUserByName(@RequestHeader String name) throws UnsupportedEncodingException { System.out.println(URLDecoder.decode(name, \"UTF-8\")); }} 修改 ProviderController ，并注释掉 @RestController ，避免与 ProviderController2 重复，导致启动报错。 1234// @RestControllerpublic class ProviderController { ......} 在 openfeign-client-consumer 中新增 ConsumerService2 接口，继承 OpenFeignService 接口，如下： 123@FeignClient(\"openfeign-client-provider\")public interface ConsumerService2 extends OpenFeignService {} 修改 ConsumerService ，并注释掉 @FeignClient ，避免与 ConsumerService2 重复，导致启动报错。 1234// @FeignClient(\"openfeign-client-provider\")public interface ConsumerService { ......} 修改 ConsumerController ，换成新的 ConsumerService ，避免找不到 ConsumerService ，导致启动报错 1234// @Autowired// ConsumerService consumerService;@AutowiredConsumerService2 consumerService; 访问 http://127.0.0.1:4002/testOpenFeign 完成测试。 关于继承特性： 使用继承特性，代码简洁明了不易出错。服务端和消费端的代码统一，一改俱改，不易出错。这是优点也是缺点，这样会提高服务端和消费端的耦合度。 上文中所讲的参数传递，在使用了继承之后，依然不变，参数该怎么传还是怎么传。 6 日志配置OpenFeign 中，我们可以通过配置日志，来查看整个请求的调用过程。日志级别一共分为四种： NONE：不开启日志，默认就是这个 BASIC：记录请求方法、URL、响应状态码、执行时间 HEADERS：在 BASIC 的基础上，加载请求 / 响应头 FULL：在 HEADERS 基础上，再增加 Body 以及请求元数据。 配置方式如下： 1234567891011121314@SpringBootApplication@EnableFeignClients // 开启 OpenFeign 功能public class OpenfeignClientConsumerApplication { public static void main(String[] args) { SpringApplication.run(OpenfeignClientConsumerApplication.class, args); } @Bean Logger.Level loggerLevel() { return Logger.Level.FULL; }} 另外，还要在 application.properties 中配置日志级别： 12# 配置 OpenFeign 的日志级别logging.level.com.cxy35.sample.springcloud.openfeign.client.consumer.service=debug 7 数据压缩 修改配置文件，如下： 12345678# 开启请求的数据压缩feign.compression.request.enabled=true# 开启响应的数据压缩feign.compression.response.enabled=true# 压缩的数据类型，默认如下feign.compression.request.mime-types=text/html,application/xml,application/json# 压缩的数据下限，默认 2048 表示当要传输的数据大于 2048 时，才会进行数据压缩feign.compression.request.min-request-size=2048 8 服务降级 / 容错Hystrix 中的服务降级 / 容错等功能，在 OpenFeign 中一样要使用，有两种方式。 首先，在 application.properties 中开启 Hystrix 。 12# 开启 Hystrixfeign.hystrix.enabled=true fallback 新增 ConsumerService2Fallback 类，实现 ConsumerService2 接口，实现对应服务降级的方法，如下： 1234567891011121314151617181920212223242526@Component@RequestMapping(\"/abc\") // 防止请求地址重复，可随意定义public class ConsumerService2Fallback implements ConsumerService2 { @Override public String hello() { return \"error-fallback\"; } @Override public String hello2(String name) { return \"error2-fallback\"; } @Override public User addUser(User user) { return null; } @Override public void deleteUser(Integer id) { } @Override public void getUserByName(String name) throws UnsupportedEncodingException { }} 接着，在 ConsumerService2 中配置这个服务降级类，如下： 1234// @FeignClient(\"openfeign-client-provider\")@FeignClient(value = \"openfeign-client-provider\", fallback = ConsumerService2Fallback.class)public interface ConsumerService2 extends OpenFeignService {} 最后，关闭 openfeign-client-provider ，模拟服务调用失败，访问 http://127.0.0.1:4002/hello 完成测试。 fallbackFactory 新增 ConsumerService2FallbackFactory 类，实现 ConsumerService2 接口，实现对应服务降级的方法，如下： 123456789101112131415161718192021222324252627282930@Componentpublic class ConsumerService2FallbackFactory implements FallbackFactory&lt;ConsumerService2&gt; { @Override public ConsumerService2 create(Throwable throwable) { return new ConsumerService2() { @Override public String hello() { return \"error-fallbackFactory\"; } @Override public String hello2(String name) { return \"error2-fallbackFactory\"; } @Override public User addUser(User user) { return null; } @Override public void deleteUser(Integer id) { } @Override public void getUserByName(String name) throws UnsupportedEncodingException { } }; }} 接着，在 ConsumerService2 中配置这个服务降级类，如下： 12345// @FeignClient(\"openfeign-client-provider\")// @FeignClient(value = \"openfeign-client-provider\", fallback = ConsumerService2Fallback.class)@FeignClient(value = \"openfeign-client-provider\", fallbackFactory = ConsumerService2FallbackFactory.class)public interface ConsumerService2 extends OpenFeignService {} 最后，关闭 openfeign-client-provider ，模拟服务调用失败，访问 http://127.0.0.1:4002/hello 完成测试。 Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 本文示例代码：https://github.com/cxy35/spring-cloud-samples/tree/master/spring-cloud-openfeign 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/04/24/springcloud/spring-cloud-openfeign/"},{"title":"Spring Cloud Resilience4j 断路器","text":"学习在 Spring Cloud 中使用 Resilience4j 实现断路器，包括断路器 CircuitBreaker 、限流 RateLimiter 、请求重试 Retry 等功能。 1 概述 Resilience4j 是 Spring Cloud Greenwich 版推荐的 容错解决方案，相比 Hystrix ， Resilience4j 专为 Java 8 以及函数式编程而设计。它主要提供了如下功能： 断路器 限流 基于信号量的隔离 缓存 限时 请求重试 2 基本用法 创建普通的 Maven 项目 resilience4j ，手动添加依赖，如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.github.resilience4j&lt;/groupId&gt; &lt;artifactId&gt;resilience4j-circuitbreaker&lt;/artifactId&gt; &lt;version&gt;0.13.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.github.resilience4j&lt;/groupId&gt; &lt;artifactId&gt;resilience4j-ratelimiter&lt;/artifactId&gt; &lt;version&gt;0.13.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.github.resilience4j&lt;/groupId&gt; &lt;artifactId&gt;resilience4j-retry&lt;/artifactId&gt; &lt;version&gt;0.13.2&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; Resilience4j 提供了很多功能，不同的功能对应不同的依赖，可以按需添加。 2.1 断路器 CircuitBreaker断路器功能相关依赖如下： 12345&lt;dependency&gt; &lt;groupId&gt;io.github.resilience4j&lt;/groupId&gt; &lt;artifactId&gt;resilience4j-circuitbreaker&lt;/artifactId&gt; &lt;version&gt;0.13.2&lt;/version&gt;&lt;/dependency&gt; 测试断路器：正常情况，断路器关闭 12345678910111213141516171819202122232425@Testpublic void testCircuitBreakerSuccess() { // 获取一个默认的 CircuitBreakerRegistry 实例 // CircuitBreakerRegistry cbr = CircuitBreakerRegistry.ofDefaults(); // 自定义一个 CircuitBreakerRegistry 实例 CircuitBreakerConfig config = CircuitBreakerConfig.custom() // 故障率阈值百分比，超过这个阈值，断路器就会打开，这里是 50% .failureRateThreshold(50) // 断路器保持打开的时间，在到达设置的时间之后，断路器会进入到 HalfOpen 状态 .waitDurationInOpenState(Duration.ofMillis(1000)) // 当断路器处于 HalfOpen 状态时，环形缓冲区的大小 .ringBufferSizeInHalfOpenState(2) // 当断路器处于 Closed 状态时，环形缓冲区的大小 .ringBufferSizeInClosedState(2) .build(); CircuitBreakerRegistry cbr2 = CircuitBreakerRegistry.of(config); CircuitBreaker cb1 = cbr2.circuitBreaker(\"cxy35\"); // CircuitBreaker cb2 = cbr2.circuitBreaker(\"cxy352\", config); CheckedFunction0&lt;String&gt; supplier = CircuitBreaker.decorateCheckedSupplier(cb1, () -&gt; \"hello resilience4j\"); Try&lt;String&gt; result = Try.of(supplier).map(v -&gt; v + \"hello world\"); System.out.println(result.isSuccess()); System.out.println(result.get());} 执行结果如下： 12truehello resilience4j hello world 测试断路器：异常情况，断路器打开 1234567891011121314151617181920212223242526@Testpublic void testCircuitBreakerError() { // 自定义一个 CircuitBreakerRegistry 实例 CircuitBreakerConfig config = CircuitBreakerConfig.custom() // 故障率阈值百分比，超过这个阈值，断路器就会打开，这里是 50% .failureRateThreshold(50) // 断路器保持打开的时间，在到达设置的时间之后，断路器会进入到 half open 状态 .waitDurationInOpenState(Duration.ofMillis(1000)) // 当断路器处于 Closed 状态时，环形缓冲区的大小 .ringBufferSizeInClosedState(2) .build(); CircuitBreakerRegistry cbr = CircuitBreakerRegistry.of(config); CircuitBreaker cb1 = cbr.circuitBreaker(\"cxy35\"); // 模拟异常，使断路器打开 System.out.println(cb1.getState());// 断路器状态 cb1.onError(0, new RuntimeException()); System.out.println(cb1.getState()); cb1.onError(0, new RuntimeException()); System.out.println(cb1.getState()); CheckedFunction0&lt;String&gt; supplier = CircuitBreaker.decorateCheckedSupplier(cb1, () -&gt; \"hello resilience4j\"); Try&lt;String&gt; result = Try.of(supplier).map(v -&gt; v + \"hello world\"); System.out.println(result.isSuccess()); System.out.println(result.get());} 执行结果如下： 123456CLOSEDCLOSEDOPENfalseio.github.resilience4j.circuitbreaker.CircuitBreakerOpenException: CircuitBreaker 'cxy35' is open 注意，由于 ringBuﬀerSizeInClosedState 的值为 2 ，表示当有 2 条数据时才会去统计故障率，所以手动故障测试，至少调用 2 次 onError ，断路器才会打开。 2.2 限流 RateLimiter限流功能相关依赖如下： 12345&lt;dependency&gt; &lt;groupId&gt;io.github.resilience4j&lt;/groupId&gt; &lt;artifactId&gt;resilience4j-ratelimiter&lt;/artifactId&gt; &lt;version&gt;0.13.2&lt;/version&gt;&lt;/dependency&gt; 测试限流 123456789101112131415161718@Testpublic void testRateLimiter() { RateLimiterConfig config = RateLimiterConfig.custom() // 限制每 1s 处理 2 个请求 .limitRefreshPeriod(Duration.ofMillis(1000)) .limitForPeriod(2) .timeoutDuration(Duration.ofMillis(3000)) .build(); RateLimiter rateLimiter = RateLimiter.of(\"cxy35\", config); CheckedRunnable checkedRunnable = RateLimiter.decorateCheckedRunnable(rateLimiter, () -&gt; { System.out.println(new Date()); }); Try.run(checkedRunnable) .andThenTry(checkedRunnable) .andThenTry(checkedRunnable) .andThenTry(checkedRunnable) .onFailure(t -&gt; System.out.println(t.getMessage()));} 执行结果如下： 1234Sun Apr 25 15:32:27 CST 2020Sun Apr 25 15:32:27 CST 2020Sun Apr 25 15:32:28 CST 2020Sun Apr 25 15:32:28 CST 2020 2.3 请求重试 Retry请求重试功能相关依赖如下： 12345&lt;dependency&gt; &lt;groupId&gt;io.github.resilience4j&lt;/groupId&gt; &lt;artifactId&gt;resilience4j-retry&lt;/artifactId&gt; &lt;version&gt;0.13.2&lt;/version&gt;&lt;/dependency&gt; 测试请求重试 12345678910111213141516171819202122@Testpublic void testRetry() { RetryConfig config = RetryConfig.custom() // 重试次数 .maxAttempts(4) // 重试间隔 .waitDuration(Duration.ofMillis(500)) // 重试异常 .retryExceptions(RuntimeException.class) .build(); Retry retry = Retry.of(\"cxy35\", config); Retry.decorateRunnable(retry, new Runnable() { int count = 0; // 开启了重试功能之后，run 方法执行时，如果抛出异常，会自动触发重试功能 @Override public void run() { if (count++ &lt; 3) { throw new RuntimeException(); } } }).run();} 当重试次数配置成 &lt; 4 的时候，程序执行结果会抛出异常，否则不会。 3 结合微服务 3.1 准备工作3.1.1 服务注册 创建 Spring Boot 项目 resilience4j-client-provider ，作为我们的 服务提供者，添加 Web/Eureka Client 依赖，如下： 最终的依赖如下： 123456789101112131415161718192021&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，修改 application.properties 配置文件，将 resilience4j-client-provider 注册到 Eureka Server 上（服务注册中心使用 Eureka Server ），如下： 1234567# 当前服务的名称spring.application.name=resilience4j-client-provider# 当前服务的端口server.port=5000# 服务注册中心地址eureka.client.service-url.defaultZone=http://127.0.0.1:1111/eureka 接下来，启动 Eureka Server ，待服务注册中心启动成功后，再启动 resilience4j-client-provider ，两者都启动成功后，访问 http://127.0.0.1:1111 可以看到 resilience4j-client-provider 的注册信息。 当然 resilience4j-client-provider 也可以集群化部署，下面对 resilience4j-client-provider 进行打包，之后我们在命令行启动两个 provider 实例： 12java -jar resilience4j-client-provider-0.0.1-SNAPSHOT.jar --server.port=5000java -jar resilience4j-client-provider-0.0.1-SNAPSHOT.jar --server.port=5001 最后在 resilience4j-client-provider 提供一个 hello 接口，用于后续服务消费者 resilience4j-client-consumer 来消费，如下： 12345678910@RestControllerpublic class ProviderController { @Value(\"${server.port}\") Integer port; // 支持启动多个实例，做负载均衡，用端口区分 @GetMapping(\"/hello\") public String hello() { return \"hello cxy35:\" + port; }} 3.1.2 服务消费 创建 Spring Boot 项目 resilience4j-client-consumer ，作为我们的 服务消费者，添加 Web/Eureka Client 依赖，如下： 再手动添加 Resilience4j 相关依赖，最终的依赖如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.github.resilience4j&lt;/groupId&gt; &lt;artifactId&gt;resilience4j-spring-boot2&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.github.resilience4j&lt;/groupId&gt; &lt;artifactId&gt;resilience4j-circuitbreaker&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;io.github.resilience4j&lt;/groupId&gt; &lt;artifactId&gt;resilience4j-ratelimiter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;io.github.resilience4j&lt;/groupId&gt; &lt;artifactId&gt;resilience4j-bulkhead&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;io.github.resilience4j&lt;/groupId&gt; &lt;artifactId&gt;resilience4j-timelimiter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 注意： resilience4j-spring-boot2 中包含了 Resilience4j 的所有功能，但是没有配置的功能无法使用，启动会报错，所以需要将之从依赖中剔除掉。这里先全部移除掉，下面需要测试哪块功能时，再把对应的依赖从移除列表中删除。 项目创建成功后，新建 application.yml 配置文件，将 resilience4j-client-consumer 注册到 Eureka Server 上（服务注册中心使用 Eureka Server ），如下： 12345678910111213# 当前服务的名称spring: application: name: resilience4j-client-consumer# 当前服务的端口server: port: 5002# 服务注册中心地址eureka: client: service-url: defaultZone: http://127.0.0.1:1111/eureka 接着，在项目启动类上添加 RestTemplate ，如下： 12345678910111213@SpringBootApplicationpublic class Resilience4jClientConsumerApplication { public static void main(String[] args) { SpringApplication.run(Resilience4jClientConsumerApplication.class, args); } @Bean @LoadBalanced RestTemplate restTemplate() { return new RestTemplate(); }} 接下来，启动 resilience4j-client-consumer ，访问 http://127.0.0.1:1111 可以看到 resilience4j-client-consumer 的注册信息。 最后在 resilience4j-client-consumer 中新增测试业务类和接口，去实现服务调用，从而消费 resilience4j-client-provider 中提供的接口，如下： 约定：本文中的服务调用失败（测试服务降级 / 容错），可以采用关闭某个 resilience4j-client-provider 来模拟，短时间内会报错（因为 provider 地址会缓存 consumer 上一段时间），从而达到我们的目的。 3.2 断路器 CircuitBreaker在 resilience4j-client-provider 中修改 ProviderController ，新增接口，如下： 1234567@GetMapping(\"/testCircuitBreaker\")public String testCircuitBreaker() { String s = \"hello cxy35:\" + port; System.out.println(s); int i = 1 / 0; return \"testCircuitBreaker:\" + s;} 在 resilience4j-client-consumer 中修改 pom.xml 文件，把 resilience4j-circuitbreaker 从移除列表中删除。 然后在 application.yml 中增加断路器 CircuitBreaker 相关配置： 123456789101112# Resilience4j 配置resilience4j: # 配置断路器 circuitbreaker: circuit-breaker-aspect-order: 398 # 优先级 instances: cbA: ringBufferSizeInHalfOpenState: 3 # 当断路器处于 HalfOpen 状态时，环形缓冲区的大小 ringBufferSizeInClosedState: 5 # 当断路器处于 Closed 状态时，环形缓冲区的大小 waitInterval: 5000 recordExceptions: - org.springframework.web.client.HttpServerErrorException # 记录异常 新建 ConsumerService ，新增接口，如下： 1234567891011121314@Service@CircuitBreaker(name = \"cbA\", fallbackMethod = \"error\") // 测试断路器，服务降级 / 容错public class ConsumerService { @Autowired RestTemplate restTemplate; public String testCircuitBreaker() { return restTemplate.getForObject(\"http://resilience4j-client-provider/testCircuitBreaker\", String.class); } public String error(Throwable t) { return \"error\"; }} 其中 @CircuitBreaker 注解中的 name 属性用来指定 circuitbreaker 配置（对应配置文件）， fallbackMethod 属性用来指定服务降级的方法，需要注意的是，服务降级方法中，要添加异常参数。 新建 ConsumerController ，新增接口，如下： 12345678910@RestControllerpublic class ConsumerController { @Autowired ConsumerService consumerService; @GetMapping(\"/testCircuitBreaker\") public String testCircuitBreaker() { return consumerService.testCircuitBreaker(); }} 访问 http://127.0.0.1:5002/testCircuitBreaker 完成测试，服务降级，返回 “error” 。 3.3 限流 RateLimiterRateLimiter 作为限流工具，主要在 服务端 / 服务提供者 使用，用来保护服务端 / 服务提供者的接口。 在 resilience4j-client-provider 中修改 pom.xml 文件，手动添加 Resilience4j 相关依赖，最终的依赖如下： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.github.resilience4j&lt;/groupId&gt; &lt;artifactId&gt;resilience4j-spring-boot2&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.github.resilience4j&lt;/groupId&gt; &lt;artifactId&gt;resilience4j-circuitbreaker&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;io.github.resilience4j&lt;/groupId&gt; &lt;artifactId&gt;resilience4j-bulkhead&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;io.github.resilience4j&lt;/groupId&gt; &lt;artifactId&gt;resilience4j-timelimiter&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 注意： resilience4j-spring-boot2 中包含了 Resilience4j 的所有功能，但是没有配置的功能无法使用，启动会报错，所以需要将之从依赖中剔除掉。这里移除掉 resilience4j-ratelimiter ，用于测试限流功能。 在 resilience4j-client-provider 中修改 application.properties ，增加限流 RateLimiter 相关配置： 12345# 限流配置## 定义一个限流器 rlA ，这里限制每 1s 处理 2 个请求resilience4j.ratelimiter.limiters.rlA.limit-refresh-period=1sresilience4j.ratelimiter.limiters.rlA.limit-for-period=2resilience4j.ratelimiter.limiters.rlA.timeout-duration=3s 在 resilience4j-client-provider 中修改 ProviderController ，新增接口，如下： 1234567@GetMapping(\"/testRateLimiter\")@RateLimiter(name = \"rlA\") // 测试限流public String testRateLimiter() { String s = \"hello cxy35:\" + port; System.out.println(new Date()); return \"testRateLimiter:\" + s;} 这里通过 @RateLimiter 注解来标记该接口限流。 在 resilience4j-client-consumer 中修改 pom.xml 文件，把 resilience4j-ratelimiter 从移除列表中删除。 修改 ConsumerService ，新增接口，如下： 123456public String testRateLimiter() { for (int i = 0; i &lt; 5; i++) { restTemplate.getForObject(\"http://resilience4j-client-provider/testRateLimiter\", String.class); } return \"success\";} 修改 ConsumerController ，新增接口，如下： 1234@GetMapping(\"/testRateLimiter\")public String testRateLimiter() { return consumerService.testRateLimiter();} 访问 http://127.0.0.1:5002/testRateLimiter 完成测试， provider 中打印如下： 12345Mon Apr 27 15:29:51 CST 2020Mon Apr 27 15:29:51 CST 2020Mon Apr 27 15:29:52 CST 2020Mon Apr 27 15:29:52 CST 2020Mon Apr 27 15:29:53 CST 2020 3.4 请求重试 Retry在 resilience4j-client-provider 中修改 ProviderController ，新增接口，如下： 1234567@GetMapping(\"/testRetry\")public String testRetry() { String s = \"hello cxy35:\" + port; System.out.println(s); int i = 1 / 0; return \"testRetry:\" + s;} 在 resilience4j-client-consumer 中修改 application.yml ，增加请求重试 Retry 相关配置： 123456789101112# Resilience4j 配置resilience4j: # 配置请求重试 retry: retry-aspect-order: 399 # 优先级 backends: retryA: maxRetryAttempts: 5 # 重试次数 waitDuration: 500 # 重试等待时间 exponentialBackoffMultiplier: 1.1 # 间隔乘数 retryExceptions: - java.lang.RuntimeException # 重试异常 修改 ConsumerService ，新增接口，如下： 1234567891011@Service@CircuitBreaker(name = \"cbA\", fallbackMethod = \"error\") // 测试断路器，服务降级 / 容错@Retry(name = \"retryA\") // 测试请求重试public class ConsumerService { @Autowired RestTemplate restTemplate; public String testRetry() { return restTemplate.getForObject(\"http://resilience4j-client-provider/testRetry\", String.class); }} 其中 @CircuitBreaker 注解中的 name 属性用来指定 retry 配置（对应配置文件）。 修改 ConsumerController ，新增接口，如下： 1234@GetMapping(\"/testRetry\")public String testRetry() { return consumerService.testRetry();} 访问 http://127.0.0.1:5002/testRetry 完成测试，会重试 5 次， provider 中打印如下： 123456789hello cxy35:5000java.lang.ArithmeticException: / by zerohello cxy35:5000java.lang.ArithmeticException: / by zero... 3.5 服务监控 微服务由于服务数量众多，所以出故障的概率很大，这种时候不能单纯的依靠人肉运维。早期的 Spring Cloud 中，服务监控主要使用 Hystrix Dashboard ，集群数据库监控使用 Turbine 。在 Greenwich 版本中，官方建议监控工具使用 Micrometer ，有如下功能： 提供了度量指标，例如 timers、counters 一揽子开箱即用的解决方案，例如缓存、类加载器、垃圾收集等等 新建一个 Spring Boot 项目，添加 Web/Actuator 依赖。项目创建成功后，添加如下配置，开启所有端点： 1management.endpoints.web.exposure.include=* 然后就可以在浏览器查看项目的各项运行数据，但是这些数据都是 JSON 格式。 我们需要一个可视化工具来展示这些 JSON 数据。这里主要和大家介绍 Prometheus 。 3.5.1 Prometheus123# 安装wget https://github.com/prometheus/prometheus/releases/download/v2.16.0/prometheus-2.16.0.linux-amd64.tar.gztar -zxvf prometheus-2.16.0.linux-amd64.tar.gz 解压完成后，配置一下数据路径和要监控的服务地址： 12cd prometheus-2.16.0.linux-amd64/vi prometheus.yml 修改 prometheus.yml 配置文件，主要改两个地方，一个是数据接口，另一个是服务地址： 接下来，将 Prometheus 整合到 Spring Boot 项目中。 首先加依赖： 1234&lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;&lt;/dependency&gt; 然后在 application.properties 配置中，添加 Prometheus 配置： 1234management.endpoints.web.exposure.include=*management.endpoint.prometheus.enabled=truemanagement.metrics.export.prometheus.enabled=truemanagement.endpoint.metrics.enabled=true 接下来启动 Prometheus 。启动命令： 1./prometheus --config.file=prometheus.yml 启动成功后，浏览器输入 http://192.168.91.128:9090 查看 Prometheus 数据信息。 3.5.1 Grafanahttps://grafana.com/grafana/download?platform=linux Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 本文示例代码：https://github.com/cxy35/spring-cloud-samples/tree/master/spring-cloud-resilience4j 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/04/27/springcloud/spring-cloud-resilience4j/"},{"title":"Hexo 主题配置 - NexT","text":"hexo-theme-next 主题配置大全，图文并茂，持续更新中。 1 安装 NexT 主题 参考 hexo-theme-next 主题官网 1.1 下载 NexT 主题 建议你使用 克隆最新版本 的方式，之后的更新可以通过 git pull 来快速更新， 而不用再次下载压缩包替换。 12cd bloggit clone https://github.com/iissnan/hexo-theme-next themes/next 1.2 启用 NexT 主题 与所有 Hexo 主题启用的模式一样。 当 克隆 / 下载 完成后，打开 站点配置文件， 找到 theme 字段，并将其值更改为 next。 1234# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: next 到此，NexT 主题安装完成。下一步我们将验证主题是否正确启用。在切换主题之后、验证之前， 我们最好使用 hexo clean 来清除 Hexo 的缓存。 2 配置 NexT 主题 设置站点信息 效果图： 编辑 站点配置文件，具体配置参考 Hexo 搭建个人博客网站 。 设置页面文章的篇数 编辑 站点配置文件，具体配置参考 Hexo 搭建个人博客网站 。 主题配置文件 编辑 主题配置文件，具体配置参考 themes/next/_config.yml。 1# ...... 选择 SchemeScheme 是 NexT 提供的一种特性，借助于 Scheme，NexT 为你提供多种不同的外观。同时，几乎所有的配置都可以 在 Scheme 之间共用。目前 NexT 支持三种 Scheme，他们是： Muse - 默认 Scheme，这是 NexT 最初的版本，黑白主调，大量留白 Mist - Muse 的紧凑版本，整洁有序的单栏外观 Pisces - 双栏 Scheme，小家碧玉似的清新 Gemini Scheme 的切换通过更改 主题配置文件，搜索 scheme 关键字，将你需用启用的 scheme 前面注释 # 去除即可。 12345# Schemes#scheme: Muse#scheme: Mist#scheme: Piscesscheme: Gemini 设置菜单 效果图： 菜单配置包括三个部分，第一是菜单项（名称和链接），第二是菜单项的显示文本，第三是菜单项对应的图标。 NexT 使用的是 Font Awesome 提供的图标， Font Awesome 提供了 600+ 的图标，可以满足绝大的多数的场景，同时无须担心在 Retina 屏幕下 图标模糊的问题。 编辑 主题配置文件，修改以下内容： 设定菜单内容，对应的字段是 menu。 菜单内容的设置格式是：item name: link。其中 item name 是一个名称，这个名称并不直接显示在页面上，它将用于匹配图标以及翻译。 12345678910111213141516# When running the site in a subdirectory (e.g. domain.tld/blog), remove the leading slash from link value (/archives -&gt; archives).# Usage: `Key: /link/ || icon`# Key is the name of menu item. If translate for this menu will find in languages - this translate will be loaded; if not - Key name will be used. Key is case-senstive.# Value before `||` delimeter is the target link.# Value after `||` delimeter is the name of FontAwesome icon. If icon (with or without delimeter) is not specified, question icon will be loaded.menu: home: / || home 咖啡豆: /cherry/ || coffee 咖啡粉: /powder/ || coffee categories: /categories/ || th archives: /archives/ || archive tags: /tags/ || tags #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat about: /about/ || user 若你的站点运行在子目录中，请将链接前缀的 / 去掉。 NexT 默认的菜单项有（标注 ! 的项表示需要手动创建这个页面）： 键值 设定值 显示文本（简体中文） home home: / 主页 archives archives: /archives 归档页 categories categories: /categories 分类页 ! tags tags: /tags 标签页 ! about about: /about 关于页面 ! commonweal commonweal: /404.html 公益 404 ! 设置菜单项的显示文本。在第一步中设置的菜单的名称并不直接用于界面上的展示。Hexo 在生成的时候将使用 这个名称查找对应的语言翻译，并提取显示文本。这些翻译文本放置在 NexT 主题目录下的 languages/{language}.yml （{language} 为你所使用的语言）。 以简体中文为例，若你需要添加一个菜单项，比如 something。那么就需要修改简体中文对应的翻译文件 languages/zh-Hans.yml，在 menu 字段下添加一项： 123456789menu: home: 首页 archives: 归档 categories: 分类 tags: 标签 about: 关于 search: 搜索 commonweal: 公益 404 something: 有料 设定菜单项的图标。enable 可用于控制是否显示图标，你可以设置成 false 来去掉图标。 123# Enable/Disable menu icons.menu_icons: enable: true 在菜单图标开启的情况下，如果菜单项与菜单未匹配（没有设置或者无效的 Font Awesome 图标名字） 的情况下，NexT 将会使用 ? 作为图标。 请注意键值（如 home）的大小写要严格匹配。 设置侧栏 效果图： 默认情况下，侧栏仅在文章页面（拥有目录列表）时才显示，并放置于右侧位置。 可以通过修改 主题配置文件 中的 sidebar 字段来控制侧栏的行为。侧栏的设置包括两个部分，其一是侧栏的位置， 其二是侧栏显示的时机。 设置侧栏的位置，修改 sidebar.position 的值，支持的选项有： left - 靠左放置 right - 靠右放置 12sidebar: position: left 目前仅 Pisces Scheme 支持 position 配置。影响版本 5.0.0 及更低版本。 设置侧栏显示的时机，修改 sidebar.display 的值，支持的选项有： post - 默认行为，在文章页面（拥有目录列表）时显示 always - 在所有页面中都显示 hide - 在所有页面中都隐藏（可以手动展开） remove - 完全移除 12sidebar: display: post 已知侧栏在 use motion: false 的情况下不会展示。 影响版本 5.0.0 及更低版本。 设置头像 效果图： 编辑 主题配置文件， 修改字段 avatar， 值设置成头像的链接地址。其中，头像的链接地址可以是： 完整的互联网 URI，如：http://example.com/avatar.png 站点内的地址，主题或站点的 source 目录下。 1234# Sidebar Avatar# in theme directory(source/images): /images/avatar.gif# in site directory(source/uploads): /uploads/avatar.gifavatar: /images/custom/avatar.jpg 设置 RSS效果图： 安装 RSS 插件: npm install --save hexo-generator-feed 编辑 站点配置文件，新增如下配置： 123####################### add ######################## rssplugins: hexo-generate-feed 编辑 主题配置文件，配置如下： 1234# Set rss to false to disable feed link.# Leave rss as empty to use site's feed link.# Set rss to specific value if you have burned your feed already.rss: /atom.xml 侧边栏社交链接 效果图： 侧栏社交链接的修改包含两个部分，第一是链接，第二是链接图标。 两者配置均在 主题配置文件 中。 链接放置在 social 字段下，一行一个链接。其键值格式是 显示文本: 链接地址。 123456789101112131415161718# Social Links.# Usage: `Key: permalink || icon`# Key is the link label showing to end users.# Value before `||` delimeter is the target permalink.# Value after `||` delimeter is the name of FontAwesome icon. If icon (with or without delimeter) is not specified, globe icon will be loaded.social: 微信: https://wx.qq.com/ || weixin 微博: https://weibo.com/ || weibo GitHub: https://github.com/ || github #E-Mail: mailto:yourname@gmail.com || envelope #Google: https://plus.google.com/yourname || google Twitter: https://twitter.com/ || twitter #FB Page: https://www.facebook.com/yourname || facebook #VK Group: https://vk.com/yourname || vk #StackOverflow: https://stackoverflow.com/yourname || stack-overflow #YouTube: https://youtube.com/yourname || youtube #Instagram: https://instagram.com/yourname || instagram #Skype: skype:yourname?call|chat || skype 设定链接的图标，对应的字段是 social_icons。其键值格式是 匹配键: Font Awesome 图标名称， 匹配键 与上一步所配置的链接的 显示文本 相同（大小写严格匹配），图标名称 是 Font Awesome 图标的名字（不必带 fa- 前缀）。 enable 选项用于控制是否显示图标，你可以设置成 false 来去掉图标。 1234social_icons: enable: true icons_only: false transition: false 开启打赏功能 效果图： 越来越多的平台（微信公众平台，新浪微博，简书，百度打赏等）支持打赏功能，付费阅读时代越来越近，特此增加了打赏功能，支持微信打赏和支付宝打赏。 只需要 主题配置文件 中填入 微信 和 支付宝 收款二维码图片地址 即可开启该功能。 12345# Rewardreward_comment: 坚持原创技术分享，您的支持将鼓励我继续创作！wechatpay: /images/custom/wechatpay.jpgalipay: /images/custom/alipay.jpg#bitcoin: /images/bitcoin.png 设置友情链接 效果图： 编辑 主题配置文件 ，配置如下： 12345678links_icon: linklinks_title: 友情链接#links_layout: blocklinks_layout: inlinelinks: Hexo: https://hexo.io/zh-cn/ NexT: https://theme-next.iissnan.com/ Hexo Admin: https://github.com/jaredly/hexo-admin 腾讯公益 404 页面 腾讯公益 404 页面，寻找丢失儿童，让大家一起关注此项公益事业！效果如下 http://www.ixirong.com/404.html 使用方法，新建 404.html 页面，放到主题的 source 目录下，内容如下： 123456789101112131415161718&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" /&gt; &lt;meta name=\"robots\" content=\"all\" /&gt; &lt;meta name=\"robots\" content=\"index,follow\"/&gt; &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"https://qzone.qq.com/gy/404/style/404style.css\"&gt;&lt;/head&gt;&lt;body&gt; &lt;script type=\"text/plain\" src=\"http://www.qq.com/404/search_children.js\" charset=\"utf-8\" homePageUrl=\"/\" homePageName=\"回到我的主页\"&gt; &lt;/script&gt; &lt;script src=\"https://qzone.qq.com/gy/404/data.js\" charset=\"utf-8\"&gt;&lt;/script&gt; &lt;script src=\"https://qzone.qq.com/gy/404/page.js\" charset=\"utf-8\"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 站点建立时间 这个时间将在站点的底部显示，例如 © 2015 - 2019。 编辑 主题配置文件，配置如下： 1234footer: # Specify the date when the site was setup. # If not defined, current year will be used. #since: 2015 订阅微信公众号 效果图： 注意： 此特性在版本 5.0.1 中引入，要使用此功能请确保所使用的 NexT 版本在此之后 在每篇文章的末尾显示微信公众号二维码，扫一扫，轻松订阅博客。 在微信公众号平台下载您的二维码，并将它存放于主题 source/images/custom/ 目录下。 然后编辑 主题配置文件，配置如下： 12345# Wechat Subscriberwechat_subscriber: enabled: true qcode: /images/custom/wechat-qcode.jpg description: 欢迎您扫一扫上面的微信公众号，订阅我的博客！ 设置动画效果NexT 默认开启动画效果，效果使用 JavaScript 编写，因此需要等待 JavaScript 脚本完全加载完毕后才会显示内容。 如果您比较在乎速度，可以将设置此字段的值为 false 来关闭动画。 编辑 主题配置文件， 搜索 use_motion，根据您的需求设置值为 true 或者 false 即可： 123456789101112131415161718# Use velocity to animate everything.motion: enable: true async: true transition: # Transition variants: # fadeIn | fadeOut | flipXIn | flipXOut | flipYIn | flipYOut | flipBounceXIn | flipBounceXOut | flipBounceYIn | flipBounceYOut # swoopIn | swoopOut | whirlIn | whirlOut | shrinkIn | shrinkOut | expandIn | expandOut # bounceIn | bounceOut | bounceUpIn | bounceUpOut | bounceDownIn | bounceDownOut | bounceLeftIn | bounceLeftOut | bounceRightIn | bounceRightOut # slideUpIn | slideUpOut | slideDownIn | slideDownOut | slideLeftIn | slideLeftOut | slideRightIn | slideRightOut # slideUpBigIn | slideUpBigOut | slideDownBigIn | slideDownBigOut | slideLeftBigIn | slideLeftBigOut | slideRightBigIn | slideRightBigOut # perspectiveUpIn | perspectiveUpOut | perspectiveDownIn | perspectiveDownOut | perspectiveLeftIn | perspectiveLeftOut | perspectiveRightIn | perspectiveRightOut post_block: fadeIn post_header: slideDownIn post_body: slideDownIn coll_header: slideLeftIn # Only for Pisces | Gemini. sidebar: slideUpIn 设置背景动画 注意： three_waves 在版本 5.1.1 中引入。只能同时开启一种背景动画效果。 编辑 主题配置文件，配置如下： 12345678910111213141516171819202122# Canvas-nestcanvas_nest: false# three_wavesthree_waves: false# canvas_linescanvas_lines: false# canvas_spherecanvas_sphere: false# Only fit scheme Pisces# Canvas-ribbon# size: The width of the ribbon.# alpha: The transparency of the ribbon.# zIndex: The display level of the ribbon.canvas_ribbon: enable: false size: 300 alpha: 0.6 zIndex: -1 设置阅读全文 效果图： 在首页显示一篇文章的部分内容，并提供一个链接跳转到全文页面是一个常见的需求。 NexT 提供三种方式来控制文章在首页的显示方式。 也就是说，在首页显示文章的摘录并显示 阅读全文 按钮，可以通过以下方法： 在文章中使用 &lt;!-- more --&gt; 手动进行截断，Hexo 提供的方式 推荐。 在文章的 front-matter 中添加 description，并提供文章摘录 自动形成摘要，在 主题配置文件 中添加： 12345# Automatically Excerpt. Not recommend.# Please use &lt;!-- more --&gt; in the post to control excerpt accurately.auto_excerpt: enable: true length: 150 建议使用 &lt;!-- more --&gt;（即第一种方式），除了可以精确控制需要显示的摘录内容以外， 这种方式也可以让 Hexo 中的插件更好的识别。 设置字数统计 / 阅读时长 效果图： 安装字数统计插件: npm i --save hexo-wordcount 编辑 主题配置文件，配置如下： 12345678# Post wordcount display settings# Dependencies: https://github.com/willin/hexo-wordcountpost_wordcount: item_text: true wordcount: true min2read: true totalcount: false separated_meta: true 设置顶部加载条 效果图： 编辑 主题配置文件，配置如下： 12345678910111213141516171819# Progress bar in the top during page loading.pace: true# Themes list:#pace-theme-big-counter#pace-theme-bounce#pace-theme-barber-shop#pace-theme-center-atom#pace-theme-center-circle#pace-theme-center-radar#pace-theme-center-simple#pace-theme-corner-indicator#pace-theme-fill-left#pace-theme-flash#pace-theme-loading-bar#pace-theme-mac-osx#pace-theme-minimal# For example# pace_theme: pace-theme-center-simplepace_theme: pace-theme-minimal 设置底部内容 效果图： 编辑 主题配置文件，配置如下： 12345678910111213141516171819202122footer: # Specify the date when the site was setup. # If not defined, current year will be used. #since: 2015 # Icon between year and copyright info. icon: user # If not defined, will be used `author` from Hexo main config. copyright: # ------------------------------------------------------------- # Hexo link (Powered by Hexo). powered: false theme: # Theme &amp; scheme info link (Theme - NexT.scheme). enable: false # Version info of NexT after scheme info (vX.X.X). version: false # ------------------------------------------------------------- # Any custom text can be defined here. #custom_text: Hosted by &lt;a target=\"_blank\" href=\"https://pages.github.com\"&gt;GitHub Pages&lt;/a&gt; TODO- 评论系统 数据统计与分析 不蒜子统计 效果图： 注意： 此特性在版本 5.0.1 中引入，要使用此功能请确保所使用的 NexT 版本在此之后 编辑 主题配置文件，配置如下： 1234567891011121314151617# Show PV/UV of the website/page with busuanzi.# Get more information on http://ibruce.info/2015/04/04/busuanzi/busuanzi_count: # count values only if the other configs are false enable: true # custom uv span for the whole site site_uv: true site_uv_header: &lt;i class=\"fa fa-user\"&gt;&lt;/i&gt; 本站访客数 site_uv_footer: 人次 # custom pv span for the whole site site_pv: true site_pv_header: &lt;i class=\"fa fa-eye\"&gt;&lt;/i&gt; 本站总访问量 site_pv_footer: 次 # custom pv span for one page only page_pv: true page_pv_header: &lt;i class=\"fa fa-file-o\"&gt;&lt;/i&gt; 本文总阅读量 page_pv_footer: 次 内容分享服务 百度分享 效果图： 编辑 主题配置文件，配置如下： 123456# Baidu Share# Available value:# button | slide# Warning: Baidu Share does not support https.baidushare: type: slide type（=slide 测试成功，=button 测试未成功） 搜索服务 Local Search 效果图： 安装 Local Search 搜索插件: npm install --save hexo-generator-searchdb 编辑 站点配置文件，新增如下配置： 1234567####################### add ######################## hexo-generator-searchdbsearch: path: search.xml field: post format: html limit: 10000 编辑 主题配置文件，配置如下： 123456789# Local search# Dependencies: https://github.com/flashlab/hexo-generator-searchlocal_search: enable: true # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: 1 增加最新文章模块 效果图： 编辑主题目录下的 layout/_custom/sidebar.swig 文件，新增如下内容： 1234567891011121314151617{# recent_posts #}{% if theme.recent_posts %} &lt;div class=\"links-of-blogroll motion-element {{\"links-of-blogroll-\"+ theme.recent_posts_layout | default('block') }}\"&gt; &lt;div class=\"links-of-blogroll-title\"&gt; &lt;i class=\"fa fa-fw fa-{{ theme.recent_posts_icon | default('globe') | lower }}\"&gt;&lt;/i&gt; {{ theme.recent_posts_title }} &lt;/div&gt; &lt;ul class=\"links-of-blogroll-list\"&gt; {% set posts = site.posts.sort('-date') %} {% for post in posts.slice('0', '5') %} &lt;li class=\"links-of-blogroll-item\"&gt; &lt;a href=\"{{ url_for(post.path) }}\" title=\"{{ post.title }}\" target=\"_blank\"&gt;{{ post.title }}&lt;/a&gt; &lt;/li&gt; {% endfor %} &lt;/ul&gt; &lt;/div&gt;{% endif %} 编辑 主题配置文件，新增如下配置： 123456####################### add #######################recent_posts: truerecent_posts_icon: historyrecent_posts_title: 最新文章recent_posts_layout: block#recent_posts_layout: inline 增加博客后台管理功能Hexo Admin 插件 GitHub 首页：https://github.com/jaredly/hexo-admin 演示 Demo：https://jaredforsyth.com/hexo-admin/ 安装 Hexo Admin 插件 1npm install --save hexo-admin 配置用户名密码 启动服务 hexo server -d 之后，访问 http://127.0.0.1:4000/admin ，按下列步骤完成配置： 注意：我们只能在本地进行后台管理，无法在自己的域名下进行后台管理。 编辑 站点配置文件，新增如下配置（从 2 中拷贝）： 123456####################### add ######################## hexo-admin authentificationadmin: username: admin password_hash: $2a$10$d/U.IVXaAL86EWnsBQU2GuGgfbETQ6TK1UUgLsL3U5h4883tg3YyK secret: 1234567890abc 验证 123hexo cleanhexo generatehexo server -d 访问 http://127.0.0.1:4000/admin 登录。 Hexo 教程合集 （微信左下方 阅读全文 可直达）。 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2019/09/20/tool/hexo-theme-next/"},{"title":"Maven 实战","text":"从零开始学习 Maven ，从入门到精通。 1 坐标 1.1 groupId 必须，定义当前项目隶属的 实际项目。如 com.cxy35.account 。 1.2 artifactId必须，定义实际项目中的一个Maven 项目或模块，推荐使用实际项目名称作为 artifactId 的前缀。如 account-web 。 1.3 version必须，定义 Maven 项目当前所处的版本。如 1.0.0 或 1.0.0-SNAPSHOT 。 1.4 packaging定义 Maven 项目的打包方式，默认 jar 。如 jar 或 war 。 1.5 classifier用来帮助定义构建输出的一些附属附件，不能直接定义。 2 依赖 2.1 依赖的配置 在项目 pom.xml 文件中配置，当前项目有效，如：&lt;dependencies&gt;&lt;dependency&gt;...&lt;/dependency&gt;......&lt;/dependencies&gt; 。元素包括： groupId、artifactId、version：依赖的基本坐标，必须。对于任何一个依赖来说，基本坐标是最重要的， Maven 根据坐标才能找到需要的依赖。 type：依赖的类型，默认 jar ，对应坐标中的 packaging 。 scope：依赖的范围，默认 compile 。 optional：标记依赖是否可选。 exclusions：用来排除传递性依赖。 2.2 依赖范围 compile：编译依赖范围，默认该值。对编译、测试、运行三种 classpath 都有效，如 spring-core 。 test：测试依赖范围。只对测试 classpath 有效，如 jUnit 。 provided：已提供依赖范围。对编译和测试 classpath 有效，因为运行时容器已经提供，如 servlet-api 。 runtime：运行时依赖范围。对测试和运行 classpath 有效，因为编译时用的是 JDK 提供的 JDBC 接口，如 JDBC 驱动实现，只有在执行测试或者运行项目的时候才需要实现上述接口的具体 JDBC 驱动。 system：系统依赖范围。对编译和测试 classpath 有效，通过 systemPath 元素显示地指定本地依赖文件的路径，可能造成构建的不可移植，因此应该谨慎使用。 import：导入依赖范围。对编译、测试、运行三种 classpath 都无效。 依赖范围与 classpath 的关系，如下图： 2.3 传递性依赖 如项目 A 有这样的依赖关系：A-&gt;B-&gt;C-&gt;X ，则 X 是 A 的传递性依赖。依赖范围影响传递性依赖，第一列表示第一直接依赖范围，第一行表示第二直接依赖范围，中间的交叉单元格则表示传递性依赖范围，如下图： 2.4 依赖调解 第一原则：路径最近者优先：如项目 A 有这样的依赖关系：A-&gt;B-&gt;C-&gt;X(1.0) 和 A-&gt;D-&gt;X(2.0) ， X 是 A 的传递性依赖，但有 2 个版本，最终 X(2.0) 会被解析使用。 第二原则：第一申明者优先：如项目 A 有这样的依赖关系：A-&gt;B-&gt;X(1.0) 和 A-&gt;D-&gt;X(2.0) ， X 是 A 的传递性依赖，但有 2 个版本，且路径相同，最终 X(1.0) 会被解析使用。 2.5 可选依赖 有时候我们不想让依赖传递，那么可配置该依赖为可选依赖，即将参数 optional 设置为 true ，这样其他项目用到时就不会得到此依赖的传递。 2.6 排除依赖 当我们引入第三方 jar 包的时候，难免会引入传递性依赖。如果不想引入，则可在依赖中配置去除对应的传递性依赖，如： &lt;dependency&gt;&lt;exclusions&gt;&lt;exclusion&gt;...&lt;/exclusion&gt;......&lt;/exclusions&gt;&lt;/dependency&gt; 。 3 仓库 在 Maven 世界中，任何一个依赖、插件或者项目构建的输出，都可以称为 构件 。仓库分为两类： 本地仓库和远程仓库，如下图。 3.1 本地仓库 默认在当前用户的目录下，如：C:\\Users\\Administrator.m2\\repository 下。可在 settings.xml 文件中修改。 &lt;localRepository&gt;D:\\.m2\\repository&lt;/localRepository&gt; 。 3.2 远程仓库 远程仓库分为中央仓库(http://repo1.maven.org/maven2 )、私服（一般搭建在局域网内）、其他公共库。 3.2.1 远程仓库的配置 在项目 pom.xml 文件中配置，当前项目有效。在 setting.xml 文件中配置，全局有效。如 ：&lt;repositories&gt;&lt;repository&gt;...&lt;/repository&gt;......&lt;/repositories&gt; 。 3.2.3 远程仓库的认证 在 setting.xml 文件中配置，全局有效，如： &lt;servers&gt;&lt;server&gt;...&lt;/server&gt;......&lt;/servers&gt; 。 3.2.3 部署到远程仓库 在项目 pom.xml 文件中配置，当前项目有效，如： &lt;distributionManagement&gt;&lt;repository&gt;...&lt;/repository&gt;&lt;snapshotRepository&gt;...&lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; 。 3.3 镜像 在 setting.xml 文件中配置，全局有效，如： &lt;mirrors&gt;&lt;mirror&gt;...&lt;/mirror&gt;......&lt;/mirrors&gt; 。 4 生命周期 Maven 的生命周期是抽象的，其实际行为都 由插件来完成 ，如 clean 阶段的任务由 maven-clean-plugin 完成。主要包含了项目的清理、初始化、编译、测试、打包、集成测试、验证、部署、站点生成等构建步骤。有 3 套生命周期， 每套生命周期包含一些阶段（phase），这些阶段有顺序，且后面的阶段依赖前面的阶段，但每套生命周期本身是相互独立的。 4.1 clean 生命周期（清理项目）pre-clean、clean、post-clean 。 4.2 dafault 生命周期（构建项目） validate：验证项目是否正确和所有需要的相关资源是否可用。 initialize：初始化构建。 generate-sources process-sources：处理项目主资源文件。一般来说，是对 src/main/resources 目录的内容进行变量替换等工作后，复制到项目输出的主 classpath 目录中。 generate-resources process-resources compile：编译项目的主源码。一般来说，是编译 src/main/java 目录下的 Java 文件至项目输出的主 classpath 目录中。 process-classes generate-test-sources process-test-sources：处理项目测试资源文件。一般来说，是对 src/test/resources 目录的内容进行变量替换等工作后，复制到项目输出的测试 classpath 目录中。 generate-test-resources process-test-resources test-compile：编译项目的测试代码。一般来说，是编译 src/test/java 目录下的 Java 文件至项目输出的测试 classpath 目录中。 process-test-classes test：使用单元测试框架运行测试，测试代码不会被打包或部署。 prepare-package：做好打包的准备。 package：接受编译好的代码，打包成可发布的格式，如 JAR 。 pre-integration-test integration-test post-integration-test verify install：将包安装到 Maven 本地仓库，供本地其他 Maven 项目使用。 deploy：将最终的包复制到远程仓库，供其他开发人员和 Maven 项目使用。 4.3 site 生命周期（建立项目站点）pre-site、site、post-site、site-deploy。 5 插件 5.1 插件目标(Plugin Goal) 一个插件可以完成很多功能，每个功能就是一个插件目标 ，如 dependency:list(或 maven-dependency-plugin:list)、dependency:tree(或 maven-dependency-plugin:tree)， 冒号前面的是插件前缀或插件，冒号后面的是目标。 5.2 插件绑定 一些生命周期中的阶段会 内置绑定某个插件目标，如 clean 生命周期的 clean 阶段内置绑定的插件目标是 maven-clean-plugin:clean 。 5.3 插件配置 在项目 pom.xml 文件中配置，当前项目有效，如： &lt;build&gt;&lt;plugins&gt;&lt;plugin&gt;...&lt;/plugin&gt;......&lt;/plugins&gt;&lt;/build&gt; 。在命令行中中配置，当前项目有效，使用 -D 参数，如： mvn clean install -Dmaven.test.skip=true。 6 聚合与继承 6.1 聚合 目的是为了方便快速构建项目，分为聚合模块和被聚合模块。聚合模块命名一般为： xxx-aggregator 或 xxx ，打包方式 packaging 为 pom ，可以是父子目录结构（推荐，聚合模块放在项目目录的最顶层），也可以是平行目录结构。在聚合模块的 pom.xml 文件中配置，如： &lt;modules&gt;&lt;module&gt;...&lt;/module&gt;......&lt;/modules&gt; 。 6.2 继承 目的是为了消除重复配置，分为父模块和子模块。父模块命名一般为： xxx-parent ，打包方式 packaging 为 pom 。在子模块 pom.xml 文件中配置，如： &lt;parent&gt;...&lt;/parent&gt; ，可由 relativePath 属性指定父模块的位置，默认认为在子模块的上一级。任何一个 maven 项目都隐式地继承 1 个默认的超级 pom ，里面定义了一些默认的配置。 6.3 依赖管理dependencyManagement 元素能让子模块继承到父模块的依赖配置，但不会引入实际的依赖，实际引入由子模块灵活控制，类似于接口与实现类。在父项目 pom.xml 文件中配置，如： &lt;dependencyManagement&gt;&lt;dependencies&gt;&lt;dependency&gt;...&lt;/dependency&gt;......&lt;/dependencies&gt;&lt;/dependencyManagement&gt; 。 6.4 插件管理 类似于依赖管理。在父项目 pom.xml 文件中配置，如： &lt;pluginManagement&gt;&lt;plugins&gt;&lt;plugin&gt;...&lt;/plugin&gt;......&lt;/plugins&gt;&lt;/pluginManagement&gt; 。 6.5 反应堆(Reactor) 所有模块组成的一个构建结构。对于单模块的项目，反应堆就是该模块本身，但对于多模块的项目，反应堆就包含了各模块之间继承与依赖的关系，从而能够自动计算出合理的模块构建顺序。 6.6 聚合与继承合并 可以用 xxx 或 xxx-parent 来 合并聚合与继承的功能，既是聚合 pom ，又是父 pom 。 7 灵活的构建 Maven 为了支持构建的灵活性，内置了三大特性，即 属性、Profile 和资源过滤。 Maven 用户可以在 POM 和资源文件中使用 Maven 属性表示那些可能变化的量，通过不同 profile 中的属性值和资源过滤特性为不同环境执行不同的构建。 7.1 Maven 属性（6 类）7.1.1 内置属性 主要有两个常用内置属性， ${basedir} 表示项目根目录，即包含 pom.xml 文件的目录； ${version} 表示项目版本。 7.1.2 POM 属性 用户可以使用该类属性引用 POM 文件中对应元素的值。例如 ${project.artifactId} 就对应了 &lt;project&gt;&lt;artifactId&gt; 元素的值。常用的 POM 属性包括： ${project.build.sourceDirectory}：项目的主源码目录，默认为 src/main/java/ 。 ${project.build.testSourceDirectory}：项目的测试源码目录，默认为 src/test/java/ 。 ${project.build.directory}：项目构建输出目录，默认为 target/ 。 ${project.outputDirectory}：项目的主代码编译输出目录，默认为 target/classes/ 。 ${project.testOutputDirectory}：项目测试代码编译输出目录，默认为 target/test-classes/ 。 ${project.groupId}：项目的 groupId 。 ${project.artifactId}：项目的 artifactId 。 ${project.version}：项目的 version ，与 ${version} 等价。 ${project.build.finalName}：项目打包输出文件的名称，默认为 ${project.artifactId}-${project.version} 。 这些属性都对应了一个 POM 元素，它们中一些属性的默认值都是在超级 POM 中定义的。 7.1.3 自定义属性 用户可以在 POM 的 &lt;properties&gt; 元素下自定义 Maven 属性。例如： 1234567&lt;project&gt; ... &lt;properties&gt; &lt;my.prop&gt;hello&lt;/my.prop&gt; &lt;/properties&gt; ... &lt;/project&gt; 然后在 POM 中其他地方使用 ${my.prop} 的时候会被替换成 hello 。 7.1.4 Settings 属性 与 POM 属性同理，用户使用以 settings. 开头的属性引用 settings.xml 文件中 XML 元素的值，如常用的 ${settings.localRepository} 指向用户本地仓库的地址。 7.1.5 Java 系统属性 所有 Java 系统属性都可以使用 Maven 属性引用，例如 ${user.home} 指向了用户目录。用户可以使用 mvn help:system 查看所有的 Java 系统属性。 7.1.6 环境变量属性 所有环境变量都可以使用以 env. 开头的 Maven 属性引用。例如 ${env.JAVA_HOME} 指代了 JAVA_HOME 环境变量的值。用户可以使用 mvn help:system 查看所有的环境变量。 7.2 资源过滤 在项目 pom.xml 文件中配置，当前项目有效。如： &lt;build&gt;&lt;resources&gt;&lt;resource&gt;...&lt;/resource&gt;......&lt;/resources&gt;&lt;/build&gt; 。会使用 maven-resources-plugin 插件解析资源文件（如 src/main/resources ）中的 Maven 属性，替换成对应的值，如数据库配置信息。 7.3 Maven Profile在项目 pom.xml 文件中配置，当前项目有效。在 setting.xml 文件中配置，全局有效。如： &lt;profiles&gt;&lt;profile&gt;...&lt;/profile&gt;......&lt;/profiles&gt; 。常用于配置不同环境下的数据库配置信息，如开发环境、测试环境、测试环境，再激活其中一个 profile ，如可用命令激活： mvn clean install -Pdev ， -P 参数表示在命令行激活一个 profile 。也可配置默认激活某一个 profile 。当执行 Maven 构建的时候，激活的 profile 会将配置应用到项目中去。 7.4 Web 资源过滤 在项目 pom.xml 文件中配置，当前项目有效。会使用 maven-war-plugin 插件解析 web 资源文件（如 src/main/webapp ）中的 Maven 属性，替换成对应的值，如 logo 图片或 css 主题。 8 使用 Nexus 搭建 Maven 私服 Nexus 有两种安装包：一种是包含 Jetty 容器的 Bundle 包，另一种是不包含 Web 容器的 war 包。默认端口是 8081 ，默认管理员用户名和密码是 admin/admin123 。 Nexus 仓库类型有四种： group （仓库组，如 Public Repositories ）、 hosted （宿主，如 3rd party/Releases/Snapshots ）、 proxy （代理，如 Central ）、 virtual （虚拟）。 Nexus 通过维护仓库的索引来提供搜索功能。注意默认情况下，中央仓库的代理仓库（ Central ）中下载远程索引的配置（ Download Remote Indexes ）是关闭的，需要在配置中开启，这样才能搜索中央仓库中的构件。注意：对于在仓库浏览器中浏览或者搜索构件，其搜索的是存在 nexus 服务器本地 ${bundleBasedir}/../sonatype-work /nexus/storage 目录下的构件，如果找不到就找不到了。这些构件当 maven 应用配置指向 nexus 地址，并且 nexus 在自己层面找不到构件，才从相应的所代理的远程仓库中下载构件，并且存入 storage 目录。对于点击某仓库，查看其 “Browse Remote” ，则只要网络通，就总能看到某版本构件，因为你直接查看了远程仓库的构件索引。 9 常用命令Maven 常用命令 mvn clean：清理 target 目录。 mvn clean compile：清理，编译主代码与资源。 mvn clean test：清理，编译主代码与资源，编译测试代码与资源，测试。 mvn clean package：清理，编译主代码与资源，编译测试代码与资源，测试，打包。 mvn clean install：清理，编译主代码与资源，编译测试代码与资源，测试，打包，安装到本地仓库。 mvn clean deploy：清理，编译主代码与资源，编译测试代码与资源，测试，打包，安装到本地仓库，部署到远程仓库。 mvn archetype:generate ：快速创建项目骨架。 mvn dependency:list ：查看当前项目的已解析依赖。 mvn dependency:tree ：查看当前项目的依赖属。 mvn dependency:analyze ：分析当前项目的依赖。可分析出“项目中使用到的但没有显式声明的依赖”和“项目中未使用的但显式声明的依赖（注意只会分析编译时需要用到的依赖，测试和运行时的发现不了，删除时务必小心）”。 10 常用插件 maven-clean-plugin（清理） maven-compiler-plugin（编译，可指定编译版本） maven-resources-plugin maven-war-plugin maven-source-plugin（创建源码 jar 包） maven-surefire-plugin（测试，自动运行单元测试，测试类的命名或目录需保持一定的规则） maven-shade-plugin（生成可执行的 jar 文件） maven-dependency-plugin（依赖相关的插件） maven-help-plugin（获取插件的详细信息） jetty-maven-plugin（测试，自动扫描项目并更新部署到 Web 容器中，帮助日常的快速开发和测试） cargo-maven2-plugin（自动化部署） mybatis-generator-maven-plugin（ mybatis 代码生成器） 11 常用仓库与查询 中央仓库：http://repo1.maven.org/maven2/ 中央仓库：https://repo.maven.apache.org/maven2/ 查询：http://search.maven.org/ 查询：http://mvnrepository.com/ 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 ## 程序员的 35，35 的程序员 ## 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2018/06/02/tool/maven-in-action/"},{"title":"Elasticsearch 常用命令","text":"通过本文学习 Elasticsearch 常用命令，以下所有命令都在 Kibana 的 Dev Tools 中执行。 1 全局 查看集群健康状态：GET /_cat/health?v 查看节点状态：GET /_cat/nodes?v 查看所有索引信息：GET /_cat/indices?v 2 索引 新增索引：PUT /user 新增索引 - 自定义settings：1234567PUT /user{ &quot;settings&quot;: { &quot;number_of_shards&quot;: 1, &quot;number_of_replicas&quot;: 0 }} 新增索引 - 自定义mappings：12345678910111213141516171819202122232425PUT /user{ &quot;mappings&quot;: { &quot;properties&quot;: { &quot;username&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 } } }, &quot;address&quot; : { &quot;type&quot; : &quot;text&quot;, &quot;analyzer&quot; : &quot;ik_max_word&quot;, &quot;search_analyzer&quot; : &quot;ik_smart&quot; }, &quot;location&quot;: { &quot;type&quot;: &quot;geo_point&quot; }, ...... } }} 查看索引：GET /user 查看索引中的settings：GET /user/_settings 查看索引中的mappings：GET /user/_mappings 删除索引：DELETE /user 3 文档 新增文档 - 指定 id（id 不存在则新增，存在则更新）：123456789101112POST /user/_doc/1{ &quot;id&quot;: 1, &quot;username&quot;: &quot;zhangsan&quot;, &quot;password&quot;: &quot;123456&quot;, &quot;enabled&quot;: true, &quot;locked&quot;: false, &quot;address&quot;: &quot; 浙江杭州 &quot;, &quot;nickName&quot;: &quot; 张三 &quot;, &quot;createTime&quot;: 1602836232511, &quot;updateTime&quot;: 1602836232511} 新增文档 - 指定 id（id 不存在则新增，存在则报错）：123456789101112POST /user/_create/1{ &quot;id&quot;: 1, &quot;username&quot;: &quot;zhangsan&quot;, &quot;password&quot;: &quot;123456&quot;, &quot;enabled&quot;: true, &quot;locked&quot;: false, &quot;address&quot;: &quot; 浙江杭州 &quot;, &quot;nickName&quot;: &quot; 张三 &quot;, &quot;createTime&quot;: 1602836232511, &quot;updateTime&quot;: 1602836232511} 新增文档 - 自动生成 id：123456789101112POST /user/_doc{ &quot;id&quot;: 2, &quot;username&quot;: &quot;lisi&quot;, &quot;password&quot;: &quot;123456&quot;, &quot;enabled&quot;: true, &quot;locked&quot;: false, &quot;address&quot;: &quot; 浙江宁波 &quot;, &quot;nickName&quot;: &quot; 李四 &quot;, &quot;createTime&quot;: 1602836232511, &quot;updateTime&quot;: 1602836232511} 新增文档 - 批量_bulk：12345POST /user/_bulk{&quot;index&quot;:{&quot;_id&quot;:&quot;1&quot;}}{&quot;id&quot;:1,&quot;username&quot;:&quot;zhangsan&quot;}{&quot;index&quot;:{&quot;_id&quot;:&quot;2&quot;}}{&quot;id&quot;:2,&quot;username&quot;:&quot;zhangsan2&quot;} 查看文档：GET /user/_doc/1 查看文档 - 批量_mget：1234GET /user/_mget{ &quot;ids&quot;: [&quot;1&quot;, &quot;2&quot;]} 修改文档 - 指定 id（id 不存在则新增，存在则替换）- 整体修改（因此需要传所有字段）：123456789101112POST /user/_doc/1{ &quot;id&quot;: 1, &quot;username&quot;: &quot;zhangsan&quot;, &quot;password&quot;: &quot;654321&quot;, &quot;enabled&quot;: true, &quot;locked&quot;: false, &quot;address&quot;: &quot; 浙江杭州 &quot;, &quot;nickName&quot;: &quot; 张三 &quot;, &quot;createTime&quot;: 1602836232511, &quot;updateTime&quot;: 1602836232511} 修改文档 - 指定 id（id 不存在则报错，存在则合并）- 局部修改（因此只需要传修改的字段）：123456POST /user/_update/1{ &quot;doc&quot;: { &quot;password&quot;: &quot;121212&quot; }} 修改文档 - 指定 id（id 不存在则创建，存在则合并）- 局部修改（因此只需要传修改的字段）：1234567POST /user/_update/1{ &quot;doc&quot;: { &quot;password&quot;: &quot;121212&quot; }, &quot;doc_as_upsert&quot;: true} 修改文档 - 指定 id- 局部修改 - 脚本方式：1234567891011POST /user/_update/1{ &quot;script&quot; : { &quot;source&quot;: &quot;ctx._source.password = params.password;ctx._source.address = params.address&quot;, &quot;lang&quot;: &quot;painless&quot;, &quot;params&quot;: { &quot;password&quot;: &quot;232323&quot;, &quot;address&quot;: &quot; 浙江宁波 &quot; } }} 修改文档 -update_by_query- 局部修改 - 脚本方式：12345678910111213141516POST /user/_update_by_query{ &quot;query&quot;: { &quot;match&quot;: { &quot;username&quot;: &quot;zhangsan&quot; } }, &quot;script&quot;: { &quot;source&quot;: &quot;ctx._source.password = params.password;ctx._source.address = params.address, &quot;lang&quot;: &quot;painless&quot;, &quot;params&quot;: { &quot;password&quot;: &quot;654321&quot;, &quot;address&quot;: &quot; 浙江杭州 &quot; } }} 检查文档是否存在：HEAD /user/_doc/1 删除文档 - 指定 id：DELETE /user/_doc/1 删除文档 - 批量_bulk：123POST /_bulk{ &quot;delete&quot; : { &quot;_index&quot; : &quot;user2&quot;, &quot;_id&quot;: 1 }}{ &quot;delete&quot; : { &quot;_index&quot; : &quot;user2&quot;, &quot;_id&quot;: 6 }} 删除文档 -delete_by_query：12345678POST /user/_delete_by_query{ &quot;query&quot;: { &quot;match&quot;: { &quot;username&quot;: &quot;zhangsan&quot; } }} 4 搜索4.1 普通 搜索 - 文档总数_count：GET /user/_count 搜索 - 文档数量_count：12345678GET /user/_count{ &quot;query&quot;: { &quot;match&quot;: { &quot;address&quot;: &quot; 浙江杭州 &quot; } }} 搜索_search：12345678GET /_searchGET /user,user2/_searchGET /user/_searchGET /user/_search?size=20GET /user/_search?size=20&amp;from=3GET /user/_search?q=address:&quot; 浙江杭州 &quot;GET /user/_search?filter_path=hits.totalGET /user/_search?_source=username,address 搜索 - 所有文档match_all：123456GET /user/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }} 搜索 - 分页from/size：12345678GET /user/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;from&quot;: 0, &quot;size&quot;: 2} 搜索 - 排序sort：1234567891011GET /user/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;sort&quot;: { &quot;updateTime&quot;: { &quot;order&quot;: &quot;desc&quot; } }} 搜索 - 指定返回字段_source：1234567GET /user/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;_source&quot;: [&quot;username&quot;, &quot;address&quot;]} 4.2 匹配 搜索 - 匹配match（数值类型是精确匹配，文本类型是模糊匹配）：12345678910GET /user/_search{ &quot;query&quot;: { &quot;match&quot;: { &quot;enabled&quot;: 1 } }}@ GET /user/_search?q=enabled:1 搜索 - 多字段匹配multi_match（或）：123456789101112POST /user/_search{ &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;zhang&quot;, &quot;fields&quot;: [ &quot;username&quot;, &quot;nickName&quot; ] } }} 搜索 - 短语匹配match_phrase（同时包含多个短语）：12345678GET /user/_search{ &quot;query&quot;: { &quot;match_phrase&quot;: { &quot;address&quot;: &quot;zhejiang hangzhou&quot; } }} 4.3 组合 搜索 - 组合bool/must（同时满足多个条件）：1234567891011GET /user/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;match&quot;: { &quot;address&quot;: &quot;zhejiang&quot; } }, { &quot;match&quot;: { &quot;address&quot;: &quot;hangzhou&quot; } } ] } }} 搜索 - 组合bool/should（满足其中任意一个条件）：1234567891011GET /user/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;should&quot;: [ { &quot;match&quot;: { &quot;address&quot;: &quot;zhejiang&quot; } }, { &quot;match&quot;: { &quot;address&quot;: &quot;hangzhou&quot; } } ] } }} 搜索 - 组合bool/must_not（同时不满足多个条件）：1234567891011GET /user/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must_not&quot;: [ { &quot;match&quot;: { &quot;address&quot;: &quot;zhejiang&quot; } }, { &quot;match&quot;: { &quot;address&quot;: &quot;hangzhou&quot; } } ] } }} 搜索 - 组合bool/filter（过滤，keyword 字段用于一般用于精确搜索、聚合、排序）：123456789101112GET /user/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;filter&quot;: { &quot;term&quot;: { &quot;address.keyword&quot;: &quot; 浙江杭州 &quot; } } } }} 搜索 - 多种组合：12345678910111213GET /user/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;match&quot;: { &quot;enabled&quot;: 1 } } ], &quot;must_not&quot;: [ { &quot;match&quot;: { &quot;address&quot;: &quot;hangzhou&quot; } } ] } }} 4.4 过滤 搜索 - 过滤filter：12345678910111213141516GET /user/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: { &quot;match_all&quot;: {} }, &quot;filter&quot;: { &quot;range&quot;: { &quot;id&quot;: { &quot;gte&quot;: 3, &quot;lte&quot;: 6 } } } } }} 4.5 聚合 搜索 - 聚合aggs（类似于 MySQL 中的 group by）： 1234567891011GET /user/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;myagg_enabled&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;enabled.keyword&quot; } } }} 搜索 - 嵌套聚合aggs：123456789101112131415161718GET /user/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;myagg_enabled&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;enabled.keyword&quot; }, &quot;aggs&quot;: { &quot;myagg_age&quot;: { &quot;avg&quot;: { &quot;field&quot;: &quot;age&quot; } } } } }} 搜索 - 嵌套聚合 aggs 并对结果进行排序order：123456789101112131415161718192021GET /user/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;myagg_enabled&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;enabled.keyword&quot;, &quot;order&quot;: { &quot;myagg_age&quot;: &quot;desc&quot; } }, &quot;aggs&quot;: { &quot;myagg_age&quot;: { &quot;avg&quot;: { &quot;field&quot;: &quot;age&quot; } } } } }} 搜索 - 分段聚合aggs/range：123456789101112131415161718192021222324252627282930313233343536373839GET /user/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;myagg_id&quot;: { &quot;range&quot;: { &quot;field&quot;: &quot;id&quot;, &quot;ranges&quot;: [ { &quot;from&quot;: 20, &quot;to&quot;: 30 }, { &quot;from&quot;: 30, &quot;to&quot;: 40 }, { &quot;from&quot;: 40, &quot;to&quot;: 50 } ] }, &quot;aggs&quot;: { &quot;myagg_enabled&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;enabled.keyword&quot; }, &quot;aggs&quot;: { &quot;myagg_age&quot;: { &quot;avg&quot;: { &quot;field&quot;: &quot;age&quot; } } } } } } }} 4.6 原生 SQL123456789101112131415161718192021222324GET /_sql?format=txt{ &quot;query&quot;: &quot;SHOW TABLES&quot;}GET /_sql?format=txt{ &quot;query&quot;: &quot;SELECT * FROM user&quot;}GET /_sql?format=txt{ &quot;query&quot;: &quot;DESCRIBE user&quot;}POST /_sql?format=txt{ &quot;query&quot;: &quot;SHOW FUNCTIONS LIKE '%DATE%'&quot;}POST /_sql?format=txt{ &quot;query&quot;: &quot;SELECT id,username,nick_name,address,SCORE() FROM user WHERE MATCH(address,' 杭州 ') LIMIT 10&quot;} 4.7 官方搜索例子 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924@ 准备数据POST twitter/_bulk{ &quot;index&quot; : { &quot;_id&quot;: 1 } }{&quot;user&quot;:&quot; 双榆树 - 张三 &quot;,&quot;message&quot;:&quot; 今儿天气不错啊，出去转转去 &quot;,&quot;uid&quot;:2,&quot;age&quot;:20,&quot;city&quot;:&quot; 北京 &quot;,&quot;province&quot;:&quot; 北京 &quot;,&quot;country&quot;:&quot; 中国 &quot;,&quot;address&quot;:&quot; 中国北京市海淀区 &quot;,&quot;location&quot;:{&quot;lat&quot;:&quot;39.970718&quot;,&quot;lon&quot;:&quot;116.325747&quot;}}{ &quot;index&quot; : { &quot;_id&quot;: 2 } }{&quot;user&quot;:&quot; 东城区 - 老刘 &quot;,&quot;message&quot;:&quot; 出发，下一站云南！&quot;,&quot;uid&quot;:3,&quot;age&quot;:30,&quot;city&quot;:&quot; 北京 &quot;,&quot;province&quot;:&quot; 北京 &quot;,&quot;country&quot;:&quot; 中国 &quot;,&quot;address&quot;:&quot; 中国北京市东城区台基厂三条 3 号 &quot;,&quot;location&quot;:{&quot;lat&quot;:&quot;39.904313&quot;,&quot;lon&quot;:&quot;116.412754&quot;}}{ &quot;index&quot; : { &quot;_id&quot;: 3 } }{&quot;user&quot;:&quot; 东城区 - 李四 &quot;,&quot;message&quot;:&quot;happy birthday!&quot;,&quot;uid&quot;:4,&quot;age&quot;:30,&quot;city&quot;:&quot; 北京 &quot;,&quot;province&quot;:&quot; 北京 &quot;,&quot;country&quot;:&quot; 中国 &quot;,&quot;address&quot;:&quot; 中国北京市东城区 &quot;,&quot;location&quot;:{&quot;lat&quot;:&quot;39.893801&quot;,&quot;lon&quot;:&quot;116.408986&quot;}}{ &quot;index&quot; : { &quot;_id&quot;: 4 } }{&quot;user&quot;:&quot; 朝阳区 - 老贾 &quot;,&quot;message&quot;:&quot;123,gogogo&quot;,&quot;uid&quot;:5,&quot;age&quot;:35,&quot;city&quot;:&quot; 北京 &quot;,&quot;province&quot;:&quot; 北京 &quot;,&quot;country&quot;:&quot; 中国 &quot;,&quot;address&quot;:&quot; 中国北京市朝阳区建国门 &quot;,&quot;location&quot;:{&quot;lat&quot;:&quot;39.718256&quot;,&quot;lon&quot;:&quot;116.367910&quot;}}{ &quot;index&quot; : { &quot;_id&quot;: 5 } }{&quot;user&quot;:&quot; 朝阳区 - 老王 &quot;,&quot;message&quot;:&quot;Happy BirthDay My Friend!&quot;,&quot;uid&quot;:6,&quot;age&quot;:50,&quot;city&quot;:&quot; 北京 &quot;,&quot;province&quot;:&quot; 北京 &quot;,&quot;country&quot;:&quot; 中国 &quot;,&quot;address&quot;:&quot; 中国北京市朝阳区国贸 &quot;,&quot;location&quot;:{&quot;lat&quot;:&quot;39.918256&quot;,&quot;lon&quot;:&quot;116.467910&quot;}}{ &quot;index&quot; : { &quot;_id&quot;: 6 } }{&quot;user&quot;:&quot; 虹桥 - 老吴 &quot;,&quot;message&quot;:&quot; 好友来了都今天我生日，好友来了, 什么 birthday happy 就成!&quot;,&quot;uid&quot;:7,&quot;age&quot;:90,&quot;city&quot;:&quot; 上海 &quot;,&quot;province&quot;:&quot; 上海 &quot;,&quot;country&quot;:&quot; 中国 &quot;,&quot;address&quot;:&quot; 中国上海市闵行区 &quot;,&quot;location&quot;:{&quot;lat&quot;:&quot;31.175927&quot;,&quot;lon&quot;:&quot;121.383328&quot;}}@ 查询@@ _searchGET _searchGET /twitter,twitter2/_searchGET /twitter/_searchGET /twitter/_search?size=20GET /twitter/_search?size=20&amp;from=3GET /twitter/_search?filter_path=hits.totalGET /twitter/_search?_source=user,city@@ _countGET /twitter/_countGET /twitter/_count{ &quot;query&quot;: { &quot;match&quot;: { &quot;city&quot;: &quot; 北京 &quot; } }}@@ 查看 / 设置 settingsGET /twitter/_settingsPUT twitter{ &quot;settings&quot;: { &quot;number_of_shards&quot;: 1, &quot;number_of_replicas&quot;: 1 }}@@ 查看 / 设置 mappingGET /twitter/_mappingPUT twitter/_mapping{ &quot;properties&quot;: { &quot;address&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 } } }, &quot;age&quot;: { &quot;type&quot;: &quot;long&quot; }, &quot;city&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 } } }, &quot;country&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 } } }, &quot;location&quot;: { &quot;type&quot;: &quot;geo_point&quot; }, &quot;message&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 } } }, &quot;province&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 } } }, &quot;uid&quot;: { &quot;type&quot;: &quot;long&quot; }, &quot;user&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 } } } }}@@ 普通查询@@@ matchGET /twitter/_search{ &quot;query&quot;: { &quot;match&quot;: { &quot;city&quot;: &quot; 北京 &quot; } }}GET /twitter/_search?q=city:&quot; 北京 &quot;@@@ keyword 字段用于精确搜索，aggregation 和排序（sorting）GET /twitter/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;filter&quot;: { &quot;term&quot;: { &quot;city.keyword&quot;: &quot; 北京 &quot; } } } }}GET /twitter/_search{ &quot;query&quot;: { &quot;constant_score&quot;: { &quot;filter&quot;: { &quot;term&quot;: { &quot;city.keyword&quot;: { &quot;value&quot;: &quot; 北京 &quot; } } } } }}@@@ 匹配“朝”，“阳”，“区”，“老”及“贾”这 5 个字中的任何一个将被显示GET /twitter/_search{ &quot;query&quot;: { &quot;match&quot;: { &quot;user&quot;: { &quot;query&quot;: &quot; 朝阳区 - 老贾 &quot;, &quot;operator&quot;: &quot;or&quot; } } }}@@@ 至少要匹配“朝”，“阳”，“区”，“老”及“贾这 5 个中的 3 个字才可以GET /twitter/_search{ &quot;query&quot;: { &quot;match&quot;: { &quot;user&quot;: { &quot;query&quot;: &quot; 朝阳区 - 老贾 &quot;, &quot;operator&quot;: &quot;or&quot;, &quot;minimum_should_match&quot;: 3 } } }}@@@ 需要同时匹配索引的 5 个字才可以GET /twitter/_search{ &quot;query&quot;: { &quot;match&quot;: { &quot;user&quot;: { &quot;query&quot;: &quot; 朝阳区 - 老贾 &quot;, &quot;operator&quot;: &quot;and&quot; } } }}@@@ multi：同时对三个 fields: user，adress 及 message 进行搜索GET /twitter/_search{ &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot; 朝阳 &quot;, &quot;fields&quot;: [ &quot;user&quot;, &quot;address^3&quot;, &quot;message&quot; ], &quot;type&quot;: &quot;best_fields&quot; } }}@@@ prefix：查询 user 字段里以“朝”为开头的所有文档GET /twitter/_search{ &quot;query&quot;: { &quot;prefix&quot;: { &quot;user&quot;: { &quot;value&quot;: &quot; 朝 &quot; } } }}@@@ term：使用 user.keyword 来对“朝阳区 - 老贾”进行精确匹配查询相应的文档GET /twitter/_search{ &quot;query&quot;: { &quot;term&quot;: { &quot;user.keyword&quot;: { &quot;value&quot;: &quot; 朝阳区 - 老贾 &quot; } } }}@@@ terms：查询 user.keyword 里含有“双榆树 - 张三”或“东城区 - 老刘”的所有文档GET /twitter/_search{ &quot;query&quot;: { &quot;terms&quot;: { &quot;user.keyword&quot;: [ &quot; 双榆树 - 张三 &quot;, &quot; 东城区 - 老刘 &quot; ] } }}@@ 复合查询@@@ must：查询的是必须是 北京城市的，并且年刚好是 30 岁的GET /twitter/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;match&quot;: { &quot;city&quot;: &quot; 北京 &quot; } }, { &quot;match&quot;: { &quot;age&quot;: &quot;30&quot; } } ] } }}@@@ must_not：寻找不在北京的所有的文档GET /twitter/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must_not&quot;: [ { &quot;match&quot;: { &quot;city&quot;: &quot; 北京 &quot; } } ] } }}@@@ should：表述“或”的意思，也就是有就更好，没有就算了。age 必须是 30 岁，但是如果文档里含有“Hanppy birthday”，相关性会更高GET /twitter/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;match&quot;: { &quot;age&quot;: &quot;30&quot; } } ], &quot;should&quot;: [ { &quot;match_phrase&quot;: { &quot;message&quot;: &quot;Happy birthday&quot; } } ] } }}@@@ 位置查询 geo_distance ：查找在地址栏里有“北京”，并且在以位置(116.454182, 39.920086) 为中心的 5 公里以内的所有文档，并按照远近大小进行排序GET /twitter/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ { &quot;match&quot;: { &quot;address&quot;: &quot; 北京 &quot; } } ] } }, &quot;post_filter&quot;: { &quot;geo_distance&quot;: { &quot;distance&quot;: &quot;5km&quot;, &quot;location&quot;: { &quot;lat&quot;: 39.920086, &quot;lon&quot;: 116.454182 } } }, &quot;sort&quot;: [ { &quot;_geo_distance&quot;: { &quot;location&quot;: &quot;39.920086,116.454182&quot;, &quot;order&quot;: &quot;asc&quot;, &quot;unit&quot;: &quot;km&quot; } } ]}@@@ 范围查询 range ：查询年龄介于 30 到 40 岁的文档GET /twitter/_search{ &quot;query&quot;: { &quot;range&quot;: { &quot;age&quot;: { &quot;gte&quot;: 30, &quot;lte&quot;: 40 } } }}@@@ 范围查询 range ：查询年龄介于 30 到 40 岁的文档，并对它们进行排序GET /twitter/_search{ &quot;query&quot;: { &quot;range&quot;: { &quot;age&quot;: { &quot;gte&quot;: 30, &quot;lte&quot;: 40 } } },&quot;sort&quot;: [ { &quot;age&quot;: { &quot;order&quot;: &quot;desc&quot; } } ]}@@@ Exists 查询：查询 district 字段是否存在GET /twitter/_search{ &quot;query&quot;: { &quot;exists&quot;: { &quot;field&quot;: &quot;district&quot; } }}@@@ 匹配查询PUT twitter/_doc/8{ &quot;user&quot;: &quot; 朝阳区 - 老王 &quot;, &quot;message&quot;: &quot;Happy&quot;, &quot;uid&quot;: 6, &quot;age&quot;: 50, &quot;city&quot;: &quot; 北京 &quot;, &quot;province&quot;: &quot; 北京 &quot;, &quot;country&quot;: &quot; 中国 &quot;, &quot;address&quot;: &quot; 中国北京市朝阳区国贸 &quot;, &quot;location&quot;: { &quot;lat&quot;: &quot;39.918256&quot;, &quot;lon&quot;: &quot;116.467910&quot; }}@@@ 匹配查询：match 查询时不分大小写，不分先后顺序@@@ 默认“或”，匹配到一个单词即可GET /twitter/_search{ &quot;query&quot;: { &quot;match&quot;: { &quot;message&quot;: &quot;happy birthday&quot; } }}@@@ “与”，需要同时匹配两个单词GET /twitter/_search{ &quot;query&quot;: { &quot;match&quot;: { &quot;message&quot;: { &quot;query&quot;: &quot;happy birthday&quot;, &quot;operator&quot;: &quot;and&quot; } } }}@@@ minimum_should_match 至少应该要匹配两个单词GET /twitter/_search{ &quot;query&quot;: { &quot;match&quot;: { &quot;message&quot;: { &quot;query&quot;: &quot;happy birthday&quot;, &quot;minimum_should_match&quot;: 2 } } }}@@@ 匹配查询：match_phrase 查询时不分大小写，但区分先后顺序GET /twitter/_search{ &quot;query&quot;: { &quot;match_phrase&quot;: { &quot;message&quot;: &quot;happy birthday&quot; } }, &quot;highlight&quot;: { &quot;fields&quot;: { &quot;message&quot;: {} } }}@@@ SQL 查询GET /_sql?{ &quot;query&quot;: &quot;&quot;&quot; SELECT * FROM twitter WHERE age = 30 &quot;&quot;&quot;}@@@ Multi Search：减少请求次数@@@ 同时获取两个文档GET /twitter/_doc/_mget{ &quot;ids&quot;: [&quot;1&quot;, &quot;2&quot;]}@@@ 同时到多个索引中查询GET _msearch{&quot;index&quot;:&quot;twitter&quot;}{&quot;query&quot;:{&quot;match_all&quot;:{}},&quot;from&quot;:0,&quot;size&quot;:1}{&quot;index&quot;:&quot;twitter&quot;}{&quot;query&quot;:{&quot;bool&quot;:{&quot;filter&quot;:{&quot;term&quot;:{&quot;city.keyword&quot;:&quot; 北京 &quot;}}}}, &quot;size&quot;:1}{&quot;index&quot;:&quot;twitter2&quot;}{&quot;query&quot;:{&quot;match_all&quot;:{}}}GET /twitter,twitter2/_searchGET /twitter*/_search@@@ Profile：调试工具，它添加了有关执行的详细信息搜索请求中的每个组件，它为用户提供有关搜索的每个步骤的洞察力GET /twitter/_search{ &quot;profile&quot;: &quot;true&quot;, &quot;query&quot;: { &quot;match&quot;: { &quot;city&quot;: &quot; 北京 &quot; } }}@@ 聚合查询 aggregation 及 analyzer@@@ 准备数据DELETE twitterPUT twitter{ &quot;mappings&quot;: { &quot;properties&quot;: { &quot;DOB&quot;: { &quot;type&quot;: &quot;date&quot; }, &quot;address&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 } } }, &quot;age&quot;: { &quot;type&quot;: &quot;long&quot; }, &quot;city&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;country&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;location&quot;: { &quot;type&quot;: &quot;geo_point&quot; }, &quot;message&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 } } }, &quot;province&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;uid&quot;: { &quot;type&quot;: &quot;long&quot; }, &quot;user&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 } } } } }}POST _bulk{&quot;index&quot;:{&quot;_index&quot;:&quot;twitter&quot;,&quot;_id&quot;:1}}{&quot;user&quot;:&quot; 张三 &quot;,&quot;message&quot;:&quot; 今儿天气不错啊，出去转转去 &quot;,&quot;uid&quot;:2,&quot;age&quot;:20,&quot;city&quot;:&quot; 北京 &quot;,&quot;province&quot;:&quot; 北京 &quot;,&quot;country&quot;:&quot; 中国 &quot;,&quot;address&quot;:&quot; 中国北京市海淀区 &quot;,&quot;location&quot;:{&quot;lat&quot;:&quot;39.970718&quot;,&quot;lon&quot;:&quot;116.325747&quot;}, &quot;DOB&quot;: &quot;1999-04-01&quot;}{&quot;index&quot;:{&quot;_index&quot;:&quot;twitter&quot;,&quot;_id&quot;:2}}{&quot;user&quot;:&quot; 老刘 &quot;,&quot;message&quot;:&quot; 出发，下一站云南！&quot;,&quot;uid&quot;:3,&quot;age&quot;:22,&quot;city&quot;:&quot; 北京 &quot;,&quot;province&quot;:&quot; 北京 &quot;,&quot;country&quot;:&quot; 中国 &quot;,&quot;address&quot;:&quot; 中国北京市东城区台基厂三条 3 号 &quot;,&quot;location&quot;:{&quot;lat&quot;:&quot;39.904313&quot;,&quot;lon&quot;:&quot;116.412754&quot;}, &quot;DOB&quot;: &quot;1997-04-01&quot;}{&quot;index&quot;:{&quot;_index&quot;:&quot;twitter&quot;,&quot;_id&quot;:3}}{&quot;user&quot;:&quot; 李四 &quot;,&quot;message&quot;:&quot;happy birthday!&quot;,&quot;uid&quot;:4,&quot;age&quot;:25,&quot;city&quot;:&quot; 北京 &quot;,&quot;province&quot;:&quot; 北京 &quot;,&quot;country&quot;:&quot; 中国 &quot;,&quot;address&quot;:&quot; 中国北京市东城区 &quot;,&quot;location&quot;:{&quot;lat&quot;:&quot;39.893801&quot;,&quot;lon&quot;:&quot;116.408986&quot;}, &quot;DOB&quot;: &quot;1994-04-01&quot;}{&quot;index&quot;:{&quot;_index&quot;:&quot;twitter&quot;,&quot;_id&quot;:4}}{&quot;user&quot;:&quot; 老贾 &quot;,&quot;message&quot;:&quot;123,gogogo&quot;,&quot;uid&quot;:5,&quot;age&quot;:30,&quot;city&quot;:&quot; 北京 &quot;,&quot;province&quot;:&quot; 北京 &quot;,&quot;country&quot;:&quot; 中国 &quot;,&quot;address&quot;:&quot; 中国北京市朝阳区建国门 &quot;,&quot;location&quot;:{&quot;lat&quot;:&quot;39.718256&quot;,&quot;lon&quot;:&quot;116.367910&quot;}, &quot;DOB&quot;: &quot;1989-04-01&quot;}{&quot;index&quot;:{&quot;_index&quot;:&quot;twitter&quot;,&quot;_id&quot;:5}}{&quot;user&quot;:&quot; 老王 &quot;,&quot;message&quot;:&quot;Happy BirthDay My Friend!&quot;,&quot;uid&quot;:6,&quot;age&quot;:26,&quot;city&quot;:&quot; 北京 &quot;,&quot;province&quot;:&quot; 北京 &quot;,&quot;country&quot;:&quot; 中国 &quot;,&quot;address&quot;:&quot; 中国北京市朝阳区国贸 &quot;,&quot;location&quot;:{&quot;lat&quot;:&quot;39.918256&quot;,&quot;lon&quot;:&quot;116.467910&quot;}, &quot;DOB&quot;: &quot;1993-04-01&quot;}{&quot;index&quot;:{&quot;_index&quot;:&quot;twitter&quot;,&quot;_id&quot;:6}}{&quot;user&quot;:&quot; 老吴 &quot;,&quot;message&quot;:&quot; 好友来了都今天我生日，好友来了, 什么 birthday happy 就成!&quot;,&quot;uid&quot;:7,&quot;age&quot;:28,&quot;city&quot;:&quot; 上海 &quot;,&quot;province&quot;:&quot; 上海 &quot;,&quot;country&quot;:&quot; 中国 &quot;,&quot;address&quot;:&quot; 中国上海市闵行区 &quot;,&quot;location&quot;:{&quot;lat&quot;:&quot;31.175927&quot;,&quot;lon&quot;:&quot;121.383328&quot;}, &quot;DOB&quot;: &quot;1991-04-01&quot;}@@@ range 聚合：把用户进行年龄分段，查出来在不同的年龄段的用户GET /twitter/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;age_range&quot;: { &quot;range&quot;: { &quot;field&quot;: &quot;age&quot;, &quot;ranges&quot;: [ { &quot;from&quot;: 20, &quot;to&quot;: 30 }, { &quot;from&quot;: 30, &quot;to&quot;: 40 }, { &quot;from&quot;: 40, &quot;to&quot;: 50 } ] } } }}@@@ date_range 聚合：统计在某个时间段里的文档数POST twitter/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;birth_range&quot;: { &quot;date_range&quot;: { &quot;field&quot;: &quot;DOB&quot;, &quot;format&quot;: &quot;yyyy-MM-dd&quot;, &quot;ranges&quot;: [ { &quot;from&quot;: &quot;1989-01-01&quot;, &quot;to&quot;: &quot;1990-01-01&quot; }, { &quot;from&quot;: &quot;1991-01-01&quot;, &quot;to&quot;: &quot;1992-01-01&quot; } ] } } }}@@@ terms 聚合：寻找在所有的文档出现”happy birthday”里按照城市进行分类的一个聚合GET /twitter/_search{ &quot;query&quot;: { &quot;match&quot;: { &quot;message&quot;: &quot;happy birthday&quot; } }, &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;city&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;city&quot;, &quot;size&quot;: 10 } } }}@@@ terms 聚合：我们也可以使用 script 来生成一个在索引里没有的术语来进行统计。比如，我们可以通过如下的 script 来生成一个对文档人出生年份的统计：POST twitter/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;birth_year&quot;: { &quot;terms&quot;: { &quot;script&quot;: { &quot;source&quot;: &quot;2019 - doc['age'].value&quot; }, &quot;size&quot;: 10 } } }}@@@ histogram 聚合：根据值动态构建固定大小（也称为间隔）的存储桶GET /twitter/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;age_distribution&quot;: { &quot;histogram&quot;: { &quot;field&quot;: &quot;age&quot;, &quot;interval&quot;: 2 } } }}@@@ date_histogram 聚合：这种聚合类似于正常的直方图，但只能与日期或日期范围值一起使用。这里我们按照每隔一年这样的时间间隔来进行GET /twitter/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;age_distribution&quot;: { &quot;date_histogram&quot;: { &quot;field&quot;: &quot;DOB&quot;, &quot;interval&quot;: &quot;year&quot; } } }}@@@ cardinality 聚合：统计有多少个城市GET /twitter/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;number_of_cities&quot;: { &quot;cardinality&quot;: { &quot;field&quot;: &quot;city.keyword&quot; } } }}@@@ Metric 聚合：我们可以使用 Metrics 来统计我们的数值数据@@@ 对年龄字段全方位统计，包括数据总条数、平均值、最大 / 小值、求和GET /twitter/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;age_stats&quot;: { &quot;stats&quot;: { &quot;field&quot;: &quot;age&quot; } } }}@@@ 只得到平均值GET /twitter/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;average_age&quot;: { &quot;avg&quot;: { &quot;field&quot;: &quot;age&quot; } } }}POST twitter/_search{ &quot;size&quot;: 0, &quot;query&quot;: { &quot;match&quot;: { &quot;city&quot;: &quot; 北京 &quot; } }, &quot;aggs&quot;: { &quot;average_age_beijing&quot;: { &quot;avg&quot;: { &quot;field&quot;: &quot;age&quot; } } }}POST twitter/_search{ &quot;size&quot;: 0, &quot;query&quot;: { &quot;match&quot;: { &quot;city&quot;: &quot; 北京 &quot; } }, &quot;aggs&quot;: { &quot;average_age_beijing&quot;: { &quot;avg&quot;: { &quot;field&quot;: &quot;age&quot; } }, &quot;average_age_all&quot;: { &quot;global&quot;: {}, &quot;aggs&quot;: { &quot;age_global_avg&quot;: { &quot;avg&quot;: { &quot;field&quot;: &quot;age&quot; } } } } }}@@@ 使用 script，计算平均值再乘以 2 倍的结果GET /twitter/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;average_age_2&quot;: { &quot;avg&quot;: { &quot;field&quot;: &quot;age&quot;, &quot;script&quot;: { &quot;source&quot;: &quot;_value * params.correction&quot;, &quot;params&quot;: { &quot;correction&quot;: 2 } } } } }}@@@ 或者直接使用 script 的方法来进行聚合GET /twitter/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;average_2_times_age&quot;: { &quot;avg&quot;: { &quot;script&quot;: { &quot;source&quot;: &quot;doc['age'].value * params.times&quot;, &quot;params&quot;: { &quot;times&quot;: 2.0 } } } } }}@@@ percentile：得到 25%，50%、75% 及 100% 的人在什么年龄范围GET /twitter/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;age_quartiles&quot;: { &quot;percentiles&quot;: { &quot;field&quot;: &quot;age&quot;, &quot;percents&quot;: [ 25, 50, 75, 100 ] } } }}@@@ 更为复杂的聚合：结合上面的 bucket 聚合及 metric 聚合@@@ 我们首先通过 terms 来生成每个城市的桶聚合，然后在每个桶里计算所有文档的平均年龄，并根据平均年龄来进行降序排序GET /twitter/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;cities&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;city&quot;, &quot;order&quot;: { &quot;average_age&quot;: &quot;desc&quot; }, &quot;size&quot;: 5 }, &quot;aggs&quot;: { &quot;average_age&quot;: { &quot;avg&quot;: { &quot;field&quot;: &quot;age&quot; } } } } }}@@ Analyzer 分为三个部分：Char Filters, Tokenizer 及 Token Filter@@@ happy、birthdayGET /twitter/_analyze{ &quot;text&quot;: [ &quot;Happy Birthday&quot; ], &quot;analyzer&quot;: &quot;standard&quot;}@@@ happi、birthdai（词根）GET /twitter/_analyze{ &quot;text&quot;: [ &quot;Happy Birthday&quot; ], &quot;analyzer&quot;: &quot;english&quot;}@@@ Happy、BirthdayGET /twitter/_analyze{ &quot;text&quot;: [ &quot;Happy Birthday&quot; ], &quot;analyzer&quot;: &quot;whitespace&quot;}@@@ happy、birthdayGET /twitter/_analyze{ &quot;text&quot;: [ &quot;Happy.Birthday&quot; ], &quot;analyzer&quot;: &quot;simple&quot;}@@@ 生、日、快、乐GET /twitter/_analyze{ &quot;text&quot;: [ &quot; 生日快乐 &quot; ], &quot;analyzer&quot;: &quot;standard&quot;}@@@ 也可以只使用 Analyzer 中的 Tokenizer 部分@@@ Happy、BirthdayGET /twitter/_analyze{ &quot;text&quot;: [ &quot;Happy Birthday&quot; ], &quot;tokenizer&quot;: &quot;standard&quot;}@@@ Happy BirthdayGET /twitter/_analyze{ &quot;text&quot;: [ &quot;Happy Birthday&quot; ], &quot;tokenizer&quot;: &quot;keyword&quot;}@@@ happy birthdayGET /twitter/_analyze{ &quot;text&quot;: [ &quot;Happy Birthday&quot; ], &quot;tokenizer&quot;: &quot;keyword&quot;, &quot;filter&quot;: [&quot;lowercase&quot;]} 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 @程序员的 35，35 的程序员 @ 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/10/21/elastic/elasticsearch-command/"},{"title":"Spring Cloud Netflix Hystrix 断路器","text":"学习在 Spring Cloud 中使用 Hystrix 实现断路器，包括服务降级 / 容错、异步调用、异常处理、请求缓存、请求合并等功能。它是 Netflix 家族成员之一。 1 概述 Hystrix 叫做 断路器 / 熔断器。微服务系统中，整个系统出错的概率非常高，因为在微服务系统中，涉及到的模块太多了，每一个模块出错，都有可能导致整个服务出错，只有当所有模块都稳定运行时，整个服务才算是稳定运行。 我们希望当整个系统中，某一个模块无法正常工作时，能够通过我们提前配置的一些东西，来使得整个系统正常运行，即单个模块出问题，不影响整个系统。 2 准备工作 2.1 服务注册 创建 Spring Boot 项目 hystrix-client-provider ，作为我们的 服务提供者，添加 Web/Eureka Client 依赖，如下： 最终的依赖如下： 12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，修改 application.properties 配置文件，将 hystrix-client-provider 注册到 Eureka Server 上（服务注册中心使用 Eureka Server ），如下： 1234567# 当前服务的名称spring.application.name=hystrix-client-provider# 当前服务的端口server.port=3000# 服务注册中心地址eureka.client.service-url.defaultZone=http://127.0.0.1:1111/eureka 接下来，启动 Eureka Server ，待服务注册中心启动成功后，再启动 hystrix-client-provider ，两者都启动成功后，访问 http://127.0.0.1:1111 可以看到 hystrix-client-provider 的注册信息。 当然 hystrix-client-provider 也可以集群化部署，下面对 hystrix-client-provider 进行打包，之后我们在命令行启动两个 provider 实例： 12java -jar hystrix-client-provider-0.0.1-SNAPSHOT.jar --server.port=3000java -jar hystrix-client-provider-0.0.1-SNAPSHOT.jar --server.port=3001 最后在 hystrix-client-provider 提供一个 hello 接口，用于后续服务消费者 hystrix-client-consumer 来消费，如下： 12345678910@RestControllerpublic class ProviderController { @Value(\"${server.port}\") Integer port; // 支持启动多个实例，做负载均衡，用端口区分 @GetMapping(\"/hello\") public String hello() { return \"hello cxy35:\" + port; }} 2.2 服务消费 创建 Spring Boot 项目 hystrix-client-consumer ，作为我们的 服务消费者，添加 Web/Eureka Client/Hystrix 依赖，如下： 最终的依赖如下： 1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 项目创建成功后，修改 application.properties 配置文件，将 hystrix-client-consumer 注册到 Eureka Server 上（服务注册中心使用 Eureka Server ），如下： 1234567# 当前服务的名称spring.application.name=hystrix-client-consumer# 当前服务的端口server.port=3002# 服务注册中心地址eureka.client.service-url.defaultZone=http://127.0.0.1:1111/eureka 接着，在项目启动类上添加 @EnableCircuitBreaker 注解，开启断路器功能，并添加 RestTemplate ，如下： 123456789101112131415@SpringBootApplication@EnableCircuitBreaker // 开启断路器的功能// @SpringCloudApplication // 组合注解public class HystrixClientConsumerApplication { public static void main(String[] args) { SpringApplication.run(HystrixClientConsumerApplication.class, args); } @Bean @LoadBalanced RestTemplate restTemplate() { return new RestTemplate(); }} 接下来，启动 hystrix-client-consumer ，访问 http://127.0.0.1:1111 可以看到 hystrix-client-consumer 的注册信息。 最后在 hystrix-client-consumer 中新增测试业务类和接口，去实现服务调用，从而消费 hystrix-client-provider 中提供的接口，如下： 约定：本文中的服务调用失败（测试服务降级 / 容错），可以采用关闭某个 hystrix-client-provider 来模拟，短时间内会报错（因为 provider 地址会缓存 consumer 上一段时间），从而达到我们的目的。 3 服务降级 / 容错 注解方式 新建测试业务类 ConsumerService ，如下： 1234567891011121314151617181920212223242526272829303132@Servicepublic class ConsumerService { @Autowired RestTemplate restTemplate; /** * 在这个方法中，我们将发起一个远程调用，去调用 hystrix-client-provider 中提供的 /hello 接口 * &lt;p&gt; * 但是，这个调用可能会失败，可以采用关闭某个 hystrix-client-provider 来模拟。 * &lt;p&gt; * 我们在这个方法上添加 @HystrixCommand 注解，配置 fallbackMethod 属性，这个属性表示该方法调用失败时的临时替代方法 * * @return */ // 服务降级 / 容错 @HystrixCommand(fallbackMethod = \"error\") public String testHystrix() { return restTemplate.getForObject(\"http://hystrix-client-provider/hello\", String.class); } /** * 实现服务容错 / 降级：这个方法就是请求失败的回调 * &lt;p&gt; * 注意：这个方法名字要和上述 fallbackMethod 中指定的一致，方法返回值也要和对应的方法一致 * * @return */ // 服务降级 / 容错，这里简单实现 public String error() { return \"error\"; }} 新建测试接口 ConsumerController ，如下： 12345678910111213@RestControllerpublic class ConsumerController { @Autowired ConsumerService consumerService; @Autowired RestTemplate restTemplate; // 服务降级 / 容错 @GetMapping(\"/testHystrix\") public String testHystrix() { return consumerService.testHystrix(); }} 访问 http://127.0.0.1:3002/testHystrix 完成测试。 请求命令方式 请求命令方式就是以 继承类 的方式来替代前面的注解方式。 新建测试业务类 ConsumerService2 ，如下： 123456789101112131415161718192021public class ConsumerService2 extends HystrixCommand&lt;String&gt; { RestTemplate restTemplate; public ConsumerService2(Setter setter, RestTemplate restTemplate) { super(setter); this.restTemplate = restTemplate; } // 服务降级 / 容错 @Override protected String run() throws Exception { return restTemplate.getForObject(\"http://hystrix-client-provider/hello\", String.class); } // 服务降级 / 容错，这个方法就是请求失败的回调 @Override protected String getFallback() { return \"error2\"; }} 新建测试接口 ConsumerController2 ，如下： 12345678910111213@RestControllerpublic class ConsumerController2 { @Autowired RestTemplate restTemplate; // 服务降级 / 容错 @GetMapping(\"/testHystrix2\") public String testHystrix2() { // 1. 直接执行 ConsumerService2 command = new ConsumerService2(HystrixCommand.Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"cxy35\")), restTemplate); return command.execute(); }} 访问 http://127.0.0.1:3002/testHystrix2 完成测试。 注意：一个 HystrixCommand 实例只能执行一次。 4 异步调用 注解方式 修改测试业务类 ConsumerService ，增加方法，如下： 12345678910// 异步调用@HystrixCommand(fallbackMethod = \"error\")public Future&lt;String&gt; testHystrixAsync() { return new AsyncResult&lt;String&gt;() { @Override public String invoke() { return restTemplate.getForObject(\"http://hystrix-client-provider/hello\", String.class); } };} 修改测试接口 ConsumerController ，增加方法，如下： 12345678910111213// 异步调用@GetMapping(\"/testHystrixAsync\")public String testHystrixAsync() { Future&lt;String&gt; future = consumerService.testHystrixAsync(); try { return future.get(); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } return \"\";} 访问 http://127.0.0.1:3002/testHystrixAsync 完成测试。 请求命令方式 修改测试接口 ConsumerController2 ，增加方法，如下： 123456789101112131415// 异步调用@GetMapping(\"/testHystrixAsync2\")public String testHystrixAsync2() { // 2. 先入队，后执行 ConsumerService2 command = new ConsumerService2(HystrixCommand.Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"cxy35\")), restTemplate); try { Future&lt;String&gt; queue = command.queue(); return queue.get(); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } return \"\";} 访问 http://127.0.0.1:3002/testHystrixAsync2 完成测试。 5 异常处理 当发起服务调用时，如果不是 hystrix-client-provider 的原因导致请求调用失败，而是 hystrix-client-consumer 中本身代码有问题导致的请求失败，即 hystrix-client-consumer 中抛出了异常，这个时候，也会自动进行服务降级，只不过这个时候降级，我们还需要知道到底是哪里出异常了。 如下示例代码，执行时抛出异常，那么一样也会进行服务降级，进入到对应的 error 方法中，在 error 方法中，我们可以获取到异常的详细信息： 注解方式 修改测试业务类 ConsumerService ，增加方法，如下： 1234567891011// 异常处理@HystrixCommand(fallbackMethod = \"error2\")public String testHystrixException() { int i = 1 / 0; // 抛异常，会自动进行服务降级 return restTemplate.getForObject(\"http://hystrix-client-provider/hello\", String.class);}// 异常处理public String error2(Throwable t) { return \"error:\" + t.getMessage();} 修改测试接口 ConsumerController ，增加方法，如下： 12345// 异常处理@GetMapping(\"/testHystrixException\")public String testHystrixException() { return consumerService.testHystrixException();} 访问 http://127.0.0.1:3002/testHystrixException 完成测试。 另外，如果抛异常了，我们希望异常直接抛出，不要服务降级，那么只需要配置忽略某一个异常即可，如下： 123456// 异常处理@HystrixCommand(fallbackMethod = \"error2\", ignoreExceptions = ArithmeticException.class)public String testHystrixException() { int i = 1 / 0; return restTemplate.getForObject(\"http://hystrix-client-provider/hello\", String.class);} 请求命令方式 修改测试业务类 ConsumerService2 ，修改方法，如下： 123456789101112// 异常处理@Overrideprotected String run() throws Exception { int i = 1 / 0; return restTemplate.getForObject(\"http://hystrix-client-provider/hello\", String.class);}// 异常处理@Overrideprotected String getFallback() { return \"error2:\" + getExecutionException().getMessage();} 修改测试接口 ConsumerController2 ，修改方法，如下： 123456// 异常处理@GetMapping(\"/testHystrixException2\")public String testHystrixException2() { ConsumerService2 command = new ConsumerService2(HystrixCommand.Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"cxy35\")), restTemplate); return command.execute();} 访问 http://127.0.0.1:3002/testHystrixException2 完成测试。 6 请求缓存 请求缓存就是在 hystrix-client-consumer 中调用同一个接口，如果参数相同，则可以使用之前缓存下来的数据。 首先在 ProviderController 中增加 /hello2 接口，如下： 12345@GetMapping(\"/hello2\")public String hello2(String name) { System.out.println(new Date()); return \"hello\" + name + \":\" + port;} 注解方式 修改测试业务类 ConsumerService ，增加方法，如下： 123456789101112131415161718192021222324// 请求缓存@HystrixCommand(fallbackMethod = \"error3\")// 这个注解表示该方法的请求结果会被缓存起来// 默认缓存的 key 为所有参数的值（可通过 @CacheKey 修改，如指定某一个参数），缓存的 value 为方法的返回值@CacheResult// 下面的配置，虽然有两个参数，但是缓存时以 name 为准。// 也就是说，两次请求中，只要 name 一样，即使 age 不一样，第二次请求也可以使用第一次请求缓存的结果。// public String testHystrixCache(@CacheKey String name, Integer age) {public String testHystrixCache(String name) { return restTemplate.getForObject(\"http://hystrix-client-provider/hello2?name={1}\", String.class, name);}// 请求缓存：删除数据库中的数据，同时删除缓存中的数据@HystrixCommand// 必须指定 commandKey 属性，commandKey 其实就是缓存方法的名字，指定了 commandKey，@CacheRemove 才能找到数据缓存在哪里了，进而才能成功删除掉数据。@CacheRemove(commandKey = \"testHystrixCache\")public String deleteUserByName(String name) { return null;}// 请求缓存public String error3(String name) { return \"error:\" + name;} 修改测试接口 ConsumerController ，增加方法，如下： 123456789101112131415161718192021222324// 请求缓存@GetMapping(\"/testHystrixCache\")public void testHystrixCache() { // 开启缓存 // 缓存默认不会生效，我们使用缓存，都有一个缓存生命周期这样一个概念。 // 需要初始化 HystrixRequestContext，初始化完成后，缓存开始生效。close 之后，缓存失效。 HystrixRequestContext ctx = HystrixRequestContext.initializeContext(); // 第一请求完，数据已经缓存下来了 String cxy35 = consumerService.testHystrixCache(\"cxy35\"); System.out.println(cxy35); // 删除数据，同时缓存中的数据也会被删除 consumerService.deleteUserByName(\"cxy35\"); // 第二次请求时，直接使用缓存数据，不会再调用 provider 。除非中间调用了 deleteUserByName 清除掉缓存 cxy35 = consumerService.testHystrixCache(\"cxy35\"); System.out.println(cxy35); // 关闭缓存 // 在 ctx close 之前，缓存是有效的，close 之后，缓存就失效了。 // 访问一次本接口，provider 只会被调用一次（第二次使用的缓存，除非中间调了清除缓存的接口，如 deleteUserByName）。 ctx.close();} 访问 http://127.0.0.1:3002/testHystrixCache 完成测试，会发现 consumer 中调用了两次，而 provider 中只打印了一次。 请求命令方式 如果是继承的方式使用 Hystrix ，只需要重写 getCacheKey 方法即可。 修改测试业务类 ConsumerService2 ，增加方法，如下： 1234567891011121314151617// 请求缓存@Overrideprotected String run() throws Exception { return restTemplate.getForObject(\"http://hystrix-client-provider/hello2?name={1}\", String.class, name);}// 请求缓存@Overrideprotected String getFallback() { return \"error2:\" + getExecutionException().getMessage();}// 请求缓存@Overrideprotected String getCacheKey() { return name;} 修改测试接口 ConsumerController2 ，增加方法，如下： 1234567891011121314151617181920212223// 请求缓存@GetMapping(\"/testHystrixCache2\")public void testHystrixCache2() { // 开启缓存 // 缓存默认不会生效，我们使用缓存，都有一个缓存生命周期这样一个概念。 // 需要初始化 HystrixRequestContext，初始化完成后，缓存开始生效。close 之后，缓存失效。 HystrixRequestContext ctx = HystrixRequestContext.initializeContext(); // 第一请求完，数据已经缓存下来了 ConsumerService2 command = new ConsumerService2(HystrixCommand.Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"cxy35\")), restTemplate, \"cxy35\"); String r = command.execute(); System.out.println(r); // 第二次请求时，直接使用缓存数据，不会再调用 provider 。除非中间调用了 deleteUserByName 清除掉缓存 command = new ConsumerService2(HystrixCommand.Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"cxy35\")), restTemplate, \"cxy35\"); r = command.execute(); System.out.println(r); // 关闭缓存 // 在 ctx close 之前，缓存是有效的，close 之后，缓存就失效了。 // 访问一次本接口，provider 只会被调用一次（第二次使用的缓存，除非中间调了清除缓存的接口，如 deleteUserByName）。 ctx.close();} 访问 http://127.0.0.1:3002/testHystrixCache2 完成测试，会发现 consumer 中调用了两次，而 provider 中只打印了一次。 7 请求合并 如果 hystrix-client-consumer 中，频繁的调用 hystrix-client-provider 中的同一个接口，在调用时，只是参数不一样，那么这样情况下，我们就可以将多个请求合并成一个，这样可以有效提高请求发送的效率。 首先我们在 hystrix-client-provider 的 ProviderController 中提供一个请求合并的接口，如下： 12345678910111213// 假设 consumer 传过来的多个 id 的格式是 1,2,3,4....@GetMapping(\"/user/{ids}\")public List&lt;User&gt; getUserByIds(@PathVariable String ids) { System.out.println(ids); String[] split = ids.split(\",\"); List&lt;User&gt; users = new ArrayList&lt;&gt;(); for (String s : split) { User u = new User(); u.setId(Integer.parseInt(s)); users.add(u); } return users;} 注解方式（简单，推荐） 修改测试业务类 ConsumerService ，增加方法，如下： 12345678910111213// 请求合并，必须要用异步调用方式，并指定批处理的方法为 getUsersByIds// 这里还配置了一个属性 timerDelayInMilliseconds 为 200 毫秒@HystrixCollapser(batchMethod = \"getUsersByIds\", collapserProperties = {@HystrixProperty(name = \"timerDelayInMilliseconds\", value = \"200\")})public Future&lt;User&gt; testHystrixCollapser(Integer id) { return null;}// 请求合并@HystrixCommandpublic List&lt;User&gt; getUsersByIds(List&lt;Integer&gt; ids) { User[] users = restTemplate.getForObject(\"http://hystrix-client-provider/user/{1}\", User[].class, StringUtils.join(ids, \",\")); return Arrays.asList(users);} 修改测试接口 ConsumerController ，增加方法，如下： 12345678910111213141516171819202122232425// 请求合并@GetMapping(\"/testHystrixCollapser\")public void testHystrixCollapser() throws ExecutionException, InterruptedException { HystrixRequestContext ctx = HystrixRequestContext.initializeContext(); // 这 3 个请求会一起发起 Future&lt;User&gt; q1 = consumerService.testHystrixCollapser(99); Future&lt;User&gt; q2 = consumerService.testHystrixCollapser(98); Future&lt;User&gt; q3 = consumerService.testHystrixCollapser(97); User u1 = q1.get(); User u2 = q2.get(); User u3 = q3.get(); System.out.println(u1); System.out.println(u2); System.out.println(u3); Thread.sleep(2000); // 这个请求会单独发起 Future&lt;User&gt; q4 = consumerService.testHystrixCollapser(96); User u4 = q4.get(); System.out.println(u4); ctx.close();} 访问 http://127.0.0.1:3002/testHystrixCollapser 完成测试。 请求命令方式 新增 UserService ，如下： 12345678910@Servicepublic class UserService { @Autowired RestTemplate restTemplate; public List&lt;User&gt; getUsersByIds(List&lt;Integer&gt; ids) { User[] users = restTemplate.getForObject(\"http://hystrix-client-provider/user/{1}\", User[].class, StringUtils.join(ids, \",\")); return Arrays.asList(users); }} 新增 UserCollapser ，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class UserCollapser extends HystrixCollapser&lt;List&lt;User&gt;, User, Integer&gt; { private UserService userService; private Integer id; public UserCollapser(UserService userService, Integer id) { super(Setter.withCollapserKey(HystrixCollapserKey.Factory.asKey(\"userCollapserKey\")).andCollapserPropertiesDefaults(HystrixCollapserProperties.Setter().withTimerDelayInMilliseconds(200))); this.userService = userService; this.id = id; } /** * 请求参数 * * @return */ @Override public Integer getRequestArgument() { return id; } /** * 请求合并的方法 * * @param collection * @return */ @Override protected HystrixCommand&lt;List&lt;User&gt;&gt; createCommand(Collection&lt;CollapsedRequest&lt;User, Integer&gt;&gt; collection) { List&lt;Integer&gt; ids = new ArrayList&lt;&gt;(collection.size()); for (CollapsedRequest&lt;User, Integer&gt; userIntegerCollapsedRequest : collection) { ids.add(userIntegerCollapsedRequest.getArgument()); } return new UserCommand(ids, userService); } /** * 请求结果分发 * * @param users * @param collection */ @Override protected void mapResponseToRequests(List&lt;User&gt; users, Collection&lt;CollapsedRequest&lt;User, Integer&gt;&gt; collection) { int count = 0; for (CollapsedRequest&lt;User, Integer&gt; request : collection) { request.setResponse(users.get(count++)); } }} 新增 UserCommand ，如下： 1234567891011121314151617181920public class UserCommand extends HystrixCommand&lt;List&lt;User&gt;&gt; { private List&lt;Integer&gt; ids; private UserService userService; public UserCommand(List&lt;Integer&gt; ids, UserService userService) { super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(\"userCommandGroupKey\")).andCommandKey(HystrixCommandKey.Factory.asKey(\"userCommandKey\"))); this.ids = ids; this.userService = userService; } @Override protected List&lt;User&gt; run() throws Exception { return userService.getUsersByIds(ids); } @Override protected List&lt;User&gt; getFallback() { return null; }} 修改测试接口 ConsumerController2 ，增加方法，如下： 1234567891011121314151617181920212223242526272829303132@AutowiredUserService userService;// 请求合并@GetMapping(\"/testHystrixCollapser2\")public void testHystrixCollapser2() throws ExecutionException, InterruptedException { HystrixRequestContext ctx = HystrixRequestContext.initializeContext(); // 这 3 个请求会一起发起 UserCollapser collapser1 = new UserCollapser(userService, 99); UserCollapser collapser2 = new UserCollapser(userService, 98); UserCollapser collapser3 = new UserCollapser(userService, 97); Future&lt;User&gt; q1 = collapser1.queue(); Future&lt;User&gt; q2 = collapser2.queue(); Future&lt;User&gt; q3 = collapser3.queue(); User u1 = q1.get(); User u2 = q2.get(); User u3 = q3.get(); System.out.println(u1); System.out.println(u2); System.out.println(u3); Thread.sleep(2000); // 这个请求会单独发起 UserCollapser collapser4 = new UserCollapser(userService, 96); Future&lt;User&gt; q4 = collapser4.queue(); User u4 = q4.get(); System.out.println(u4); ctx.close();} 访问 http://127.0.0.1:3002/testHystrixCache2 完成测试。 Spring Cloud 教程合集 （微信左下方 阅读全文 可直达）。 Spring Cloud 教程合集示例代码：https://github.com/cxy35/spring-cloud-samples 本文示例代码：https://github.com/cxy35/spring-cloud-samples/tree/master/spring-cloud-netflix-hystrix 扫码关注微信公众号 程序员 35 ，获取最新技术干货，畅聊 #程序员的 35，35 的程序员# 。独立站点：https://cxy35.com","link":"/website-hexo-icarus/2020/04/18/springcloud/spring-cloud-netflix-hystrix/"}],"tags":[{"name":"HR","slug":"HR","link":"/website-hexo-icarus/tags/HR/"},{"name":"RabbitMQ","slug":"RabbitMQ","link":"/website-hexo-icarus/tags/RabbitMQ/"},{"name":"Linux","slug":"Linux","link":"/website-hexo-icarus/tags/Linux/"},{"name":"命令","slug":"命令","link":"/website-hexo-icarus/tags/%E5%91%BD%E4%BB%A4/"},{"name":"分区","slug":"分区","link":"/website-hexo-icarus/tags/%E5%88%86%E5%8C%BA/"},{"name":"格式化","slug":"格式化","link":"/website-hexo-icarus/tags/%E6%A0%BC%E5%BC%8F%E5%8C%96/"},{"name":"挂载","slug":"挂载","link":"/website-hexo-icarus/tags/%E6%8C%82%E8%BD%BD/"},{"name":"MySQL","slug":"MySQL","link":"/website-hexo-icarus/tags/MySQL/"},{"name":"备份","slug":"备份","link":"/website-hexo-icarus/tags/%E5%A4%87%E4%BB%BD/"},{"name":"xtrabackup","slug":"xtrabackup","link":"/website-hexo-icarus/tags/xtrabackup/"},{"name":"问题","slug":"问题","link":"/website-hexo-icarus/tags/%E9%97%AE%E9%A2%98/"},{"name":"事件","slug":"事件","link":"/website-hexo-icarus/tags/%E4%BA%8B%E4%BB%B6/"},{"name":"索引","slug":"索引","link":"/website-hexo-icarus/tags/%E7%B4%A2%E5%BC%95/"},{"name":"安装","slug":"安装","link":"/website-hexo-icarus/tags/%E5%AE%89%E8%A3%85/"},{"name":"存储过程","slug":"存储过程","link":"/website-hexo-icarus/tags/%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B/"},{"name":"Nginx","slug":"Nginx","link":"/website-hexo-icarus/tags/Nginx/"},{"name":"fair","slug":"fair","link":"/website-hexo-icarus/tags/fair/"},{"name":"SSL","slug":"SSL","link":"/website-hexo-icarus/tags/SSL/"},{"name":"HTTPS","slug":"HTTPS","link":"/website-hexo-icarus/tags/HTTPS/"},{"name":"Tomcat","slug":"Tomcat","link":"/website-hexo-icarus/tags/Tomcat/"},{"name":"集群","slug":"集群","link":"/website-hexo-icarus/tags/%E9%9B%86%E7%BE%A4/"},{"name":"Apache","slug":"Apache","link":"/website-hexo-icarus/tags/Apache/"},{"name":"mod_jk","slug":"mod-jk","link":"/website-hexo-icarus/tags/mod-jk/"},{"name":"mod_proxy","slug":"mod-proxy","link":"/website-hexo-icarus/tags/mod-proxy/"},{"name":"JVM","slug":"JVM","link":"/website-hexo-icarus/tags/JVM/"},{"name":"工具","slug":"工具","link":"/website-hexo-icarus/tags/%E5%B7%A5%E5%85%B7/"},{"name":"MAT","slug":"MAT","link":"/website-hexo-icarus/tags/MAT/"},{"name":"MyBatis","slug":"MyBatis","link":"/website-hexo-icarus/tags/MyBatis/"},{"name":"POI","slug":"POI","link":"/website-hexo-icarus/tags/POI/"},{"name":"PowerJob","slug":"PowerJob","link":"/website-hexo-icarus/tags/PowerJob/"},{"name":"分布式","slug":"分布式","link":"/website-hexo-icarus/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"任务调度","slug":"任务调度","link":"/website-hexo-icarus/tags/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/"},{"name":"Redis","slug":"Redis","link":"/website-hexo-icarus/tags/Redis/"},{"name":"HyperLogLog","slug":"HyperLogLog","link":"/website-hexo-icarus/tags/HyperLogLog/"},{"name":"Jedis","slug":"Jedis","link":"/website-hexo-icarus/tags/Jedis/"},{"name":"Lettuce","slug":"Lettuce","link":"/website-hexo-icarus/tags/Lettuce/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/website-hexo-icarus/tags/Spring-Boot/"},{"name":"跨域","slug":"跨域","link":"/website-hexo-icarus/tags/%E8%B7%A8%E5%9F%9F/"},{"name":"CORS","slug":"CORS","link":"/website-hexo-icarus/tags/CORS/"},{"name":"JdbcTemplate","slug":"JdbcTemplate","link":"/website-hexo-icarus/tags/JdbcTemplate/"},{"name":"多数据源","slug":"多数据源","link":"/website-hexo-icarus/tags/%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90/"},{"name":"Jpa","slug":"Jpa","link":"/website-hexo-icarus/tags/Jpa/"},{"name":"properties","slug":"properties","link":"/website-hexo-icarus/tags/properties/"},{"name":"Session","slug":"Session","link":"/website-hexo-icarus/tags/Session/"},{"name":"Spring Security","slug":"Spring-Security","link":"/website-hexo-icarus/tags/Spring-Security/"},{"name":"Starter","slug":"Starter","link":"/website-hexo-icarus/tags/Starter/"},{"name":"静态资源","slug":"静态资源","link":"/website-hexo-icarus/tags/%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90/"},{"name":"单元测试","slug":"单元测试","link":"/website-hexo-icarus/tags/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"},{"name":"yaml","slug":"yaml","link":"/website-hexo-icarus/tags/yaml/"},{"name":"Thymeleaf","slug":"Thymeleaf","link":"/website-hexo-icarus/tags/Thymeleaf/"},{"name":"Spring Cloud","slug":"Spring-Cloud","link":"/website-hexo-icarus/tags/Spring-Cloud/"},{"name":"Sentinel","slug":"Sentinel","link":"/website-hexo-icarus/tags/Sentinel/"},{"name":"Bus","slug":"Bus","link":"/website-hexo-icarus/tags/Bus/"},{"name":"Eureka","slug":"Eureka","link":"/website-hexo-icarus/tags/Eureka/"},{"name":"IDE","slug":"IDE","link":"/website-hexo-icarus/tags/IDE/"},{"name":"Eclipse","slug":"Eclipse","link":"/website-hexo-icarus/tags/Eclipse/"},{"name":"插件","slug":"插件","link":"/website-hexo-icarus/tags/%E6%8F%92%E4%BB%B6/"},{"name":"Git","slug":"Git","link":"/website-hexo-icarus/tags/Git/"},{"name":"SSH","slug":"SSH","link":"/website-hexo-icarus/tags/SSH/"},{"name":"IntelliJ IDEA","slug":"IntelliJ-IDEA","link":"/website-hexo-icarus/tags/IntelliJ-IDEA/"},{"name":"快捷键","slug":"快捷键","link":"/website-hexo-icarus/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"name":"EasyCode","slug":"EasyCode","link":"/website-hexo-icarus/tags/EasyCode/"},{"name":"配置","slug":"配置","link":"/website-hexo-icarus/tags/%E9%85%8D%E7%BD%AE/"},{"name":"Maven","slug":"Maven","link":"/website-hexo-icarus/tags/Maven/"},{"name":"Sublime","slug":"Sublime","link":"/website-hexo-icarus/tags/Sublime/"},{"name":"SVN","slug":"SVN","link":"/website-hexo-icarus/tags/SVN/"},{"name":"mydumper","slug":"mydumper","link":"/website-hexo-icarus/tags/mydumper/"},{"name":"binlog","slug":"binlog","link":"/website-hexo-icarus/tags/binlog/"},{"name":"优化","slug":"优化","link":"/website-hexo-icarus/tags/%E4%BC%98%E5%8C%96/"},{"name":"函数","slug":"函数","link":"/website-hexo-icarus/tags/%E5%87%BD%E6%95%B0/"},{"name":"主从","slug":"主从","link":"/website-hexo-icarus/tags/%E4%B8%BB%E4%BB%8E/"},{"name":"分区表","slug":"分区表","link":"/website-hexo-icarus/tags/%E5%88%86%E5%8C%BA%E8%A1%A8/"},{"name":"canal","slug":"canal","link":"/website-hexo-icarus/tags/canal/"},{"name":"Elasticsearch","slug":"Elasticsearch","link":"/website-hexo-icarus/tags/Elasticsearch/"},{"name":"ES","slug":"ES","link":"/website-hexo-icarus/tags/ES/"},{"name":"Mycat","slug":"Mycat","link":"/website-hexo-icarus/tags/Mycat/"},{"name":"AWStats","slug":"AWStats","link":"/website-hexo-icarus/tags/AWStats/"},{"name":"PSI Probe","slug":"PSI-Probe","link":"/website-hexo-icarus/tags/PSI-Probe/"},{"name":"DevTools","slug":"DevTools","link":"/website-hexo-icarus/tags/DevTools/"},{"name":"LiveReload","slug":"LiveReload","link":"/website-hexo-icarus/tags/LiveReload/"},{"name":"Freemarker","slug":"Freemarker","link":"/website-hexo-icarus/tags/Freemarker/"},{"name":"Rest","slug":"Rest","link":"/website-hexo-icarus/tags/Rest/"},{"name":"JSON","slug":"JSON","link":"/website-hexo-icarus/tags/JSON/"},{"name":"TkMybatis","slug":"TkMybatis","link":"/website-hexo-icarus/tags/TkMybatis/"},{"name":"幂等","slug":"幂等","link":"/website-hexo-icarus/tags/%E5%B9%82%E7%AD%89/"},{"name":"Shiro","slug":"Shiro","link":"/website-hexo-icarus/tags/Shiro/"},{"name":"Spring Cache","slug":"Spring-Cache","link":"/website-hexo-icarus/tags/Spring-Cache/"},{"name":"Ehcache","slug":"Ehcache","link":"/website-hexo-icarus/tags/Ehcache/"},{"name":"OAuth2","slug":"OAuth2","link":"/website-hexo-icarus/tags/OAuth2/"},{"name":"Swagger2","slug":"Swagger2","link":"/website-hexo-icarus/tags/Swagger2/"},{"name":"Nacos","slug":"Nacos","link":"/website-hexo-icarus/tags/Nacos/"},{"name":"Consul","slug":"Consul","link":"/website-hexo-icarus/tags/Consul/"},{"name":"Gateway","slug":"Gateway","link":"/website-hexo-icarus/tags/Gateway/"},{"name":"Zuul","slug":"Zuul","link":"/website-hexo-icarus/tags/Zuul/"},{"name":"RestTemplate","slug":"RestTemplate","link":"/website-hexo-icarus/tags/RestTemplate/"},{"name":"Sleuth","slug":"Sleuth","link":"/website-hexo-icarus/tags/Sleuth/"},{"name":"Stream","slug":"Stream","link":"/website-hexo-icarus/tags/Stream/"},{"name":"Hexo","slug":"Hexo","link":"/website-hexo-icarus/tags/Hexo/"},{"name":"Icarus","slug":"Icarus","link":"/website-hexo-icarus/tags/Icarus/"},{"name":"博客","slug":"博客","link":"/website-hexo-icarus/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"Markdown","slug":"Markdown","link":"/website-hexo-icarus/tags/Markdown/"},{"name":"mysqldump","slug":"mysqldump","link":"/website-hexo-icarus/tags/mysqldump/"},{"name":"JWT","slug":"JWT","link":"/website-hexo-icarus/tags/JWT/"},{"name":"Config","slug":"Config","link":"/website-hexo-icarus/tags/Config/"},{"name":"OpenFeign","slug":"OpenFeign","link":"/website-hexo-icarus/tags/OpenFeign/"},{"name":"Resilience4j","slug":"Resilience4j","link":"/website-hexo-icarus/tags/Resilience4j/"},{"name":"NexT","slug":"NexT","link":"/website-hexo-icarus/tags/NexT/"},{"name":"Elastic","slug":"Elastic","link":"/website-hexo-icarus/tags/Elastic/"},{"name":"Hystrix","slug":"Hystrix","link":"/website-hexo-icarus/tags/Hystrix/"}],"categories":[{"name":"HR","slug":"HR","link":"/website-hexo-icarus/categories/HR/"},{"name":"Linux","slug":"Linux","link":"/website-hexo-icarus/categories/Linux/"},{"name":"MySQL","slug":"MySQL","link":"/website-hexo-icarus/categories/MySQL/"},{"name":"Nginx","slug":"Nginx","link":"/website-hexo-icarus/categories/Nginx/"},{"name":"Apache","slug":"Apache","link":"/website-hexo-icarus/categories/Apache/"},{"name":"JVM","slug":"JVM","link":"/website-hexo-icarus/categories/JVM/"},{"name":"MyBatis","slug":"MyBatis","link":"/website-hexo-icarus/categories/MyBatis/"},{"name":"POI","slug":"POI","link":"/website-hexo-icarus/categories/POI/"},{"name":"PowerJob","slug":"PowerJob","link":"/website-hexo-icarus/categories/PowerJob/"},{"name":"Tomcat","slug":"Tomcat","link":"/website-hexo-icarus/categories/Tomcat/"},{"name":"Redis","slug":"Redis","link":"/website-hexo-icarus/categories/Redis/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/website-hexo-icarus/categories/Spring-Boot/"},{"name":"Spring Cloud","slug":"Spring-Cloud","link":"/website-hexo-icarus/categories/Spring-Cloud/"},{"name":"IDE","slug":"IDE","link":"/website-hexo-icarus/categories/IDE/"},{"name":"Git","slug":"Git","link":"/website-hexo-icarus/categories/Git/"},{"name":"Maven","slug":"Maven","link":"/website-hexo-icarus/categories/Maven/"},{"name":"SVN","slug":"SVN","link":"/website-hexo-icarus/categories/SVN/"},{"name":"canal","slug":"canal","link":"/website-hexo-icarus/categories/canal/"},{"name":"工具","slug":"工具","link":"/website-hexo-icarus/categories/%E5%B7%A5%E5%85%B7/"},{"name":"Mycat","slug":"Mycat","link":"/website-hexo-icarus/categories/Mycat/"},{"name":"Hexo","slug":"Hexo","link":"/website-hexo-icarus/categories/Hexo/"},{"name":"Markdown","slug":"Markdown","link":"/website-hexo-icarus/categories/Markdown/"},{"name":"Elasticsearch","slug":"Elasticsearch","link":"/website-hexo-icarus/categories/Elasticsearch/"}]}